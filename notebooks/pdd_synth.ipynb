{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11f2619",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/miniconda3/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xarray as xr\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torchmetrics.utilities.checks import _check_same_shape\n",
    "from torchmetrics import Metric\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim.lr_scheduler import ExponentialLR, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from pismemulator.metrics import AbsoluteError, absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d882c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDDEmulator(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_parameters: int,\n",
    "        n_outputs: int,\n",
    "        hparams,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(hparams)\n",
    "        n_layers = self.hparams.n_layers\n",
    "        n_hidden = self.hparams.n_hidden\n",
    "\n",
    "        if isinstance(n_hidden, int):\n",
    "            n_hidden = [n_hidden] * (n_layers - 1)\n",
    "\n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.l_first = nn.Linear(n_parameters, n_hidden[0])\n",
    "        self.norm_first = nn.LayerNorm(n_hidden[0])\n",
    "        self.dropout_first = nn.Dropout(p=0.0)\n",
    "\n",
    "        models = []\n",
    "        for n in range(n_layers - 2):\n",
    "            models.append(\n",
    "                nn.Sequential(\n",
    "                    OrderedDict(\n",
    "                        [\n",
    "                            (\"Linear\", nn.Linear(n_hidden[n], n_hidden[n + 1])),\n",
    "                            (\"LayerNorm\", nn.LayerNorm(n_hidden[n + 1])),\n",
    "                            (\"Dropout\", nn.Dropout(p=0.1)),\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        self.dnn = nn.ModuleList(models)\n",
    "        self.l_last = nn.Linear(n_hidden[-1], n_outputs)\n",
    "\n",
    "        self.train_ae = AbsoluteError()\n",
    "        self.test_ae = AbsoluteError()\n",
    "\n",
    "    def forward(self, x, add_mean=False):\n",
    "        # Pass the input tensor through each of our operations\n",
    "\n",
    "        a = self.l_first(x)\n",
    "        a = self.norm_first(a)\n",
    "        a = self.dropout_first(a)\n",
    "        z = torch.relu(a)\n",
    "\n",
    "        for dnn in self.dnn:\n",
    "            a = dnn(z)\n",
    "            z = torch.relu(a) + z\n",
    "\n",
    "        return self.l_last(z)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = parent_parser.add_argument_group(\"NNEmulator\")\n",
    "        parser.add_argument(\"--batch_size\", type=int, default=128)\n",
    "        parser.add_argument(\"--n_hidden\", default=128)\n",
    "        parser.add_argument(\"--learning_rate\", type=float, default=0.1)\n",
    "\n",
    "        return parent_parser\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(), self.hparams.learning_rate, weight_decay=0.0\n",
    "        )\n",
    "        # This is an approximation to Doug's version:\n",
    "        scheduler = {\n",
    "            \"scheduler\": ExponentialLR(optimizer, 0.9975, verbose=True),\n",
    "        }\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, f, o, _ = batch\n",
    "        f_pred = self.forward(x)\n",
    "        loss = absolute_error(f_pred, f, o)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, f, o, o_0 = batch\n",
    "        f_pred = self.forward(x)\n",
    "\n",
    "        self.log(\"train_loss\", self.train_ae(f_pred, f, o))\n",
    "        self.log(\"test_loss\", self.test_ae(f_pred, f, o_0))\n",
    "\n",
    "        return {\"x\": x, \"f\": f, \"f_pred\": f_pred, \"o\": o, \"o_0\": o_0}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            self.train_ae,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        self.log(\n",
    "            \"test_loss\",\n",
    "            self.test_ae,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83bc210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchPDDModel(torch.nn.modules.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    # Copyright (c) 2013--2018, Julien Seguinot <seguinot@vaw.baug.ethz.ch>\n",
    "    # GNU General Public License v3.0+ (https://www.gnu.org/licenses/gpl-3.0.txt)\n",
    "\n",
    "    A positive degree day model for glacier surface mass balance\n",
    "\n",
    "    Return a callable Positive Degree Day (PDD) model instance.\n",
    "\n",
    "    Model parameters are held as public attributes, and can be set using\n",
    "    corresponding keyword arguments at initialization time:\n",
    "\n",
    "    *pdd_factor_snow* : float\n",
    "        Positive degree-day factor for snow.\n",
    "    *pdd_factor_ice* : float\n",
    "        Positive degree-day factor for ice.\n",
    "    *refreeze_snow* : float\n",
    "        Refreezing fraction of melted snow.\n",
    "    *refreeze_ice* : float\n",
    "        Refreezing fraction of melted ice.\n",
    "    *temp_snow* : float\n",
    "        Temperature at which all precipitation falls as snow.\n",
    "    *temp_rain* : float\n",
    "        Temperature at which all precipitation falls as rain.\n",
    "    *interpolate_rule* : [ 'linear' | 'nearest' | 'zero' |\n",
    "                           'slinear' | 'quadratic' | 'cubic' ]\n",
    "        Interpolation rule passed to `scipy.interpolate.interp1d`.\n",
    "    *interpolate_n*: int\n",
    "        Number of points used in interpolations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        pdd_factor_snow=3,\n",
    "        pdd_factor_ice=8,\n",
    "        refreeze_snow=0.0,\n",
    "        refreeze_ice=0.0,\n",
    "        temp_snow=0.0,\n",
    "        temp_rain=2.0,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # set pdd model parameters\n",
    "        self.pdd_factor_snow = pdd_factor_snow\n",
    "        self.pdd_factor_ice = pdd_factor_ice\n",
    "        self.refreeze_snow = refreeze_snow\n",
    "        self.refreeze_ice = refreeze_ice\n",
    "        self.temp_snow = temp_snow\n",
    "        self.temp_rain = temp_rain\n",
    "\n",
    "    def forward(self, temp, prec):\n",
    "        \"\"\"Run the positive degree day model.\n",
    "\n",
    "        Use temperature, precipitation, and standard deviation of temperature\n",
    "        to compute the number of positive degree days, accumulation and melt\n",
    "        surface mass fluxes, and the resulting surface mass balance.\n",
    "\n",
    "        *temp*: array_like\n",
    "            Input near-surface air temperature in degrees Celcius.\n",
    "        *prec*: array_like\n",
    "            Input precipitation rate in meter per year.\n",
    "        \"\"\"\n",
    "\n",
    "        # ensure numpy arrays\n",
    "        temp = torch.asarray(temp)\n",
    "        prec = torch.asarray(prec)\n",
    "\n",
    "        # compute accumulation and pdd\n",
    "        accu_rate = self.accu_rate(temp, prec)\n",
    "        inst_pdd = self.inst_pdd(temp)\n",
    "\n",
    "        # initialize snow depth, melt and refreeze rates\n",
    "        snow_depth = torch.zeros_like(temp)\n",
    "        snow_melt_rate = torch.zeros_like(temp)\n",
    "        ice_melt_rate = torch.zeros_like(temp)\n",
    "        snow_refreeze_rate = torch.zeros_like(temp)\n",
    "        ice_refreeze_rate = torch.zeros_like(temp)\n",
    "\n",
    "        # snow_depth[:-1] = torch.clone(snow_depth[1:])\n",
    "        snow_depth = snow_depth + accu_rate\n",
    "        snow_melt_rate, ice_melt_rate = self.melt_rates(snow_depth, inst_pdd)\n",
    "        snow_depth = snow_depth - snow_melt_rate\n",
    "\n",
    "        melt_rate = snow_melt_rate + ice_melt_rate\n",
    "        snow_refreeze_rate = self.refreeze_snow * snow_melt_rate\n",
    "        ice_refreeze_rate = self.refreeze_ice * ice_melt_rate\n",
    "        refreeze_rate = snow_refreeze_rate + ice_refreeze_rate\n",
    "        runoff_rate = melt_rate - refreeze_rate\n",
    "        inst_smb = accu_rate - runoff_rate\n",
    "\n",
    "        # output\n",
    "        return {\n",
    "            \"temp\": temp,\n",
    "            \"prec\": prec,\n",
    "            \"pdds\": inst_pdd,\n",
    "            \"accu_rate\": accu_rate,\n",
    "            \"snow_melt_rate\": snow_melt_rate,\n",
    "            \"ice_melt_rate\": ice_melt_rate,\n",
    "            \"melt_rate\": melt_rate,\n",
    "            \"snow_refreeze_rate\": snow_refreeze_rate,\n",
    "            \"ice_refreeze_rate\": ice_refreeze_rate,\n",
    "            \"refreeze_rate\": refreeze_rate,\n",
    "            \"runoff_rate\": runoff_rate,\n",
    "            \"smb_rate\": inst_smb,\n",
    "            \"snow_depth\": snow_depth,\n",
    "        }\n",
    "\n",
    "\n",
    "    def inst_pdd(self, temp):\n",
    "        \"\"\"Compute instantaneous positive degree days from temperature.\n",
    "\n",
    "        Use near-surface air temperature to compute\n",
    "        positive degree days (effective temperature for melt,\n",
    "        unit degrees C).\n",
    "\n",
    "        *temp*: array_like\n",
    "            Near-surface air temperature in degrees Celcius.\n",
    "        \"\"\"\n",
    "\n",
    "        # compute positive part of temperature everywhere\n",
    "        pdd = torch.greater(temp, 0) * temp\n",
    "\n",
    "        # convert to degree-days\n",
    "        return pdd\n",
    "\n",
    "    def accu_rate(self, temp, prec):\n",
    "        \"\"\"Compute accumulation rate from temperature and precipitation.\n",
    "\n",
    "        The fraction of precipitation that falls as snow decreases linearly\n",
    "        from one to zero between temperature thresholds defined by the\n",
    "        `temp_snow` and `temp_rain` attributes.\n",
    "\n",
    "        *temp*: array_like\n",
    "            Near-surface air temperature in degrees Celcius.\n",
    "        *prec*: array_like\n",
    "            Precipitation rate in meter per year.\n",
    "        \"\"\"\n",
    "\n",
    "        # compute snow fraction as a function of temperature\n",
    "        reduced_temp = (self.temp_rain - temp) / (self.temp_rain - self.temp_snow)\n",
    "        snowfrac = torch.clip(reduced_temp, 0, 1)\n",
    "\n",
    "        # return accumulation rate\n",
    "        return snowfrac * prec\n",
    "\n",
    "    def melt_rates(self, snow, pdd):\n",
    "        \"\"\"Compute melt rates from snow precipitation and pdd sum.\n",
    "\n",
    "        Snow melt is computed from the number of positive degree days (*pdd*)\n",
    "        and the `pdd_factor_snow` model attribute. If all snow is melted and\n",
    "        some energy (PDD) remains, ice melt is computed using `pdd_factor_ice`.\n",
    "\n",
    "        *snow*: array_like\n",
    "            Snow precipitation rate.\n",
    "        *pdd*: array_like\n",
    "            Number of positive degree days.\n",
    "        \"\"\"\n",
    "\n",
    "        # parse model parameters for readability\n",
    "        ddf_snow = self.pdd_factor_snow / 1e3\n",
    "        ddf_ice = self.pdd_factor_ice / 1e3\n",
    "\n",
    "        # compute a potential snow melt\n",
    "        pot_snow_melt = ddf_snow * pdd\n",
    "\n",
    "        # effective snow melt can't exceed amount of snow\n",
    "        snow_melt = torch.minimum(snow, pot_snow_melt)\n",
    "\n",
    "        # ice melt is proportional to excess snow melt\n",
    "        ice_melt = (pot_snow_melt - snow_melt) * ddf_ice / ddf_snow\n",
    "\n",
    "        # return melt rates\n",
    "        return (snow_melt, ice_melt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0859e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.sample import saltelli\n",
    "from pyDOE import lhs\n",
    "from scipy.stats.distributions import truncnorm, gamma, uniform, randint\n",
    "method = \"lhs\"\n",
    "n_prior_samples = 10000\n",
    "np.random.seed(2)\n",
    "\n",
    "distributions = {\n",
    "    \"T\": uniform(loc=-20, scale=40),\n",
    "    \"P\": uniform(loc=0, scale=1), \n",
    "    \"f_snow\": uniform(\n",
    "        loc=2.0, scale=4.0\n",
    "    ),  # uniform between 2 and 6\n",
    "    \"f_ice\": uniform(\n",
    "        loc=3.0, scale=9\n",
    "    ),  # uniform between 3 and 12\n",
    "    \"refreeze\": uniform(loc=0, scale=1.0),  # uniform between 0 and 1\n",
    "}\n",
    "# Names of all the variables\n",
    "keys = [x for x in distributions.keys()]\n",
    "\n",
    "# Describe the Problem\n",
    "problem = {\"num_vars\": len(keys), \"names\": keys, \"bounds\": [[0, 1]] * len(keys)}\n",
    "\n",
    "# Generate uniform samples (i.e. one unit hypercube)\n",
    "if method == \"saltelli\":\n",
    "    unif_sample = saltelli.sample(problem, n_prior_samples, calc_second_order=False)\n",
    "elif method == \"lhs\":\n",
    "    unif_sample = lhs(len(keys), n_prior_samples)\n",
    "else:\n",
    "    print(f\"Method {method} not available\")\n",
    "\n",
    "# To hold the transformed variables\n",
    "dist_sample = np.zeros_like(unif_sample)\n",
    "\n",
    "# Now transform the unit hypercube to the prescribed distributions\n",
    "# For each variable, transform with the inverse of the CDF (inv(CDF)=ppf)\n",
    "for i, key in enumerate(keys):\n",
    "    dist_sample[:, i] = distributions[key].ppf(unif_sample[:, i])\n",
    "\n",
    "# Save to CSV file using Pandas DataFrame and to_csv method\n",
    "header = keys\n",
    "# Convert to Pandas dataframe, append column headers, output as csv\n",
    "df = pd.DataFrame(data=dist_sample, columns=header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52677e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    X = []\n",
    "    Y = []\n",
    "    for k, row in df.iterrows():   \n",
    "        m_f_snow = row[\"f_snow\"]\n",
    "        m_f_ice = row[\"f_ice\"]\n",
    "        m_refreeze = row[\"refreeze\"]\n",
    "        m_T = np.copy(row[\"T\"])\n",
    "        m_P = np.copy(row[\"P\"])\n",
    "\n",
    "        pdd = TorchPDDModel(\n",
    "            pdd_factor_snow=m_f_snow,\n",
    "            pdd_factor_ice=m_f_ice,\n",
    "            refreeze_snow=m_refreeze,\n",
    "            refreeze_ice=m_refreeze,\n",
    "        )\n",
    "        result = pdd(m_T, m_P)\n",
    "\n",
    "        M_train = result[\"melt_rate\"]\n",
    "        A_train = result[\"accu_rate\"]\n",
    "        R_train = result[\"refreeze_rate\"]\n",
    "        B_train = result[\"smb_rate\"]\n",
    "        m_Y = torch.vstack((M_train, A_train, R_train,)).T\n",
    "        Y.append(m_Y)\n",
    "        X.append(torch.from_numpy(np.hstack((m_P, m_T, m_f_snow, m_f_ice, m_refreeze))))\n",
    "\n",
    "    X_train = torch.vstack(X).type(torch.FloatTensor)\n",
    "    Y_train = torch.vstack(Y).type(torch.FloatTensor)\n",
    "    n_samples, n_parameters = X_train.shape\n",
    "    n_outputs = Y_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2a45752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "X_train_mean = X_train.mean(axis=0)\n",
    "X_train_std = X_train.std(axis=0)\n",
    "X_train_norm = (X_train - X_train_mean) / X_train_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99141a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7319)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_norm.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e2e05bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 5]) torch.Size([10000, 3])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "237942c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "    import os\n",
    "    from scipy.stats import dirichlet\n",
    "\n",
    "    model_index = 0\n",
    "    torch.manual_seed(0)\n",
    "    pl.seed_everything(0)\n",
    "    np.random.seed(model_index)\n",
    "    emulator_dir = \"pddemulator\"\n",
    "\n",
    "    if not os.path.isdir(emulator_dir):\n",
    "        os.makedirs(emulator_dir)\n",
    "        os.makedirs(os.path.join(emulator_dir, \"emulator\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f4d63d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2021 Andy Aschwanden, Douglas C Brinkerhoff\n",
    "#\n",
    "# This file is part of pism-emulator.\n",
    "#\n",
    "# PISM-EMULATOR is free software; you can redistribute it and/or modify it under the\n",
    "# terms of the GNU General Public License as published by the Free Software\n",
    "# Foundation; either version 3 of the License, or (at your option) any later\n",
    "# version.\n",
    "#\n",
    "# PISM-EMULATOR is distributed in the hope that it will be useful, but WITHOUT ANY\n",
    "# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n",
    "# FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n",
    "# details.\n",
    "#\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with PISM; if not, write to the Free Software\n",
    "# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torchmetrics.utilities.checks import _check_same_shape\n",
    "from torchmetrics import Metric\n",
    "\n",
    "\n",
    "def _absolute_error_update(\n",
    "    preds: Tensor, target: Tensor, omegas: Tensor) -> Tensor:\n",
    "    _check_same_shape(preds, target)\n",
    "    diff = torch.abs(preds - target)\n",
    "    sum_abs_error = torch.sum(diff * diff, axis=1)\n",
    "    absolute_error = torch.sum(sum_abs_error * omegas.squeeze())\n",
    "    return absolute_error\n",
    "\n",
    "\n",
    "def _absolute_error_compute(absolute_error) -> Tensor:\n",
    "    return absolute_error\n",
    "\n",
    "\n",
    "def absolute_error(\n",
    "    preds: Tensor, target: Tensor, omegas: Tensor\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Computes squared absolute error\n",
    "    Args:\n",
    "        preds: estimated labels\n",
    "        target: ground truth labels\n",
    "        omegas: weights\n",
    "        area: area of each cell\n",
    "    Return:\n",
    "        Tensor with absolute error\n",
    "    Example:\n",
    "        >>> x = torch.tensor([[0, 1, 2, 3], [1, 2, 3, 4]]).T\n",
    "        >>> y = torch.tensor([[0, 1, 2, 1], [2, 3, 4, 4]]).T\n",
    "        >>> o = torch.tensor([0.25, 0.25, 0.3, 0.2])\n",
    "        >>> a = torch.tensor([0.25, 0.25])\n",
    "        >>> absolute_error(x, y, o, a)\n",
    "        tensor(0.4000)\n",
    "    \"\"\"\n",
    "    sum_abs_error = _absolute_error_update(preds, target, omegas)\n",
    "    return _absolute_error_compute(sum_abs_error)\n",
    "\n",
    "\n",
    "class AbsoluteError(Metric):\n",
    "    def __init__(self, compute_on_step: bool = True, dist_sync_on_step=False):\n",
    "        # call `self.add_state`for every internal state that is needed for the metrics computations\n",
    "        # dist_reduce_fx indicates the function that should be used to reduce\n",
    "        # state from multiple processes\n",
    "        super().__init__(\n",
    "            compute_on_step=compute_on_step, dist_sync_on_step=dist_sync_on_step\n",
    "        )\n",
    "\n",
    "        self.add_state(\"sum_abs_error\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: Tensor, target: Tensor, omegas: Tensor):\n",
    "        \"\"\"\n",
    "        Update state with predictions and targets, and area.\n",
    "        Args:\n",
    "            preds: Predictions from model\n",
    "            target: Ground truth values\n",
    "            omegas: Weights\n",
    "            area: Area of each cell\n",
    "        \"\"\"\n",
    "        sum_abs_error = _absolute_error_update(preds, target, omegas)\n",
    "        self.sum_abs_error += sum_abs_error\n",
    "\n",
    "    def compute(self):\n",
    "        \"\"\"\n",
    "        Computes absolute error over state.\n",
    "        \"\"\"\n",
    "        return _absolute_error_compute(self.sum_abs_error)\n",
    "\n",
    "    @property\n",
    "    def is_differentiable(self):\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05a2f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDDDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        X,\n",
    "        Y,\n",
    "        omegas,\n",
    "        omegas_0,\n",
    "        batch_size: int = 128,\n",
    "        train_size: float = 0.9,\n",
    "        num_workers: int = 0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.omegas = omegas\n",
    "        self.omegas_0 = omegas_0\n",
    "        self.batch_size = batch_size\n",
    "        self.train_size = train_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage: str = None):\n",
    "\n",
    "        all_data = TensorDataset(self.X, self.Y, self.omegas, self.omegas_0)\n",
    "        self.all_data = all_data\n",
    "\n",
    "        training_data, val_data = train_test_split(\n",
    "            all_data, train_size=self.train_size, random_state=0\n",
    "        )\n",
    "        self.training_data = training_data\n",
    "        self.test_data = training_data\n",
    "\n",
    "        self.val_data = val_data\n",
    "        train_all_loader = DataLoader(\n",
    "            dataset=all_data,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        self.train_all_loader = train_all_loader\n",
    "        val_all_loader = DataLoader(\n",
    "            dataset=all_data,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        self.val_all_loader = val_all_loader\n",
    "        train_loader = DataLoader(\n",
    "            dataset=training_data,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = train_loader\n",
    "        val_loader = DataLoader(\n",
    "            dataset=val_data,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "    def prepare_data(self, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.train_loader\n",
    "\n",
    "    def validation_dataloader(self):\n",
    "        return self.val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64b35190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | l_first       | Linear        | 768   \n",
      "1 | norm_first    | LayerNorm     | 256   \n",
      "2 | dropout_first | Dropout       | 0     \n",
      "3 | dnn           | ModuleList    | 50.3 K\n",
      "4 | l_last        | Linear        | 387   \n",
      "5 | train_ae      | AbsoluteError | 0     \n",
      "6 | test_ae       | AbsoluteError | 0     \n",
      "------------------------------------------------\n",
      "51.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "51.7 K    Total params\n",
      "0.207     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch 0:  49%|███████████████████████████████████████▉                                         | 78/158 [00:01<00:01, 57.29it/s, loss=0.000939, v_num=23]Adjusting learning rate of group 0 to 9.9750e-03.\n",
      "Epoch 0:  50%|████████████████████████████████████████▌                                        | 79/158 [00:01<00:01, 56.39it/s, loss=0.000871, v_num=23]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  56%|█████████████████████████████████████████████                                    | 88/158 [00:01<00:01, 54.34it/s, loss=0.000871, v_num=23]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████████████████████| 158/158 [00:01<00:00, 87.39it/s, loss=0.000871, v_num=23, train_loss=0.0257, test_loss=0.0255]\u001b[A\n",
      "Epoch 1:  49%|█████████████████████▏                     | 78/158 [00:00<00:00, 149.42it/s, loss=0.000527, v_num=23, train_loss=0.0257, test_loss=0.0255]\u001b[AAdjusting learning rate of group 0 to 9.9501e-03.\n",
      "Epoch 1:  50%|█████████████████████▌                     | 79/158 [00:00<00:00, 139.03it/s, loss=0.000493, v_num=23, train_loss=0.0257, test_loss=0.0255]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  61%|██████████████████████████▏                | 96/158 [00:00<00:00, 124.51it/s, loss=0.000493, v_num=23, train_loss=0.0257, test_loss=0.0255]\u001b[A\n",
      "Epoch 1: 100%|██████████████████████████████████████████| 158/158 [00:00<00:00, 171.58it/s, loss=0.000493, v_num=23, train_loss=0.0268, test_loss=0.0268]\u001b[A\n",
      "Epoch 2:  49%|█████████████████████▋                      | 78/158 [00:00<00:00, 149.57it/s, loss=0.00042, v_num=23, train_loss=0.0268, test_loss=0.0268]\u001b[AAdjusting learning rate of group 0 to 9.9252e-03.\n",
      "Epoch 2:  50%|█████████████████████▌                     | 79/158 [00:00<00:00, 139.47it/s, loss=0.000397, v_num=23, train_loss=0.0268, test_loss=0.0268]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  67%|████████████████████████████▏             | 106/158 [00:00<00:00, 132.08it/s, loss=0.000397, v_num=23, train_loss=0.0268, test_loss=0.0268]\u001b[A\n",
      "Epoch 2: 100%|███████████████████████████████████████████| 158/158 [00:00<00:00, 167.60it/s, loss=0.000397, v_num=23, train_loss=0.030, test_loss=0.0301]\u001b[A\n",
      "Epoch 3:  49%|█████████████████████▋                      | 78/158 [00:00<00:00, 149.07it/s, loss=0.000268, v_num=23, train_loss=0.030, test_loss=0.0301]\u001b[AAdjusting learning rate of group 0 to 9.9004e-03.\n",
      "Epoch 3:  50%|██████████████████████                      | 79/158 [00:00<00:00, 141.32it/s, loss=0.000254, v_num=23, train_loss=0.030, test_loss=0.0301]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  67%|████████████████████████████▊              | 106/158 [00:00<00:00, 133.21it/s, loss=0.000254, v_num=23, train_loss=0.030, test_loss=0.0301]\u001b[A\n",
      "Epoch 3: 100%|██████████████████████████████████████████| 158/158 [00:00<00:00, 168.07it/s, loss=0.000254, v_num=23, train_loss=0.0138, test_loss=0.0139]\u001b[A\n",
      "Epoch 4:  49%|█████████████████████▏                     | 78/158 [00:00<00:00, 149.62it/s, loss=0.000187, v_num=23, train_loss=0.0138, test_loss=0.0139]\u001b[AAdjusting learning rate of group 0 to 9.8756e-03.\n",
      "Epoch 4:  50%|█████████████████████▌                     | 79/158 [00:00<00:00, 139.78it/s, loss=0.000177, v_num=23, train_loss=0.0138, test_loss=0.0139]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  67%|████████████████████████████▏             | 106/158 [00:00<00:00, 133.12it/s, loss=0.000177, v_num=23, train_loss=0.0138, test_loss=0.0139]\u001b[A\n",
      "Epoch 4: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 168.36it/s, loss=0.000177, v_num=23, train_loss=0.00904, test_loss=0.0091]\u001b[A\n",
      "Epoch 5:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 149.79it/s, loss=0.000169, v_num=23, train_loss=0.00904, test_loss=0.0091]\u001b[AAdjusting learning rate of group 0 to 9.8509e-03.\n",
      "Epoch 5:  50%|█████████████████████                     | 79/158 [00:00<00:00, 139.53it/s, loss=0.000162, v_num=23, train_loss=0.00904, test_loss=0.0091]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 132.19it/s, loss=0.000162, v_num=23, train_loss=0.00904, test_loss=0.0091]\u001b[A\n",
      "Epoch 5: 100%|██████████████████████████████████████████| 158/158 [00:00<00:00, 167.40it/s, loss=0.000162, v_num=23, train_loss=0.0121, test_loss=0.0123]\u001b[A\n",
      "Epoch 6:  49%|█████████████████████▏                     | 78/158 [00:00<00:00, 148.57it/s, loss=9.96e-05, v_num=23, train_loss=0.0121, test_loss=0.0123]\u001b[AAdjusting learning rate of group 0 to 9.8263e-03.\n",
      "Epoch 6:  50%|█████████████████████▌                     | 79/158 [00:00<00:00, 138.10it/s, loss=9.44e-05, v_num=23, train_loss=0.0121, test_loss=0.0123]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  67%|████████████████████████████▏             | 106/158 [00:00<00:00, 132.73it/s, loss=9.44e-05, v_num=23, train_loss=0.0121, test_loss=0.0123]\u001b[A\n",
      "Epoch 6: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 167.37it/s, loss=9.44e-05, v_num=23, train_loss=0.00586, test_loss=0.00592]\u001b[A\n",
      "Epoch 7:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 149.05it/s, loss=8.16e-05, v_num=23, train_loss=0.00586, test_loss=0.00592]\u001b[AAdjusting learning rate of group 0 to 9.8017e-03.\n",
      "Epoch 7:  50%|█████████████████████                     | 79/158 [00:00<00:00, 138.28it/s, loss=7.8e-05, v_num=23, train_loss=0.00586, test_loss=0.00592]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 132.28it/s, loss=7.8e-05, v_num=23, train_loss=0.00586, test_loss=0.00592]\u001b[A\n",
      "Epoch 7: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 167.56it/s, loss=7.8e-05, v_num=23, train_loss=0.00397, test_loss=0.00395]\u001b[A\n",
      "Epoch 8:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 149.22it/s, loss=7.02e-05, v_num=23, train_loss=0.00397, test_loss=0.00395]\u001b[AAdjusting learning rate of group 0 to 9.7772e-03.\n",
      "Epoch 8:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 141.30it/s, loss=6.71e-05, v_num=23, train_loss=0.00397, test_loss=0.00395]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 133.76it/s, loss=6.71e-05, v_num=23, train_loss=0.00397, test_loss=0.00395]\u001b[A\n",
      "Epoch 8: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 170.04it/s, loss=6.71e-05, v_num=23, train_loss=0.00347, test_loss=0.0035]\u001b[A\n",
      "Epoch 9:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 149.48it/s, loss=5.69e-05, v_num=23, train_loss=0.00347, test_loss=0.0035]\u001b[AAdjusting learning rate of group 0 to 9.7528e-03.\n",
      "Epoch 9:  50%|█████████████████████                     | 79/158 [00:00<00:00, 138.60it/s, loss=5.44e-05, v_num=23, train_loss=0.00347, test_loss=0.0035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 130.75it/s, loss=5.44e-05, v_num=23, train_loss=0.00347, test_loss=0.0035]\u001b[A\n",
      "Epoch 9: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 165.74it/s, loss=5.44e-05, v_num=23, train_loss=0.00861, test_loss=0.00862]\u001b[A\n",
      "Epoch 10:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.69it/s, loss=5.37e-05, v_num=23, train_loss=0.00861, test_loss=0.00862]\u001b[AAdjusting learning rate of group 0 to 9.7284e-03.\n",
      "Epoch 10:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.20it/s, loss=5.11e-05, v_num=23, train_loss=0.00861, test_loss=0.00862]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 129.97it/s, loss=5.11e-05, v_num=23, train_loss=0.00861, test_loss=0.00862]\u001b[A\n",
      "Epoch 10: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 166.83it/s, loss=5.11e-05, v_num=23, train_loss=0.0032, test_loss=0.00325]\u001b[A\n",
      "Epoch 11:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.87it/s, loss=4.84e-05, v_num=23, train_loss=0.0032, test_loss=0.00325]\u001b[AAdjusting learning rate of group 0 to 9.7041e-03.\n",
      "Epoch 11:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 138.56it/s, loss=4.65e-05, v_num=23, train_loss=0.0032, test_loss=0.00325]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 130.94it/s, loss=4.65e-05, v_num=23, train_loss=0.0032, test_loss=0.00325]\u001b[A\n",
      "Epoch 11: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.14it/s, loss=4.65e-05, v_num=23, train_loss=0.00235, test_loss=0.00239]\u001b[A\n",
      "Epoch 12:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.84it/s, loss=4.79e-05, v_num=23, train_loss=0.00235, test_loss=0.00239]\u001b[AAdjusting learning rate of group 0 to 9.6798e-03.\n",
      "Epoch 12:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 141.56it/s, loss=4.6e-05, v_num=23, train_loss=0.00235, test_loss=0.00239]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 135.17it/s, loss=4.6e-05, v_num=23, train_loss=0.00235, test_loss=0.00239]\u001b[A\n",
      "Epoch 12: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 170.49it/s, loss=4.6e-05, v_num=23, train_loss=0.00603, test_loss=0.00616]\u001b[A\n",
      "Epoch 13:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 150.49it/s, loss=3.54e-05, v_num=23, train_loss=0.00603, test_loss=0.00616]\u001b[AAdjusting learning rate of group 0 to 9.6556e-03.\n",
      "Epoch 13:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 139.59it/s, loss=3.4e-05, v_num=23, train_loss=0.00603, test_loss=0.00616]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 132.55it/s, loss=3.4e-05, v_num=23, train_loss=0.00603, test_loss=0.00616]\u001b[A\n",
      "Epoch 13: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 167.66it/s, loss=3.4e-05, v_num=23, train_loss=0.00209, test_loss=0.00212]\u001b[A\n",
      "Epoch 14:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 150.00it/s, loss=2.47e-05, v_num=23, train_loss=0.00209, test_loss=0.00212]\u001b[AAdjusting learning rate of group 0 to 9.6315e-03.\n",
      "Epoch 14:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.68it/s, loss=2.41e-05, v_num=23, train_loss=0.00209, test_loss=0.00212]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 128.76it/s, loss=2.41e-05, v_num=23, train_loss=0.00209, test_loss=0.00212]\u001b[A\n",
      "Epoch 14: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 165.16it/s, loss=2.41e-05, v_num=23, train_loss=0.0013, test_loss=0.00133]\u001b[A\n",
      "Epoch 15:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.68it/s, loss=2.54e-05, v_num=23, train_loss=0.0013, test_loss=0.00133]\u001b[AAdjusting learning rate of group 0 to 9.6074e-03.\n",
      "Epoch 15:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 138.39it/s, loss=2.44e-05, v_num=23, train_loss=0.0013, test_loss=0.00133]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 133.24it/s, loss=2.44e-05, v_num=23, train_loss=0.0013, test_loss=0.00133]\u001b[A\n",
      "Epoch 15: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.89it/s, loss=2.44e-05, v_num=23, train_loss=0.00507, test_loss=0.00505]\u001b[A\n",
      "Epoch 16:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.53it/s, loss=3.47e-05, v_num=23, train_loss=0.00507, test_loss=0.00505]\u001b[AAdjusting learning rate of group 0 to 9.5834e-03.\n",
      "Epoch 16:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.37it/s, loss=3.32e-05, v_num=23, train_loss=0.00507, test_loss=0.00505]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.22it/s, loss=3.32e-05, v_num=23, train_loss=0.00507, test_loss=0.00505]\u001b[A\n",
      "Epoch 16: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.24it/s, loss=3.32e-05, v_num=23, train_loss=0.00332, test_loss=0.00332]\u001b[A\n",
      "Epoch 17:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.49it/s, loss=2.62e-05, v_num=23, train_loss=0.00332, test_loss=0.00332]\u001b[AAdjusting learning rate of group 0 to 9.5594e-03.\n",
      "Epoch 17:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.42it/s, loss=2.49e-05, v_num=23, train_loss=0.00332, test_loss=0.00332]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 130.38it/s, loss=2.49e-05, v_num=23, train_loss=0.00332, test_loss=0.00332]\u001b[A\n",
      "Epoch 17: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 165.51it/s, loss=2.49e-05, v_num=23, train_loss=0.00327, test_loss=0.00329]\u001b[A\n",
      "Epoch 18:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 149.50it/s, loss=2.6e-05, v_num=23, train_loss=0.00327, test_loss=0.00329]\u001b[AAdjusting learning rate of group 0 to 9.5355e-03.\n",
      "Epoch 18:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.06it/s, loss=2.57e-05, v_num=23, train_loss=0.00327, test_loss=0.00329]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.81it/s, loss=2.57e-05, v_num=23, train_loss=0.00327, test_loss=0.00329]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 168.50it/s, loss=2.57e-05, v_num=23, train_loss=0.0109, test_loss=0.0109]\u001b[A\n",
      "Epoch 19:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 149.28it/s, loss=1.84e-05, v_num=23, train_loss=0.0109, test_loss=0.0109]\u001b[AAdjusting learning rate of group 0 to 9.5117e-03.\n",
      "Epoch 19:  50%|█████████████████████                     | 79/158 [00:00<00:00, 138.65it/s, loss=1.76e-05, v_num=23, train_loss=0.0109, test_loss=0.0109]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 132.57it/s, loss=1.76e-05, v_num=23, train_loss=0.0109, test_loss=0.0109]\u001b[A\n",
      "Epoch 19: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.64it/s, loss=1.76e-05, v_num=23, train_loss=0.00321, test_loss=0.00323]\u001b[A\n",
      "Epoch 20:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.42it/s, loss=1.75e-05, v_num=23, train_loss=0.00321, test_loss=0.00323]\u001b[AAdjusting learning rate of group 0 to 9.4879e-03.\n",
      "Epoch 20:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.64it/s, loss=1.63e-05, v_num=23, train_loss=0.00321, test_loss=0.00323]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 20:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 135.23it/s, loss=1.63e-05, v_num=23, train_loss=0.00321, test_loss=0.00323]\u001b[A\n",
      "Epoch 20: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.41it/s, loss=1.63e-05, v_num=23, train_loss=0.00143, test_loss=0.00144]\u001b[A\n",
      "Epoch 21:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 150.47it/s, loss=1.7e-05, v_num=23, train_loss=0.00143, test_loss=0.00144]\u001b[AAdjusting learning rate of group 0 to 9.4642e-03.\n",
      "Epoch 21:  50%|████████████████████                    | 79/158 [00:00<00:00, 142.52it/s, loss=1.57e-05, v_num=23, train_loss=0.00143, test_loss=0.00144]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 21:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 136.71it/s, loss=1.57e-05, v_num=23, train_loss=0.00143, test_loss=0.00144]\u001b[A\n",
      "Epoch 21: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 173.24it/s, loss=1.57e-05, v_num=23, train_loss=0.00125, test_loss=0.00129]\u001b[A\n",
      "Epoch 22:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.04it/s, loss=2.43e-05, v_num=23, train_loss=0.00125, test_loss=0.00129]\u001b[AAdjusting learning rate of group 0 to 9.4405e-03.\n",
      "Epoch 22:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.82it/s, loss=2.27e-05, v_num=23, train_loss=0.00125, test_loss=0.00129]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 22:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.97it/s, loss=2.27e-05, v_num=23, train_loss=0.00125, test_loss=0.00129]\u001b[A\n",
      "Epoch 22: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.80it/s, loss=2.27e-05, v_num=23, train_loss=0.00304, test_loss=0.00306]\u001b[A\n",
      "Epoch 23:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.24it/s, loss=1.61e-05, v_num=23, train_loss=0.00304, test_loss=0.00306]\u001b[AAdjusting learning rate of group 0 to 9.4169e-03.\n",
      "Epoch 23:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.19it/s, loss=1.55e-05, v_num=23, train_loss=0.00304, test_loss=0.00306]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 23:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.84it/s, loss=1.55e-05, v_num=23, train_loss=0.00304, test_loss=0.00306]\u001b[A\n",
      "Epoch 23: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.91it/s, loss=1.55e-05, v_num=23, train_loss=0.00178, test_loss=0.00179]\u001b[A\n",
      "Epoch 24:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.66it/s, loss=1.72e-05, v_num=23, train_loss=0.00178, test_loss=0.00179]\u001b[AAdjusting learning rate of group 0 to 9.3934e-03.\n",
      "Epoch 24:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 138.63it/s, loss=1.7e-05, v_num=23, train_loss=0.00178, test_loss=0.00179]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 24:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 131.48it/s, loss=1.7e-05, v_num=23, train_loss=0.00178, test_loss=0.00179]\u001b[A\n",
      "Epoch 24: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 168.52it/s, loss=1.7e-05, v_num=23, train_loss=0.00215, test_loss=0.00217]\u001b[A\n",
      "Epoch 25:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.38it/s, loss=1.68e-05, v_num=23, train_loss=0.00215, test_loss=0.00217]\u001b[AAdjusting learning rate of group 0 to 9.3699e-03.\n",
      "Epoch 25:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.76it/s, loss=1.63e-05, v_num=23, train_loss=0.00215, test_loss=0.00217]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 25:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 134.39it/s, loss=1.63e-05, v_num=23, train_loss=0.00215, test_loss=0.00217]\u001b[A\n",
      "Epoch 25: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.12it/s, loss=1.63e-05, v_num=23, train_loss=0.00155, test_loss=0.00156]\u001b[A\n",
      "Epoch 26:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.55it/s, loss=2.85e-05, v_num=23, train_loss=0.00155, test_loss=0.00156]\u001b[AAdjusting learning rate of group 0 to 9.3465e-03.\n",
      "Epoch 26:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.77it/s, loss=2.67e-05, v_num=23, train_loss=0.00155, test_loss=0.00156]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 26:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.89it/s, loss=2.67e-05, v_num=23, train_loss=0.00155, test_loss=0.00156]\u001b[A\n",
      "Epoch 26: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 171.03it/s, loss=2.67e-05, v_num=23, train_loss=0.00863, test_loss=0.00867]\u001b[A\n",
      "Epoch 27:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.85it/s, loss=2.93e-05, v_num=23, train_loss=0.00863, test_loss=0.00867]\u001b[AAdjusting learning rate of group 0 to 9.3231e-03.\n",
      "Epoch 27:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.31it/s, loss=2.93e-05, v_num=23, train_loss=0.00863, test_loss=0.00867]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 27:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.18it/s, loss=2.93e-05, v_num=23, train_loss=0.00863, test_loss=0.00867]\u001b[A\n",
      "Epoch 27: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 168.47it/s, loss=2.93e-05, v_num=23, train_loss=0.0215, test_loss=0.0216]\u001b[A\n",
      "Epoch 28:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 149.64it/s, loss=2.01e-05, v_num=23, train_loss=0.0215, test_loss=0.0216]\u001b[AAdjusting learning rate of group 0 to 9.2998e-03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28:  50%|█████████████████████                     | 79/158 [00:00<00:00, 138.32it/s, loss=1.91e-05, v_num=23, train_loss=0.0215, test_loss=0.0216]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 28:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 131.62it/s, loss=1.91e-05, v_num=23, train_loss=0.0215, test_loss=0.0216]\u001b[A\n",
      "Epoch 28: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.86it/s, loss=1.91e-05, v_num=23, train_loss=0.00323, test_loss=0.00323]\u001b[A\n",
      "Epoch 29:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.64it/s, loss=2.08e-05, v_num=23, train_loss=0.00323, test_loss=0.00323]\u001b[AAdjusting learning rate of group 0 to 9.2766e-03.\n",
      "Epoch 29:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.66it/s, loss=1.99e-05, v_num=23, train_loss=0.00323, test_loss=0.00323]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 29:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.70it/s, loss=1.99e-05, v_num=23, train_loss=0.00323, test_loss=0.00323]\u001b[A\n",
      "Epoch 29: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 166.95it/s, loss=1.99e-05, v_num=23, train_loss=0.0066, test_loss=0.00662]\u001b[A\n",
      "Epoch 30:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 147.81it/s, loss=1.72e-05, v_num=23, train_loss=0.0066, test_loss=0.00662]\u001b[AAdjusting learning rate of group 0 to 9.2534e-03.\n",
      "Epoch 30:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 137.74it/s, loss=1.66e-05, v_num=23, train_loss=0.0066, test_loss=0.00662]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 30:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 130.60it/s, loss=1.66e-05, v_num=23, train_loss=0.0066, test_loss=0.00662]\u001b[A\n",
      "Epoch 30: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 165.86it/s, loss=1.66e-05, v_num=23, train_loss=0.00784, test_loss=0.00783]\u001b[A\n",
      "Epoch 31:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.49it/s, loss=1.61e-05, v_num=23, train_loss=0.00784, test_loss=0.00783]\u001b[AAdjusting learning rate of group 0 to 9.2302e-03.\n",
      "Epoch 31:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.54it/s, loss=1.54e-05, v_num=23, train_loss=0.00784, test_loss=0.00783]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 31:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 134.78it/s, loss=1.54e-05, v_num=23, train_loss=0.00784, test_loss=0.00783]\u001b[A\n",
      "Epoch 31: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.05it/s, loss=1.54e-05, v_num=23, train_loss=0.00183, test_loss=0.00184]\u001b[A\n",
      "Epoch 32:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.76it/s, loss=1.77e-05, v_num=23, train_loss=0.00183, test_loss=0.00184]\u001b[AAdjusting learning rate of group 0 to 9.2072e-03.\n",
      "Epoch 32:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.82it/s, loss=1.65e-05, v_num=23, train_loss=0.00183, test_loss=0.00184]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 32:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.75it/s, loss=1.65e-05, v_num=23, train_loss=0.00183, test_loss=0.00184]\u001b[A\n",
      "Epoch 32: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.44it/s, loss=1.65e-05, v_num=23, train_loss=0.00829, test_loss=0.00835]\u001b[A\n",
      "Epoch 33:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.22it/s, loss=1.12e-05, v_num=23, train_loss=0.00829, test_loss=0.00835]\u001b[AAdjusting learning rate of group 0 to 9.1841e-03.\n",
      "Epoch 33:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.86it/s, loss=1.08e-05, v_num=23, train_loss=0.00829, test_loss=0.00835]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 33:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.17it/s, loss=1.08e-05, v_num=23, train_loss=0.00829, test_loss=0.00835]\u001b[A\n",
      "Epoch 33: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.99it/s, loss=1.08e-05, v_num=23, train_loss=0.00112, test_loss=0.00114]\u001b[A\n",
      "Epoch 34:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.26it/s, loss=7.49e-06, v_num=23, train_loss=0.00112, test_loss=0.00114]\u001b[AAdjusting learning rate of group 0 to 9.1612e-03.\n",
      "Epoch 34:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.70it/s, loss=7.32e-06, v_num=23, train_loss=0.00112, test_loss=0.00114]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 34:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.09it/s, loss=7.32e-06, v_num=23, train_loss=0.00112, test_loss=0.00114]\u001b[A\n",
      "Epoch 34: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.29it/s, loss=7.32e-06, v_num=23, train_loss=0.00139, test_loss=0.00141]\u001b[A\n",
      "Epoch 35:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.09it/s, loss=8.14e-06, v_num=23, train_loss=0.00139, test_loss=0.00141]\u001b[AAdjusting learning rate of group 0 to 9.1383e-03.\n",
      "Epoch 35:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.44it/s, loss=7.71e-06, v_num=23, train_loss=0.00139, test_loss=0.00141]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 35:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.06it/s, loss=7.71e-06, v_num=23, train_loss=0.00139, test_loss=0.00141]\u001b[A\n",
      "Epoch 35: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.33it/s, loss=7.71e-06, v_num=23, train_loss=0.00062, test_loss=0.000636]\u001b[A\n",
      "Epoch 36:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.13it/s, loss=1.42e-05, v_num=23, train_loss=0.00062, test_loss=0.000636]\u001b[AAdjusting learning rate of group 0 to 9.1154e-03.\n",
      "Epoch 36:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.17it/s, loss=1.36e-05, v_num=23, train_loss=0.00062, test_loss=0.000636]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 36:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.81it/s, loss=1.36e-05, v_num=23, train_loss=0.00062, test_loss=0.000636]\u001b[A\n",
      "Epoch 36: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 167.62it/s, loss=1.36e-05, v_num=23, train_loss=0.00448, test_loss=0.0045]\u001b[A\n",
      "Epoch 37:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 150.71it/s, loss=1.41e-05, v_num=23, train_loss=0.00448, test_loss=0.0045]\u001b[AAdjusting learning rate of group 0 to 9.0926e-03.\n",
      "Epoch 37:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 142.84it/s, loss=1.37e-05, v_num=23, train_loss=0.00448, test_loss=0.0045]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 134.82it/s, loss=1.37e-05, v_num=23, train_loss=0.00448, test_loss=0.0045]\u001b[A\n",
      "Epoch 37: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.28it/s, loss=1.37e-05, v_num=23, train_loss=0.00434, test_loss=0.00437]\u001b[A\n",
      "Epoch 38:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.76it/s, loss=8.66e-06, v_num=23, train_loss=0.00434, test_loss=0.00437]\u001b[AAdjusting learning rate of group 0 to 9.0699e-03.\n",
      "Epoch 38:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.25it/s, loss=8.16e-06, v_num=23, train_loss=0.00434, test_loss=0.00437]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 38:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.92it/s, loss=8.16e-06, v_num=23, train_loss=0.00434, test_loss=0.00437]\u001b[A\n",
      "Epoch 38: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.71it/s, loss=8.16e-06, v_num=23, train_loss=0.000661, test_loss=0.000671]\u001b[A\n",
      "Epoch 39:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.43it/s, loss=1.24e-05, v_num=23, train_loss=0.000661, test_loss=0.000671]\u001b[AAdjusting learning rate of group 0 to 9.0472e-03.\n",
      "Epoch 39:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.83it/s, loss=1.2e-05, v_num=23, train_loss=0.000661, test_loss=0.000671]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 39:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.69it/s, loss=1.2e-05, v_num=23, train_loss=0.000661, test_loss=0.000671]\u001b[A\n",
      "Epoch 39: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 169.38it/s, loss=1.2e-05, v_num=23, train_loss=0.0029, test_loss=0.00292]\u001b[A\n",
      "Epoch 40:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 147.62it/s, loss=1.22e-05, v_num=23, train_loss=0.0029, test_loss=0.00292]\u001b[AAdjusting learning rate of group 0 to 9.0246e-03.\n",
      "Epoch 40:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 136.78it/s, loss=1.19e-05, v_num=23, train_loss=0.0029, test_loss=0.00292]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 40:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 130.06it/s, loss=1.19e-05, v_num=23, train_loss=0.0029, test_loss=0.00292]\u001b[A\n",
      "Epoch 40: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.65it/s, loss=1.19e-05, v_num=23, train_loss=0.00055, test_loss=0.000578]\u001b[A\n",
      "Epoch 41:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.85it/s, loss=5.79e-06, v_num=23, train_loss=0.00055, test_loss=0.000578]\u001b[AAdjusting learning rate of group 0 to 9.0021e-03.\n",
      "Epoch 41:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.16it/s, loss=5.61e-06, v_num=23, train_loss=0.00055, test_loss=0.000578]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 41:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.97it/s, loss=5.61e-06, v_num=23, train_loss=0.00055, test_loss=0.000578]\u001b[A\n",
      "Epoch 41: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.08it/s, loss=5.61e-06, v_num=23, train_loss=0.000874, test_loss=0.000891]\u001b[A\n",
      "Epoch 42:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.23it/s, loss=8.47e-06, v_num=23, train_loss=0.000874, test_loss=0.000891]\u001b[AAdjusting learning rate of group 0 to 8.9796e-03.\n",
      "Epoch 42:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.29it/s, loss=8.19e-06, v_num=23, train_loss=0.000874, test_loss=0.000891]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 42:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.56it/s, loss=8.19e-06, v_num=23, train_loss=0.000874, test_loss=0.000891]\u001b[A\n",
      "Epoch 42: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 165.73it/s, loss=8.19e-06, v_num=23, train_loss=0.00277, test_loss=0.00279]\u001b[A\n",
      "Epoch 43:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 149.26it/s, loss=1.1e-05, v_num=23, train_loss=0.00277, test_loss=0.00279]\u001b[AAdjusting learning rate of group 0 to 8.9571e-03.\n",
      "Epoch 43:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.62it/s, loss=1.03e-05, v_num=23, train_loss=0.00277, test_loss=0.00279]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 43:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.22it/s, loss=1.03e-05, v_num=23, train_loss=0.00277, test_loss=0.00279]\u001b[A\n",
      "Epoch 43: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.62it/s, loss=1.03e-05, v_num=23, train_loss=0.00137, test_loss=0.00138]\u001b[A\n",
      "Epoch 44:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.64it/s, loss=1.81e-05, v_num=23, train_loss=0.00137, test_loss=0.00138]\u001b[AAdjusting learning rate of group 0 to 8.9347e-03.\n",
      "Epoch 44:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.27it/s, loss=1.76e-05, v_num=23, train_loss=0.00137, test_loss=0.00138]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 44:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.17it/s, loss=1.76e-05, v_num=23, train_loss=0.00137, test_loss=0.00138]\u001b[A\n",
      "Epoch 44: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.60it/s, loss=1.76e-05, v_num=23, train_loss=0.00405, test_loss=0.00406]\u001b[A\n",
      "Epoch 45:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.91it/s, loss=1.85e-05, v_num=23, train_loss=0.00405, test_loss=0.00406]\u001b[AAdjusting learning rate of group 0 to 8.9124e-03.\n",
      "Epoch 45:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.75it/s, loss=1.77e-05, v_num=23, train_loss=0.00405, test_loss=0.00406]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 45:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.75it/s, loss=1.77e-05, v_num=23, train_loss=0.00405, test_loss=0.00406]\u001b[A\n",
      "Epoch 45: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.40it/s, loss=1.77e-05, v_num=23, train_loss=0.00244, test_loss=0.00245]\u001b[A\n",
      "Epoch 46:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.21it/s, loss=1.54e-05, v_num=23, train_loss=0.00244, test_loss=0.00245]\u001b[AAdjusting learning rate of group 0 to 8.8901e-03.\n",
      "Epoch 46:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.29it/s, loss=1.49e-05, v_num=23, train_loss=0.00244, test_loss=0.00245]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 46:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.55it/s, loss=1.49e-05, v_num=23, train_loss=0.00244, test_loss=0.00245]\u001b[A\n",
      "Epoch 46: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.25it/s, loss=1.49e-05, v_num=23, train_loss=0.00101, test_loss=0.00103]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 147.36it/s, loss=9.1e-06, v_num=23, train_loss=0.00101, test_loss=0.00103]\u001b[AAdjusting learning rate of group 0 to 8.8679e-03.\n",
      "Epoch 47:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.74it/s, loss=8.65e-06, v_num=23, train_loss=0.00101, test_loss=0.00103]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 47:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 129.87it/s, loss=8.65e-06, v_num=23, train_loss=0.00101, test_loss=0.00103]\u001b[A\n",
      "Epoch 47: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.97it/s, loss=8.65e-06, v_num=23, train_loss=0.000509, test_loss=0.000516]\u001b[A\n",
      "Epoch 48:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.58it/s, loss=8.45e-06, v_num=23, train_loss=0.000509, test_loss=0.000516]\u001b[AAdjusting learning rate of group 0 to 8.8457e-03.\n",
      "Epoch 48:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.52it/s, loss=8.2e-06, v_num=23, train_loss=0.000509, test_loss=0.000516]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 48:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.04it/s, loss=8.2e-06, v_num=23, train_loss=0.000509, test_loss=0.000516]\u001b[A\n",
      "Epoch 48: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 167.86it/s, loss=8.2e-06, v_num=23, train_loss=0.00186, test_loss=0.00187]\u001b[A\n",
      "Epoch 49:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.95it/s, loss=1.56e-05, v_num=23, train_loss=0.00186, test_loss=0.00187]\u001b[AAdjusting learning rate of group 0 to 8.8236e-03.\n",
      "Epoch 49:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.24it/s, loss=1.52e-05, v_num=23, train_loss=0.00186, test_loss=0.00187]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 49:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.44it/s, loss=1.52e-05, v_num=23, train_loss=0.00186, test_loss=0.00187]\u001b[A\n",
      "Epoch 49: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.31it/s, loss=1.52e-05, v_num=23, train_loss=0.00363, test_loss=0.00363]\u001b[A\n",
      "Epoch 50:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.04it/s, loss=9.94e-06, v_num=23, train_loss=0.00363, test_loss=0.00363]\u001b[AAdjusting learning rate of group 0 to 8.8015e-03.\n",
      "Epoch 50:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.69it/s, loss=9.71e-06, v_num=23, train_loss=0.00363, test_loss=0.00363]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 50:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.77it/s, loss=9.71e-06, v_num=23, train_loss=0.00363, test_loss=0.00363]\u001b[A\n",
      "Epoch 50: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 170.86it/s, loss=9.71e-06, v_num=23, train_loss=0.00099, test_loss=0.001]\u001b[A\n",
      "Epoch 51:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 148.12it/s, loss=8.38e-06, v_num=23, train_loss=0.00099, test_loss=0.001]\u001b[AAdjusting learning rate of group 0 to 8.7795e-03.\n",
      "Epoch 51:  50%|█████████████████████                     | 79/158 [00:00<00:00, 138.60it/s, loss=8.15e-06, v_num=23, train_loss=0.00099, test_loss=0.001]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 51:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 131.82it/s, loss=8.15e-06, v_num=23, train_loss=0.00099, test_loss=0.001]\u001b[A\n",
      "Epoch 51: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.81it/s, loss=8.15e-06, v_num=23, train_loss=0.000466, test_loss=0.000474]\u001b[A\n",
      "Epoch 52:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.00it/s, loss=5.05e-06, v_num=23, train_loss=0.000466, test_loss=0.000474]\u001b[AAdjusting learning rate of group 0 to 8.7576e-03.\n",
      "Epoch 52:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.30it/s, loss=4.81e-06, v_num=23, train_loss=0.000466, test_loss=0.000474]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 52:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.47it/s, loss=4.81e-06, v_num=23, train_loss=0.000466, test_loss=0.000474]\u001b[A\n",
      "Epoch 52: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.45it/s, loss=4.81e-06, v_num=23, train_loss=0.000271, test_loss=0.000289]\u001b[A\n",
      "Epoch 53:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.64it/s, loss=7.46e-06, v_num=23, train_loss=0.000271, test_loss=0.000289]\u001b[AAdjusting learning rate of group 0 to 8.7357e-03.\n",
      "Epoch 53:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.96it/s, loss=6.83e-06, v_num=23, train_loss=0.000271, test_loss=0.000289]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 53:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.07it/s, loss=6.83e-06, v_num=23, train_loss=0.000271, test_loss=0.000289]\u001b[A\n",
      "Epoch 53: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.90it/s, loss=6.83e-06, v_num=23, train_loss=0.000554, test_loss=0.000571]\u001b[A\n",
      "Epoch 54:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.39it/s, loss=6.46e-06, v_num=23, train_loss=0.000554, test_loss=0.000571]\u001b[AAdjusting learning rate of group 0 to 8.7138e-03.\n",
      "Epoch 54:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.73it/s, loss=6.24e-06, v_num=23, train_loss=0.000554, test_loss=0.000571]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 54:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.04it/s, loss=6.24e-06, v_num=23, train_loss=0.000554, test_loss=0.000571]\u001b[A\n",
      "Epoch 54: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.90it/s, loss=6.24e-06, v_num=23, train_loss=0.00145, test_loss=0.00145]\u001b[A\n",
      "Epoch 55:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.90it/s, loss=1.22e-05, v_num=23, train_loss=0.00145, test_loss=0.00145]\u001b[AAdjusting learning rate of group 0 to 8.6921e-03.\n",
      "Epoch 55:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.10it/s, loss=1.21e-05, v_num=23, train_loss=0.00145, test_loss=0.00145]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 55:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.40it/s, loss=1.21e-05, v_num=23, train_loss=0.00145, test_loss=0.00145]\u001b[A\n",
      "Epoch 55: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.13it/s, loss=1.21e-05, v_num=23, train_loss=0.000654, test_loss=0.000671]\u001b[A\n",
      "Epoch 56:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.32it/s, loss=7.64e-06, v_num=23, train_loss=0.000654, test_loss=0.000671]\u001b[AAdjusting learning rate of group 0 to 8.6703e-03.\n",
      "Epoch 56:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.42it/s, loss=7.36e-06, v_num=23, train_loss=0.000654, test_loss=0.000671]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 56:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.27it/s, loss=7.36e-06, v_num=23, train_loss=0.000654, test_loss=0.000671]\u001b[A\n",
      "Epoch 56: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.14it/s, loss=7.36e-06, v_num=23, train_loss=0.00159, test_loss=0.00159]\u001b[A\n",
      "Epoch 57:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.43it/s, loss=4.15e-06, v_num=23, train_loss=0.00159, test_loss=0.00159]\u001b[AAdjusting learning rate of group 0 to 8.6487e-03.\n",
      "Epoch 57:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.13it/s, loss=3.99e-06, v_num=23, train_loss=0.00159, test_loss=0.00159]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 57:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.65it/s, loss=3.99e-06, v_num=23, train_loss=0.00159, test_loss=0.00159]\u001b[A\n",
      "Epoch 57: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.10it/s, loss=3.99e-06, v_num=23, train_loss=0.000473, test_loss=0.000476]\u001b[A\n",
      "Epoch 58:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.80it/s, loss=3.94e-06, v_num=23, train_loss=0.000473, test_loss=0.000476]\u001b[AAdjusting learning rate of group 0 to 8.6270e-03.\n",
      "Epoch 58:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.89it/s, loss=3.83e-06, v_num=23, train_loss=0.000473, test_loss=0.000476]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 58:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.13it/s, loss=3.83e-06, v_num=23, train_loss=0.000473, test_loss=0.000476]\u001b[A\n",
      "Epoch 58: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.08it/s, loss=3.83e-06, v_num=23, train_loss=0.000565, test_loss=0.000572]\u001b[A\n",
      "Epoch 59:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.89it/s, loss=5.9e-06, v_num=23, train_loss=0.000565, test_loss=0.000572]\u001b[AAdjusting learning rate of group 0 to 8.6055e-03.\n",
      "Epoch 59:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.06it/s, loss=5.63e-06, v_num=23, train_loss=0.000565, test_loss=0.000572]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 59:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.74it/s, loss=5.63e-06, v_num=23, train_loss=0.000565, test_loss=0.000572]\u001b[A\n",
      "Epoch 59: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.51it/s, loss=5.63e-06, v_num=23, train_loss=0.000299, test_loss=0.000302]\u001b[A\n",
      "Epoch 60:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.38it/s, loss=4.63e-06, v_num=23, train_loss=0.000299, test_loss=0.000302]\u001b[AAdjusting learning rate of group 0 to 8.5839e-03.\n",
      "Epoch 60:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.65it/s, loss=4.49e-06, v_num=23, train_loss=0.000299, test_loss=0.000302]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 60:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.71it/s, loss=4.49e-06, v_num=23, train_loss=0.000299, test_loss=0.000302]\u001b[A\n",
      "Epoch 60: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.08it/s, loss=4.49e-06, v_num=23, train_loss=0.000515, test_loss=0.000525]\u001b[A\n",
      "Epoch 61:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.16it/s, loss=5.33e-06, v_num=23, train_loss=0.000515, test_loss=0.000525]\u001b[AAdjusting learning rate of group 0 to 8.5625e-03.\n",
      "Epoch 61:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.79it/s, loss=5.18e-06, v_num=23, train_loss=0.000515, test_loss=0.000525]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 61:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.60it/s, loss=5.18e-06, v_num=23, train_loss=0.000515, test_loss=0.000525]\u001b[A\n",
      "Epoch 61: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.78it/s, loss=5.18e-06, v_num=23, train_loss=0.000937, test_loss=0.000937]\u001b[A\n",
      "Epoch 62:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.19it/s, loss=7.93e-06, v_num=23, train_loss=0.000937, test_loss=0.000937]\u001b[AAdjusting learning rate of group 0 to 8.5411e-03.\n",
      "Epoch 62:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.06it/s, loss=7.55e-06, v_num=23, train_loss=0.000937, test_loss=0.000937]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 62:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.56it/s, loss=7.55e-06, v_num=23, train_loss=0.000937, test_loss=0.000937]\u001b[A\n",
      "Epoch 62: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.68it/s, loss=7.55e-06, v_num=23, train_loss=0.00147, test_loss=0.00147]\u001b[A\n",
      "Epoch 63:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.48it/s, loss=7.41e-06, v_num=23, train_loss=0.00147, test_loss=0.00147]\u001b[AAdjusting learning rate of group 0 to 8.5197e-03.\n",
      "Epoch 63:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 137.91it/s, loss=7.2e-06, v_num=23, train_loss=0.00147, test_loss=0.00147]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 63:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 133.00it/s, loss=7.2e-06, v_num=23, train_loss=0.00147, test_loss=0.00147]\u001b[A\n",
      "Epoch 63: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.97it/s, loss=7.2e-06, v_num=23, train_loss=0.000625, test_loss=0.000638]\u001b[A\n",
      "Epoch 64:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.79it/s, loss=3.58e-06, v_num=23, train_loss=0.000625, test_loss=0.000638]\u001b[AAdjusting learning rate of group 0 to 8.4984e-03.\n",
      "Epoch 64:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.05it/s, loss=3.43e-06, v_num=23, train_loss=0.000625, test_loss=0.000638]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 64:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.28it/s, loss=3.43e-06, v_num=23, train_loss=0.000625, test_loss=0.000638]\u001b[A\n",
      "Epoch 64: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.12it/s, loss=3.43e-06, v_num=23, train_loss=0.000234, test_loss=0.000245]\u001b[A\n",
      "Epoch 65:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.28it/s, loss=4.4e-06, v_num=23, train_loss=0.000234, test_loss=0.000245]\u001b[AAdjusting learning rate of group 0 to 8.4772e-03.\n",
      "Epoch 65:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 141.07it/s, loss=4e-06, v_num=23, train_loss=0.000234, test_loss=0.000245]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 65:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 133.50it/s, loss=4e-06, v_num=23, train_loss=0.000234, test_loss=0.000245]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████████████████████████████████████| 158/158 [00:00<00:00, 170.89it/s, loss=4e-06, v_num=23, train_loss=0.0005, test_loss=0.000506]\u001b[A\n",
      "Epoch 66:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.18it/s, loss=5.28e-06, v_num=23, train_loss=0.0005, test_loss=0.000506]\u001b[AAdjusting learning rate of group 0 to 8.4560e-03.\n",
      "Epoch 66:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.22it/s, loss=5.11e-06, v_num=23, train_loss=0.0005, test_loss=0.000506]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 66:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.69it/s, loss=5.11e-06, v_num=23, train_loss=0.0005, test_loss=0.000506]\u001b[A\n",
      "Epoch 66: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 171.17it/s, loss=5.11e-06, v_num=23, train_loss=0.00126, test_loss=0.00127]\u001b[A\n",
      "Epoch 67:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.81it/s, loss=4.26e-06, v_num=23, train_loss=0.00126, test_loss=0.00127]\u001b[AAdjusting learning rate of group 0 to 8.4349e-03.\n",
      "Epoch 67:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.08it/s, loss=4.06e-06, v_num=23, train_loss=0.00126, test_loss=0.00127]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 67:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 130.64it/s, loss=4.06e-06, v_num=23, train_loss=0.00126, test_loss=0.00127]\u001b[A\n",
      "Epoch 67: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.14it/s, loss=4.06e-06, v_num=23, train_loss=0.000243, test_loss=0.000254]\u001b[A\n",
      "Epoch 68:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.18it/s, loss=3.8e-06, v_num=23, train_loss=0.000243, test_loss=0.000254]\u001b[AAdjusting learning rate of group 0 to 8.4138e-03.\n",
      "Epoch 68:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.23it/s, loss=3.72e-06, v_num=23, train_loss=0.000243, test_loss=0.000254]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 68:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.22it/s, loss=3.72e-06, v_num=23, train_loss=0.000243, test_loss=0.000254]\u001b[A\n",
      "Epoch 68: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 172.22it/s, loss=3.72e-06, v_num=23, train_loss=0.000747, test_loss=0.000755]\u001b[A\n",
      "Epoch 69:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.58it/s, loss=1.16e-05, v_num=23, train_loss=0.000747, test_loss=0.000755]\u001b[AAdjusting learning rate of group 0 to 8.3927e-03.\n",
      "Epoch 69:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.74it/s, loss=1.1e-05, v_num=23, train_loss=0.000747, test_loss=0.000755]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 69:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.84it/s, loss=1.1e-05, v_num=23, train_loss=0.000747, test_loss=0.000755]\u001b[A\n",
      "Epoch 69: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 170.04it/s, loss=1.1e-05, v_num=23, train_loss=0.00112, test_loss=0.00112]\u001b[A\n",
      "Epoch 70:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.55it/s, loss=3.84e-06, v_num=23, train_loss=0.00112, test_loss=0.00112]\u001b[AAdjusting learning rate of group 0 to 8.3717e-03.\n",
      "Epoch 70:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.81it/s, loss=3.71e-06, v_num=23, train_loss=0.00112, test_loss=0.00112]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 70:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.19it/s, loss=3.71e-06, v_num=23, train_loss=0.00112, test_loss=0.00112]\u001b[A\n",
      "Epoch 70: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.66it/s, loss=3.71e-06, v_num=23, train_loss=0.000394, test_loss=0.000401]\u001b[A\n",
      "Epoch 71:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.06it/s, loss=2.59e-06, v_num=23, train_loss=0.000394, test_loss=0.000401]\u001b[AAdjusting learning rate of group 0 to 8.3508e-03.\n",
      "Epoch 71:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.18it/s, loss=2.54e-06, v_num=23, train_loss=0.000394, test_loss=0.000401]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 71:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.87it/s, loss=2.54e-06, v_num=23, train_loss=0.000394, test_loss=0.000401]\u001b[A\n",
      "Epoch 71: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.25it/s, loss=2.54e-06, v_num=23, train_loss=0.000197, test_loss=0.000209]\u001b[A\n",
      "Epoch 72:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.39it/s, loss=3.42e-06, v_num=23, train_loss=0.000197, test_loss=0.000209]\u001b[AAdjusting learning rate of group 0 to 8.3299e-03.\n",
      "Epoch 72:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.91it/s, loss=3.26e-06, v_num=23, train_loss=0.000197, test_loss=0.000209]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 72:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.58it/s, loss=3.26e-06, v_num=23, train_loss=0.000197, test_loss=0.000209]\u001b[A\n",
      "Epoch 72: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.48it/s, loss=3.26e-06, v_num=23, train_loss=0.000342, test_loss=0.000348]\u001b[A\n",
      "Epoch 73:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.75it/s, loss=4.64e-06, v_num=23, train_loss=0.000342, test_loss=0.000348]\u001b[AAdjusting learning rate of group 0 to 8.3091e-03.\n",
      "Epoch 73:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.16it/s, loss=4.6e-06, v_num=23, train_loss=0.000342, test_loss=0.000348]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 73:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.94it/s, loss=4.6e-06, v_num=23, train_loss=0.000342, test_loss=0.000348]\u001b[A\n",
      "Epoch 73: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 165.04it/s, loss=4.6e-06, v_num=23, train_loss=0.00145, test_loss=0.00146]\u001b[A\n",
      "Epoch 74:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.41it/s, loss=4.78e-06, v_num=23, train_loss=0.00145, test_loss=0.00146]\u001b[AAdjusting learning rate of group 0 to 8.2883e-03.\n",
      "Epoch 74:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.50it/s, loss=4.58e-06, v_num=23, train_loss=0.00145, test_loss=0.00146]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 74:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.65it/s, loss=4.58e-06, v_num=23, train_loss=0.00145, test_loss=0.00146]\u001b[A\n",
      "Validating:  54%|████████████████████████████████████████████████████████                                               | 43/79 [00:00<00:00, 198.28it/s]\u001b[A\n",
      "Epoch 74: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 146.80it/s, loss=4.58e-06, v_num=23, train_loss=0.000334, test_loss=0.000335]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 119.78it/s, loss=6.15e-06, v_num=23, train_loss=0.000334, test_loss=0.000335]\u001b[AAdjusting learning rate of group 0 to 8.2676e-03.\n",
      "Epoch 75:  50%|███████████████████                   | 79/158 [00:00<00:00, 114.10it/s, loss=5.67e-06, v_num=23, train_loss=0.000334, test_loss=0.000335]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 75:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 114.81it/s, loss=5.67e-06, v_num=23, train_loss=0.000334, test_loss=0.000335]\u001b[A\n",
      "Validating:  56%|█████████████████████████████████████████████████████████▎                                             | 44/79 [00:00<00:00, 205.66it/s]\u001b[A\n",
      "Epoch 75: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 129.17it/s, loss=5.67e-06, v_num=23, train_loss=0.000417, test_loss=0.000422]\u001b[A\n",
      "Epoch 76:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 119.39it/s, loss=3.67e-06, v_num=23, train_loss=0.000417, test_loss=0.000422]\u001b[AAdjusting learning rate of group 0 to 8.2470e-03.\n",
      "Epoch 76:  50%|███████████████████                   | 79/158 [00:00<00:00, 113.26it/s, loss=3.52e-06, v_num=23, train_loss=0.000417, test_loss=0.000422]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 76:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 114.55it/s, loss=3.52e-06, v_num=23, train_loss=0.000417, test_loss=0.000422]\u001b[A\n",
      "Epoch 76: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 128.80it/s, loss=3.52e-06, v_num=23, train_loss=0.000274, test_loss=0.000282]\u001b[A\n",
      "Epoch 77:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 120.42it/s, loss=2.99e-06, v_num=23, train_loss=0.000274, test_loss=0.000282]\u001b[AAdjusting learning rate of group 0 to 8.2263e-03.\n",
      "Epoch 77:  50%|███████████████████                   | 79/158 [00:00<00:00, 113.18it/s, loss=2.82e-06, v_num=23, train_loss=0.000274, test_loss=0.000282]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.26it/s]\u001b[A\n",
      "Epoch 77:  67%|█████████████████████████▍            | 106/158 [00:01<00:00, 97.29it/s, loss=2.82e-06, v_num=23, train_loss=0.000274, test_loss=0.000282]\u001b[A\n",
      "Epoch 77: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 126.91it/s, loss=2.82e-06, v_num=23, train_loss=0.000173, test_loss=0.000182]\u001b[A\n",
      "Epoch 78:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 81.57it/s, loss=3.4e-06, v_num=23, train_loss=0.000173, test_loss=0.000182]\u001b[AAdjusting learning rate of group 0 to 8.2058e-03.\n",
      "Epoch 78:  50%|███████████████████▌                   | 79/158 [00:01<00:01, 78.90it/s, loss=3.32e-06, v_num=23, train_loss=0.000173, test_loss=0.000182]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 78:  67%|█████████████████████████▍            | 106/158 [00:01<00:00, 76.37it/s, loss=3.32e-06, v_num=23, train_loss=0.000173, test_loss=0.000182]\u001b[A\n",
      "Epoch 78: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 103.52it/s, loss=3.32e-06, v_num=23, train_loss=0.000474, test_loss=0.000487]\u001b[A\n",
      "Epoch 79:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 105.44it/s, loss=5.22e-06, v_num=23, train_loss=0.000474, test_loss=0.000487]\u001b[AAdjusting learning rate of group 0 to 8.1853e-03.\n",
      "Epoch 79:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 99.51it/s, loss=4.82e-06, v_num=23, train_loss=0.000474, test_loss=0.000487]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 79:  67%|████████████████████████▊            | 106/158 [00:01<00:00, 104.35it/s, loss=4.82e-06, v_num=23, train_loss=0.000474, test_loss=0.000487]\u001b[A\n",
      "Epoch 79: 100%|██████████████████████████████████████| 158/158 [00:01<00:00, 136.32it/s, loss=4.82e-06, v_num=23, train_loss=0.00057, test_loss=0.000565]\u001b[A\n",
      "Epoch 80:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.61it/s, loss=4.26e-06, v_num=23, train_loss=0.00057, test_loss=0.000565]\u001b[AAdjusting learning rate of group 0 to 8.1648e-03.\n",
      "Epoch 80:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.78it/s, loss=4.04e-06, v_num=23, train_loss=0.00057, test_loss=0.000565]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 80:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.86it/s, loss=4.04e-06, v_num=23, train_loss=0.00057, test_loss=0.000565]\u001b[A\n",
      "Epoch 80: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.21it/s, loss=4.04e-06, v_num=23, train_loss=0.000325, test_loss=0.00033]\u001b[A\n",
      "Epoch 81:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.02it/s, loss=3.1e-06, v_num=23, train_loss=0.000325, test_loss=0.00033]\u001b[AAdjusting learning rate of group 0 to 8.1444e-03.\n",
      "Epoch 81:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.97it/s, loss=2.93e-06, v_num=23, train_loss=0.000325, test_loss=0.00033]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 81:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.14it/s, loss=2.93e-06, v_num=23, train_loss=0.000325, test_loss=0.00033]\u001b[A\n",
      "Epoch 81: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.46it/s, loss=2.93e-06, v_num=23, train_loss=0.000759, test_loss=0.000759]\u001b[A\n",
      "Epoch 82:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.42it/s, loss=1.85e-06, v_num=23, train_loss=0.000759, test_loss=0.000759]\u001b[AAdjusting learning rate of group 0 to 8.1240e-03.\n",
      "Epoch 82:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.41it/s, loss=1.81e-06, v_num=23, train_loss=0.000759, test_loss=0.000759]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 82:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.45it/s, loss=1.81e-06, v_num=23, train_loss=0.000759, test_loss=0.000759]\u001b[A\n",
      "Epoch 82: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.98it/s, loss=1.81e-06, v_num=23, train_loss=0.000207, test_loss=0.00021]\u001b[A\n",
      "Epoch 83:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.54it/s, loss=1.4e-05, v_num=23, train_loss=0.000207, test_loss=0.00021]\u001b[AAdjusting learning rate of group 0 to 8.1037e-03.\n",
      "Epoch 83:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.31it/s, loss=1.38e-05, v_num=23, train_loss=0.000207, test_loss=0.00021]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 83:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.67it/s, loss=1.38e-05, v_num=23, train_loss=0.000207, test_loss=0.00021]\u001b[A\n",
      "Epoch 83: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.40it/s, loss=1.38e-05, v_num=23, train_loss=0.00319, test_loss=0.00319]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.18it/s, loss=4.57e-06, v_num=23, train_loss=0.00319, test_loss=0.00319]\u001b[AAdjusting learning rate of group 0 to 8.0835e-03.\n",
      "Epoch 84:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.32it/s, loss=4.42e-06, v_num=23, train_loss=0.00319, test_loss=0.00319]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 84:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.02it/s, loss=4.42e-06, v_num=23, train_loss=0.00319, test_loss=0.00319]\u001b[A\n",
      "Epoch 84: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.59it/s, loss=4.42e-06, v_num=23, train_loss=0.00105, test_loss=0.00103]\u001b[A\n",
      "Epoch 85:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.13it/s, loss=2.77e-06, v_num=23, train_loss=0.00105, test_loss=0.00103]\u001b[AAdjusting learning rate of group 0 to 8.0632e-03.\n",
      "Epoch 85:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.26it/s, loss=2.61e-06, v_num=23, train_loss=0.00105, test_loss=0.00103]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 85:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 130.68it/s, loss=2.61e-06, v_num=23, train_loss=0.00105, test_loss=0.00103]\u001b[A\n",
      "Epoch 85: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.72it/s, loss=2.61e-06, v_num=23, train_loss=0.000236, test_loss=0.000242]\u001b[A\n",
      "Epoch 86:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.30it/s, loss=2.59e-06, v_num=23, train_loss=0.000236, test_loss=0.000242]\u001b[AAdjusting learning rate of group 0 to 8.0431e-03.\n",
      "Epoch 86:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.97it/s, loss=2.52e-06, v_num=23, train_loss=0.000236, test_loss=0.000242]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 86:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.98it/s, loss=2.52e-06, v_num=23, train_loss=0.000236, test_loss=0.000242]\u001b[A\n",
      "Epoch 86: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.11it/s, loss=2.52e-06, v_num=23, train_loss=0.000271, test_loss=0.000273]\u001b[A\n",
      "Epoch 87:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.22it/s, loss=1.84e-06, v_num=23, train_loss=0.000271, test_loss=0.000273]\u001b[AAdjusting learning rate of group 0 to 8.0230e-03.\n",
      "Epoch 87:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.34it/s, loss=1.76e-06, v_num=23, train_loss=0.000271, test_loss=0.000273]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 87:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.90it/s, loss=1.76e-06, v_num=23, train_loss=0.000271, test_loss=0.000273]\u001b[A\n",
      "Epoch 87: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.35it/s, loss=1.76e-06, v_num=23, train_loss=0.000185, test_loss=0.000199]\u001b[A\n",
      "Epoch 88:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.24it/s, loss=3.57e-06, v_num=23, train_loss=0.000185, test_loss=0.000199]\u001b[AAdjusting learning rate of group 0 to 8.0029e-03.\n",
      "Epoch 88:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.00it/s, loss=3.44e-06, v_num=23, train_loss=0.000185, test_loss=0.000199]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 88:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.40it/s, loss=3.44e-06, v_num=23, train_loss=0.000185, test_loss=0.000199]\u001b[A\n",
      "Epoch 88: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.90it/s, loss=3.44e-06, v_num=23, train_loss=0.000395, test_loss=0.000398]\u001b[A\n",
      "Epoch 89:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.56it/s, loss=1.64e-06, v_num=23, train_loss=0.000395, test_loss=0.000398]\u001b[AAdjusting learning rate of group 0 to 7.9829e-03.\n",
      "Epoch 89:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.05it/s, loss=1.57e-06, v_num=23, train_loss=0.000395, test_loss=0.000398]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 89:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.16it/s, loss=1.57e-06, v_num=23, train_loss=0.000395, test_loss=0.000398]\u001b[A\n",
      "Epoch 89: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.80it/s, loss=1.57e-06, v_num=23, train_loss=0.000173, test_loss=0.000177]\u001b[A\n",
      "Epoch 90:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.72it/s, loss=1.78e-06, v_num=23, train_loss=0.000173, test_loss=0.000177]\u001b[AAdjusting learning rate of group 0 to 7.9630e-03.\n",
      "Epoch 90:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.61it/s, loss=1.66e-06, v_num=23, train_loss=0.000173, test_loss=0.000177]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 90:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 128.04it/s, loss=1.66e-06, v_num=23, train_loss=0.000173, test_loss=0.000177]\u001b[A\n",
      "Epoch 90: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.73it/s, loss=1.66e-06, v_num=23, train_loss=0.000216, test_loss=0.000223]\u001b[A\n",
      "Epoch 91:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.68it/s, loss=2.58e-06, v_num=23, train_loss=0.000216, test_loss=0.000223]\u001b[AAdjusting learning rate of group 0 to 7.9430e-03.\n",
      "Epoch 91:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.98it/s, loss=2.41e-06, v_num=23, train_loss=0.000216, test_loss=0.000223]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.30it/s]\u001b[A\n",
      "Epoch 91:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 125.81it/s, loss=2.41e-06, v_num=23, train_loss=0.000216, test_loss=0.000223]\u001b[A\n",
      "Epoch 91: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 160.55it/s, loss=2.41e-06, v_num=23, train_loss=0.00014, test_loss=0.000144]\u001b[A\n",
      "Epoch 92:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.16it/s, loss=2.25e-06, v_num=23, train_loss=0.00014, test_loss=0.000144]\u001b[AAdjusting learning rate of group 0 to 7.9232e-03.\n",
      "Epoch 92:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.48it/s, loss=2.2e-06, v_num=23, train_loss=0.00014, test_loss=0.000144]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 92:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.84it/s, loss=2.2e-06, v_num=23, train_loss=0.00014, test_loss=0.000144]\u001b[A\n",
      "Epoch 92: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.34it/s, loss=2.2e-06, v_num=23, train_loss=0.000188, test_loss=0.00019]\u001b[A\n",
      "Epoch 93:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.36it/s, loss=4.68e-06, v_num=23, train_loss=0.000188, test_loss=0.00019]\u001b[AAdjusting learning rate of group 0 to 7.9034e-03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.47it/s, loss=4.64e-06, v_num=23, train_loss=0.000188, test_loss=0.00019]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 93:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.80it/s, loss=4.64e-06, v_num=23, train_loss=0.000188, test_loss=0.00019]\u001b[A\n",
      "Epoch 93: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.80it/s, loss=4.64e-06, v_num=23, train_loss=0.000641, test_loss=0.000644]\u001b[A\n",
      "Epoch 94:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.20it/s, loss=1.97e-06, v_num=23, train_loss=0.000641, test_loss=0.000644]\u001b[AAdjusting learning rate of group 0 to 7.8836e-03.\n",
      "Epoch 94:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.33it/s, loss=1.89e-06, v_num=23, train_loss=0.000641, test_loss=0.000644]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 94:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.70it/s, loss=1.89e-06, v_num=23, train_loss=0.000641, test_loss=0.000644]\u001b[A\n",
      "Epoch 94: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.71it/s, loss=1.89e-06, v_num=23, train_loss=0.00016, test_loss=0.000158]\u001b[A\n",
      "Epoch 95:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.75it/s, loss=2.37e-06, v_num=23, train_loss=0.00016, test_loss=0.000158]\u001b[AAdjusting learning rate of group 0 to 7.8639e-03.\n",
      "Epoch 95:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.75it/s, loss=2.28e-06, v_num=23, train_loss=0.00016, test_loss=0.000158]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 95:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.72it/s, loss=2.28e-06, v_num=23, train_loss=0.00016, test_loss=0.000158]\u001b[A\n",
      "Epoch 95: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.86it/s, loss=2.28e-06, v_num=23, train_loss=0.000192, test_loss=0.000194]\u001b[A\n",
      "Epoch 96:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.46it/s, loss=1.88e-06, v_num=23, train_loss=0.000192, test_loss=0.000194]\u001b[AAdjusting learning rate of group 0 to 7.8443e-03.\n",
      "Epoch 96:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.41it/s, loss=1.74e-06, v_num=23, train_loss=0.000192, test_loss=0.000194]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 96:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.92it/s, loss=1.74e-06, v_num=23, train_loss=0.000192, test_loss=0.000194]\u001b[A\n",
      "Epoch 96: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.10it/s, loss=1.74e-06, v_num=23, train_loss=0.000134, test_loss=0.00014]\u001b[A\n",
      "Epoch 97:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.04it/s, loss=2.34e-06, v_num=23, train_loss=0.000134, test_loss=0.00014]\u001b[AAdjusting learning rate of group 0 to 7.8246e-03.\n",
      "Epoch 97:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.20it/s, loss=2.3e-06, v_num=23, train_loss=0.000134, test_loss=0.00014]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 97:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.37it/s, loss=2.3e-06, v_num=23, train_loss=0.000134, test_loss=0.00014]\u001b[A\n",
      "Epoch 97: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.26it/s, loss=2.3e-06, v_num=23, train_loss=0.000379, test_loss=0.000383]\u001b[A\n",
      "Epoch 98:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.25it/s, loss=2.82e-06, v_num=23, train_loss=0.000379, test_loss=0.000383]\u001b[AAdjusting learning rate of group 0 to 7.8051e-03.\n",
      "Epoch 98:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.39it/s, loss=2.68e-06, v_num=23, train_loss=0.000379, test_loss=0.000383]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 98:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 135.46it/s, loss=2.68e-06, v_num=23, train_loss=0.000379, test_loss=0.000383]\u001b[A\n",
      "Epoch 98: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.66it/s, loss=2.68e-06, v_num=23, train_loss=0.000339, test_loss=0.000339]\u001b[A\n",
      "Epoch 99:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.89it/s, loss=4.48e-06, v_num=23, train_loss=0.000339, test_loss=0.000339]\u001b[AAdjusting learning rate of group 0 to 7.7856e-03.\n",
      "Epoch 99:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.65it/s, loss=4.3e-06, v_num=23, train_loss=0.000339, test_loss=0.000339]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 99:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.39it/s, loss=4.3e-06, v_num=23, train_loss=0.000339, test_loss=0.000339]\u001b[A\n",
      "Epoch 99: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.73it/s, loss=4.3e-06, v_num=23, train_loss=0.000528, test_loss=0.000525]\u001b[A\n",
      "Epoch 100:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.93it/s, loss=1.76e-06, v_num=23, train_loss=0.000528, test_loss=0.000525]\u001b[AAdjusting learning rate of group 0 to 7.7661e-03.\n",
      "Epoch 100:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.34it/s, loss=1.67e-06, v_num=23, train_loss=0.000528, test_loss=0.000525]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 100:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 129.66it/s, loss=1.67e-06, v_num=23, train_loss=0.000528, test_loss=0.000525]\u001b[A\n",
      "Epoch 100: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.63it/s, loss=1.67e-06, v_num=23, train_loss=0.000144, test_loss=0.00015]\u001b[A\n",
      "Epoch 101:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.39it/s, loss=2.58e-06, v_num=23, train_loss=0.000144, test_loss=0.00015]\u001b[AAdjusting learning rate of group 0 to 7.7467e-03.\n",
      "Epoch 101:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.87it/s, loss=2.43e-06, v_num=23, train_loss=0.000144, test_loss=0.00015]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 101:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.65it/s, loss=2.43e-06, v_num=23, train_loss=0.000144, test_loss=0.00015]\u001b[A\n",
      "Epoch 101: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 165.33it/s, loss=2.43e-06, v_num=23, train_loss=0.000168, test_loss=0.000177]\u001b[A\n",
      "Epoch 102:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.32it/s, loss=1.64e-06, v_num=23, train_loss=0.000168, test_loss=0.000177]\u001b[AAdjusting learning rate of group 0 to 7.7273e-03.\n",
      "Epoch 102:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 139.15it/s, loss=1.57e-06, v_num=23, train_loss=0.000168, test_loss=0.000177]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 133.62it/s, loss=1.57e-06, v_num=23, train_loss=0.000168, test_loss=0.000177]\u001b[A\n",
      "Epoch 102: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.91it/s, loss=1.57e-06, v_num=23, train_loss=0.000254, test_loss=0.000255]\u001b[A\n",
      "Epoch 103:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.82it/s, loss=1.61e-06, v_num=23, train_loss=0.000254, test_loss=0.000255]\u001b[AAdjusting learning rate of group 0 to 7.7080e-03.\n",
      "Epoch 103:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.69it/s, loss=1.56e-06, v_num=23, train_loss=0.000254, test_loss=0.000255]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 103:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 133.06it/s, loss=1.56e-06, v_num=23, train_loss=0.000254, test_loss=0.000255]\u001b[A\n",
      "Epoch 103: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.81it/s, loss=1.56e-06, v_num=23, train_loss=0.000235, test_loss=0.000236]\u001b[A\n",
      "Epoch 104:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 146.46it/s, loss=1.13e-06, v_num=23, train_loss=0.000235, test_loss=0.000236]\u001b[AAdjusting learning rate of group 0 to 7.6887e-03.\n",
      "Epoch 104:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 135.82it/s, loss=1.09e-06, v_num=23, train_loss=0.000235, test_loss=0.000236]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 104:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 130.60it/s, loss=1.09e-06, v_num=23, train_loss=0.000235, test_loss=0.000236]\u001b[A\n",
      "Epoch 104: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 166.02it/s, loss=1.09e-06, v_num=23, train_loss=0.000135, test_loss=0.000139]\u001b[A\n",
      "Epoch 105:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.68it/s, loss=4.7e-06, v_num=23, train_loss=0.000135, test_loss=0.000139]\u001b[AAdjusting learning rate of group 0 to 7.6695e-03.\n",
      "Epoch 105:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.22it/s, loss=4.52e-06, v_num=23, train_loss=0.000135, test_loss=0.000139]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 105:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.75it/s, loss=4.52e-06, v_num=23, train_loss=0.000135, test_loss=0.000139]\u001b[A\n",
      "Epoch 105: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.57it/s, loss=4.52e-06, v_num=23, train_loss=0.00043, test_loss=0.000436]\u001b[A\n",
      "Epoch 106:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.94it/s, loss=2.26e-06, v_num=23, train_loss=0.00043, test_loss=0.000436]\u001b[AAdjusting learning rate of group 0 to 7.6503e-03.\n",
      "Epoch 106:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.76it/s, loss=2.21e-06, v_num=23, train_loss=0.00043, test_loss=0.000436]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 106:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.05it/s, loss=2.21e-06, v_num=23, train_loss=0.00043, test_loss=0.000436]\u001b[A\n",
      "Epoch 106: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.31it/s, loss=2.21e-06, v_num=23, train_loss=0.000527, test_loss=0.000536]\u001b[A\n",
      "Epoch 107:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.28it/s, loss=1.45e-06, v_num=23, train_loss=0.000527, test_loss=0.000536]\u001b[AAdjusting learning rate of group 0 to 7.6312e-03.\n",
      "Epoch 107:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.37it/s, loss=1.42e-06, v_num=23, train_loss=0.000527, test_loss=0.000536]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 107:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 130.37it/s, loss=1.42e-06, v_num=23, train_loss=0.000527, test_loss=0.000536]\u001b[A\n",
      "Epoch 107: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.71it/s, loss=1.42e-06, v_num=23, train_loss=9.43e-5, test_loss=9.79e-5]\u001b[A\n",
      "Epoch 108:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.83it/s, loss=3.52e-06, v_num=23, train_loss=9.43e-5, test_loss=9.79e-5]\u001b[AAdjusting learning rate of group 0 to 7.6121e-03.\n",
      "Epoch 108:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.93it/s, loss=3.39e-06, v_num=23, train_loss=9.43e-5, test_loss=9.79e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 108:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.90it/s, loss=3.39e-06, v_num=23, train_loss=9.43e-5, test_loss=9.79e-5]\u001b[A\n",
      "Epoch 108: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.33it/s, loss=3.39e-06, v_num=23, train_loss=0.000448, test_loss=0.00045]\u001b[A\n",
      "Epoch 109:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.12it/s, loss=1.72e-06, v_num=23, train_loss=0.000448, test_loss=0.00045]\u001b[AAdjusting learning rate of group 0 to 7.5931e-03.\n",
      "Epoch 109:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.19it/s, loss=1.62e-06, v_num=23, train_loss=0.000448, test_loss=0.00045]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 109:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 135.27it/s, loss=1.62e-06, v_num=23, train_loss=0.000448, test_loss=0.00045]\u001b[A\n",
      "Epoch 109: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 169.71it/s, loss=1.62e-06, v_num=23, train_loss=0.000188, test_loss=0.000188]\u001b[A\n",
      "Epoch 110:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 150.25it/s, loss=2.09e-06, v_num=23, train_loss=0.000188, test_loss=0.000188]\u001b[AAdjusting learning rate of group 0 to 7.5741e-03.\n",
      "Epoch 110:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.99it/s, loss=1.96e-06, v_num=23, train_loss=0.000188, test_loss=0.000188]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 110:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 133.55it/s, loss=1.96e-06, v_num=23, train_loss=0.000188, test_loss=0.000188]\u001b[A\n",
      "Epoch 110: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.27it/s, loss=1.96e-06, v_num=23, train_loss=0.00029, test_loss=0.000291]\u001b[A\n",
      "Epoch 111:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.24it/s, loss=2.33e-06, v_num=23, train_loss=0.00029, test_loss=0.000291]\u001b[AAdjusting learning rate of group 0 to 7.5552e-03.\n",
      "Epoch 111:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.09it/s, loss=2.15e-06, v_num=23, train_loss=0.00029, test_loss=0.000291]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 111:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.18it/s, loss=2.15e-06, v_num=23, train_loss=0.00029, test_loss=0.000291]\u001b[A\n",
      "Epoch 111: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 166.48it/s, loss=2.15e-06, v_num=23, train_loss=0.000241, test_loss=0.000246]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.26it/s, loss=1.6e-06, v_num=23, train_loss=0.000241, test_loss=0.000246]\u001b[AAdjusting learning rate of group 0 to 7.5363e-03.\n",
      "Epoch 112:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 136.38it/s, loss=1.51e-06, v_num=23, train_loss=0.000241, test_loss=0.000246]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 112:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.85it/s, loss=1.51e-06, v_num=23, train_loss=0.000241, test_loss=0.000246]\u001b[A\n",
      "Epoch 112: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.38it/s, loss=1.51e-06, v_num=23, train_loss=0.000145, test_loss=0.000151]\u001b[A\n",
      "Epoch 113:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.59it/s, loss=2.79e-06, v_num=23, train_loss=0.000145, test_loss=0.000151]\u001b[AAdjusting learning rate of group 0 to 7.5175e-03.\n",
      "Epoch 113:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 139.35it/s, loss=2.74e-06, v_num=23, train_loss=0.000145, test_loss=0.000151]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 113:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 134.43it/s, loss=2.74e-06, v_num=23, train_loss=0.000145, test_loss=0.000151]\u001b[A\n",
      "Epoch 113: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 169.70it/s, loss=2.74e-06, v_num=23, train_loss=0.000423, test_loss=0.000445]\u001b[A\n",
      "Epoch 114:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 147.48it/s, loss=1.32e-06, v_num=23, train_loss=0.000423, test_loss=0.000445]\u001b[AAdjusting learning rate of group 0 to 7.4987e-03.\n",
      "Epoch 114:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.45it/s, loss=1.28e-06, v_num=23, train_loss=0.000423, test_loss=0.000445]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 114:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.82it/s, loss=1.28e-06, v_num=23, train_loss=0.000423, test_loss=0.000445]\u001b[A\n",
      "Epoch 114: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.54it/s, loss=1.28e-06, v_num=23, train_loss=0.000173, test_loss=0.000179]\u001b[A\n",
      "Epoch 115:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.05it/s, loss=1.3e-06, v_num=23, train_loss=0.000173, test_loss=0.000179]\u001b[AAdjusting learning rate of group 0 to 7.4799e-03.\n",
      "Epoch 115:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 139.12it/s, loss=1.26e-06, v_num=23, train_loss=0.000173, test_loss=0.000179]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 115:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 134.14it/s, loss=1.26e-06, v_num=23, train_loss=0.000173, test_loss=0.000179]\u001b[A\n",
      "Epoch 115: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.72it/s, loss=1.26e-06, v_num=23, train_loss=0.000157, test_loss=0.00016]\u001b[A\n",
      "Epoch 116:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.12it/s, loss=2.79e-06, v_num=23, train_loss=0.000157, test_loss=0.00016]\u001b[AAdjusting learning rate of group 0 to 7.4612e-03.\n",
      "Epoch 116:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.73it/s, loss=2.68e-06, v_num=23, train_loss=0.000157, test_loss=0.00016]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 116:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.72it/s, loss=2.68e-06, v_num=23, train_loss=0.000157, test_loss=0.00016]\u001b[A\n",
      "Epoch 116: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.56it/s, loss=2.68e-06, v_num=23, train_loss=0.000806, test_loss=0.000795]\u001b[A\n",
      "Epoch 117:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.33it/s, loss=2.96e-06, v_num=23, train_loss=0.000806, test_loss=0.000795]\u001b[AAdjusting learning rate of group 0 to 7.4426e-03.\n",
      "Epoch 117:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.25it/s, loss=2.91e-06, v_num=23, train_loss=0.000806, test_loss=0.000795]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 117:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 133.38it/s, loss=2.91e-06, v_num=23, train_loss=0.000806, test_loss=0.000795]\u001b[A\n",
      "Epoch 117: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 169.48it/s, loss=2.91e-06, v_num=23, train_loss=0.000808, test_loss=0.000842]\u001b[A\n",
      "Epoch 118:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.38it/s, loss=3.74e-06, v_num=23, train_loss=0.000808, test_loss=0.000842]\u001b[AAdjusting learning rate of group 0 to 7.4240e-03.\n",
      "Epoch 118:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 139.35it/s, loss=3.59e-06, v_num=23, train_loss=0.000808, test_loss=0.000842]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 118:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.61it/s, loss=3.59e-06, v_num=23, train_loss=0.000808, test_loss=0.000842]\u001b[A\n",
      "Epoch 118: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.60it/s, loss=3.59e-06, v_num=23, train_loss=0.000556, test_loss=0.000582]\u001b[A\n",
      "Epoch 119:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.54it/s, loss=1.48e-06, v_num=23, train_loss=0.000556, test_loss=0.000582]\u001b[AAdjusting learning rate of group 0 to 7.4054e-03.\n",
      "Epoch 119:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.20it/s, loss=1.44e-06, v_num=23, train_loss=0.000556, test_loss=0.000582]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 119:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 130.72it/s, loss=1.44e-06, v_num=23, train_loss=0.000556, test_loss=0.000582]\u001b[A\n",
      "Epoch 119: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 166.20it/s, loss=1.44e-06, v_num=23, train_loss=0.000181, test_loss=0.000184]\u001b[A\n",
      "Epoch 120:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.14it/s, loss=1.19e-06, v_num=23, train_loss=0.000181, test_loss=0.000184]\u001b[AAdjusting learning rate of group 0 to 7.3869e-03.\n",
      "Epoch 120:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 141.11it/s, loss=1.15e-06, v_num=23, train_loss=0.000181, test_loss=0.000184]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 120:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 134.06it/s, loss=1.15e-06, v_num=23, train_loss=0.000181, test_loss=0.000184]\u001b[A\n",
      "Epoch 120: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 171.85it/s, loss=1.15e-06, v_num=23, train_loss=0.000186, test_loss=0.000187]\u001b[A\n",
      "Epoch 121:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 150.06it/s, loss=1.87e-06, v_num=23, train_loss=0.000186, test_loss=0.000187]\u001b[AAdjusting learning rate of group 0 to 7.3684e-03.\n",
      "Epoch 121:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.67it/s, loss=1.8e-06, v_num=23, train_loss=0.000186, test_loss=0.000187]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 121:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.58it/s, loss=1.8e-06, v_num=23, train_loss=0.000186, test_loss=0.000187]\u001b[A\n",
      "Epoch 121: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.80it/s, loss=1.8e-06, v_num=23, train_loss=0.000261, test_loss=0.000264]\u001b[A\n",
      "Epoch 122:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.38it/s, loss=1.67e-06, v_num=23, train_loss=0.000261, test_loss=0.000264]\u001b[AAdjusting learning rate of group 0 to 7.3500e-03.\n",
      "Epoch 122:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 140.76it/s, loss=1.59e-06, v_num=23, train_loss=0.000261, test_loss=0.000264]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 122:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.51it/s, loss=1.59e-06, v_num=23, train_loss=0.000261, test_loss=0.000264]\u001b[A\n",
      "Epoch 122: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.95it/s, loss=1.59e-06, v_num=23, train_loss=0.000208, test_loss=0.000208]\u001b[A\n",
      "Epoch 123:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 147.98it/s, loss=3.44e-06, v_num=23, train_loss=0.000208, test_loss=0.000208]\u001b[AAdjusting learning rate of group 0 to 7.3316e-03.\n",
      "Epoch 123:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.03it/s, loss=3.31e-06, v_num=23, train_loss=0.000208, test_loss=0.000208]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 123:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 130.99it/s, loss=3.31e-06, v_num=23, train_loss=0.000208, test_loss=0.000208]\u001b[A\n",
      "Epoch 123: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 165.92it/s, loss=3.31e-06, v_num=23, train_loss=0.000448, test_loss=0.000455]\u001b[A\n",
      "Epoch 124:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.83it/s, loss=1.32e-06, v_num=23, train_loss=0.000448, test_loss=0.000455]\u001b[AAdjusting learning rate of group 0 to 7.3133e-03.\n",
      "Epoch 124:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.05it/s, loss=1.25e-06, v_num=23, train_loss=0.000448, test_loss=0.000455]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 124:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 133.43it/s, loss=1.25e-06, v_num=23, train_loss=0.000448, test_loss=0.000455]\u001b[A\n",
      "Epoch 124: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.60it/s, loss=1.25e-06, v_num=23, train_loss=7.43e-5, test_loss=7.47e-5]\u001b[A\n",
      "Epoch 125:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.66it/s, loss=1.25e-06, v_num=23, train_loss=7.43e-5, test_loss=7.47e-5]\u001b[AAdjusting learning rate of group 0 to 7.2950e-03.\n",
      "Epoch 125:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.90it/s, loss=1.2e-06, v_num=23, train_loss=7.43e-5, test_loss=7.47e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 125:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.90it/s, loss=1.2e-06, v_num=23, train_loss=7.43e-5, test_loss=7.47e-5]\u001b[A\n",
      "Epoch 125: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.68it/s, loss=1.2e-06, v_num=23, train_loss=0.000133, test_loss=0.000138]\u001b[A\n",
      "Epoch 126:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.30it/s, loss=1.57e-06, v_num=23, train_loss=0.000133, test_loss=0.000138]\u001b[AAdjusting learning rate of group 0 to 7.2768e-03.\n",
      "Epoch 126:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 139.54it/s, loss=1.49e-06, v_num=23, train_loss=0.000133, test_loss=0.000138]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 126:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 133.24it/s, loss=1.49e-06, v_num=23, train_loss=0.000133, test_loss=0.000138]\u001b[A\n",
      "Epoch 126: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.81it/s, loss=1.49e-06, v_num=23, train_loss=0.000255, test_loss=0.000255]\u001b[A\n",
      "Epoch 127:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 150.09it/s, loss=2.57e-06, v_num=23, train_loss=0.000255, test_loss=0.000255]\u001b[AAdjusting learning rate of group 0 to 7.2586e-03.\n",
      "Epoch 127:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 139.09it/s, loss=2.39e-06, v_num=23, train_loss=0.000255, test_loss=0.000255]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 127:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 133.23it/s, loss=2.39e-06, v_num=23, train_loss=0.000255, test_loss=0.000255]\u001b[A\n",
      "Epoch 127: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.02it/s, loss=2.39e-06, v_num=23, train_loss=0.000301, test_loss=0.000302]\u001b[A\n",
      "Epoch 128:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.22it/s, loss=2.87e-06, v_num=23, train_loss=0.000301, test_loss=0.000302]\u001b[AAdjusting learning rate of group 0 to 7.2404e-03.\n",
      "Epoch 128:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.96it/s, loss=2.76e-06, v_num=23, train_loss=0.000301, test_loss=0.000302]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 128:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.28it/s, loss=2.76e-06, v_num=23, train_loss=0.000301, test_loss=0.000302]\u001b[A\n",
      "Epoch 128: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.89it/s, loss=2.76e-06, v_num=23, train_loss=0.000275, test_loss=0.000278]\u001b[A\n",
      "Epoch 129:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.79it/s, loss=1.31e-06, v_num=23, train_loss=0.000275, test_loss=0.000278]\u001b[AAdjusting learning rate of group 0 to 7.2223e-03.\n",
      "Epoch 129:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.81it/s, loss=1.24e-06, v_num=23, train_loss=0.000275, test_loss=0.000278]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 129:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 133.64it/s, loss=1.24e-06, v_num=23, train_loss=0.000275, test_loss=0.000278]\u001b[A\n",
      "Epoch 129: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 171.10it/s, loss=1.24e-06, v_num=23, train_loss=0.000117, test_loss=0.000121]\u001b[A\n",
      "Epoch 130:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.97it/s, loss=1.33e-06, v_num=23, train_loss=0.000117, test_loss=0.000121]\u001b[AAdjusting learning rate of group 0 to 7.2043e-03.\n",
      "Epoch 130:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.70it/s, loss=1.28e-06, v_num=23, train_loss=0.000117, test_loss=0.000121]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 130:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.33it/s, loss=1.28e-06, v_num=23, train_loss=0.000117, test_loss=0.000121]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.54it/s, loss=1.28e-06, v_num=23, train_loss=0.000136, test_loss=0.000137]\u001b[A\n",
      "Epoch 131:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 147.84it/s, loss=1.75e-06, v_num=23, train_loss=0.000136, test_loss=0.000137]\u001b[AAdjusting learning rate of group 0 to 7.1863e-03.\n",
      "Epoch 131:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.31it/s, loss=1.65e-06, v_num=23, train_loss=0.000136, test_loss=0.000137]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 131:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.34it/s, loss=1.65e-06, v_num=23, train_loss=0.000136, test_loss=0.000137]\u001b[A\n",
      "Epoch 131: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.89it/s, loss=1.65e-06, v_num=23, train_loss=9.44e-5, test_loss=0.00011]\u001b[A\n",
      "Epoch 132:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.52it/s, loss=9.75e-07, v_num=23, train_loss=9.44e-5, test_loss=0.00011]\u001b[AAdjusting learning rate of group 0 to 7.1683e-03.\n",
      "Epoch 132:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.99it/s, loss=9.2e-07, v_num=23, train_loss=9.44e-5, test_loss=0.00011]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 132:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 134.47it/s, loss=9.2e-07, v_num=23, train_loss=9.44e-5, test_loss=0.00011]\u001b[A\n",
      "Epoch 132: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 171.92it/s, loss=9.2e-07, v_num=23, train_loss=7.9e-5, test_loss=7.98e-5]\u001b[A\n",
      "Epoch 133:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 150.66it/s, loss=1.28e-06, v_num=23, train_loss=7.9e-5, test_loss=7.98e-5]\u001b[AAdjusting learning rate of group 0 to 7.1504e-03.\n",
      "Epoch 133:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.19it/s, loss=1.21e-06, v_num=23, train_loss=7.9e-5, test_loss=7.98e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 133:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.85it/s, loss=1.21e-06, v_num=23, train_loss=7.9e-5, test_loss=7.98e-5]\u001b[A\n",
      "Epoch 133: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.68it/s, loss=1.21e-06, v_num=23, train_loss=0.000371, test_loss=0.000372]\u001b[A\n",
      "Epoch 134:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 147.44it/s, loss=9.24e-07, v_num=23, train_loss=0.000371, test_loss=0.000372]\u001b[AAdjusting learning rate of group 0 to 7.1325e-03.\n",
      "Epoch 134:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.06it/s, loss=8.88e-07, v_num=23, train_loss=0.000371, test_loss=0.000372]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 134:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 130.80it/s, loss=8.88e-07, v_num=23, train_loss=0.000371, test_loss=0.000372]\u001b[A\n",
      "Epoch 134: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.58it/s, loss=8.88e-07, v_num=23, train_loss=7.75e-5, test_loss=7.67e-5]\u001b[A\n",
      "Epoch 135:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.43it/s, loss=1.16e-06, v_num=23, train_loss=7.75e-5, test_loss=7.67e-5]\u001b[AAdjusting learning rate of group 0 to 7.1147e-03.\n",
      "Epoch 135:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.53it/s, loss=1.13e-06, v_num=23, train_loss=7.75e-5, test_loss=7.67e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 135:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.62it/s, loss=1.13e-06, v_num=23, train_loss=7.75e-5, test_loss=7.67e-5]\u001b[A\n",
      "Epoch 135: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.96it/s, loss=1.13e-06, v_num=23, train_loss=0.000312, test_loss=0.00031]\u001b[A\n",
      "Epoch 136:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.67it/s, loss=2.56e-06, v_num=23, train_loss=0.000312, test_loss=0.00031]\u001b[AAdjusting learning rate of group 0 to 7.0969e-03.\n",
      "Epoch 136:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.71it/s, loss=2.45e-06, v_num=23, train_loss=0.000312, test_loss=0.00031]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 136:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.78it/s, loss=2.45e-06, v_num=23, train_loss=0.000312, test_loss=0.00031]\u001b[A\n",
      "Epoch 136: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 169.27it/s, loss=2.45e-06, v_num=23, train_loss=0.000369, test_loss=0.000375]\u001b[A\n",
      "Epoch 137:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.84it/s, loss=1.62e-06, v_num=23, train_loss=0.000369, test_loss=0.000375]\u001b[AAdjusting learning rate of group 0 to 7.0791e-03.\n",
      "Epoch 137:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.87it/s, loss=1.58e-06, v_num=23, train_loss=0.000369, test_loss=0.000375]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 137:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.59it/s, loss=1.58e-06, v_num=23, train_loss=0.000369, test_loss=0.000375]\u001b[A\n",
      "Epoch 137: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 166.85it/s, loss=1.58e-06, v_num=23, train_loss=0.000202, test_loss=0.000212]\u001b[A\n",
      "Epoch 138:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.69it/s, loss=2.11e-06, v_num=23, train_loss=0.000202, test_loss=0.000212]\u001b[AAdjusting learning rate of group 0 to 7.0614e-03.\n",
      "Epoch 138:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 139.78it/s, loss=2.08e-06, v_num=23, train_loss=0.000202, test_loss=0.000212]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 138:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 133.66it/s, loss=2.08e-06, v_num=23, train_loss=0.000202, test_loss=0.000212]\u001b[A\n",
      "Epoch 138: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.75it/s, loss=2.08e-06, v_num=23, train_loss=0.000959, test_loss=0.000971]\u001b[A\n",
      "Epoch 139:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.62it/s, loss=3.62e-06, v_num=23, train_loss=0.000959, test_loss=0.000971]\u001b[AAdjusting learning rate of group 0 to 7.0438e-03.\n",
      "Epoch 139:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.70it/s, loss=3.32e-06, v_num=23, train_loss=0.000959, test_loss=0.000971]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 139:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 130.67it/s, loss=3.32e-06, v_num=23, train_loss=0.000959, test_loss=0.000971]\u001b[A\n",
      "Epoch 139: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 166.28it/s, loss=3.32e-06, v_num=23, train_loss=0.000249, test_loss=0.000251]\u001b[A\n",
      "Epoch 140:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.98it/s, loss=1.32e-06, v_num=23, train_loss=0.000249, test_loss=0.000251]\u001b[AAdjusting learning rate of group 0 to 7.0262e-03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 140.40it/s, loss=1.23e-06, v_num=23, train_loss=0.000249, test_loss=0.000251]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 140:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.55it/s, loss=1.23e-06, v_num=23, train_loss=0.000249, test_loss=0.000251]\u001b[A\n",
      "Epoch 140: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.62it/s, loss=1.23e-06, v_num=23, train_loss=0.000136, test_loss=0.000139]\u001b[A\n",
      "Epoch 141:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.85it/s, loss=8.43e-07, v_num=23, train_loss=0.000136, test_loss=0.000139]\u001b[AAdjusting learning rate of group 0 to 7.0086e-03.\n",
      "Epoch 141:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 140.87it/s, loss=7.93e-07, v_num=23, train_loss=0.000136, test_loss=0.000139]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 141:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 134.16it/s, loss=7.93e-07, v_num=23, train_loss=0.000136, test_loss=0.000139]\u001b[A\n",
      "Epoch 141: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 169.66it/s, loss=7.93e-07, v_num=23, train_loss=0.000125, test_loss=0.000125]\u001b[A\n",
      "Epoch 142:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.49it/s, loss=1.03e-06, v_num=23, train_loss=0.000125, test_loss=0.000125]\u001b[AAdjusting learning rate of group 0 to 6.9911e-03.\n",
      "Epoch 142:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.68it/s, loss=1e-06, v_num=23, train_loss=0.000125, test_loss=0.000125]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 142:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 134.89it/s, loss=1e-06, v_num=23, train_loss=0.000125, test_loss=0.000125]\u001b[A\n",
      "Epoch 142: 100%|██████████████████████████████████████████| 158/158 [00:00<00:00, 169.96it/s, loss=1e-06, v_num=23, train_loss=9.83e-5, test_loss=0.0001]\u001b[A\n",
      "Epoch 143:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.47it/s, loss=9.8e-07, v_num=23, train_loss=9.83e-5, test_loss=0.0001]\u001b[AAdjusting learning rate of group 0 to 6.9736e-03.\n",
      "Epoch 143:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.27it/s, loss=9.58e-07, v_num=23, train_loss=9.83e-5, test_loss=0.0001]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 143:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.20it/s, loss=9.58e-07, v_num=23, train_loss=9.83e-5, test_loss=0.0001]\u001b[A\n",
      "Epoch 143: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.26it/s, loss=9.58e-07, v_num=23, train_loss=0.000381, test_loss=0.00038]\u001b[A\n",
      "Epoch 144:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 143.47it/s, loss=1.44e-06, v_num=23, train_loss=0.000381, test_loss=0.00038]\u001b[AAdjusting learning rate of group 0 to 6.9562e-03.\n",
      "Epoch 144:  50%|███████████████████                   | 79/158 [00:00<00:00, 133.70it/s, loss=1.41e-06, v_num=23, train_loss=0.000381, test_loss=0.00038]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 144:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 126.98it/s, loss=1.41e-06, v_num=23, train_loss=0.000381, test_loss=0.00038]\u001b[A\n",
      "Epoch 144: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 163.94it/s, loss=1.41e-06, v_num=23, train_loss=0.000258, test_loss=0.000258]\u001b[A\n",
      "Epoch 145:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.53it/s, loss=1.31e-06, v_num=23, train_loss=0.000258, test_loss=0.000258]\u001b[AAdjusting learning rate of group 0 to 6.9388e-03.\n",
      "Epoch 145:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.86it/s, loss=1.28e-06, v_num=23, train_loss=0.000258, test_loss=0.000258]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 145:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 128.71it/s, loss=1.28e-06, v_num=23, train_loss=0.000258, test_loss=0.000258]\u001b[A\n",
      "Epoch 145: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.87it/s, loss=1.28e-06, v_num=23, train_loss=0.000213, test_loss=0.00022]\u001b[A\n",
      "Epoch 146:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.29it/s, loss=2.06e-06, v_num=23, train_loss=0.000213, test_loss=0.00022]\u001b[AAdjusting learning rate of group 0 to 6.9214e-03.\n",
      "Epoch 146:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.27it/s, loss=2.03e-06, v_num=23, train_loss=0.000213, test_loss=0.00022]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 146:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.11it/s, loss=2.03e-06, v_num=23, train_loss=0.000213, test_loss=0.00022]\u001b[A\n",
      "Epoch 146: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.74it/s, loss=2.03e-06, v_num=23, train_loss=0.000171, test_loss=0.00017]\u001b[A\n",
      "Epoch 147:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.71it/s, loss=3.45e-06, v_num=23, train_loss=0.000171, test_loss=0.00017]\u001b[AAdjusting learning rate of group 0 to 6.9041e-03.\n",
      "Epoch 147:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.60it/s, loss=3.26e-06, v_num=23, train_loss=0.000171, test_loss=0.00017]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 147:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.37it/s, loss=3.26e-06, v_num=23, train_loss=0.000171, test_loss=0.00017]\u001b[A\n",
      "Epoch 147: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.85it/s, loss=3.26e-06, v_num=23, train_loss=0.000428, test_loss=0.000433]\u001b[A\n",
      "Epoch 148:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 147.37it/s, loss=2.76e-06, v_num=23, train_loss=0.000428, test_loss=0.000433]\u001b[AAdjusting learning rate of group 0 to 6.8869e-03.\n",
      "Epoch 148:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.52it/s, loss=2.75e-06, v_num=23, train_loss=0.000428, test_loss=0.000433]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 148:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.39it/s, loss=2.75e-06, v_num=23, train_loss=0.000428, test_loss=0.000433]\u001b[A\n",
      "Epoch 148: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 166.13it/s, loss=2.75e-06, v_num=23, train_loss=0.000651, test_loss=0.000651]\u001b[A\n",
      "Epoch 149:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.77it/s, loss=1.53e-06, v_num=23, train_loss=0.000651, test_loss=0.000651]\u001b[AAdjusting learning rate of group 0 to 6.8697e-03.\n",
      "Epoch 149:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 141.04it/s, loss=1.35e-06, v_num=23, train_loss=0.000651, test_loss=0.000651]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.77it/s, loss=1.35e-06, v_num=23, train_loss=0.000651, test_loss=0.000651]\u001b[A\n",
      "Epoch 149: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.42it/s, loss=1.35e-06, v_num=23, train_loss=0.000116, test_loss=0.000115]\u001b[A\n",
      "Epoch 150:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.21it/s, loss=6.21e-07, v_num=23, train_loss=0.000116, test_loss=0.000115]\u001b[AAdjusting learning rate of group 0 to 6.8525e-03.\n",
      "Epoch 150:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.51it/s, loss=5.85e-07, v_num=23, train_loss=0.000116, test_loss=0.000115]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 150:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.37it/s, loss=5.85e-07, v_num=23, train_loss=0.000116, test_loss=0.000115]\u001b[A\n",
      "Epoch 150: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.34it/s, loss=5.85e-07, v_num=23, train_loss=4.77e-5, test_loss=4.81e-5]\u001b[A\n",
      "Epoch 151:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.47it/s, loss=1.18e-06, v_num=23, train_loss=4.77e-5, test_loss=4.81e-5]\u001b[AAdjusting learning rate of group 0 to 6.8354e-03.\n",
      "Epoch 151:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.00it/s, loss=1.15e-06, v_num=23, train_loss=4.77e-5, test_loss=4.81e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 151:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.12it/s, loss=1.15e-06, v_num=23, train_loss=4.77e-5, test_loss=4.81e-5]\u001b[A\n",
      "Epoch 151: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.00it/s, loss=1.15e-06, v_num=23, train_loss=0.000118, test_loss=0.00012]\u001b[A\n",
      "Epoch 152:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.82it/s, loss=7.41e-07, v_num=23, train_loss=0.000118, test_loss=0.00012]\u001b[AAdjusting learning rate of group 0 to 6.8183e-03.\n",
      "Epoch 152:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.06it/s, loss=7.01e-07, v_num=23, train_loss=0.000118, test_loss=0.00012]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 152:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.16it/s, loss=7.01e-07, v_num=23, train_loss=0.000118, test_loss=0.00012]\u001b[A\n",
      "Epoch 152: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.83it/s, loss=7.01e-07, v_num=23, train_loss=0.000154, test_loss=0.000156]\u001b[A\n",
      "Epoch 153:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.95it/s, loss=7.56e-07, v_num=23, train_loss=0.000154, test_loss=0.000156]\u001b[AAdjusting learning rate of group 0 to 6.8012e-03.\n",
      "Epoch 153:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 142.06it/s, loss=7.12e-07, v_num=23, train_loss=0.000154, test_loss=0.000156]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 153:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 134.26it/s, loss=7.12e-07, v_num=23, train_loss=0.000154, test_loss=0.000156]\u001b[A\n",
      "Epoch 153: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.75it/s, loss=7.12e-07, v_num=23, train_loss=0.00011, test_loss=0.00011]\u001b[A\n",
      "Epoch 154:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.61it/s, loss=8.46e-07, v_num=23, train_loss=0.00011, test_loss=0.00011]\u001b[AAdjusting learning rate of group 0 to 6.7842e-03.\n",
      "Epoch 154:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.20it/s, loss=7.86e-07, v_num=23, train_loss=0.00011, test_loss=0.00011]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 154:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.25it/s, loss=7.86e-07, v_num=23, train_loss=0.00011, test_loss=0.00011]\u001b[A\n",
      "Epoch 154: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.94it/s, loss=7.86e-07, v_num=23, train_loss=0.000116, test_loss=0.000117]\u001b[A\n",
      "Epoch 155:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.60it/s, loss=8.06e-07, v_num=23, train_loss=0.000116, test_loss=0.000117]\u001b[AAdjusting learning rate of group 0 to 6.7673e-03.\n",
      "Epoch 155:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 140.71it/s, loss=7.63e-07, v_num=23, train_loss=0.000116, test_loss=0.000117]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 155:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 134.15it/s, loss=7.63e-07, v_num=23, train_loss=0.000116, test_loss=0.000117]\u001b[A\n",
      "Epoch 155: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 169.83it/s, loss=7.63e-07, v_num=23, train_loss=0.000107, test_loss=0.000109]\u001b[A\n",
      "Epoch 156:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.65it/s, loss=1.49e-06, v_num=23, train_loss=0.000107, test_loss=0.000109]\u001b[AAdjusting learning rate of group 0 to 6.7503e-03.\n",
      "Epoch 156:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 140.77it/s, loss=1.46e-06, v_num=23, train_loss=0.000107, test_loss=0.000109]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 156:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.19it/s, loss=1.46e-06, v_num=23, train_loss=0.000107, test_loss=0.000109]\u001b[A\n",
      "Epoch 156: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.60it/s, loss=1.46e-06, v_num=23, train_loss=0.000272, test_loss=0.000267]\u001b[A\n",
      "Epoch 157:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.38it/s, loss=5.77e-07, v_num=23, train_loss=0.000272, test_loss=0.000267]\u001b[AAdjusting learning rate of group 0 to 6.7335e-03.\n",
      "Epoch 157:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 139.02it/s, loss=5.33e-07, v_num=23, train_loss=0.000272, test_loss=0.000267]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 157:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 130.40it/s, loss=5.33e-07, v_num=23, train_loss=0.000272, test_loss=0.000267]\u001b[A\n",
      "Epoch 157: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.45it/s, loss=5.33e-07, v_num=23, train_loss=4.34e-5, test_loss=4.45e-5]\u001b[A\n",
      "Epoch 158:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.34it/s, loss=6.66e-07, v_num=23, train_loss=4.34e-5, test_loss=4.45e-5]\u001b[AAdjusting learning rate of group 0 to 6.7166e-03.\n",
      "Epoch 158:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.25it/s, loss=6.4e-07, v_num=23, train_loss=4.34e-5, test_loss=4.45e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 158:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.33it/s, loss=6.4e-07, v_num=23, train_loss=4.34e-5, test_loss=4.45e-5]\u001b[A\n",
      "Epoch 158: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.02it/s, loss=6.4e-07, v_num=23, train_loss=0.000168, test_loss=0.00017]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.73it/s, loss=1.33e-06, v_num=23, train_loss=0.000168, test_loss=0.00017]\u001b[AAdjusting learning rate of group 0 to 6.6998e-03.\n",
      "Epoch 159:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.80it/s, loss=1.26e-06, v_num=23, train_loss=0.000168, test_loss=0.00017]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 159:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.82it/s, loss=1.26e-06, v_num=23, train_loss=0.000168, test_loss=0.00017]\u001b[A\n",
      "Epoch 159: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.12it/s, loss=1.26e-06, v_num=23, train_loss=0.000137, test_loss=0.000138]\u001b[A\n",
      "Epoch 160:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 146.38it/s, loss=2.98e-06, v_num=23, train_loss=0.000137, test_loss=0.000138]\u001b[AAdjusting learning rate of group 0 to 6.6831e-03.\n",
      "Epoch 160:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.04it/s, loss=2.9e-06, v_num=23, train_loss=0.000137, test_loss=0.000138]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 160:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.40it/s, loss=2.9e-06, v_num=23, train_loss=0.000137, test_loss=0.000138]\u001b[A\n",
      "Epoch 160: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.05it/s, loss=2.9e-06, v_num=23, train_loss=0.000334, test_loss=0.00033]\u001b[A\n",
      "Epoch 161:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.69it/s, loss=1.23e-06, v_num=23, train_loss=0.000334, test_loss=0.00033]\u001b[AAdjusting learning rate of group 0 to 6.6664e-03.\n",
      "Epoch 161:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.35it/s, loss=1.2e-06, v_num=23, train_loss=0.000334, test_loss=0.00033]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 161:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.83it/s, loss=1.2e-06, v_num=23, train_loss=0.000334, test_loss=0.00033]\u001b[A\n",
      "Epoch 161: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.99it/s, loss=1.2e-06, v_num=23, train_loss=0.000145, test_loss=0.000146]\u001b[A\n",
      "Epoch 162:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.41it/s, loss=2.72e-06, v_num=23, train_loss=0.000145, test_loss=0.000146]\u001b[AAdjusting learning rate of group 0 to 6.6497e-03.\n",
      "Epoch 162:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 139.24it/s, loss=2.66e-06, v_num=23, train_loss=0.000145, test_loss=0.000146]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 162:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 133.24it/s, loss=2.66e-06, v_num=23, train_loss=0.000145, test_loss=0.000146]\u001b[A\n",
      "Epoch 162: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.72it/s, loss=2.66e-06, v_num=23, train_loss=0.000483, test_loss=0.000481]\u001b[A\n",
      "Epoch 163:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.40it/s, loss=8.51e-07, v_num=23, train_loss=0.000483, test_loss=0.000481]\u001b[AAdjusting learning rate of group 0 to 6.6331e-03.\n",
      "Epoch 163:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.01it/s, loss=8.22e-07, v_num=23, train_loss=0.000483, test_loss=0.000481]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 163:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.56it/s, loss=8.22e-07, v_num=23, train_loss=0.000483, test_loss=0.000481]\u001b[A\n",
      "Epoch 163: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 169.55it/s, loss=8.22e-07, v_num=23, train_loss=0.000143, test_loss=0.000139]\u001b[A\n",
      "Epoch 164:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.12it/s, loss=9.33e-07, v_num=23, train_loss=0.000143, test_loss=0.000139]\u001b[AAdjusting learning rate of group 0 to 6.6165e-03.\n",
      "Epoch 164:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.11it/s, loss=8.69e-07, v_num=23, train_loss=0.000143, test_loss=0.000139]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 164:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.65it/s, loss=8.69e-07, v_num=23, train_loss=0.000143, test_loss=0.000139]\u001b[A\n",
      "Epoch 164: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.49it/s, loss=8.69e-07, v_num=23, train_loss=0.00011, test_loss=0.00011]\u001b[A\n",
      "Epoch 165:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.15it/s, loss=9.81e-07, v_num=23, train_loss=0.00011, test_loss=0.00011]\u001b[AAdjusting learning rate of group 0 to 6.6000e-03.\n",
      "Epoch 165:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.96it/s, loss=9.58e-07, v_num=23, train_loss=0.00011, test_loss=0.00011]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 165:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.09it/s, loss=9.58e-07, v_num=23, train_loss=0.00011, test_loss=0.00011]\u001b[A\n",
      "Epoch 165: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.45it/s, loss=9.58e-07, v_num=23, train_loss=5.18e-5, test_loss=5.24e-5]\u001b[A\n",
      "Epoch 166:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.33it/s, loss=1.23e-06, v_num=23, train_loss=5.18e-5, test_loss=5.24e-5]\u001b[AAdjusting learning rate of group 0 to 6.5835e-03.\n",
      "Epoch 166:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.26it/s, loss=1.18e-06, v_num=23, train_loss=5.18e-5, test_loss=5.24e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 166:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.05it/s, loss=1.18e-06, v_num=23, train_loss=5.18e-5, test_loss=5.24e-5]\u001b[A\n",
      "Epoch 166: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.89it/s, loss=1.18e-06, v_num=23, train_loss=8.43e-5, test_loss=8.55e-5]\u001b[A\n",
      "Epoch 167:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.23it/s, loss=1.62e-06, v_num=23, train_loss=8.43e-5, test_loss=8.55e-5]\u001b[AAdjusting learning rate of group 0 to 6.5670e-03.\n",
      "Epoch 167:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.21it/s, loss=1.56e-06, v_num=23, train_loss=8.43e-5, test_loss=8.55e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 167:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.30it/s, loss=1.56e-06, v_num=23, train_loss=8.43e-5, test_loss=8.55e-5]\u001b[A\n",
      "Epoch 167: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.68it/s, loss=1.56e-06, v_num=23, train_loss=0.00022, test_loss=0.00022]\u001b[A\n",
      "Epoch 168:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.00it/s, loss=1.19e-06, v_num=23, train_loss=0.00022, test_loss=0.00022]\u001b[AAdjusting learning rate of group 0 to 6.5506e-03.\n",
      "Epoch 168:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.20it/s, loss=1.12e-06, v_num=23, train_loss=0.00022, test_loss=0.00022]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 168:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.57it/s, loss=1.12e-06, v_num=23, train_loss=0.00022, test_loss=0.00022]\u001b[A\n",
      "Epoch 168: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 166.45it/s, loss=1.12e-06, v_num=23, train_loss=0.000107, test_loss=0.000108]\u001b[A\n",
      "Epoch 169:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 150.09it/s, loss=1.01e-06, v_num=23, train_loss=0.000107, test_loss=0.000108]\u001b[AAdjusting learning rate of group 0 to 6.5342e-03.\n",
      "Epoch 169:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 139.58it/s, loss=9.68e-07, v_num=23, train_loss=0.000107, test_loss=0.000108]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 169:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 133.82it/s, loss=9.68e-07, v_num=23, train_loss=0.000107, test_loss=0.000108]\u001b[A\n",
      "Epoch 169: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 169.13it/s, loss=9.68e-07, v_num=23, train_loss=0.000123, test_loss=0.000125]\u001b[A\n",
      "Epoch 170:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.29it/s, loss=4.75e-07, v_num=23, train_loss=0.000123, test_loss=0.000125]\u001b[AAdjusting learning rate of group 0 to 6.5179e-03.\n",
      "Epoch 170:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.40it/s, loss=4.49e-07, v_num=23, train_loss=0.000123, test_loss=0.000125]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 170:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.32it/s, loss=4.49e-07, v_num=23, train_loss=0.000123, test_loss=0.000125]\u001b[A\n",
      "Epoch 170: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.26it/s, loss=4.49e-07, v_num=23, train_loss=3.74e-5, test_loss=3.84e-5]\u001b[A\n",
      "Epoch 171:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.00it/s, loss=4.85e-07, v_num=23, train_loss=3.74e-5, test_loss=3.84e-5]\u001b[AAdjusting learning rate of group 0 to 6.5016e-03.\n",
      "Epoch 171:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.28it/s, loss=4.59e-07, v_num=23, train_loss=3.74e-5, test_loss=3.84e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 171:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.52it/s, loss=4.59e-07, v_num=23, train_loss=3.74e-5, test_loss=3.84e-5]\u001b[A\n",
      "Epoch 171: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.23it/s, loss=4.59e-07, v_num=23, train_loss=4.36e-5, test_loss=4.41e-5]\u001b[A\n",
      "Epoch 172:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.53it/s, loss=1.15e-06, v_num=23, train_loss=4.36e-5, test_loss=4.41e-5]\u001b[AAdjusting learning rate of group 0 to 6.4853e-03.\n",
      "Epoch 172:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.69it/s, loss=1.06e-06, v_num=23, train_loss=4.36e-5, test_loss=4.41e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 172:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.69it/s, loss=1.06e-06, v_num=23, train_loss=4.36e-5, test_loss=4.41e-5]\u001b[A\n",
      "Epoch 172: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 169.35it/s, loss=1.06e-06, v_num=23, train_loss=0.000155, test_loss=0.000155]\u001b[A\n",
      "Epoch 173:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.55it/s, loss=1.67e-06, v_num=23, train_loss=0.000155, test_loss=0.000155]\u001b[AAdjusting learning rate of group 0 to 6.4691e-03.\n",
      "Epoch 173:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 141.36it/s, loss=1.61e-06, v_num=23, train_loss=0.000155, test_loss=0.000155]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 173:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 134.38it/s, loss=1.61e-06, v_num=23, train_loss=0.000155, test_loss=0.000155]\u001b[A\n",
      "Epoch 173: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 171.37it/s, loss=1.61e-06, v_num=23, train_loss=0.000279, test_loss=0.000282]\u001b[A\n",
      "Epoch 174:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.44it/s, loss=1.06e-06, v_num=23, train_loss=0.000279, test_loss=0.000282]\u001b[AAdjusting learning rate of group 0 to 6.4529e-03.\n",
      "Epoch 174:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 141.64it/s, loss=1.03e-06, v_num=23, train_loss=0.000279, test_loss=0.000282]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 174:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 133.27it/s, loss=1.03e-06, v_num=23, train_loss=0.000279, test_loss=0.000282]\u001b[A\n",
      "Epoch 174: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.96it/s, loss=1.03e-06, v_num=23, train_loss=0.000214, test_loss=0.000219]\u001b[A\n",
      "Epoch 175:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.72it/s, loss=2.13e-06, v_num=23, train_loss=0.000214, test_loss=0.000219]\u001b[AAdjusting learning rate of group 0 to 6.4368e-03.\n",
      "Epoch 175:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.93it/s, loss=2e-06, v_num=23, train_loss=0.000214, test_loss=0.000219]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 175:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.79it/s, loss=2e-06, v_num=23, train_loss=0.000214, test_loss=0.000219]\u001b[A\n",
      "Epoch 175: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.49it/s, loss=2e-06, v_num=23, train_loss=0.000151, test_loss=0.000157]\u001b[A\n",
      "Epoch 176:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 147.26it/s, loss=6.98e-07, v_num=23, train_loss=0.000151, test_loss=0.000157]\u001b[AAdjusting learning rate of group 0 to 6.4207e-03.\n",
      "Epoch 176:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 136.76it/s, loss=6.65e-07, v_num=23, train_loss=0.000151, test_loss=0.000157]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 176:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.26it/s, loss=6.65e-07, v_num=23, train_loss=0.000151, test_loss=0.000157]\u001b[A\n",
      "Epoch 176: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 166.69it/s, loss=6.65e-07, v_num=23, train_loss=0.000169, test_loss=0.000172]\u001b[A\n",
      "Epoch 177:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.63it/s, loss=2.04e-06, v_num=23, train_loss=0.000169, test_loss=0.000172]\u001b[AAdjusting learning rate of group 0 to 6.4047e-03.\n",
      "Epoch 177:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.67it/s, loss=2.05e-06, v_num=23, train_loss=0.000169, test_loss=0.000172]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 177:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 130.96it/s, loss=2.05e-06, v_num=23, train_loss=0.000169, test_loss=0.000172]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.79it/s, loss=2.05e-06, v_num=23, train_loss=0.000453, test_loss=0.000456]\u001b[A\n",
      "Epoch 178:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.34it/s, loss=1.75e-06, v_num=23, train_loss=0.000453, test_loss=0.000456]\u001b[AAdjusting learning rate of group 0 to 6.3887e-03.\n",
      "Epoch 178:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.30it/s, loss=1.68e-06, v_num=23, train_loss=0.000453, test_loss=0.000456]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 178:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 130.53it/s, loss=1.68e-06, v_num=23, train_loss=0.000453, test_loss=0.000456]\u001b[A\n",
      "Epoch 178: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.27it/s, loss=1.68e-06, v_num=23, train_loss=0.000157, test_loss=0.000161]\u001b[A\n",
      "Epoch 179:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 147.87it/s, loss=1.05e-06, v_num=23, train_loss=0.000157, test_loss=0.000161]\u001b[AAdjusting learning rate of group 0 to 6.3727e-03.\n",
      "Epoch 179:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 136.97it/s, loss=1.01e-06, v_num=23, train_loss=0.000157, test_loss=0.000161]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 179:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 130.44it/s, loss=1.01e-06, v_num=23, train_loss=0.000157, test_loss=0.000161]\u001b[A\n",
      "Epoch 179: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 164.92it/s, loss=1.01e-06, v_num=23, train_loss=0.000133, test_loss=0.000135]\u001b[A\n",
      "Epoch 180:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 147.96it/s, loss=7.65e-07, v_num=23, train_loss=0.000133, test_loss=0.000135]\u001b[AAdjusting learning rate of group 0 to 6.3568e-03.\n",
      "Epoch 180:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.27it/s, loss=7.12e-07, v_num=23, train_loss=0.000133, test_loss=0.000135]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 180:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 129.40it/s, loss=7.12e-07, v_num=23, train_loss=0.000133, test_loss=0.000135]\u001b[A\n",
      "Epoch 180: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 166.29it/s, loss=7.12e-07, v_num=23, train_loss=0.000115, test_loss=0.000113]\u001b[A\n",
      "Epoch 181:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.31it/s, loss=1.77e-06, v_num=23, train_loss=0.000115, test_loss=0.000113]\u001b[AAdjusting learning rate of group 0 to 6.3409e-03.\n",
      "Epoch 181:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.72it/s, loss=1.72e-06, v_num=23, train_loss=0.000115, test_loss=0.000113]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 181:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.18it/s, loss=1.72e-06, v_num=23, train_loss=0.000115, test_loss=0.000113]\u001b[A\n",
      "Epoch 181: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.28it/s, loss=1.72e-06, v_num=23, train_loss=0.000207, test_loss=0.000213]\u001b[A\n",
      "Epoch 182:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 147.64it/s, loss=1.66e-06, v_num=23, train_loss=0.000207, test_loss=0.000213]\u001b[AAdjusting learning rate of group 0 to 6.3250e-03.\n",
      "Epoch 182:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 139.90it/s, loss=1.61e-06, v_num=23, train_loss=0.000207, test_loss=0.000213]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 182:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 133.71it/s, loss=1.61e-06, v_num=23, train_loss=0.000207, test_loss=0.000213]\u001b[A\n",
      "Epoch 182: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.99it/s, loss=1.61e-06, v_num=23, train_loss=0.000162, test_loss=0.000165]\u001b[A\n",
      "Epoch 183:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.49it/s, loss=4.11e-06, v_num=23, train_loss=0.000162, test_loss=0.000165]\u001b[AAdjusting learning rate of group 0 to 6.3092e-03.\n",
      "Epoch 183:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.20it/s, loss=4e-06, v_num=23, train_loss=0.000162, test_loss=0.000165]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 183:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.34it/s, loss=4e-06, v_num=23, train_loss=0.000162, test_loss=0.000165]\u001b[A\n",
      "Epoch 183: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 166.61it/s, loss=4e-06, v_num=23, train_loss=0.00052, test_loss=0.00052]\u001b[A\n",
      "Epoch 184:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.82it/s, loss=1.54e-06, v_num=23, train_loss=0.00052, test_loss=0.00052]\u001b[AAdjusting learning rate of group 0 to 6.2934e-03.\n",
      "Epoch 184:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.86it/s, loss=1.46e-06, v_num=23, train_loss=0.00052, test_loss=0.00052]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 184:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.95it/s, loss=1.46e-06, v_num=23, train_loss=0.00052, test_loss=0.00052]\u001b[A\n",
      "Epoch 184: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.57it/s, loss=1.46e-06, v_num=23, train_loss=0.000133, test_loss=0.000135]\u001b[A\n",
      "Epoch 185:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.80it/s, loss=1.42e-06, v_num=23, train_loss=0.000133, test_loss=0.000135]\u001b[AAdjusting learning rate of group 0 to 6.2777e-03.\n",
      "Epoch 185:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.30it/s, loss=1.37e-06, v_num=23, train_loss=0.000133, test_loss=0.000135]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 185:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.31it/s, loss=1.37e-06, v_num=23, train_loss=0.000133, test_loss=0.000135]\u001b[A\n",
      "Epoch 185: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.02it/s, loss=1.37e-06, v_num=23, train_loss=0.000152, test_loss=0.000155]\u001b[A\n",
      "Epoch 186:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.11it/s, loss=1.03e-06, v_num=23, train_loss=0.000152, test_loss=0.000155]\u001b[AAdjusting learning rate of group 0 to 6.2620e-03.\n",
      "Epoch 186:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 140.17it/s, loss=9.46e-07, v_num=23, train_loss=0.000152, test_loss=0.000155]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 186:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 133.68it/s, loss=9.46e-07, v_num=23, train_loss=0.000152, test_loss=0.000155]\u001b[A\n",
      "Epoch 186: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.78it/s, loss=9.46e-07, v_num=23, train_loss=0.000138, test_loss=0.000135]\u001b[A\n",
      "Epoch 187:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.50it/s, loss=8.75e-07, v_num=23, train_loss=0.000138, test_loss=0.000135]\u001b[AAdjusting learning rate of group 0 to 6.2463e-03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 139.21it/s, loss=8.17e-07, v_num=23, train_loss=0.000138, test_loss=0.000135]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 187:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.60it/s, loss=8.17e-07, v_num=23, train_loss=0.000138, test_loss=0.000135]\u001b[A\n",
      "Epoch 187: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.31it/s, loss=8.17e-07, v_num=23, train_loss=9.36e-5, test_loss=9.29e-5]\u001b[A\n",
      "Epoch 188:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.29it/s, loss=5.59e-07, v_num=23, train_loss=9.36e-5, test_loss=9.29e-5]\u001b[AAdjusting learning rate of group 0 to 6.2307e-03.\n",
      "Epoch 188:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.93it/s, loss=5.34e-07, v_num=23, train_loss=9.36e-5, test_loss=9.29e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.40it/s]\u001b[A\n",
      "Epoch 188:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 125.93it/s, loss=5.34e-07, v_num=23, train_loss=9.36e-5, test_loss=9.29e-5]\u001b[A\n",
      "Epoch 188: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 162.23it/s, loss=5.34e-07, v_num=23, train_loss=4.1e-5, test_loss=4.12e-5]\u001b[A\n",
      "Epoch 189:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.15it/s, loss=6.13e-07, v_num=23, train_loss=4.1e-5, test_loss=4.12e-5]\u001b[AAdjusting learning rate of group 0 to 6.2152e-03.\n",
      "Epoch 189:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.95it/s, loss=5.82e-07, v_num=23, train_loss=4.1e-5, test_loss=4.12e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 189:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 135.24it/s, loss=5.82e-07, v_num=23, train_loss=4.1e-5, test_loss=4.12e-5]\u001b[A\n",
      "Epoch 189: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 172.07it/s, loss=5.82e-07, v_num=23, train_loss=0.000118, test_loss=0.00012]\u001b[A\n",
      "Epoch 190:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.42it/s, loss=1.52e-06, v_num=23, train_loss=0.000118, test_loss=0.00012]\u001b[AAdjusting learning rate of group 0 to 6.1996e-03.\n",
      "Epoch 190:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.38it/s, loss=1.47e-06, v_num=23, train_loss=0.000118, test_loss=0.00012]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 190:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.43it/s, loss=1.47e-06, v_num=23, train_loss=0.000118, test_loss=0.00012]\u001b[A\n",
      "Epoch 190: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.80it/s, loss=1.47e-06, v_num=23, train_loss=0.000321, test_loss=0.000324]\u001b[A\n",
      "Epoch 191:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.72it/s, loss=1.2e-06, v_num=23, train_loss=0.000321, test_loss=0.000324]\u001b[AAdjusting learning rate of group 0 to 6.1841e-03.\n",
      "Epoch 191:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.06it/s, loss=1.16e-06, v_num=23, train_loss=0.000321, test_loss=0.000324]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 191:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.88it/s, loss=1.16e-06, v_num=23, train_loss=0.000321, test_loss=0.000324]\u001b[A\n",
      "Epoch 191: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 169.11it/s, loss=1.16e-06, v_num=23, train_loss=0.000277, test_loss=0.000279]\u001b[A\n",
      "Epoch 192:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 147.54it/s, loss=1.47e-06, v_num=23, train_loss=0.000277, test_loss=0.000279]\u001b[AAdjusting learning rate of group 0 to 6.1687e-03.\n",
      "Epoch 192:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.43it/s, loss=1.37e-06, v_num=23, train_loss=0.000277, test_loss=0.000279]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 192:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 133.07it/s, loss=1.37e-06, v_num=23, train_loss=0.000277, test_loss=0.000279]\u001b[A\n",
      "Epoch 192: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.15it/s, loss=1.37e-06, v_num=23, train_loss=0.000129, test_loss=0.000131]\u001b[A\n",
      "Epoch 193:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.82it/s, loss=1.18e-06, v_num=23, train_loss=0.000129, test_loss=0.000131]\u001b[AAdjusting learning rate of group 0 to 6.1532e-03.\n",
      "Epoch 193:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 139.54it/s, loss=1.14e-06, v_num=23, train_loss=0.000129, test_loss=0.000131]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 193:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 133.94it/s, loss=1.14e-06, v_num=23, train_loss=0.000129, test_loss=0.000131]\u001b[A\n",
      "Epoch 193: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.99it/s, loss=1.14e-06, v_num=23, train_loss=0.000204, test_loss=0.000202]\u001b[A\n",
      "Epoch 194:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.09it/s, loss=7.38e-07, v_num=23, train_loss=0.000204, test_loss=0.000202]\u001b[AAdjusting learning rate of group 0 to 6.1379e-03.\n",
      "Epoch 194:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.45it/s, loss=7.1e-07, v_num=23, train_loss=0.000204, test_loss=0.000202]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 194:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.44it/s, loss=7.1e-07, v_num=23, train_loss=0.000204, test_loss=0.000202]\u001b[A\n",
      "Epoch 194: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.65it/s, loss=7.1e-07, v_num=23, train_loss=6.03e-5, test_loss=6.08e-5]\u001b[A\n",
      "Epoch 195:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.91it/s, loss=1.7e-06, v_num=23, train_loss=6.03e-5, test_loss=6.08e-5]\u001b[AAdjusting learning rate of group 0 to 6.1225e-03.\n",
      "Epoch 195:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.94it/s, loss=1.66e-06, v_num=23, train_loss=6.03e-5, test_loss=6.08e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 195:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.23it/s, loss=1.66e-06, v_num=23, train_loss=6.03e-5, test_loss=6.08e-5]\u001b[A\n",
      "Epoch 195: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 169.94it/s, loss=1.66e-06, v_num=23, train_loss=0.000144, test_loss=0.000147]\u001b[A\n",
      "Epoch 196:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.65it/s, loss=1.31e-06, v_num=23, train_loss=0.000144, test_loss=0.000147]\u001b[AAdjusting learning rate of group 0 to 6.1072e-03.\n",
      "Epoch 196:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.56it/s, loss=1.25e-06, v_num=23, train_loss=0.000144, test_loss=0.000147]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 196:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.85it/s, loss=1.25e-06, v_num=23, train_loss=0.000144, test_loss=0.000147]\u001b[A\n",
      "Epoch 196: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.17it/s, loss=1.25e-06, v_num=23, train_loss=0.000145, test_loss=0.000147]\u001b[A\n",
      "Epoch 197:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.43it/s, loss=4.51e-07, v_num=23, train_loss=0.000145, test_loss=0.000147]\u001b[AAdjusting learning rate of group 0 to 6.0919e-03.\n",
      "Epoch 197:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.99it/s, loss=4.3e-07, v_num=23, train_loss=0.000145, test_loss=0.000147]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 197:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.65it/s, loss=4.3e-07, v_num=23, train_loss=0.000145, test_loss=0.000147]\u001b[A\n",
      "Epoch 197: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 166.90it/s, loss=4.3e-07, v_num=23, train_loss=4.1e-5, test_loss=4.12e-5]\u001b[A\n",
      "Epoch 198:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.04it/s, loss=7.38e-07, v_num=23, train_loss=4.1e-5, test_loss=4.12e-5]\u001b[AAdjusting learning rate of group 0 to 6.0767e-03.\n",
      "Epoch 198:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.03it/s, loss=7.04e-07, v_num=23, train_loss=4.1e-5, test_loss=4.12e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 198:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.68it/s, loss=7.04e-07, v_num=23, train_loss=4.1e-5, test_loss=4.12e-5]\u001b[A\n",
      "Epoch 198: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.27it/s, loss=7.04e-07, v_num=23, train_loss=8.02e-5, test_loss=8.06e-5]\u001b[A\n",
      "Epoch 199:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.75it/s, loss=6.07e-07, v_num=23, train_loss=8.02e-5, test_loss=8.06e-5]\u001b[AAdjusting learning rate of group 0 to 6.0615e-03.\n",
      "Epoch 199:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.85it/s, loss=5.81e-07, v_num=23, train_loss=8.02e-5, test_loss=8.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 199:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.88it/s, loss=5.81e-07, v_num=23, train_loss=8.02e-5, test_loss=8.06e-5]\u001b[A\n",
      "Epoch 199: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.69it/s, loss=5.81e-07, v_num=23, train_loss=0.000139, test_loss=0.000138]\u001b[A\n",
      "Epoch 200:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.28it/s, loss=1.58e-06, v_num=23, train_loss=0.000139, test_loss=0.000138]\u001b[AAdjusting learning rate of group 0 to 6.0464e-03.\n",
      "Epoch 200:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 139.06it/s, loss=1.56e-06, v_num=23, train_loss=0.000139, test_loss=0.000138]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 200:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.61it/s, loss=1.56e-06, v_num=23, train_loss=0.000139, test_loss=0.000138]\u001b[A\n",
      "Epoch 200: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.34it/s, loss=1.56e-06, v_num=23, train_loss=0.000189, test_loss=0.000187]\u001b[A\n",
      "Epoch 201:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.77it/s, loss=8.45e-07, v_num=23, train_loss=0.000189, test_loss=0.000187]\u001b[AAdjusting learning rate of group 0 to 6.0312e-03.\n",
      "Epoch 201:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 139.61it/s, loss=7.92e-07, v_num=23, train_loss=0.000189, test_loss=0.000187]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 201:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.29it/s, loss=7.92e-07, v_num=23, train_loss=0.000189, test_loss=0.000187]\u001b[A\n",
      "Epoch 201: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.61it/s, loss=7.92e-07, v_num=23, train_loss=0.000121, test_loss=0.00012]\u001b[A\n",
      "Epoch 202:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.64it/s, loss=6.97e-07, v_num=23, train_loss=0.000121, test_loss=0.00012]\u001b[AAdjusting learning rate of group 0 to 6.0162e-03.\n",
      "Epoch 202:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.14it/s, loss=6.68e-07, v_num=23, train_loss=0.000121, test_loss=0.00012]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 202:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.40it/s, loss=6.68e-07, v_num=23, train_loss=0.000121, test_loss=0.00012]\u001b[A\n",
      "Epoch 202: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.75it/s, loss=6.68e-07, v_num=23, train_loss=6.93e-5, test_loss=7.08e-5]\u001b[A\n",
      "Epoch 203:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.94it/s, loss=1.24e-06, v_num=23, train_loss=6.93e-5, test_loss=7.08e-5]\u001b[AAdjusting learning rate of group 0 to 6.0011e-03.\n",
      "Epoch 203:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.96it/s, loss=1.16e-06, v_num=23, train_loss=6.93e-5, test_loss=7.08e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 203:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.98it/s, loss=1.16e-06, v_num=23, train_loss=6.93e-5, test_loss=7.08e-5]\u001b[A\n",
      "Epoch 203: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.00it/s, loss=1.16e-06, v_num=23, train_loss=7.37e-5, test_loss=7.46e-5]\u001b[A\n",
      "Epoch 204:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.13it/s, loss=1.56e-06, v_num=23, train_loss=7.37e-5, test_loss=7.46e-5]\u001b[AAdjusting learning rate of group 0 to 5.9861e-03.\n",
      "Epoch 204:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.80it/s, loss=1.53e-06, v_num=23, train_loss=7.37e-5, test_loss=7.46e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 204:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.93it/s, loss=1.53e-06, v_num=23, train_loss=7.37e-5, test_loss=7.46e-5]\u001b[A\n",
      "Epoch 204: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.93it/s, loss=1.53e-06, v_num=23, train_loss=6.68e-5, test_loss=6.85e-5]\u001b[A\n",
      "Epoch 205:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.57it/s, loss=5.43e-07, v_num=23, train_loss=6.68e-5, test_loss=6.85e-5]\u001b[AAdjusting learning rate of group 0 to 5.9712e-03.\n",
      "Epoch 205:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.18it/s, loss=5.32e-07, v_num=23, train_loss=6.68e-5, test_loss=6.85e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 205:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.50it/s, loss=5.32e-07, v_num=23, train_loss=6.68e-5, test_loss=6.85e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.65it/s, loss=5.32e-07, v_num=23, train_loss=5.28e-5, test_loss=5.32e-5]\u001b[A\n",
      "Epoch 206:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.11it/s, loss=4.81e-07, v_num=23, train_loss=5.28e-5, test_loss=5.32e-5]\u001b[AAdjusting learning rate of group 0 to 5.9562e-03.\n",
      "Epoch 206:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.97it/s, loss=4.58e-07, v_num=23, train_loss=5.28e-5, test_loss=5.32e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 206:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.53it/s, loss=4.58e-07, v_num=23, train_loss=5.28e-5, test_loss=5.32e-5]\u001b[A\n",
      "Epoch 206: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.03it/s, loss=4.58e-07, v_num=23, train_loss=7.31e-5, test_loss=7.41e-5]\u001b[A\n",
      "Epoch 207:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 146.60it/s, loss=6.07e-07, v_num=23, train_loss=7.31e-5, test_loss=7.41e-5]\u001b[AAdjusting learning rate of group 0 to 5.9413e-03.\n",
      "Epoch 207:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.85it/s, loss=5.91e-07, v_num=23, train_loss=7.31e-5, test_loss=7.41e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 207:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.60it/s, loss=5.91e-07, v_num=23, train_loss=7.31e-5, test_loss=7.41e-5]\u001b[A\n",
      "Epoch 207: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.65it/s, loss=5.91e-07, v_num=23, train_loss=0.000159, test_loss=0.000159]\u001b[A\n",
      "Epoch 208:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.29it/s, loss=8.38e-07, v_num=23, train_loss=0.000159, test_loss=0.000159]\u001b[AAdjusting learning rate of group 0 to 5.9265e-03.\n",
      "Epoch 208:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 140.36it/s, loss=8.12e-07, v_num=23, train_loss=0.000159, test_loss=0.000159]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 208:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 134.83it/s, loss=8.12e-07, v_num=23, train_loss=0.000159, test_loss=0.000159]\u001b[A\n",
      "Epoch 208: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 171.44it/s, loss=8.12e-07, v_num=23, train_loss=0.000105, test_loss=0.000106]\u001b[A\n",
      "Epoch 209:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.19it/s, loss=8.55e-07, v_num=23, train_loss=0.000105, test_loss=0.000106]\u001b[AAdjusting learning rate of group 0 to 5.9117e-03.\n",
      "Epoch 209:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.27it/s, loss=8.26e-07, v_num=23, train_loss=0.000105, test_loss=0.000106]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 209:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 130.92it/s, loss=8.26e-07, v_num=23, train_loss=0.000105, test_loss=0.000106]\u001b[A\n",
      "Epoch 209: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 165.75it/s, loss=8.26e-07, v_num=23, train_loss=0.000126, test_loss=0.000126]\u001b[A\n",
      "Epoch 210:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.16it/s, loss=7.5e-07, v_num=23, train_loss=0.000126, test_loss=0.000126]\u001b[AAdjusting learning rate of group 0 to 5.8969e-03.\n",
      "Epoch 210:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.01it/s, loss=7.06e-07, v_num=23, train_loss=0.000126, test_loss=0.000126]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 210:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.23it/s, loss=7.06e-07, v_num=23, train_loss=0.000126, test_loss=0.000126]\u001b[A\n",
      "Epoch 210: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.40it/s, loss=7.06e-07, v_num=23, train_loss=5.02e-5, test_loss=4.98e-5]\u001b[A\n",
      "Epoch 211:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.82it/s, loss=6.08e-07, v_num=23, train_loss=5.02e-5, test_loss=4.98e-5]\u001b[AAdjusting learning rate of group 0 to 5.8821e-03.\n",
      "Epoch 211:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.38it/s, loss=5.96e-07, v_num=23, train_loss=5.02e-5, test_loss=4.98e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 211:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.33it/s, loss=5.96e-07, v_num=23, train_loss=5.02e-5, test_loss=4.98e-5]\u001b[A\n",
      "Epoch 211: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.56it/s, loss=5.96e-07, v_num=23, train_loss=0.000122, test_loss=0.000122]\u001b[A\n",
      "Epoch 212:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.45it/s, loss=4.32e-07, v_num=23, train_loss=0.000122, test_loss=0.000122]\u001b[AAdjusting learning rate of group 0 to 5.8674e-03.\n",
      "Epoch 212:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 139.13it/s, loss=4.05e-07, v_num=23, train_loss=0.000122, test_loss=0.000122]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 212:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.57it/s, loss=4.05e-07, v_num=23, train_loss=0.000122, test_loss=0.000122]\u001b[A\n",
      "Epoch 212: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.38it/s, loss=4.05e-07, v_num=23, train_loss=4.94e-5, test_loss=4.99e-5]\u001b[A\n",
      "Epoch 213:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.16it/s, loss=6.64e-07, v_num=23, train_loss=4.94e-5, test_loss=4.99e-5]\u001b[AAdjusting learning rate of group 0 to 5.8528e-03.\n",
      "Epoch 213:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.69it/s, loss=6.32e-07, v_num=23, train_loss=4.94e-5, test_loss=4.99e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 213:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.52it/s, loss=6.32e-07, v_num=23, train_loss=4.94e-5, test_loss=4.99e-5]\u001b[A\n",
      "Epoch 213: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.63it/s, loss=6.32e-07, v_num=23, train_loss=6.34e-5, test_loss=6.4e-5]\u001b[A\n",
      "Epoch 214:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.03it/s, loss=1.11e-06, v_num=23, train_loss=6.34e-5, test_loss=6.4e-5]\u001b[AAdjusting learning rate of group 0 to 5.8381e-03.\n",
      "Epoch 214:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.20it/s, loss=1.09e-06, v_num=23, train_loss=6.34e-5, test_loss=6.4e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 214:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.33it/s, loss=1.09e-06, v_num=23, train_loss=6.34e-5, test_loss=6.4e-5]\u001b[A\n",
      "Epoch 214: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.77it/s, loss=1.09e-06, v_num=23, train_loss=0.000244, test_loss=0.000244]\u001b[A\n",
      "Epoch 215:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.04it/s, loss=1.47e-06, v_num=23, train_loss=0.000244, test_loss=0.000244]\u001b[AAdjusting learning rate of group 0 to 5.8235e-03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.35it/s, loss=1.38e-06, v_num=23, train_loss=0.000244, test_loss=0.000244]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 215:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.52it/s, loss=1.38e-06, v_num=23, train_loss=0.000244, test_loss=0.000244]\u001b[A\n",
      "Epoch 215: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.59it/s, loss=1.38e-06, v_num=23, train_loss=0.000199, test_loss=0.0002]\u001b[A\n",
      "Epoch 216:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 146.48it/s, loss=5.22e-07, v_num=23, train_loss=0.000199, test_loss=0.0002]\u001b[AAdjusting learning rate of group 0 to 5.8090e-03.\n",
      "Epoch 216:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 135.93it/s, loss=4.89e-07, v_num=23, train_loss=0.000199, test_loss=0.0002]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 216:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.90it/s, loss=4.89e-07, v_num=23, train_loss=0.000199, test_loss=0.0002]\u001b[A\n",
      "Epoch 216: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.25it/s, loss=4.89e-07, v_num=23, train_loss=3.67e-5, test_loss=3.71e-5]\u001b[A\n",
      "Epoch 217:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.63it/s, loss=5.01e-07, v_num=23, train_loss=3.67e-5, test_loss=3.71e-5]\u001b[AAdjusting learning rate of group 0 to 5.7945e-03.\n",
      "Epoch 217:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.83it/s, loss=4.82e-07, v_num=23, train_loss=3.67e-5, test_loss=3.71e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 217:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.08it/s, loss=4.82e-07, v_num=23, train_loss=3.67e-5, test_loss=3.71e-5]\u001b[A\n",
      "Epoch 217: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.12it/s, loss=4.82e-07, v_num=23, train_loss=3.54e-5, test_loss=3.62e-5]\u001b[A\n",
      "Epoch 218:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.70it/s, loss=1.12e-06, v_num=23, train_loss=3.54e-5, test_loss=3.62e-5]\u001b[AAdjusting learning rate of group 0 to 5.7800e-03.\n",
      "Epoch 218:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.17it/s, loss=1.04e-06, v_num=23, train_loss=3.54e-5, test_loss=3.62e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 218:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.99it/s, loss=1.04e-06, v_num=23, train_loss=3.54e-5, test_loss=3.62e-5]\u001b[A\n",
      "Epoch 218: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.84it/s, loss=1.04e-06, v_num=23, train_loss=0.000274, test_loss=0.000277]\u001b[A\n",
      "Epoch 219:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.77it/s, loss=1.18e-06, v_num=23, train_loss=0.000274, test_loss=0.000277]\u001b[AAdjusting learning rate of group 0 to 5.7655e-03.\n",
      "Epoch 219:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.03it/s, loss=1.07e-06, v_num=23, train_loss=0.000274, test_loss=0.000277]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 219:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.59it/s, loss=1.07e-06, v_num=23, train_loss=0.000274, test_loss=0.000277]\u001b[A\n",
      "Epoch 219: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.44it/s, loss=1.07e-06, v_num=23, train_loss=6.35e-5, test_loss=6.39e-5]\u001b[A\n",
      "Epoch 220:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.14it/s, loss=1.24e-06, v_num=23, train_loss=6.35e-5, test_loss=6.39e-5]\u001b[AAdjusting learning rate of group 0 to 5.7511e-03.\n",
      "Epoch 220:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.38it/s, loss=1.16e-06, v_num=23, train_loss=6.35e-5, test_loss=6.39e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 220:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.87it/s, loss=1.16e-06, v_num=23, train_loss=6.35e-5, test_loss=6.39e-5]\u001b[A\n",
      "Epoch 220: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 165.81it/s, loss=1.16e-06, v_num=23, train_loss=7.2e-5, test_loss=7.17e-5]\u001b[A\n",
      "Epoch 221:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 149.60it/s, loss=8.2e-07, v_num=23, train_loss=7.2e-5, test_loss=7.17e-5]\u001b[AAdjusting learning rate of group 0 to 5.7367e-03.\n",
      "Epoch 221:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.20it/s, loss=7.91e-07, v_num=23, train_loss=7.2e-5, test_loss=7.17e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 221:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.90it/s, loss=7.91e-07, v_num=23, train_loss=7.2e-5, test_loss=7.17e-5]\u001b[A\n",
      "Epoch 221: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.71it/s, loss=7.91e-07, v_num=23, train_loss=7.98e-5, test_loss=8.14e-5]\u001b[A\n",
      "Epoch 222:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.58it/s, loss=6.2e-07, v_num=23, train_loss=7.98e-5, test_loss=8.14e-5]\u001b[AAdjusting learning rate of group 0 to 5.7224e-03.\n",
      "Epoch 222:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.05it/s, loss=5.94e-07, v_num=23, train_loss=7.98e-5, test_loss=8.14e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 222:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.56it/s, loss=5.94e-07, v_num=23, train_loss=7.98e-5, test_loss=8.14e-5]\u001b[A\n",
      "Epoch 222: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.23it/s, loss=5.94e-07, v_num=23, train_loss=6.07e-5, test_loss=6.2e-5]\u001b[A\n",
      "Epoch 223:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.36it/s, loss=4.84e-07, v_num=23, train_loss=6.07e-5, test_loss=6.2e-5]\u001b[AAdjusting learning rate of group 0 to 5.7081e-03.\n",
      "Epoch 223:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.38it/s, loss=4.44e-07, v_num=23, train_loss=6.07e-5, test_loss=6.2e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 223:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 130.90it/s, loss=4.44e-07, v_num=23, train_loss=6.07e-5, test_loss=6.2e-5]\u001b[A\n",
      "Epoch 223: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 166.72it/s, loss=4.44e-07, v_num=23, train_loss=3.87e-5, test_loss=4e-5]\u001b[A\n",
      "Epoch 224:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 150.05it/s, loss=7.92e-07, v_num=23, train_loss=3.87e-5, test_loss=4e-5]\u001b[AAdjusting learning rate of group 0 to 5.6938e-03.\n",
      "Epoch 224:  50%|█████████████████████                     | 79/158 [00:00<00:00, 139.73it/s, loss=7.62e-07, v_num=23, train_loss=3.87e-5, test_loss=4e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 134.29it/s, loss=7.62e-07, v_num=23, train_loss=3.87e-5, test_loss=4e-5]\u001b[A\n",
      "Epoch 224: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.13it/s, loss=7.62e-07, v_num=23, train_loss=8.1e-5, test_loss=8.42e-5]\u001b[A\n",
      "Epoch 225:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.59it/s, loss=1.21e-06, v_num=23, train_loss=8.1e-5, test_loss=8.42e-5]\u001b[AAdjusting learning rate of group 0 to 5.6796e-03.\n",
      "Epoch 225:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.34it/s, loss=1.18e-06, v_num=23, train_loss=8.1e-5, test_loss=8.42e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 225:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.86it/s, loss=1.18e-06, v_num=23, train_loss=8.1e-5, test_loss=8.42e-5]\u001b[A\n",
      "Epoch 225: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.51it/s, loss=1.18e-06, v_num=23, train_loss=0.000208, test_loss=0.000211]\u001b[A\n",
      "Epoch 226:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.67it/s, loss=6.94e-07, v_num=23, train_loss=0.000208, test_loss=0.000211]\u001b[AAdjusting learning rate of group 0 to 5.6654e-03.\n",
      "Epoch 226:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.28it/s, loss=6.68e-07, v_num=23, train_loss=0.000208, test_loss=0.000211]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 226:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.22it/s, loss=6.68e-07, v_num=23, train_loss=0.000208, test_loss=0.000211]\u001b[A\n",
      "Epoch 226: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.66it/s, loss=6.68e-07, v_num=23, train_loss=6.52e-5, test_loss=6.51e-5]\u001b[A\n",
      "Epoch 227:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.82it/s, loss=8.6e-07, v_num=23, train_loss=6.52e-5, test_loss=6.51e-5]\u001b[AAdjusting learning rate of group 0 to 5.6512e-03.\n",
      "Epoch 227:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.48it/s, loss=8.51e-07, v_num=23, train_loss=6.52e-5, test_loss=6.51e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 227:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.11it/s, loss=8.51e-07, v_num=23, train_loss=6.52e-5, test_loss=6.51e-5]\u001b[A\n",
      "Epoch 227: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.59it/s, loss=8.51e-07, v_num=23, train_loss=9.52e-5, test_loss=9.59e-5]\u001b[A\n",
      "Epoch 228:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.22it/s, loss=1.2e-06, v_num=23, train_loss=9.52e-5, test_loss=9.59e-5]\u001b[AAdjusting learning rate of group 0 to 5.6371e-03.\n",
      "Epoch 228:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.21it/s, loss=1.1e-06, v_num=23, train_loss=9.52e-5, test_loss=9.59e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 228:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 129.68it/s, loss=1.1e-06, v_num=23, train_loss=9.52e-5, test_loss=9.59e-5]\u001b[A\n",
      "Epoch 228: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.23it/s, loss=1.1e-06, v_num=23, train_loss=0.000136, test_loss=0.000136]\u001b[A\n",
      "Epoch 229:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.25it/s, loss=6.96e-07, v_num=23, train_loss=0.000136, test_loss=0.000136]\u001b[AAdjusting learning rate of group 0 to 5.6230e-03.\n",
      "Epoch 229:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.13it/s, loss=6.63e-07, v_num=23, train_loss=0.000136, test_loss=0.000136]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 229:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.13it/s, loss=6.63e-07, v_num=23, train_loss=0.000136, test_loss=0.000136]\u001b[A\n",
      "Epoch 229: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 166.89it/s, loss=6.63e-07, v_num=23, train_loss=0.000108, test_loss=0.000109]\u001b[A\n",
      "Epoch 230:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.58it/s, loss=5.1e-07, v_num=23, train_loss=0.000108, test_loss=0.000109]\u001b[AAdjusting learning rate of group 0 to 5.6089e-03.\n",
      "Epoch 230:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.71it/s, loss=4.95e-07, v_num=23, train_loss=0.000108, test_loss=0.000109]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.14it/s]\u001b[A\n",
      "Epoch 230: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 162.25it/s, loss=4.95e-07, v_num=23, train_loss=5.9e-5, test_loss=5.94e-5]\u001b[A\n",
      "Epoch 231:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.16it/s, loss=7.06e-07, v_num=23, train_loss=5.9e-5, test_loss=5.94e-5]\u001b[AAdjusting learning rate of group 0 to 5.5949e-03.\n",
      "Epoch 231:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.50it/s, loss=6.92e-07, v_num=23, train_loss=5.9e-5, test_loss=5.94e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 231:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.40it/s, loss=6.92e-07, v_num=23, train_loss=5.9e-5, test_loss=5.94e-5]\u001b[A\n",
      "Epoch 231: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.56it/s, loss=6.92e-07, v_num=23, train_loss=8.53e-5, test_loss=8.59e-5]\u001b[A\n",
      "Epoch 232:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.33it/s, loss=4.56e-07, v_num=23, train_loss=8.53e-5, test_loss=8.59e-5]\u001b[AAdjusting learning rate of group 0 to 5.5809e-03.\n",
      "Epoch 232:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.74it/s, loss=4.31e-07, v_num=23, train_loss=8.53e-5, test_loss=8.59e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 232:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.85it/s, loss=4.31e-07, v_num=23, train_loss=8.53e-5, test_loss=8.59e-5]\u001b[A\n",
      "Epoch 232: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.94it/s, loss=4.31e-07, v_num=23, train_loss=5.89e-5, test_loss=6.04e-5]\u001b[A\n",
      "Epoch 233:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.23it/s, loss=6.36e-07, v_num=23, train_loss=5.89e-5, test_loss=6.04e-5]\u001b[AAdjusting learning rate of group 0 to 5.5670e-03.\n",
      "Epoch 233:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.54it/s, loss=6.15e-07, v_num=23, train_loss=5.89e-5, test_loss=6.04e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 233:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.19it/s, loss=6.15e-07, v_num=23, train_loss=5.89e-5, test_loss=6.04e-5]\u001b[A\n",
      "Epoch 233: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.44it/s, loss=6.15e-07, v_num=23, train_loss=6.99e-5, test_loss=6.93e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.56it/s, loss=6.25e-07, v_num=23, train_loss=6.99e-5, test_loss=6.93e-5]\u001b[AAdjusting learning rate of group 0 to 5.5531e-03.\n",
      "Epoch 234:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.58it/s, loss=5.87e-07, v_num=23, train_loss=6.99e-5, test_loss=6.93e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 234:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.58it/s, loss=5.87e-07, v_num=23, train_loss=6.99e-5, test_loss=6.93e-5]\u001b[A\n",
      "Epoch 234: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.07it/s, loss=5.87e-07, v_num=23, train_loss=4.49e-5, test_loss=4.69e-5]\u001b[A\n",
      "Epoch 235:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.49it/s, loss=8.58e-07, v_num=23, train_loss=4.49e-5, test_loss=4.69e-5]\u001b[AAdjusting learning rate of group 0 to 5.5392e-03.\n",
      "Epoch 235:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.72it/s, loss=7.86e-07, v_num=23, train_loss=4.49e-5, test_loss=4.69e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 235:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.30it/s, loss=7.86e-07, v_num=23, train_loss=4.49e-5, test_loss=4.69e-5]\u001b[A\n",
      "Epoch 235: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.77it/s, loss=7.86e-07, v_num=23, train_loss=4.59e-5, test_loss=4.7e-5]\u001b[A\n",
      "Epoch 236:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.25it/s, loss=7.68e-07, v_num=23, train_loss=4.59e-5, test_loss=4.7e-5]\u001b[AAdjusting learning rate of group 0 to 5.5253e-03.\n",
      "Epoch 236:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.41it/s, loss=7.49e-07, v_num=23, train_loss=4.59e-5, test_loss=4.7e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 236:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.28it/s, loss=7.49e-07, v_num=23, train_loss=4.59e-5, test_loss=4.7e-5]\u001b[A\n",
      "Epoch 236: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 166.05it/s, loss=7.49e-07, v_num=23, train_loss=0.000314, test_loss=0.000315]\u001b[A\n",
      "Epoch 237:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.18it/s, loss=1.39e-06, v_num=23, train_loss=0.000314, test_loss=0.000315]\u001b[AAdjusting learning rate of group 0 to 5.5115e-03.\n",
      "Epoch 237:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 141.18it/s, loss=1.31e-06, v_num=23, train_loss=0.000314, test_loss=0.000315]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 237:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.24it/s, loss=1.31e-06, v_num=23, train_loss=0.000314, test_loss=0.000315]\u001b[A\n",
      "Epoch 237: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 169.56it/s, loss=1.31e-06, v_num=23, train_loss=0.000147, test_loss=0.000148]\u001b[A\n",
      "Epoch 238:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.49it/s, loss=5.99e-07, v_num=23, train_loss=0.000147, test_loss=0.000148]\u001b[AAdjusting learning rate of group 0 to 5.4977e-03.\n",
      "Epoch 238:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.89it/s, loss=5.71e-07, v_num=23, train_loss=0.000147, test_loss=0.000148]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 238:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.58it/s, loss=5.71e-07, v_num=23, train_loss=0.000147, test_loss=0.000148]\u001b[A\n",
      "Epoch 238: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.79it/s, loss=5.71e-07, v_num=23, train_loss=5.92e-5, test_loss=5.97e-5]\u001b[A\n",
      "Epoch 239:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.92it/s, loss=8.88e-07, v_num=23, train_loss=5.92e-5, test_loss=5.97e-5]\u001b[AAdjusting learning rate of group 0 to 5.4840e-03.\n",
      "Epoch 239:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.03it/s, loss=8.59e-07, v_num=23, train_loss=5.92e-5, test_loss=5.97e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 239:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.53it/s, loss=8.59e-07, v_num=23, train_loss=5.92e-5, test_loss=5.97e-5]\u001b[A\n",
      "Epoch 239: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.39it/s, loss=8.59e-07, v_num=23, train_loss=0.000148, test_loss=0.00015]\u001b[A\n",
      "Epoch 240:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.99it/s, loss=1.53e-06, v_num=23, train_loss=0.000148, test_loss=0.00015]\u001b[AAdjusting learning rate of group 0 to 5.4703e-03.\n",
      "Epoch 240:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.02it/s, loss=1.44e-06, v_num=23, train_loss=0.000148, test_loss=0.00015]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 240:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.19it/s, loss=1.44e-06, v_num=23, train_loss=0.000148, test_loss=0.00015]\u001b[A\n",
      "Epoch 240: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.44it/s, loss=1.44e-06, v_num=23, train_loss=8.13e-5, test_loss=8.24e-5]\u001b[A\n",
      "Epoch 241:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.50it/s, loss=4.31e-06, v_num=23, train_loss=8.13e-5, test_loss=8.24e-5]\u001b[AAdjusting learning rate of group 0 to 5.4566e-03.\n",
      "Epoch 241:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.61it/s, loss=4.12e-06, v_num=23, train_loss=8.13e-5, test_loss=8.24e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 241:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.55it/s, loss=4.12e-06, v_num=23, train_loss=8.13e-5, test_loss=8.24e-5]\u001b[A\n",
      "Epoch 241: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.61it/s, loss=4.12e-06, v_num=23, train_loss=0.000298, test_loss=0.000313]\u001b[A\n",
      "Epoch 242:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.08it/s, loss=7.98e-07, v_num=23, train_loss=0.000298, test_loss=0.000313]\u001b[AAdjusting learning rate of group 0 to 5.4430e-03.\n",
      "Epoch 242:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.96it/s, loss=7.56e-07, v_num=23, train_loss=0.000298, test_loss=0.000313]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 242:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 127.74it/s, loss=7.56e-07, v_num=23, train_loss=0.000298, test_loss=0.000313]\u001b[A\n",
      "Epoch 242: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 162.56it/s, loss=7.56e-07, v_num=23, train_loss=5.71e-5, test_loss=5.79e-5]\u001b[A\n",
      "Epoch 243:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.00it/s, loss=5.04e-07, v_num=23, train_loss=5.71e-5, test_loss=5.79e-5]\u001b[AAdjusting learning rate of group 0 to 5.4294e-03.\n",
      "Epoch 243:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.84it/s, loss=4.87e-07, v_num=23, train_loss=5.71e-5, test_loss=5.79e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 243:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.57it/s, loss=4.87e-07, v_num=23, train_loss=5.71e-5, test_loss=5.79e-5]\u001b[A\n",
      "Epoch 243: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 164.72it/s, loss=4.87e-07, v_num=23, train_loss=4.5e-5, test_loss=4.6e-5]\u001b[A\n",
      "Epoch 244:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.25it/s, loss=5.66e-07, v_num=23, train_loss=4.5e-5, test_loss=4.6e-5]\u001b[AAdjusting learning rate of group 0 to 5.4158e-03.\n",
      "Epoch 244:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 137.23it/s, loss=5.44e-07, v_num=23, train_loss=4.5e-5, test_loss=4.6e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 244:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 130.20it/s, loss=5.44e-07, v_num=23, train_loss=4.5e-5, test_loss=4.6e-5]\u001b[A\n",
      "Epoch 244: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.42it/s, loss=5.44e-07, v_num=23, train_loss=4.18e-5, test_loss=4.28e-5]\u001b[A\n",
      "Epoch 245:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.40it/s, loss=4.82e-07, v_num=23, train_loss=4.18e-5, test_loss=4.28e-5]\u001b[AAdjusting learning rate of group 0 to 5.4022e-03.\n",
      "Epoch 245:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.67it/s, loss=4.61e-07, v_num=23, train_loss=4.18e-5, test_loss=4.28e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 245:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.84it/s, loss=4.61e-07, v_num=23, train_loss=4.18e-5, test_loss=4.28e-5]\u001b[A\n",
      "Epoch 245: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.70it/s, loss=4.61e-07, v_num=23, train_loss=5.79e-5, test_loss=5.83e-5]\u001b[A\n",
      "Epoch 246:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.00it/s, loss=3.83e-07, v_num=23, train_loss=5.79e-5, test_loss=5.83e-5]\u001b[AAdjusting learning rate of group 0 to 5.3887e-03.\n",
      "Epoch 246:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.85it/s, loss=3.64e-07, v_num=23, train_loss=5.79e-5, test_loss=5.83e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 246:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.73it/s, loss=3.64e-07, v_num=23, train_loss=5.79e-5, test_loss=5.83e-5]\u001b[A\n",
      "Epoch 246: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.89it/s, loss=3.64e-07, v_num=23, train_loss=5.63e-5, test_loss=5.77e-5]\u001b[A\n",
      "Epoch 247:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.98it/s, loss=6.08e-07, v_num=23, train_loss=5.63e-5, test_loss=5.77e-5]\u001b[AAdjusting learning rate of group 0 to 5.3753e-03.\n",
      "Epoch 247:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.48it/s, loss=5.83e-07, v_num=23, train_loss=5.63e-5, test_loss=5.77e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 247:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.45it/s, loss=5.83e-07, v_num=23, train_loss=5.63e-5, test_loss=5.77e-5]\u001b[A\n",
      "Epoch 247: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.10it/s, loss=5.83e-07, v_num=23, train_loss=8.01e-5, test_loss=8.14e-5]\u001b[A\n",
      "Epoch 248:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.15it/s, loss=9.24e-07, v_num=23, train_loss=8.01e-5, test_loss=8.14e-5]\u001b[AAdjusting learning rate of group 0 to 5.3618e-03.\n",
      "Epoch 248:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.22it/s, loss=8.73e-07, v_num=23, train_loss=8.01e-5, test_loss=8.14e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 248:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.94it/s, loss=8.73e-07, v_num=23, train_loss=8.01e-5, test_loss=8.14e-5]\u001b[A\n",
      "Epoch 248: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.50it/s, loss=8.73e-07, v_num=23, train_loss=0.000153, test_loss=0.000154]\u001b[A\n",
      "Epoch 249:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.27it/s, loss=6.33e-07, v_num=23, train_loss=0.000153, test_loss=0.000154]\u001b[AAdjusting learning rate of group 0 to 5.3484e-03.\n",
      "Epoch 249:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.87it/s, loss=6.25e-07, v_num=23, train_loss=0.000153, test_loss=0.000154]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 249:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.44it/s, loss=6.25e-07, v_num=23, train_loss=0.000153, test_loss=0.000154]\u001b[A\n",
      "Epoch 249: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.64it/s, loss=6.25e-07, v_num=23, train_loss=7.05e-5, test_loss=7.12e-5]\u001b[A\n",
      "Epoch 250:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.64it/s, loss=5.57e-07, v_num=23, train_loss=7.05e-5, test_loss=7.12e-5]\u001b[AAdjusting learning rate of group 0 to 5.3351e-03.\n",
      "Epoch 250:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.69it/s, loss=5.06e-07, v_num=23, train_loss=7.05e-5, test_loss=7.12e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 250:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.86it/s, loss=5.06e-07, v_num=23, train_loss=7.05e-5, test_loss=7.12e-5]\u001b[A\n",
      "Epoch 250: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.16it/s, loss=5.06e-07, v_num=23, train_loss=8.11e-5, test_loss=8.12e-5]\u001b[A\n",
      "Epoch 251:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.76it/s, loss=8.2e-07, v_num=23, train_loss=8.11e-5, test_loss=8.12e-5]\u001b[AAdjusting learning rate of group 0 to 5.3217e-03.\n",
      "Epoch 251:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.76it/s, loss=7.87e-07, v_num=23, train_loss=8.11e-5, test_loss=8.12e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 251:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.87it/s, loss=7.87e-07, v_num=23, train_loss=8.11e-5, test_loss=8.12e-5]\u001b[A\n",
      "Epoch 251: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.99it/s, loss=7.87e-07, v_num=23, train_loss=5.53e-5, test_loss=5.62e-5]\u001b[A\n",
      "Epoch 252:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.34it/s, loss=6.35e-07, v_num=23, train_loss=5.53e-5, test_loss=5.62e-5]\u001b[AAdjusting learning rate of group 0 to 5.3084e-03.\n",
      "Epoch 252:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.37it/s, loss=6.16e-07, v_num=23, train_loss=5.53e-5, test_loss=5.62e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 252:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.49it/s, loss=6.16e-07, v_num=23, train_loss=5.53e-5, test_loss=5.62e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.48it/s, loss=6.16e-07, v_num=23, train_loss=4.95e-5, test_loss=4.89e-5]\u001b[A\n",
      "Epoch 253:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.18it/s, loss=8.31e-07, v_num=23, train_loss=4.95e-5, test_loss=4.89e-5]\u001b[AAdjusting learning rate of group 0 to 5.2951e-03.\n",
      "Epoch 253:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.02it/s, loss=7.99e-07, v_num=23, train_loss=4.95e-5, test_loss=4.89e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 253:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.64it/s, loss=7.99e-07, v_num=23, train_loss=4.95e-5, test_loss=4.89e-5]\u001b[A\n",
      "Epoch 253: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.43it/s, loss=7.99e-07, v_num=23, train_loss=0.000106, test_loss=0.000107]\u001b[A\n",
      "Epoch 254:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.86it/s, loss=1.11e-06, v_num=23, train_loss=0.000106, test_loss=0.000107]\u001b[AAdjusting learning rate of group 0 to 5.2819e-03.\n",
      "Epoch 254:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.81it/s, loss=1.07e-06, v_num=23, train_loss=0.000106, test_loss=0.000107]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 254:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.35it/s, loss=1.07e-06, v_num=23, train_loss=0.000106, test_loss=0.000107]\u001b[A\n",
      "Epoch 254: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.50it/s, loss=1.07e-06, v_num=23, train_loss=0.000153, test_loss=0.000154]\u001b[A\n",
      "Epoch 255:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.25it/s, loss=6.93e-07, v_num=23, train_loss=0.000153, test_loss=0.000154]\u001b[AAdjusting learning rate of group 0 to 5.2687e-03.\n",
      "Epoch 255:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.78it/s, loss=6.5e-07, v_num=23, train_loss=0.000153, test_loss=0.000154]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 255:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.94it/s, loss=6.5e-07, v_num=23, train_loss=0.000153, test_loss=0.000154]\u001b[A\n",
      "Epoch 255: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.79it/s, loss=6.5e-07, v_num=23, train_loss=0.000113, test_loss=0.000115]\u001b[A\n",
      "Epoch 256:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.20it/s, loss=4.82e-07, v_num=23, train_loss=0.000113, test_loss=0.000115]\u001b[AAdjusting learning rate of group 0 to 5.2555e-03.\n",
      "Epoch 256:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.72it/s, loss=4.55e-07, v_num=23, train_loss=0.000113, test_loss=0.000115]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 256:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.39it/s, loss=4.55e-07, v_num=23, train_loss=0.000113, test_loss=0.000115]\u001b[A\n",
      "Epoch 256: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.38it/s, loss=4.55e-07, v_num=23, train_loss=8.79e-5, test_loss=8.87e-5]\u001b[A\n",
      "Epoch 257:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.43it/s, loss=7.36e-07, v_num=23, train_loss=8.79e-5, test_loss=8.87e-5]\u001b[AAdjusting learning rate of group 0 to 5.2424e-03.\n",
      "Epoch 257:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.63it/s, loss=6.77e-07, v_num=23, train_loss=8.79e-5, test_loss=8.87e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 257:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.59it/s, loss=6.77e-07, v_num=23, train_loss=8.79e-5, test_loss=8.87e-5]\u001b[A\n",
      "Epoch 257: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.67it/s, loss=6.77e-07, v_num=23, train_loss=6.99e-5, test_loss=7.06e-5]\u001b[A\n",
      "Epoch 258:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.35it/s, loss=4.19e-07, v_num=23, train_loss=6.99e-5, test_loss=7.06e-5]\u001b[AAdjusting learning rate of group 0 to 5.2293e-03.\n",
      "Epoch 258:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.92it/s, loss=4.01e-07, v_num=23, train_loss=6.99e-5, test_loss=7.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 258:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.03it/s, loss=4.01e-07, v_num=23, train_loss=6.99e-5, test_loss=7.06e-5]\u001b[A\n",
      "Epoch 258: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.74it/s, loss=4.01e-07, v_num=23, train_loss=2.59e-5, test_loss=2.61e-5]\u001b[A\n",
      "Epoch 259:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.86it/s, loss=3.15e-07, v_num=23, train_loss=2.59e-5, test_loss=2.61e-5]\u001b[AAdjusting learning rate of group 0 to 5.2162e-03.\n",
      "Epoch 259:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.59it/s, loss=3.02e-07, v_num=23, train_loss=2.59e-5, test_loss=2.61e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 259:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.69it/s, loss=3.02e-07, v_num=23, train_loss=2.59e-5, test_loss=2.61e-5]\u001b[A\n",
      "Epoch 259: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.36it/s, loss=3.02e-07, v_num=23, train_loss=2.83e-5, test_loss=2.97e-5]\u001b[A\n",
      "Epoch 260:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.10it/s, loss=4.58e-07, v_num=23, train_loss=2.83e-5, test_loss=2.97e-5]\u001b[AAdjusting learning rate of group 0 to 5.2032e-03.\n",
      "Epoch 260:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.00it/s, loss=4.43e-07, v_num=23, train_loss=2.83e-5, test_loss=2.97e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 260:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.82it/s, loss=4.43e-07, v_num=23, train_loss=2.83e-5, test_loss=2.97e-5]\u001b[A\n",
      "Epoch 260: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.51it/s, loss=4.43e-07, v_num=23, train_loss=6.04e-5, test_loss=5.98e-5]\u001b[A\n",
      "Epoch 261:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.53it/s, loss=5.58e-07, v_num=23, train_loss=6.04e-5, test_loss=5.98e-5]\u001b[AAdjusting learning rate of group 0 to 5.1902e-03.\n",
      "Epoch 261:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.75it/s, loss=5.21e-07, v_num=23, train_loss=6.04e-5, test_loss=5.98e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 261:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.36it/s, loss=5.21e-07, v_num=23, train_loss=6.04e-5, test_loss=5.98e-5]\u001b[A\n",
      "Epoch 261: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.82it/s, loss=5.21e-07, v_num=23, train_loss=9.42e-5, test_loss=9.74e-5]\u001b[A\n",
      "Epoch 262:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.61it/s, loss=1.29e-06, v_num=23, train_loss=9.42e-5, test_loss=9.74e-5]\u001b[AAdjusting learning rate of group 0 to 5.1772e-03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.60it/s, loss=1.28e-06, v_num=23, train_loss=9.42e-5, test_loss=9.74e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 262:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.67it/s, loss=1.28e-06, v_num=23, train_loss=9.42e-5, test_loss=9.74e-5]\u001b[A\n",
      "Epoch 262: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 166.21it/s, loss=1.28e-06, v_num=23, train_loss=0.000113, test_loss=0.000114]\u001b[A\n",
      "Epoch 263:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.23it/s, loss=1.38e-06, v_num=23, train_loss=0.000113, test_loss=0.000114]\u001b[AAdjusting learning rate of group 0 to 5.1642e-03.\n",
      "Epoch 263:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 140.18it/s, loss=1.34e-06, v_num=23, train_loss=0.000113, test_loss=0.000114]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 263:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 133.36it/s, loss=1.34e-06, v_num=23, train_loss=0.000113, test_loss=0.000114]\u001b[A\n",
      "Epoch 263: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 170.02it/s, loss=1.34e-06, v_num=23, train_loss=0.000159, test_loss=0.000158]\u001b[A\n",
      "Epoch 264:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.30it/s, loss=7.08e-07, v_num=23, train_loss=0.000159, test_loss=0.000158]\u001b[AAdjusting learning rate of group 0 to 5.1513e-03.\n",
      "Epoch 264:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 139.92it/s, loss=6.52e-07, v_num=23, train_loss=0.000159, test_loss=0.000158]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 264:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.84it/s, loss=6.52e-07, v_num=23, train_loss=0.000159, test_loss=0.000158]\u001b[A\n",
      "Epoch 264: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.58it/s, loss=6.52e-07, v_num=23, train_loss=8.17e-5, test_loss=8.62e-5]\u001b[A\n",
      "Epoch 265:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.27it/s, loss=6.27e-07, v_num=23, train_loss=8.17e-5, test_loss=8.62e-5]\u001b[AAdjusting learning rate of group 0 to 5.1385e-03.\n",
      "Epoch 265:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.92it/s, loss=6.09e-07, v_num=23, train_loss=8.17e-5, test_loss=8.62e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 265:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.04it/s, loss=6.09e-07, v_num=23, train_loss=8.17e-5, test_loss=8.62e-5]\u001b[A\n",
      "Epoch 265: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.63it/s, loss=6.09e-07, v_num=23, train_loss=0.000114, test_loss=0.000114]\u001b[A\n",
      "Epoch 266:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.17it/s, loss=5.7e-07, v_num=23, train_loss=0.000114, test_loss=0.000114]\u001b[AAdjusting learning rate of group 0 to 5.1256e-03.\n",
      "Epoch 266:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.86it/s, loss=5.4e-07, v_num=23, train_loss=0.000114, test_loss=0.000114]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 266:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.93it/s, loss=5.4e-07, v_num=23, train_loss=0.000114, test_loss=0.000114]\u001b[A\n",
      "Epoch 266: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.50it/s, loss=5.4e-07, v_num=23, train_loss=7.59e-5, test_loss=7.49e-5]\u001b[A\n",
      "Epoch 267:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.61it/s, loss=8.26e-07, v_num=23, train_loss=7.59e-5, test_loss=7.49e-5]\u001b[AAdjusting learning rate of group 0 to 5.1128e-03.\n",
      "Epoch 267:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.24it/s, loss=8.07e-07, v_num=23, train_loss=7.59e-5, test_loss=7.49e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 267:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.56it/s, loss=8.07e-07, v_num=23, train_loss=7.59e-5, test_loss=7.49e-5]\u001b[A\n",
      "Epoch 267: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.13it/s, loss=8.07e-07, v_num=23, train_loss=0.00017, test_loss=0.000171]\u001b[A\n",
      "Epoch 268:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.35it/s, loss=1.32e-06, v_num=23, train_loss=0.00017, test_loss=0.000171]\u001b[AAdjusting learning rate of group 0 to 5.1000e-03.\n",
      "Epoch 268:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.50it/s, loss=1.27e-06, v_num=23, train_loss=0.00017, test_loss=0.000171]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 268:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.57it/s, loss=1.27e-06, v_num=23, train_loss=0.00017, test_loss=0.000171]\u001b[A\n",
      "Epoch 268: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.87it/s, loss=1.27e-06, v_num=23, train_loss=0.000308, test_loss=0.000306]\u001b[A\n",
      "Epoch 269:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 147.05it/s, loss=1.45e-06, v_num=23, train_loss=0.000308, test_loss=0.000306]\u001b[AAdjusting learning rate of group 0 to 5.0873e-03.\n",
      "Epoch 269:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 139.17it/s, loss=1.39e-06, v_num=23, train_loss=0.000308, test_loss=0.000306]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 269:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.50it/s, loss=1.39e-06, v_num=23, train_loss=0.000308, test_loss=0.000306]\u001b[A\n",
      "Epoch 269: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 166.97it/s, loss=1.39e-06, v_num=23, train_loss=0.000121, test_loss=0.000128]\u001b[A\n",
      "Epoch 270:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.29it/s, loss=1.16e-06, v_num=23, train_loss=0.000121, test_loss=0.000128]\u001b[AAdjusting learning rate of group 0 to 5.0745e-03.\n",
      "Epoch 270:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.13it/s, loss=1.09e-06, v_num=23, train_loss=0.000121, test_loss=0.000128]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 270:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.56it/s, loss=1.09e-06, v_num=23, train_loss=0.000121, test_loss=0.000128]\u001b[A\n",
      "Epoch 270: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 166.78it/s, loss=1.09e-06, v_num=23, train_loss=0.000112, test_loss=0.000112]\u001b[A\n",
      "Epoch 271:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 150.28it/s, loss=7.24e-07, v_num=23, train_loss=0.000112, test_loss=0.000112]\u001b[AAdjusting learning rate of group 0 to 5.0619e-03.\n",
      "Epoch 271:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 141.18it/s, loss=7.01e-07, v_num=23, train_loss=0.000112, test_loss=0.000112]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 135.37it/s, loss=7.01e-07, v_num=23, train_loss=0.000112, test_loss=0.000112]\u001b[A\n",
      "Epoch 271: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 171.00it/s, loss=7.01e-07, v_num=23, train_loss=3.2e-5, test_loss=3.35e-5]\u001b[A\n",
      "Epoch 272:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.08it/s, loss=6.84e-07, v_num=23, train_loss=3.2e-5, test_loss=3.35e-5]\u001b[AAdjusting learning rate of group 0 to 5.0492e-03.\n",
      "Epoch 272:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.43it/s, loss=6.56e-07, v_num=23, train_loss=3.2e-5, test_loss=3.35e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 272:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.17it/s, loss=6.56e-07, v_num=23, train_loss=3.2e-5, test_loss=3.35e-5]\u001b[A\n",
      "Epoch 272: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.18it/s, loss=6.56e-07, v_num=23, train_loss=6.53e-5, test_loss=6.56e-5]\u001b[A\n",
      "Epoch 273:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 146.96it/s, loss=7.54e-07, v_num=23, train_loss=6.53e-5, test_loss=6.56e-5]\u001b[AAdjusting learning rate of group 0 to 5.0366e-03.\n",
      "Epoch 273:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.43it/s, loss=7.34e-07, v_num=23, train_loss=6.53e-5, test_loss=6.56e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 273:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.02it/s, loss=7.34e-07, v_num=23, train_loss=6.53e-5, test_loss=6.56e-5]\u001b[A\n",
      "Epoch 273: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.88it/s, loss=7.34e-07, v_num=23, train_loss=6.75e-5, test_loss=6.79e-5]\u001b[A\n",
      "Epoch 274:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.11it/s, loss=4.79e-07, v_num=23, train_loss=6.75e-5, test_loss=6.79e-5]\u001b[AAdjusting learning rate of group 0 to 5.0240e-03.\n",
      "Epoch 274:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.14it/s, loss=4.56e-07, v_num=23, train_loss=6.75e-5, test_loss=6.79e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 274:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.52it/s, loss=4.56e-07, v_num=23, train_loss=6.75e-5, test_loss=6.79e-5]\u001b[A\n",
      "Epoch 274: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 170.54it/s, loss=4.56e-07, v_num=23, train_loss=6.1e-5, test_loss=6.1e-5]\u001b[A\n",
      "Epoch 275:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 146.74it/s, loss=7.31e-07, v_num=23, train_loss=6.1e-5, test_loss=6.1e-5]\u001b[AAdjusting learning rate of group 0 to 5.0114e-03.\n",
      "Epoch 275:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 138.67it/s, loss=6.98e-07, v_num=23, train_loss=6.1e-5, test_loss=6.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 275:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 131.87it/s, loss=6.98e-07, v_num=23, train_loss=6.1e-5, test_loss=6.1e-5]\u001b[A\n",
      "Epoch 275: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 166.89it/s, loss=6.98e-07, v_num=23, train_loss=0.000161, test_loss=0.000162]\u001b[A\n",
      "Epoch 276:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.70it/s, loss=8.32e-07, v_num=23, train_loss=0.000161, test_loss=0.000162]\u001b[AAdjusting learning rate of group 0 to 4.9989e-03.\n",
      "Epoch 276:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 140.93it/s, loss=7.94e-07, v_num=23, train_loss=0.000161, test_loss=0.000162]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 276:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.52it/s, loss=7.94e-07, v_num=23, train_loss=0.000161, test_loss=0.000162]\u001b[A\n",
      "Epoch 276: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.17it/s, loss=7.94e-07, v_num=23, train_loss=8.34e-5, test_loss=8.29e-5]\u001b[A\n",
      "Epoch 277:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.48it/s, loss=3.34e-07, v_num=23, train_loss=8.34e-5, test_loss=8.29e-5]\u001b[AAdjusting learning rate of group 0 to 4.9864e-03.\n",
      "Epoch 277:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.92it/s, loss=3.07e-07, v_num=23, train_loss=8.34e-5, test_loss=8.29e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 277:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.85it/s, loss=3.07e-07, v_num=23, train_loss=8.34e-5, test_loss=8.29e-5]\u001b[A\n",
      "Epoch 277: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.64it/s, loss=3.07e-07, v_num=23, train_loss=2.93e-5, test_loss=3.03e-5]\u001b[A\n",
      "Epoch 278:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.51it/s, loss=3.45e-07, v_num=23, train_loss=2.93e-5, test_loss=3.03e-5]\u001b[AAdjusting learning rate of group 0 to 4.9739e-03.\n",
      "Epoch 278:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.96it/s, loss=3.29e-07, v_num=23, train_loss=2.93e-5, test_loss=3.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 278:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.86it/s, loss=3.29e-07, v_num=23, train_loss=2.93e-5, test_loss=3.03e-5]\u001b[A\n",
      "Epoch 278: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.90it/s, loss=3.29e-07, v_num=23, train_loss=2.75e-5, test_loss=2.84e-5]\u001b[A\n",
      "Epoch 279:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.27it/s, loss=5.98e-07, v_num=23, train_loss=2.75e-5, test_loss=2.84e-5]\u001b[AAdjusting learning rate of group 0 to 4.9615e-03.\n",
      "Epoch 279:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.26it/s, loss=5.75e-07, v_num=23, train_loss=2.75e-5, test_loss=2.84e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 279:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.08it/s, loss=5.75e-07, v_num=23, train_loss=2.75e-5, test_loss=2.84e-5]\u001b[A\n",
      "Epoch 279: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.43it/s, loss=5.75e-07, v_num=23, train_loss=4.47e-5, test_loss=4.52e-5]\u001b[A\n",
      "Epoch 280:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.16it/s, loss=5.18e-07, v_num=23, train_loss=4.47e-5, test_loss=4.52e-5]\u001b[AAdjusting learning rate of group 0 to 4.9491e-03.\n",
      "Epoch 280:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.66it/s, loss=4.6e-07, v_num=23, train_loss=4.47e-5, test_loss=4.52e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 280:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.52it/s, loss=4.6e-07, v_num=23, train_loss=4.47e-5, test_loss=4.52e-5]\u001b[A\n",
      "Epoch 280: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.16it/s, loss=4.6e-07, v_num=23, train_loss=6.64e-5, test_loss=6.81e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.46it/s, loss=5.91e-07, v_num=23, train_loss=6.64e-5, test_loss=6.81e-5]\u001b[AAdjusting learning rate of group 0 to 4.9367e-03.\n",
      "Epoch 281:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.78it/s, loss=5.64e-07, v_num=23, train_loss=6.64e-5, test_loss=6.81e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 281:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.39it/s, loss=5.64e-07, v_num=23, train_loss=6.64e-5, test_loss=6.81e-5]\u001b[A\n",
      "Epoch 281: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.95it/s, loss=5.64e-07, v_num=23, train_loss=5.54e-5, test_loss=5.46e-5]\u001b[A\n",
      "Epoch 282:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.59it/s, loss=1.05e-06, v_num=23, train_loss=5.54e-5, test_loss=5.46e-5]\u001b[AAdjusting learning rate of group 0 to 4.9244e-03.\n",
      "Epoch 282:  50%|█████████████████████                     | 79/158 [00:00<00:00, 137.88it/s, loss=1e-06, v_num=23, train_loss=5.54e-5, test_loss=5.46e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 282:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 132.68it/s, loss=1e-06, v_num=23, train_loss=5.54e-5, test_loss=5.46e-5]\u001b[A\n",
      "Epoch 282: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.70it/s, loss=1e-06, v_num=23, train_loss=0.000215, test_loss=0.000215]\u001b[A\n",
      "Epoch 283:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.65it/s, loss=1.04e-06, v_num=23, train_loss=0.000215, test_loss=0.000215]\u001b[AAdjusting learning rate of group 0 to 4.9121e-03.\n",
      "Epoch 283:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.32it/s, loss=1.02e-06, v_num=23, train_loss=0.000215, test_loss=0.000215]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 283:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.46it/s, loss=1.02e-06, v_num=23, train_loss=0.000215, test_loss=0.000215]\u001b[A\n",
      "Epoch 283: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.02it/s, loss=1.02e-06, v_num=23, train_loss=8.61e-5, test_loss=8.67e-5]\u001b[A\n",
      "Epoch 284:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.35it/s, loss=7.16e-07, v_num=23, train_loss=8.61e-5, test_loss=8.67e-5]\u001b[AAdjusting learning rate of group 0 to 4.8998e-03.\n",
      "Epoch 284:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.64it/s, loss=6.89e-07, v_num=23, train_loss=8.61e-5, test_loss=8.67e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 284:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.27it/s, loss=6.89e-07, v_num=23, train_loss=8.61e-5, test_loss=8.67e-5]\u001b[A\n",
      "Epoch 284: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.20it/s, loss=6.89e-07, v_num=23, train_loss=0.00013, test_loss=0.000133]\u001b[A\n",
      "Epoch 285:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.63it/s, loss=5.14e-07, v_num=23, train_loss=0.00013, test_loss=0.000133]\u001b[AAdjusting learning rate of group 0 to 4.8875e-03.\n",
      "Epoch 285:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.50it/s, loss=5.02e-07, v_num=23, train_loss=0.00013, test_loss=0.000133]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 285:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.65it/s, loss=5.02e-07, v_num=23, train_loss=0.00013, test_loss=0.000133]\u001b[A\n",
      "Epoch 285: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.77it/s, loss=5.02e-07, v_num=23, train_loss=4.06e-5, test_loss=4.26e-5]\u001b[A\n",
      "Epoch 286:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.44it/s, loss=6.01e-07, v_num=23, train_loss=4.06e-5, test_loss=4.26e-5]\u001b[AAdjusting learning rate of group 0 to 4.8753e-03.\n",
      "Epoch 286:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.11it/s, loss=5.8e-07, v_num=23, train_loss=4.06e-5, test_loss=4.26e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 286:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 134.99it/s, loss=5.8e-07, v_num=23, train_loss=4.06e-5, test_loss=4.26e-5]\u001b[A\n",
      "Epoch 286: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.48it/s, loss=5.8e-07, v_num=23, train_loss=0.000124, test_loss=0.000127]\u001b[A\n",
      "Epoch 287:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.23it/s, loss=4.8e-07, v_num=23, train_loss=0.000124, test_loss=0.000127]\u001b[AAdjusting learning rate of group 0 to 4.8631e-03.\n",
      "Epoch 287:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 139.16it/s, loss=4.61e-07, v_num=23, train_loss=0.000124, test_loss=0.000127]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 287:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 133.56it/s, loss=4.61e-07, v_num=23, train_loss=0.000124, test_loss=0.000127]\u001b[A\n",
      "Epoch 287: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.51it/s, loss=4.61e-07, v_num=23, train_loss=5.6e-5, test_loss=5.78e-5]\u001b[A\n",
      "Epoch 288:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.20it/s, loss=8.13e-07, v_num=23, train_loss=5.6e-5, test_loss=5.78e-5]\u001b[AAdjusting learning rate of group 0 to 4.8510e-03.\n",
      "Epoch 288:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.64it/s, loss=7.91e-07, v_num=23, train_loss=5.6e-5, test_loss=5.78e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 288:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.87it/s, loss=7.91e-07, v_num=23, train_loss=5.6e-5, test_loss=5.78e-5]\u001b[A\n",
      "Epoch 288: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.67it/s, loss=7.91e-07, v_num=23, train_loss=0.000195, test_loss=0.000197]\u001b[A\n",
      "Epoch 289:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.11it/s, loss=8.14e-07, v_num=23, train_loss=0.000195, test_loss=0.000197]\u001b[AAdjusting learning rate of group 0 to 4.8389e-03.\n",
      "Epoch 289:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.29it/s, loss=7.66e-07, v_num=23, train_loss=0.000195, test_loss=0.000197]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 289:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.42it/s, loss=7.66e-07, v_num=23, train_loss=0.000195, test_loss=0.000197]\u001b[A\n",
      "Epoch 289: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 166.64it/s, loss=7.66e-07, v_num=23, train_loss=0.000143, test_loss=0.000144]\u001b[A\n",
      "Epoch 290:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.09it/s, loss=6.3e-07, v_num=23, train_loss=0.000143, test_loss=0.000144]\u001b[AAdjusting learning rate of group 0 to 4.8268e-03.\n",
      "Epoch 290:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.64it/s, loss=6.63e-07, v_num=23, train_loss=0.000143, test_loss=0.000144]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 290:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.31it/s, loss=6.63e-07, v_num=23, train_loss=0.000143, test_loss=0.000144]\u001b[A\n",
      "Epoch 290: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.29it/s, loss=6.63e-07, v_num=23, train_loss=4.41e-5, test_loss=4.26e-5]\u001b[A\n",
      "Epoch 291:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.34it/s, loss=5.25e-07, v_num=23, train_loss=4.41e-5, test_loss=4.26e-5]\u001b[AAdjusting learning rate of group 0 to 4.8147e-03.\n",
      "Epoch 291:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.19it/s, loss=5.15e-07, v_num=23, train_loss=4.41e-5, test_loss=4.26e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 291:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.10it/s, loss=5.15e-07, v_num=23, train_loss=4.41e-5, test_loss=4.26e-5]\u001b[A\n",
      "Epoch 291: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 168.15it/s, loss=5.15e-07, v_num=23, train_loss=0.000122, test_loss=0.000122]\u001b[A\n",
      "Epoch 292:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.07it/s, loss=6.05e-07, v_num=23, train_loss=0.000122, test_loss=0.000122]\u001b[AAdjusting learning rate of group 0 to 4.8027e-03.\n",
      "Epoch 292:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.61it/s, loss=5.76e-07, v_num=23, train_loss=0.000122, test_loss=0.000122]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 292:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.65it/s, loss=5.76e-07, v_num=23, train_loss=0.000122, test_loss=0.000122]\u001b[A\n",
      "Epoch 292: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.93it/s, loss=5.76e-07, v_num=23, train_loss=0.000113, test_loss=0.000115]\u001b[A\n",
      "Epoch 293:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.73it/s, loss=7.66e-07, v_num=23, train_loss=0.000113, test_loss=0.000115]\u001b[AAdjusting learning rate of group 0 to 4.7906e-03.\n",
      "Epoch 293:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.93it/s, loss=7.32e-07, v_num=23, train_loss=0.000113, test_loss=0.000115]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 293:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.19it/s, loss=7.32e-07, v_num=23, train_loss=0.000113, test_loss=0.000115]\u001b[A\n",
      "Epoch 293: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.47it/s, loss=7.32e-07, v_num=23, train_loss=7.98e-5, test_loss=8.08e-5]\u001b[A\n",
      "Epoch 294:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.17it/s, loss=5.73e-07, v_num=23, train_loss=7.98e-5, test_loss=8.08e-5]\u001b[AAdjusting learning rate of group 0 to 4.7787e-03.\n",
      "Epoch 294:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.43it/s, loss=5.6e-07, v_num=23, train_loss=7.98e-5, test_loss=8.08e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 294:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.73it/s, loss=5.6e-07, v_num=23, train_loss=7.98e-5, test_loss=8.08e-5]\u001b[A\n",
      "Epoch 294: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 168.30it/s, loss=5.6e-07, v_num=23, train_loss=7.8e-5, test_loss=8.04e-5]\u001b[A\n",
      "Epoch 295:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.61it/s, loss=7.39e-07, v_num=23, train_loss=7.8e-5, test_loss=8.04e-5]\u001b[AAdjusting learning rate of group 0 to 4.7667e-03.\n",
      "Epoch 295:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.68it/s, loss=6.89e-07, v_num=23, train_loss=7.8e-5, test_loss=8.04e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 295:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 128.08it/s, loss=6.89e-07, v_num=23, train_loss=7.8e-5, test_loss=8.04e-5]\u001b[A\n",
      "Epoch 295: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.55it/s, loss=6.89e-07, v_num=23, train_loss=9.88e-5, test_loss=9.84e-5]\u001b[A\n",
      "Epoch 296:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.99it/s, loss=8.2e-07, v_num=23, train_loss=9.88e-5, test_loss=9.84e-5]\u001b[AAdjusting learning rate of group 0 to 4.7548e-03.\n",
      "Epoch 296:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.65it/s, loss=7.42e-07, v_num=23, train_loss=9.88e-5, test_loss=9.84e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 296:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.34it/s, loss=7.42e-07, v_num=23, train_loss=9.88e-5, test_loss=9.84e-5]\u001b[A\n",
      "Epoch 296: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.16it/s, loss=7.42e-07, v_num=23, train_loss=6.52e-5, test_loss=6.43e-5]\u001b[A\n",
      "Epoch 297:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.11it/s, loss=3.51e-07, v_num=23, train_loss=6.52e-5, test_loss=6.43e-5]\u001b[AAdjusting learning rate of group 0 to 4.7429e-03.\n",
      "Epoch 297:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.21it/s, loss=3.33e-07, v_num=23, train_loss=6.52e-5, test_loss=6.43e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 297:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.93it/s, loss=3.33e-07, v_num=23, train_loss=6.52e-5, test_loss=6.43e-5]\u001b[A\n",
      "Epoch 297: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.51it/s, loss=3.33e-07, v_num=23, train_loss=3.94e-5, test_loss=4.09e-5]\u001b[A\n",
      "Epoch 298:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.08it/s, loss=5.14e-07, v_num=23, train_loss=3.94e-5, test_loss=4.09e-5]\u001b[AAdjusting learning rate of group 0 to 4.7311e-03.\n",
      "Epoch 298:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.01it/s, loss=4.97e-07, v_num=23, train_loss=3.94e-5, test_loss=4.09e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 298:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.37it/s, loss=4.97e-07, v_num=23, train_loss=3.94e-5, test_loss=4.09e-5]\u001b[A\n",
      "Epoch 298: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.64it/s, loss=4.97e-07, v_num=23, train_loss=6.32e-5, test_loss=6.36e-5]\u001b[A\n",
      "Epoch 299:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.85it/s, loss=5.35e-07, v_num=23, train_loss=6.32e-5, test_loss=6.36e-5]\u001b[AAdjusting learning rate of group 0 to 4.7192e-03.\n",
      "Epoch 299:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.54it/s, loss=5.15e-07, v_num=23, train_loss=6.32e-5, test_loss=6.36e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 299:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.11it/s, loss=5.15e-07, v_num=23, train_loss=6.32e-5, test_loss=6.36e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.08it/s, loss=5.15e-07, v_num=23, train_loss=6.08e-5, test_loss=6.06e-5]\u001b[A\n",
      "Epoch 300:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.87it/s, loss=5.25e-07, v_num=23, train_loss=6.08e-5, test_loss=6.06e-5]\u001b[AAdjusting learning rate of group 0 to 4.7074e-03.\n",
      "Epoch 300:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.72it/s, loss=5.03e-07, v_num=23, train_loss=6.08e-5, test_loss=6.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 300:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.20it/s, loss=5.03e-07, v_num=23, train_loss=6.08e-5, test_loss=6.06e-5]\u001b[A\n",
      "Epoch 300: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.75it/s, loss=5.03e-07, v_num=23, train_loss=6.63e-5, test_loss=6.46e-5]\u001b[A\n",
      "Epoch 301:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.55it/s, loss=4.07e-07, v_num=23, train_loss=6.63e-5, test_loss=6.46e-5]\u001b[AAdjusting learning rate of group 0 to 4.6957e-03.\n",
      "Epoch 301:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.17it/s, loss=3.94e-07, v_num=23, train_loss=6.63e-5, test_loss=6.46e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 301:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.86it/s, loss=3.94e-07, v_num=23, train_loss=6.63e-5, test_loss=6.46e-5]\u001b[A\n",
      "Epoch 301: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 166.89it/s, loss=3.94e-07, v_num=23, train_loss=0.000118, test_loss=0.000117]\u001b[A\n",
      "Epoch 302:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 147.75it/s, loss=3.76e-07, v_num=23, train_loss=0.000118, test_loss=0.000117]\u001b[AAdjusting learning rate of group 0 to 4.6839e-03.\n",
      "Epoch 302:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 136.70it/s, loss=3.48e-07, v_num=23, train_loss=0.000118, test_loss=0.000117]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 302:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 129.33it/s, loss=3.48e-07, v_num=23, train_loss=0.000118, test_loss=0.000117]\u001b[A\n",
      "Epoch 302: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.29it/s, loss=3.48e-07, v_num=23, train_loss=3.28e-5, test_loss=3.31e-5]\u001b[A\n",
      "Epoch 303:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.80it/s, loss=3.74e-07, v_num=23, train_loss=3.28e-5, test_loss=3.31e-5]\u001b[AAdjusting learning rate of group 0 to 4.6722e-03.\n",
      "Epoch 303:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.78it/s, loss=3.6e-07, v_num=23, train_loss=3.28e-5, test_loss=3.31e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 303:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.17it/s, loss=3.6e-07, v_num=23, train_loss=3.28e-5, test_loss=3.31e-5]\u001b[A\n",
      "Epoch 303: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 169.61it/s, loss=3.6e-07, v_num=23, train_loss=4.58e-5, test_loss=4.6e-5]\u001b[A\n",
      "Epoch 304:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.28it/s, loss=8.29e-07, v_num=23, train_loss=4.58e-5, test_loss=4.6e-5]\u001b[AAdjusting learning rate of group 0 to 4.6605e-03.\n",
      "Epoch 304:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.63it/s, loss=7.95e-07, v_num=23, train_loss=4.58e-5, test_loss=4.6e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 304:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.85it/s, loss=7.95e-07, v_num=23, train_loss=4.58e-5, test_loss=4.6e-5]\u001b[A\n",
      "Epoch 304: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 171.13it/s, loss=7.95e-07, v_num=23, train_loss=6.44e-5, test_loss=6.5e-5]\u001b[A\n",
      "Epoch 305:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.00it/s, loss=6.11e-07, v_num=23, train_loss=6.44e-5, test_loss=6.5e-5]\u001b[AAdjusting learning rate of group 0 to 4.6489e-03.\n",
      "Epoch 305:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.32it/s, loss=5.84e-07, v_num=23, train_loss=6.44e-5, test_loss=6.5e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 305:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.53it/s, loss=5.84e-07, v_num=23, train_loss=6.44e-5, test_loss=6.5e-5]\u001b[A\n",
      "Epoch 305: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.34it/s, loss=5.84e-07, v_num=23, train_loss=7.29e-5, test_loss=7.34e-5]\u001b[A\n",
      "Epoch 306:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.75it/s, loss=5.26e-07, v_num=23, train_loss=7.29e-5, test_loss=7.34e-5]\u001b[AAdjusting learning rate of group 0 to 4.6373e-03.\n",
      "Epoch 306:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.71it/s, loss=5.1e-07, v_num=23, train_loss=7.29e-5, test_loss=7.34e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 306:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.64it/s, loss=5.1e-07, v_num=23, train_loss=7.29e-5, test_loss=7.34e-5]\u001b[A\n",
      "Epoch 306: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.44it/s, loss=5.1e-07, v_num=23, train_loss=9.71e-5, test_loss=9.84e-5]\u001b[A\n",
      "Epoch 307:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.06it/s, loss=4.27e-07, v_num=23, train_loss=9.71e-5, test_loss=9.84e-5]\u001b[AAdjusting learning rate of group 0 to 4.6257e-03.\n",
      "Epoch 307:  50%|█████████████████████                     | 79/158 [00:00<00:00, 139.28it/s, loss=4e-07, v_num=23, train_loss=9.71e-5, test_loss=9.84e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 307:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 132.45it/s, loss=4e-07, v_num=23, train_loss=9.71e-5, test_loss=9.84e-5]\u001b[A\n",
      "Epoch 307: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 167.90it/s, loss=4e-07, v_num=23, train_loss=5.91e-5, test_loss=6.07e-5]\u001b[A\n",
      "Epoch 308:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.48it/s, loss=5.19e-07, v_num=23, train_loss=5.91e-5, test_loss=6.07e-5]\u001b[AAdjusting learning rate of group 0 to 4.6141e-03.\n",
      "Epoch 308:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.15it/s, loss=5.04e-07, v_num=23, train_loss=5.91e-5, test_loss=6.07e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 308:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.78it/s, loss=5.04e-07, v_num=23, train_loss=5.91e-5, test_loss=6.07e-5]\u001b[A\n",
      "Epoch 308: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.18it/s, loss=5.04e-07, v_num=23, train_loss=7.56e-5, test_loss=7.68e-5]\u001b[A\n",
      "Epoch 309:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.79it/s, loss=3.79e-07, v_num=23, train_loss=7.56e-5, test_loss=7.68e-5]\u001b[AAdjusting learning rate of group 0 to 4.6026e-03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.67it/s, loss=3.57e-07, v_num=23, train_loss=7.56e-5, test_loss=7.68e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 309:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.70it/s, loss=3.57e-07, v_num=23, train_loss=7.56e-5, test_loss=7.68e-5]\u001b[A\n",
      "Epoch 309: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.80it/s, loss=3.57e-07, v_num=23, train_loss=5.16e-5, test_loss=5.24e-5]\u001b[A\n",
      "Epoch 310:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.12it/s, loss=3.75e-07, v_num=23, train_loss=5.16e-5, test_loss=5.24e-5]\u001b[AAdjusting learning rate of group 0 to 4.5911e-03.\n",
      "Epoch 310:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.58it/s, loss=3.63e-07, v_num=23, train_loss=5.16e-5, test_loss=5.24e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 310:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.59it/s, loss=3.63e-07, v_num=23, train_loss=5.16e-5, test_loss=5.24e-5]\u001b[A\n",
      "Epoch 310: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.45it/s, loss=3.63e-07, v_num=23, train_loss=2.36e-5, test_loss=2.41e-5]\u001b[A\n",
      "Epoch 311:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.93it/s, loss=7.91e-07, v_num=23, train_loss=2.36e-5, test_loss=2.41e-5]\u001b[AAdjusting learning rate of group 0 to 4.5796e-03.\n",
      "Epoch 311:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.12it/s, loss=7.99e-07, v_num=23, train_loss=2.36e-5, test_loss=2.41e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 311:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.68it/s, loss=7.99e-07, v_num=23, train_loss=2.36e-5, test_loss=2.41e-5]\u001b[A\n",
      "Epoch 311: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.50it/s, loss=7.99e-07, v_num=23, train_loss=7.66e-5, test_loss=7.45e-5]\u001b[A\n",
      "Epoch 312:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.36it/s, loss=1.01e-06, v_num=23, train_loss=7.66e-5, test_loss=7.45e-5]\u001b[AAdjusting learning rate of group 0 to 4.5681e-03.\n",
      "Epoch 312:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.12it/s, loss=9.74e-07, v_num=23, train_loss=7.66e-5, test_loss=7.45e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 312:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.49it/s, loss=9.74e-07, v_num=23, train_loss=7.66e-5, test_loss=7.45e-5]\u001b[A\n",
      "Epoch 312: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.46it/s, loss=9.74e-07, v_num=23, train_loss=9.31e-5, test_loss=9.28e-5]\u001b[A\n",
      "Epoch 313:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.16it/s, loss=9.64e-07, v_num=23, train_loss=9.31e-5, test_loss=9.28e-5]\u001b[AAdjusting learning rate of group 0 to 4.5567e-03.\n",
      "Epoch 313:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.11it/s, loss=8.81e-07, v_num=23, train_loss=9.31e-5, test_loss=9.28e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 313:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.15it/s, loss=8.81e-07, v_num=23, train_loss=9.31e-5, test_loss=9.28e-5]\u001b[A\n",
      "Epoch 313: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.74it/s, loss=8.81e-07, v_num=23, train_loss=7.42e-5, test_loss=7.64e-5]\u001b[A\n",
      "Epoch 314:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.00it/s, loss=4.32e-07, v_num=23, train_loss=7.42e-5, test_loss=7.64e-5]\u001b[AAdjusting learning rate of group 0 to 4.5453e-03.\n",
      "Epoch 314:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.65it/s, loss=4.06e-07, v_num=23, train_loss=7.42e-5, test_loss=7.64e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 314:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.06it/s, loss=4.06e-07, v_num=23, train_loss=7.42e-5, test_loss=7.64e-5]\u001b[A\n",
      "Epoch 314: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.42it/s, loss=4.06e-07, v_num=23, train_loss=3.4e-5, test_loss=3.48e-5]\u001b[A\n",
      "Epoch 315:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.85it/s, loss=6.09e-07, v_num=23, train_loss=3.4e-5, test_loss=3.48e-5]\u001b[AAdjusting learning rate of group 0 to 4.5340e-03.\n",
      "Epoch 315:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 138.93it/s, loss=5.9e-07, v_num=23, train_loss=3.4e-5, test_loss=3.48e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 315:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 131.19it/s, loss=5.9e-07, v_num=23, train_loss=3.4e-5, test_loss=3.48e-5]\u001b[A\n",
      "Epoch 315: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 166.60it/s, loss=5.9e-07, v_num=23, train_loss=8.5e-5, test_loss=8.54e-5]\u001b[A\n",
      "Epoch 316:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.22it/s, loss=3.93e-07, v_num=23, train_loss=8.5e-5, test_loss=8.54e-5]\u001b[AAdjusting learning rate of group 0 to 4.5226e-03.\n",
      "Epoch 316:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.05it/s, loss=3.77e-07, v_num=23, train_loss=8.5e-5, test_loss=8.54e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 316:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.05it/s, loss=3.77e-07, v_num=23, train_loss=8.5e-5, test_loss=8.54e-5]\u001b[A\n",
      "Epoch 316: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.00it/s, loss=3.77e-07, v_num=23, train_loss=3.33e-5, test_loss=3.47e-5]\u001b[A\n",
      "Epoch 317:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.14it/s, loss=3.93e-07, v_num=23, train_loss=3.33e-5, test_loss=3.47e-5]\u001b[AAdjusting learning rate of group 0 to 4.5113e-03.\n",
      "Epoch 317:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.13it/s, loss=3.58e-07, v_num=23, train_loss=3.33e-5, test_loss=3.47e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 317:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.68it/s, loss=3.58e-07, v_num=23, train_loss=3.33e-5, test_loss=3.47e-5]\u001b[A\n",
      "Epoch 317: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.13it/s, loss=3.58e-07, v_num=23, train_loss=6.39e-5, test_loss=6.41e-5]\u001b[A\n",
      "Epoch 318:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.18it/s, loss=5.09e-07, v_num=23, train_loss=6.39e-5, test_loss=6.41e-5]\u001b[AAdjusting learning rate of group 0 to 4.5000e-03.\n",
      "Epoch 318:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.41it/s, loss=4.91e-07, v_num=23, train_loss=6.39e-5, test_loss=6.41e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.26it/s, loss=4.91e-07, v_num=23, train_loss=6.39e-5, test_loss=6.41e-5]\u001b[A\n",
      "Epoch 318: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.24it/s, loss=4.91e-07, v_num=23, train_loss=9.16e-5, test_loss=9.36e-5]\u001b[A\n",
      "Epoch 319:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.60it/s, loss=3.84e-07, v_num=23, train_loss=9.16e-5, test_loss=9.36e-5]\u001b[AAdjusting learning rate of group 0 to 4.4888e-03.\n",
      "Epoch 319:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.83it/s, loss=3.72e-07, v_num=23, train_loss=9.16e-5, test_loss=9.36e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 319:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.56it/s, loss=3.72e-07, v_num=23, train_loss=9.16e-5, test_loss=9.36e-5]\u001b[A\n",
      "Epoch 319: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.65it/s, loss=3.72e-07, v_num=23, train_loss=4.45e-5, test_loss=4.5e-5]\u001b[A\n",
      "Epoch 320:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.88it/s, loss=3.93e-07, v_num=23, train_loss=4.45e-5, test_loss=4.5e-5]\u001b[AAdjusting learning rate of group 0 to 4.4776e-03.\n",
      "Epoch 320:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.00it/s, loss=3.76e-07, v_num=23, train_loss=4.45e-5, test_loss=4.5e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 320:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.74it/s, loss=3.76e-07, v_num=23, train_loss=4.45e-5, test_loss=4.5e-5]\u001b[A\n",
      "Epoch 320: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 169.22it/s, loss=3.76e-07, v_num=23, train_loss=3.2e-5, test_loss=3.2e-5]\u001b[A\n",
      "Epoch 321:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 147.84it/s, loss=3.72e-07, v_num=23, train_loss=3.2e-5, test_loss=3.2e-5]\u001b[AAdjusting learning rate of group 0 to 4.4664e-03.\n",
      "Epoch 321:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 136.99it/s, loss=3.49e-07, v_num=23, train_loss=3.2e-5, test_loss=3.2e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 321:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 130.49it/s, loss=3.49e-07, v_num=23, train_loss=3.2e-5, test_loss=3.2e-5]\u001b[A\n",
      "Epoch 321: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.48it/s, loss=3.49e-07, v_num=23, train_loss=4.29e-5, test_loss=4.33e-5]\u001b[A\n",
      "Epoch 322:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 148.75it/s, loss=4e-07, v_num=23, train_loss=4.29e-5, test_loss=4.33e-5]\u001b[AAdjusting learning rate of group 0 to 4.4552e-03.\n",
      "Epoch 322:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.19it/s, loss=3.89e-07, v_num=23, train_loss=4.29e-5, test_loss=4.33e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 322:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.86it/s, loss=3.89e-07, v_num=23, train_loss=4.29e-5, test_loss=4.33e-5]\u001b[A\n",
      "Epoch 322: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.86it/s, loss=3.89e-07, v_num=23, train_loss=7.91e-5, test_loss=7.82e-5]\u001b[A\n",
      "Epoch 323:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.50it/s, loss=8.79e-07, v_num=23, train_loss=7.91e-5, test_loss=7.82e-5]\u001b[AAdjusting learning rate of group 0 to 4.4441e-03.\n",
      "Epoch 323:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.61it/s, loss=8.38e-07, v_num=23, train_loss=7.91e-5, test_loss=7.82e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 323:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.72it/s, loss=8.38e-07, v_num=23, train_loss=7.91e-5, test_loss=7.82e-5]\u001b[A\n",
      "Epoch 323: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.06it/s, loss=8.38e-07, v_num=23, train_loss=0.000114, test_loss=0.000115]\u001b[A\n",
      "Epoch 324:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.20it/s, loss=6.38e-07, v_num=23, train_loss=0.000114, test_loss=0.000115]\u001b[AAdjusting learning rate of group 0 to 4.4330e-03.\n",
      "Epoch 324:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.94it/s, loss=5.98e-07, v_num=23, train_loss=0.000114, test_loss=0.000115]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 324:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.50it/s, loss=5.98e-07, v_num=23, train_loss=0.000114, test_loss=0.000115]\u001b[A\n",
      "Epoch 324: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.78it/s, loss=5.98e-07, v_num=23, train_loss=5.34e-5, test_loss=5.41e-5]\u001b[A\n",
      "Epoch 325:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.83it/s, loss=7.82e-07, v_num=23, train_loss=5.34e-5, test_loss=5.41e-5]\u001b[AAdjusting learning rate of group 0 to 4.4219e-03.\n",
      "Epoch 325:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.58it/s, loss=7.54e-07, v_num=23, train_loss=5.34e-5, test_loss=5.41e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 325:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.66it/s, loss=7.54e-07, v_num=23, train_loss=5.34e-5, test_loss=5.41e-5]\u001b[A\n",
      "Epoch 325: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.37it/s, loss=7.54e-07, v_num=23, train_loss=5.46e-5, test_loss=5.39e-5]\u001b[A\n",
      "Epoch 326:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.69it/s, loss=3.74e-07, v_num=23, train_loss=5.46e-5, test_loss=5.39e-5]\u001b[AAdjusting learning rate of group 0 to 4.4108e-03.\n",
      "Epoch 326:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.88it/s, loss=3.59e-07, v_num=23, train_loss=5.46e-5, test_loss=5.39e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 326:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.57it/s, loss=3.59e-07, v_num=23, train_loss=5.46e-5, test_loss=5.39e-5]\u001b[A\n",
      "Epoch 326: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.00it/s, loss=3.59e-07, v_num=23, train_loss=4.09e-5, test_loss=4.15e-5]\u001b[A\n",
      "Epoch 327:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.69it/s, loss=7.15e-07, v_num=23, train_loss=4.09e-5, test_loss=4.15e-5]\u001b[AAdjusting learning rate of group 0 to 4.3998e-03.\n",
      "Epoch 327:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.11it/s, loss=6.96e-07, v_num=23, train_loss=4.09e-5, test_loss=4.15e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 327:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.65it/s, loss=6.96e-07, v_num=23, train_loss=4.09e-5, test_loss=4.15e-5]\u001b[A\n",
      "Epoch 327: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.14it/s, loss=6.96e-07, v_num=23, train_loss=5.45e-5, test_loss=5.51e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.02it/s, loss=3.14e-07, v_num=23, train_loss=5.45e-5, test_loss=5.51e-5]\u001b[AAdjusting learning rate of group 0 to 4.3888e-03.\n",
      "Epoch 328:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.31it/s, loss=3.05e-07, v_num=23, train_loss=5.45e-5, test_loss=5.51e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 328:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.99it/s, loss=3.05e-07, v_num=23, train_loss=5.45e-5, test_loss=5.51e-5]\u001b[A\n",
      "Epoch 328: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.49it/s, loss=3.05e-07, v_num=23, train_loss=3.36e-5, test_loss=3.45e-5]\u001b[A\n",
      "Epoch 329:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.57it/s, loss=4.74e-07, v_num=23, train_loss=3.36e-5, test_loss=3.45e-5]\u001b[AAdjusting learning rate of group 0 to 4.3778e-03.\n",
      "Epoch 329:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.89it/s, loss=4.62e-07, v_num=23, train_loss=3.36e-5, test_loss=3.45e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 329:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.60it/s, loss=4.62e-07, v_num=23, train_loss=3.36e-5, test_loss=3.45e-5]\u001b[A\n",
      "Epoch 329: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.98it/s, loss=4.62e-07, v_num=23, train_loss=3.65e-5, test_loss=3.71e-5]\u001b[A\n",
      "Epoch 330:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.09it/s, loss=4.12e-07, v_num=23, train_loss=3.65e-5, test_loss=3.71e-5]\u001b[AAdjusting learning rate of group 0 to 4.3669e-03.\n",
      "Epoch 330:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.92it/s, loss=3.82e-07, v_num=23, train_loss=3.65e-5, test_loss=3.71e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 330:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.55it/s, loss=3.82e-07, v_num=23, train_loss=3.65e-5, test_loss=3.71e-5]\u001b[A\n",
      "Epoch 330: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.62it/s, loss=3.82e-07, v_num=23, train_loss=5.58e-5, test_loss=5.61e-5]\u001b[A\n",
      "Epoch 331:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.74it/s, loss=3.67e-07, v_num=23, train_loss=5.58e-5, test_loss=5.61e-5]\u001b[AAdjusting learning rate of group 0 to 4.3560e-03.\n",
      "Epoch 331:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.79it/s, loss=3.48e-07, v_num=23, train_loss=5.58e-5, test_loss=5.61e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 331:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.41it/s, loss=3.48e-07, v_num=23, train_loss=5.58e-5, test_loss=5.61e-5]\u001b[A\n",
      "Epoch 331: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.63it/s, loss=3.48e-07, v_num=23, train_loss=4.03e-5, test_loss=4.01e-5]\u001b[A\n",
      "Epoch 332:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.06it/s, loss=3.85e-07, v_num=23, train_loss=4.03e-5, test_loss=4.01e-5]\u001b[AAdjusting learning rate of group 0 to 4.3451e-03.\n",
      "Epoch 332:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.02it/s, loss=3.65e-07, v_num=23, train_loss=4.03e-5, test_loss=4.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 332:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.39it/s, loss=3.65e-07, v_num=23, train_loss=4.03e-5, test_loss=4.01e-5]\u001b[A\n",
      "Epoch 332: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.41it/s, loss=3.65e-07, v_num=23, train_loss=3.86e-5, test_loss=3.94e-5]\u001b[A\n",
      "Epoch 333:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.32it/s, loss=5.41e-07, v_num=23, train_loss=3.86e-5, test_loss=3.94e-5]\u001b[AAdjusting learning rate of group 0 to 4.3342e-03.\n",
      "Epoch 333:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.24it/s, loss=5.15e-07, v_num=23, train_loss=3.86e-5, test_loss=3.94e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 333:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.80it/s, loss=5.15e-07, v_num=23, train_loss=3.86e-5, test_loss=3.94e-5]\u001b[A\n",
      "Epoch 333: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.00it/s, loss=5.15e-07, v_num=23, train_loss=6.75e-5, test_loss=6.82e-5]\u001b[A\n",
      "Epoch 334:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.24it/s, loss=5.14e-07, v_num=23, train_loss=6.75e-5, test_loss=6.82e-5]\u001b[AAdjusting learning rate of group 0 to 4.3234e-03.\n",
      "Epoch 334:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.03it/s, loss=4.69e-07, v_num=23, train_loss=6.75e-5, test_loss=6.82e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 334:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.93it/s, loss=4.69e-07, v_num=23, train_loss=6.75e-5, test_loss=6.82e-5]\u001b[A\n",
      "Epoch 334: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.78it/s, loss=4.69e-07, v_num=23, train_loss=6.08e-5, test_loss=6.12e-5]\u001b[A\n",
      "Epoch 335:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.12it/s, loss=4.03e-07, v_num=23, train_loss=6.08e-5, test_loss=6.12e-5]\u001b[AAdjusting learning rate of group 0 to 4.3126e-03.\n",
      "Epoch 335:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.06it/s, loss=3.77e-07, v_num=23, train_loss=6.08e-5, test_loss=6.12e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 335:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.36it/s, loss=3.77e-07, v_num=23, train_loss=6.08e-5, test_loss=6.12e-5]\u001b[A\n",
      "Epoch 335: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.95it/s, loss=3.77e-07, v_num=23, train_loss=2.37e-5, test_loss=2.45e-5]\u001b[A\n",
      "Epoch 336:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.97it/s, loss=1.85e-06, v_num=23, train_loss=2.37e-5, test_loss=2.45e-5]\u001b[AAdjusting learning rate of group 0 to 4.3018e-03.\n",
      "Epoch 336:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.90it/s, loss=1.78e-06, v_num=23, train_loss=2.37e-5, test_loss=2.45e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 336:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.90it/s, loss=1.78e-06, v_num=23, train_loss=2.37e-5, test_loss=2.45e-5]\u001b[A\n",
      "Epoch 336: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.75it/s, loss=1.78e-06, v_num=23, train_loss=0.000261, test_loss=0.000256]\u001b[A\n",
      "Epoch 337:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 147.78it/s, loss=7.98e-07, v_num=23, train_loss=0.000261, test_loss=0.000256]\u001b[AAdjusting learning rate of group 0 to 4.2910e-03.\n",
      "Epoch 337:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 136.49it/s, loss=7.02e-07, v_num=23, train_loss=0.000261, test_loss=0.000256]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 337:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.42it/s, loss=7.02e-07, v_num=23, train_loss=0.000261, test_loss=0.000256]\u001b[A\n",
      "Epoch 337: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.54it/s, loss=7.02e-07, v_num=23, train_loss=5.43e-5, test_loss=5.41e-5]\u001b[A\n",
      "Epoch 338:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.43it/s, loss=4.57e-07, v_num=23, train_loss=5.43e-5, test_loss=5.41e-5]\u001b[AAdjusting learning rate of group 0 to 4.2803e-03.\n",
      "Epoch 338:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.88it/s, loss=4.37e-07, v_num=23, train_loss=5.43e-5, test_loss=5.41e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 338:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 128.93it/s, loss=4.37e-07, v_num=23, train_loss=5.43e-5, test_loss=5.41e-5]\u001b[A\n",
      "Epoch 338: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 164.62it/s, loss=4.37e-07, v_num=23, train_loss=4e-5, test_loss=4.11e-5]\u001b[A\n",
      "Epoch 339:  49%|█████████████████████▏                     | 78/158 [00:00<00:00, 148.11it/s, loss=2.8e-07, v_num=23, train_loss=4e-5, test_loss=4.11e-5]\u001b[AAdjusting learning rate of group 0 to 4.2696e-03.\n",
      "Epoch 339:  50%|█████████████████████                     | 79/158 [00:00<00:00, 138.08it/s, loss=2.69e-07, v_num=23, train_loss=4e-5, test_loss=4.11e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 339:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 132.08it/s, loss=2.69e-07, v_num=23, train_loss=4e-5, test_loss=4.11e-5]\u001b[A\n",
      "Epoch 339: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.20it/s, loss=2.69e-07, v_num=23, train_loss=3.03e-5, test_loss=3.16e-5]\u001b[A\n",
      "Epoch 340:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.92it/s, loss=3.47e-07, v_num=23, train_loss=3.03e-5, test_loss=3.16e-5]\u001b[AAdjusting learning rate of group 0 to 4.2589e-03.\n",
      "Epoch 340:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.99it/s, loss=3.34e-07, v_num=23, train_loss=3.03e-5, test_loss=3.16e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 340:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.37it/s, loss=3.34e-07, v_num=23, train_loss=3.03e-5, test_loss=3.16e-5]\u001b[A\n",
      "Epoch 340: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.00it/s, loss=3.34e-07, v_num=23, train_loss=3.53e-5, test_loss=3.63e-5]\u001b[A\n",
      "Epoch 341:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.16it/s, loss=2.86e-07, v_num=23, train_loss=3.53e-5, test_loss=3.63e-5]\u001b[AAdjusting learning rate of group 0 to 4.2483e-03.\n",
      "Epoch 341:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.92it/s, loss=2.74e-07, v_num=23, train_loss=3.53e-5, test_loss=3.63e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 341:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.43it/s, loss=2.74e-07, v_num=23, train_loss=3.53e-5, test_loss=3.63e-5]\u001b[A\n",
      "Epoch 341: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.23it/s, loss=2.74e-07, v_num=23, train_loss=4.88e-5, test_loss=4.9e-5]\u001b[A\n",
      "Epoch 342:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 149.44it/s, loss=4.8e-07, v_num=23, train_loss=4.88e-5, test_loss=4.9e-5]\u001b[AAdjusting learning rate of group 0 to 4.2377e-03.\n",
      "Epoch 342:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.59it/s, loss=4.64e-07, v_num=23, train_loss=4.88e-5, test_loss=4.9e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 342:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 134.29it/s, loss=4.64e-07, v_num=23, train_loss=4.88e-5, test_loss=4.9e-5]\u001b[A\n",
      "Epoch 342: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.14it/s, loss=4.64e-07, v_num=23, train_loss=4.53e-5, test_loss=4.75e-5]\u001b[A\n",
      "Epoch 343:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.86it/s, loss=3.8e-07, v_num=23, train_loss=4.53e-5, test_loss=4.75e-5]\u001b[AAdjusting learning rate of group 0 to 4.2271e-03.\n",
      "Epoch 343:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.66it/s, loss=3.58e-07, v_num=23, train_loss=4.53e-5, test_loss=4.75e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 343:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.02it/s, loss=3.58e-07, v_num=23, train_loss=4.53e-5, test_loss=4.75e-5]\u001b[A\n",
      "Epoch 343: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.30it/s, loss=3.58e-07, v_num=23, train_loss=4.59e-5, test_loss=4.75e-5]\u001b[A\n",
      "Epoch 344:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.51it/s, loss=4.67e-07, v_num=23, train_loss=4.59e-5, test_loss=4.75e-5]\u001b[AAdjusting learning rate of group 0 to 4.2165e-03.\n",
      "Epoch 344:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.61it/s, loss=4.59e-07, v_num=23, train_loss=4.59e-5, test_loss=4.75e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 344:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.20it/s, loss=4.59e-07, v_num=23, train_loss=4.59e-5, test_loss=4.75e-5]\u001b[A\n",
      "Epoch 344: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.83it/s, loss=4.59e-07, v_num=23, train_loss=5.23e-5, test_loss=5.26e-5]\u001b[A\n",
      "Epoch 345:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.05it/s, loss=8.74e-07, v_num=23, train_loss=5.23e-5, test_loss=5.26e-5]\u001b[AAdjusting learning rate of group 0 to 4.2060e-03.\n",
      "Epoch 345:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.78it/s, loss=8.35e-07, v_num=23, train_loss=5.23e-5, test_loss=5.26e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 345:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.82it/s, loss=8.35e-07, v_num=23, train_loss=5.23e-5, test_loss=5.26e-5]\u001b[A\n",
      "Epoch 345: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.50it/s, loss=8.35e-07, v_num=23, train_loss=6.89e-5, test_loss=7.05e-5]\u001b[A\n",
      "Epoch 346:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.10it/s, loss=7.79e-07, v_num=23, train_loss=6.89e-5, test_loss=7.05e-5]\u001b[AAdjusting learning rate of group 0 to 4.1954e-03.\n",
      "Epoch 346:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.59it/s, loss=7.58e-07, v_num=23, train_loss=6.89e-5, test_loss=7.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 346:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.34it/s, loss=7.58e-07, v_num=23, train_loss=6.89e-5, test_loss=7.05e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.68it/s, loss=7.58e-07, v_num=23, train_loss=0.000121, test_loss=0.000123]\u001b[A\n",
      "Epoch 347:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.67it/s, loss=4.7e-07, v_num=23, train_loss=0.000121, test_loss=0.000123]\u001b[AAdjusting learning rate of group 0 to 4.1850e-03.\n",
      "Epoch 347:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.53it/s, loss=4.59e-07, v_num=23, train_loss=0.000121, test_loss=0.000123]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 347:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 131.32it/s, loss=4.59e-07, v_num=23, train_loss=0.000121, test_loss=0.000123]\u001b[A\n",
      "Epoch 347: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.36it/s, loss=4.59e-07, v_num=23, train_loss=4.55e-5, test_loss=4.71e-5]\u001b[A\n",
      "Epoch 348:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.18it/s, loss=6.69e-07, v_num=23, train_loss=4.55e-5, test_loss=4.71e-5]\u001b[AAdjusting learning rate of group 0 to 4.1745e-03.\n",
      "Epoch 348:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.97it/s, loss=6.15e-07, v_num=23, train_loss=4.55e-5, test_loss=4.71e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 348:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.55it/s, loss=6.15e-07, v_num=23, train_loss=4.55e-5, test_loss=4.71e-5]\u001b[A\n",
      "Epoch 348: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.12it/s, loss=6.15e-07, v_num=23, train_loss=5.6e-5, test_loss=5.52e-5]\u001b[A\n",
      "Epoch 349:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 147.98it/s, loss=3.6e-07, v_num=23, train_loss=5.6e-5, test_loss=5.52e-5]\u001b[AAdjusting learning rate of group 0 to 4.1641e-03.\n",
      "Epoch 349:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.62it/s, loss=3.45e-07, v_num=23, train_loss=5.6e-5, test_loss=5.52e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 349:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.70it/s, loss=3.45e-07, v_num=23, train_loss=5.6e-5, test_loss=5.52e-5]\u001b[A\n",
      "Epoch 349: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 168.69it/s, loss=3.45e-07, v_num=23, train_loss=4e-5, test_loss=4.16e-5]\u001b[A\n",
      "Epoch 350:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 148.52it/s, loss=3.31e-07, v_num=23, train_loss=4e-5, test_loss=4.16e-5]\u001b[AAdjusting learning rate of group 0 to 4.1536e-03.\n",
      "Epoch 350:  50%|█████████████████████                     | 79/158 [00:00<00:00, 138.45it/s, loss=3.17e-07, v_num=23, train_loss=4e-5, test_loss=4.16e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 350:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 132.90it/s, loss=3.17e-07, v_num=23, train_loss=4e-5, test_loss=4.16e-5]\u001b[A\n",
      "Epoch 350: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.23it/s, loss=3.17e-07, v_num=23, train_loss=3.67e-5, test_loss=3.72e-5]\u001b[A\n",
      "Epoch 351:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.28it/s, loss=5.43e-07, v_num=23, train_loss=3.67e-5, test_loss=3.72e-5]\u001b[AAdjusting learning rate of group 0 to 4.1433e-03.\n",
      "Epoch 351:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.72it/s, loss=5.13e-07, v_num=23, train_loss=3.67e-5, test_loss=3.72e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 351:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.72it/s, loss=5.13e-07, v_num=23, train_loss=3.67e-5, test_loss=3.72e-5]\u001b[A\n",
      "Epoch 351: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 171.81it/s, loss=5.13e-07, v_num=23, train_loss=3.33e-5, test_loss=3.4e-5]\u001b[A\n",
      "Epoch 352:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.79it/s, loss=2.91e-07, v_num=23, train_loss=3.33e-5, test_loss=3.4e-5]\u001b[AAdjusting learning rate of group 0 to 4.1329e-03.\n",
      "Epoch 352:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.43it/s, loss=2.69e-07, v_num=23, train_loss=3.33e-5, test_loss=3.4e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 352:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.64it/s, loss=2.69e-07, v_num=23, train_loss=3.33e-5, test_loss=3.4e-5]\u001b[A\n",
      "Epoch 352: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.38it/s, loss=2.69e-07, v_num=23, train_loss=3.44e-5, test_loss=3.48e-5]\u001b[A\n",
      "Epoch 353:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 146.02it/s, loss=3.06e-07, v_num=23, train_loss=3.44e-5, test_loss=3.48e-5]\u001b[AAdjusting learning rate of group 0 to 4.1226e-03.\n",
      "Epoch 353:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.44it/s, loss=2.98e-07, v_num=23, train_loss=3.44e-5, test_loss=3.48e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 353:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.05it/s, loss=2.98e-07, v_num=23, train_loss=3.44e-5, test_loss=3.48e-5]\u001b[A\n",
      "Epoch 353: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.64it/s, loss=2.98e-07, v_num=23, train_loss=5.24e-5, test_loss=5.24e-5]\u001b[A\n",
      "Epoch 354:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.31it/s, loss=3.59e-07, v_num=23, train_loss=5.24e-5, test_loss=5.24e-5]\u001b[AAdjusting learning rate of group 0 to 4.1123e-03.\n",
      "Epoch 354:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.54it/s, loss=3.46e-07, v_num=23, train_loss=5.24e-5, test_loss=5.24e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 354:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.29it/s, loss=3.46e-07, v_num=23, train_loss=5.24e-5, test_loss=5.24e-5]\u001b[A\n",
      "Epoch 354: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.25it/s, loss=3.46e-07, v_num=23, train_loss=4.28e-5, test_loss=4.28e-5]\u001b[A\n",
      "Epoch 355:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.66it/s, loss=3.68e-07, v_num=23, train_loss=4.28e-5, test_loss=4.28e-5]\u001b[AAdjusting learning rate of group 0 to 4.1020e-03.\n",
      "Epoch 355:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.37it/s, loss=3.58e-07, v_num=23, train_loss=4.28e-5, test_loss=4.28e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 355:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.47it/s, loss=3.58e-07, v_num=23, train_loss=4.28e-5, test_loss=4.28e-5]\u001b[A\n",
      "Epoch 355: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.32it/s, loss=3.58e-07, v_num=23, train_loss=6.06e-5, test_loss=6.1e-5]\u001b[A\n",
      "Epoch 356:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.74it/s, loss=3.17e-07, v_num=23, train_loss=6.06e-5, test_loss=6.1e-5]\u001b[AAdjusting learning rate of group 0 to 4.0917e-03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.16it/s, loss=3.06e-07, v_num=23, train_loss=6.06e-5, test_loss=6.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 356:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.86it/s, loss=3.06e-07, v_num=23, train_loss=6.06e-5, test_loss=6.1e-5]\u001b[A\n",
      "Epoch 356: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.60it/s, loss=3.06e-07, v_num=23, train_loss=3.04e-5, test_loss=3.05e-5]\u001b[A\n",
      "Epoch 357:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.80it/s, loss=3.45e-07, v_num=23, train_loss=3.04e-5, test_loss=3.05e-5]\u001b[AAdjusting learning rate of group 0 to 4.0815e-03.\n",
      "Epoch 357:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.37it/s, loss=3.34e-07, v_num=23, train_loss=3.04e-5, test_loss=3.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 357:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.30it/s, loss=3.34e-07, v_num=23, train_loss=3.04e-5, test_loss=3.05e-5]\u001b[A\n",
      "Epoch 357: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.01it/s, loss=3.34e-07, v_num=23, train_loss=3.25e-5, test_loss=3.3e-5]\u001b[A\n",
      "Epoch 358:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.12it/s, loss=4.84e-07, v_num=23, train_loss=3.25e-5, test_loss=3.3e-5]\u001b[AAdjusting learning rate of group 0 to 4.0713e-03.\n",
      "Epoch 358:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 139.11it/s, loss=4.5e-07, v_num=23, train_loss=3.25e-5, test_loss=3.3e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 358:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 128.63it/s, loss=4.5e-07, v_num=23, train_loss=3.25e-5, test_loss=3.3e-5]\u001b[A\n",
      "Epoch 358: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.11it/s, loss=4.5e-07, v_num=23, train_loss=0.000118, test_loss=0.000118]\u001b[A\n",
      "Epoch 359:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 147.73it/s, loss=4.11e-07, v_num=23, train_loss=0.000118, test_loss=0.000118]\u001b[AAdjusting learning rate of group 0 to 4.0611e-03.\n",
      "Epoch 359:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.50it/s, loss=3.91e-07, v_num=23, train_loss=0.000118, test_loss=0.000118]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 359:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.33it/s, loss=3.91e-07, v_num=23, train_loss=0.000118, test_loss=0.000118]\u001b[A\n",
      "Epoch 359: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.74it/s, loss=3.91e-07, v_num=23, train_loss=4.81e-5, test_loss=4.94e-5]\u001b[A\n",
      "Epoch 360:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.77it/s, loss=4.01e-07, v_num=23, train_loss=4.81e-5, test_loss=4.94e-5]\u001b[AAdjusting learning rate of group 0 to 4.0510e-03.\n",
      "Epoch 360:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.80it/s, loss=3.94e-07, v_num=23, train_loss=4.81e-5, test_loss=4.94e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 360:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.46it/s, loss=3.94e-07, v_num=23, train_loss=4.81e-5, test_loss=4.94e-5]\u001b[A\n",
      "Epoch 360: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.75it/s, loss=3.94e-07, v_num=23, train_loss=5.91e-5, test_loss=6.05e-5]\u001b[A\n",
      "Epoch 361:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.96it/s, loss=5.53e-07, v_num=23, train_loss=5.91e-5, test_loss=6.05e-5]\u001b[AAdjusting learning rate of group 0 to 4.0408e-03.\n",
      "Epoch 361:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.24it/s, loss=5.38e-07, v_num=23, train_loss=5.91e-5, test_loss=6.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 361:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.15it/s, loss=5.38e-07, v_num=23, train_loss=5.91e-5, test_loss=6.05e-5]\u001b[A\n",
      "Epoch 361: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 164.26it/s, loss=5.38e-07, v_num=23, train_loss=0.000126, test_loss=0.000126]\u001b[A\n",
      "Epoch 362:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 148.69it/s, loss=5.45e-07, v_num=23, train_loss=0.000126, test_loss=0.000126]\u001b[AAdjusting learning rate of group 0 to 4.0307e-03.\n",
      "Epoch 362:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 137.46it/s, loss=4.99e-07, v_num=23, train_loss=0.000126, test_loss=0.000126]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 362:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.51it/s, loss=4.99e-07, v_num=23, train_loss=0.000126, test_loss=0.000126]\u001b[A\n",
      "Epoch 362: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.68it/s, loss=4.99e-07, v_num=23, train_loss=6.21e-5, test_loss=6.11e-5]\u001b[A\n",
      "Epoch 363:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.94it/s, loss=6.06e-07, v_num=23, train_loss=6.21e-5, test_loss=6.11e-5]\u001b[AAdjusting learning rate of group 0 to 4.0207e-03.\n",
      "Epoch 363:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 142.86it/s, loss=5.81e-07, v_num=23, train_loss=6.21e-5, test_loss=6.11e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 363:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.12it/s, loss=5.81e-07, v_num=23, train_loss=6.21e-5, test_loss=6.11e-5]\u001b[A\n",
      "Epoch 363: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.72it/s, loss=5.81e-07, v_num=23, train_loss=5.23e-5, test_loss=5.22e-5]\u001b[A\n",
      "Epoch 364:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.67it/s, loss=3.66e-07, v_num=23, train_loss=5.23e-5, test_loss=5.22e-5]\u001b[AAdjusting learning rate of group 0 to 4.0106e-03.\n",
      "Epoch 364:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.34it/s, loss=3.48e-07, v_num=23, train_loss=5.23e-5, test_loss=5.22e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 364:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.26it/s, loss=3.48e-07, v_num=23, train_loss=5.23e-5, test_loss=5.22e-5]\u001b[A\n",
      "Epoch 364: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.45it/s, loss=3.48e-07, v_num=23, train_loss=5.47e-5, test_loss=5.44e-5]\u001b[A\n",
      "Epoch 365:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.42it/s, loss=4.01e-07, v_num=23, train_loss=5.47e-5, test_loss=5.44e-5]\u001b[AAdjusting learning rate of group 0 to 4.0006e-03.\n",
      "Epoch 365:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.35it/s, loss=3.96e-07, v_num=23, train_loss=5.47e-5, test_loss=5.44e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.68it/s, loss=3.96e-07, v_num=23, train_loss=5.47e-5, test_loss=5.44e-5]\u001b[A\n",
      "Epoch 365: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.37it/s, loss=3.96e-07, v_num=23, train_loss=4.39e-5, test_loss=4.47e-5]\u001b[A\n",
      "Epoch 366:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.30it/s, loss=4.02e-07, v_num=23, train_loss=4.39e-5, test_loss=4.47e-5]\u001b[AAdjusting learning rate of group 0 to 3.9906e-03.\n",
      "Epoch 366:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.06it/s, loss=3.84e-07, v_num=23, train_loss=4.39e-5, test_loss=4.47e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 366:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.56it/s, loss=3.84e-07, v_num=23, train_loss=4.39e-5, test_loss=4.47e-5]\u001b[A\n",
      "Epoch 366: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.31it/s, loss=3.84e-07, v_num=23, train_loss=4.92e-5, test_loss=4.96e-5]\u001b[A\n",
      "Epoch 367:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.44it/s, loss=5.59e-07, v_num=23, train_loss=4.92e-5, test_loss=4.96e-5]\u001b[AAdjusting learning rate of group 0 to 3.9806e-03.\n",
      "Epoch 367:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.15it/s, loss=5.37e-07, v_num=23, train_loss=4.92e-5, test_loss=4.96e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 367:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.90it/s, loss=5.37e-07, v_num=23, train_loss=4.92e-5, test_loss=4.96e-5]\u001b[A\n",
      "Epoch 367: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.49it/s, loss=5.37e-07, v_num=23, train_loss=8.96e-5, test_loss=8.78e-5]\u001b[A\n",
      "Epoch 368:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.92it/s, loss=4.24e-07, v_num=23, train_loss=8.96e-5, test_loss=8.78e-5]\u001b[AAdjusting learning rate of group 0 to 3.9707e-03.\n",
      "Epoch 368:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.49it/s, loss=3.99e-07, v_num=23, train_loss=8.96e-5, test_loss=8.78e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 368:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.71it/s, loss=3.99e-07, v_num=23, train_loss=8.96e-5, test_loss=8.78e-5]\u001b[A\n",
      "Epoch 368: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.59it/s, loss=3.99e-07, v_num=23, train_loss=3.74e-5, test_loss=3.73e-5]\u001b[A\n",
      "Epoch 369:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.06it/s, loss=2.76e-07, v_num=23, train_loss=3.74e-5, test_loss=3.73e-5]\u001b[AAdjusting learning rate of group 0 to 3.9607e-03.\n",
      "Epoch 369:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.59it/s, loss=2.59e-07, v_num=23, train_loss=3.74e-5, test_loss=3.73e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 369:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 127.18it/s, loss=2.59e-07, v_num=23, train_loss=3.74e-5, test_loss=3.73e-5]\u001b[A\n",
      "Epoch 369: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 161.60it/s, loss=2.59e-07, v_num=23, train_loss=2.1e-5, test_loss=2.18e-5]\u001b[A\n",
      "Epoch 370:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.51it/s, loss=5.56e-07, v_num=23, train_loss=2.1e-5, test_loss=2.18e-5]\u001b[AAdjusting learning rate of group 0 to 3.9508e-03.\n",
      "Epoch 370:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.44it/s, loss=5.24e-07, v_num=23, train_loss=2.1e-5, test_loss=2.18e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 370:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.59it/s, loss=5.24e-07, v_num=23, train_loss=2.1e-5, test_loss=2.18e-5]\u001b[A\n",
      "Epoch 370: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.75it/s, loss=5.24e-07, v_num=23, train_loss=5.62e-5, test_loss=5.74e-5]\u001b[A\n",
      "Epoch 371:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.24it/s, loss=2.97e-07, v_num=23, train_loss=5.62e-5, test_loss=5.74e-5]\u001b[AAdjusting learning rate of group 0 to 3.9409e-03.\n",
      "Epoch 371:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.37it/s, loss=2.89e-07, v_num=23, train_loss=5.62e-5, test_loss=5.74e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 371:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.19it/s, loss=2.89e-07, v_num=23, train_loss=5.62e-5, test_loss=5.74e-5]\u001b[A\n",
      "Epoch 371: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 171.19it/s, loss=2.89e-07, v_num=23, train_loss=2.45e-5, test_loss=2.5e-5]\u001b[A\n",
      "Epoch 372:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.81it/s, loss=4.19e-07, v_num=23, train_loss=2.45e-5, test_loss=2.5e-5]\u001b[AAdjusting learning rate of group 0 to 3.9311e-03.\n",
      "Epoch 372:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.68it/s, loss=3.97e-07, v_num=23, train_loss=2.45e-5, test_loss=2.5e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 372:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.53it/s, loss=3.97e-07, v_num=23, train_loss=2.45e-5, test_loss=2.5e-5]\u001b[A\n",
      "Epoch 372: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.16it/s, loss=3.97e-07, v_num=23, train_loss=4.44e-5, test_loss=4.51e-5]\u001b[A\n",
      "Epoch 373:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.01it/s, loss=2.35e-07, v_num=23, train_loss=4.44e-5, test_loss=4.51e-5]\u001b[AAdjusting learning rate of group 0 to 3.9213e-03.\n",
      "Epoch 373:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.87it/s, loss=2.14e-07, v_num=23, train_loss=4.44e-5, test_loss=4.51e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 373:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.02it/s, loss=2.14e-07, v_num=23, train_loss=4.44e-5, test_loss=4.51e-5]\u001b[A\n",
      "Epoch 373: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.50it/s, loss=2.14e-07, v_num=23, train_loss=2.3e-5, test_loss=2.33e-5]\u001b[A\n",
      "Epoch 374:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.85it/s, loss=3.48e-07, v_num=23, train_loss=2.3e-5, test_loss=2.33e-5]\u001b[AAdjusting learning rate of group 0 to 3.9115e-03.\n",
      "Epoch 374:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.03it/s, loss=3.32e-07, v_num=23, train_loss=2.3e-5, test_loss=2.33e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 374:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 134.20it/s, loss=3.32e-07, v_num=23, train_loss=2.3e-5, test_loss=2.33e-5]\u001b[A\n",
      "Epoch 374: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.42it/s, loss=3.32e-07, v_num=23, train_loss=4.62e-5, test_loss=4.81e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 375:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.89it/s, loss=6.64e-07, v_num=23, train_loss=4.62e-5, test_loss=4.81e-5]\u001b[AAdjusting learning rate of group 0 to 3.9017e-03.\n",
      "Epoch 375:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.13it/s, loss=6.48e-07, v_num=23, train_loss=4.62e-5, test_loss=4.81e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 375:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.20it/s, loss=6.48e-07, v_num=23, train_loss=4.62e-5, test_loss=4.81e-5]\u001b[A\n",
      "Epoch 375: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 167.44it/s, loss=6.48e-07, v_num=23, train_loss=0.000179, test_loss=0.000181]\u001b[A\n",
      "Epoch 376:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.17it/s, loss=4.1e-07, v_num=23, train_loss=0.000179, test_loss=0.000181]\u001b[AAdjusting learning rate of group 0 to 3.8919e-03.\n",
      "Epoch 376:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.54it/s, loss=3.84e-07, v_num=23, train_loss=0.000179, test_loss=0.000181]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 376:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 132.20it/s, loss=3.84e-07, v_num=23, train_loss=0.000179, test_loss=0.000181]\u001b[A\n",
      "Epoch 376: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.72it/s, loss=3.84e-07, v_num=23, train_loss=5.21e-5, test_loss=5.53e-5]\u001b[A\n",
      "Epoch 377:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.20it/s, loss=4.82e-07, v_num=23, train_loss=5.21e-5, test_loss=5.53e-5]\u001b[AAdjusting learning rate of group 0 to 3.8822e-03.\n",
      "Epoch 377:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.35it/s, loss=4.64e-07, v_num=23, train_loss=5.21e-5, test_loss=5.53e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 377:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.61it/s, loss=4.64e-07, v_num=23, train_loss=5.21e-5, test_loss=5.53e-5]\u001b[A\n",
      "Epoch 377: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.45it/s, loss=4.64e-07, v_num=23, train_loss=4.44e-5, test_loss=4.36e-5]\u001b[A\n",
      "Epoch 378:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.95it/s, loss=4.77e-07, v_num=23, train_loss=4.44e-5, test_loss=4.36e-5]\u001b[AAdjusting learning rate of group 0 to 3.8725e-03.\n",
      "Epoch 378:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.93it/s, loss=4.58e-07, v_num=23, train_loss=4.44e-5, test_loss=4.36e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 378:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.91it/s, loss=4.58e-07, v_num=23, train_loss=4.44e-5, test_loss=4.36e-5]\u001b[A\n",
      "Epoch 378: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.74it/s, loss=4.58e-07, v_num=23, train_loss=5.57e-5, test_loss=5.82e-5]\u001b[A\n",
      "Epoch 379:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.45it/s, loss=3.79e-07, v_num=23, train_loss=5.57e-5, test_loss=5.82e-5]\u001b[AAdjusting learning rate of group 0 to 3.8628e-03.\n",
      "Epoch 379:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.82it/s, loss=3.48e-07, v_num=23, train_loss=5.57e-5, test_loss=5.82e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 379:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.62it/s, loss=3.48e-07, v_num=23, train_loss=5.57e-5, test_loss=5.82e-5]\u001b[A\n",
      "Epoch 379: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.59it/s, loss=3.48e-07, v_num=23, train_loss=4.92e-5, test_loss=5.02e-5]\u001b[A\n",
      "Epoch 380:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.44it/s, loss=3.37e-07, v_num=23, train_loss=4.92e-5, test_loss=5.02e-5]\u001b[AAdjusting learning rate of group 0 to 3.8532e-03.\n",
      "Epoch 380:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.01it/s, loss=3.29e-07, v_num=23, train_loss=4.92e-5, test_loss=5.02e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 380:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.36it/s, loss=3.29e-07, v_num=23, train_loss=4.92e-5, test_loss=5.02e-5]\u001b[A\n",
      "Epoch 380: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.66it/s, loss=3.29e-07, v_num=23, train_loss=5.58e-5, test_loss=5.58e-5]\u001b[A\n",
      "Epoch 381:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.26it/s, loss=2.69e-07, v_num=23, train_loss=5.58e-5, test_loss=5.58e-5]\u001b[AAdjusting learning rate of group 0 to 3.8435e-03.\n",
      "Epoch 381:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.80it/s, loss=2.52e-07, v_num=23, train_loss=5.58e-5, test_loss=5.58e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 381:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.06it/s, loss=2.52e-07, v_num=23, train_loss=5.58e-5, test_loss=5.58e-5]\u001b[A\n",
      "Epoch 381: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.57it/s, loss=2.52e-07, v_num=23, train_loss=5.19e-5, test_loss=5.32e-5]\u001b[A\n",
      "Epoch 382:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.56it/s, loss=2.36e-07, v_num=23, train_loss=5.19e-5, test_loss=5.32e-5]\u001b[AAdjusting learning rate of group 0 to 3.8339e-03.\n",
      "Epoch 382:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.78it/s, loss=2.31e-07, v_num=23, train_loss=5.19e-5, test_loss=5.32e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 382:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.69it/s, loss=2.31e-07, v_num=23, train_loss=5.19e-5, test_loss=5.32e-5]\u001b[A\n",
      "Epoch 382: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.33it/s, loss=2.31e-07, v_num=23, train_loss=2.82e-5, test_loss=2.85e-5]\u001b[A\n",
      "Epoch 383:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.14it/s, loss=4.71e-07, v_num=23, train_loss=2.82e-5, test_loss=2.85e-5]\u001b[AAdjusting learning rate of group 0 to 3.8243e-03.\n",
      "Epoch 383:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.86it/s, loss=4.36e-07, v_num=23, train_loss=2.82e-5, test_loss=2.85e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 383:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.55it/s, loss=4.36e-07, v_num=23, train_loss=2.82e-5, test_loss=2.85e-5]\u001b[A\n",
      "Epoch 383: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.86it/s, loss=4.36e-07, v_num=23, train_loss=2.84e-5, test_loss=2.93e-5]\u001b[A\n",
      "Epoch 384:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.80it/s, loss=3.06e-07, v_num=23, train_loss=2.84e-5, test_loss=2.93e-5]\u001b[AAdjusting learning rate of group 0 to 3.8148e-03.\n",
      "Epoch 384:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.57it/s, loss=2.94e-07, v_num=23, train_loss=2.84e-5, test_loss=2.93e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 384:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.81it/s, loss=2.94e-07, v_num=23, train_loss=2.84e-5, test_loss=2.93e-5]\u001b[A\n",
      "Epoch 384: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.42it/s, loss=2.94e-07, v_num=23, train_loss=3.95e-5, test_loss=3.96e-5]\u001b[A\n",
      "Epoch 385:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 147.51it/s, loss=6e-07, v_num=23, train_loss=3.95e-5, test_loss=3.96e-5]\u001b[AAdjusting learning rate of group 0 to 3.8052e-03.\n",
      "Epoch 385:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.07it/s, loss=5.82e-07, v_num=23, train_loss=3.95e-5, test_loss=3.96e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 385:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.17it/s, loss=5.82e-07, v_num=23, train_loss=3.95e-5, test_loss=3.96e-5]\u001b[A\n",
      "Epoch 385: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.35it/s, loss=5.82e-07, v_num=23, train_loss=7.19e-5, test_loss=7.31e-5]\u001b[A\n",
      "Epoch 386:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.67it/s, loss=3.19e-07, v_num=23, train_loss=7.19e-5, test_loss=7.31e-5]\u001b[AAdjusting learning rate of group 0 to 3.7957e-03.\n",
      "Epoch 386:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.07it/s, loss=3.1e-07, v_num=23, train_loss=7.19e-5, test_loss=7.31e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 386:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.05it/s, loss=3.1e-07, v_num=23, train_loss=7.19e-5, test_loss=7.31e-5]\u001b[A\n",
      "Epoch 386: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.01it/s, loss=3.1e-07, v_num=23, train_loss=3.19e-5, test_loss=3.28e-5]\u001b[A\n",
      "Epoch 387:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.38it/s, loss=3.15e-07, v_num=23, train_loss=3.19e-5, test_loss=3.28e-5]\u001b[AAdjusting learning rate of group 0 to 3.7862e-03.\n",
      "Epoch 387:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.39it/s, loss=3.06e-07, v_num=23, train_loss=3.19e-5, test_loss=3.28e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 387:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.45it/s, loss=3.06e-07, v_num=23, train_loss=3.19e-5, test_loss=3.28e-5]\u001b[A\n",
      "Epoch 387: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.69it/s, loss=3.06e-07, v_num=23, train_loss=3.57e-5, test_loss=3.71e-5]\u001b[A\n",
      "Epoch 388:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.57it/s, loss=3.65e-07, v_num=23, train_loss=3.57e-5, test_loss=3.71e-5]\u001b[AAdjusting learning rate of group 0 to 3.7768e-03.\n",
      "Epoch 388:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.10it/s, loss=3.55e-07, v_num=23, train_loss=3.57e-5, test_loss=3.71e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 388:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.04it/s, loss=3.55e-07, v_num=23, train_loss=3.57e-5, test_loss=3.71e-5]\u001b[A\n",
      "Epoch 388: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.96it/s, loss=3.55e-07, v_num=23, train_loss=4.37e-5, test_loss=4.59e-5]\u001b[A\n",
      "Epoch 389:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.58it/s, loss=4.19e-07, v_num=23, train_loss=4.37e-5, test_loss=4.59e-5]\u001b[AAdjusting learning rate of group 0 to 3.7673e-03.\n",
      "Epoch 389:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.62it/s, loss=4.02e-07, v_num=23, train_loss=4.37e-5, test_loss=4.59e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 389:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.21it/s, loss=4.02e-07, v_num=23, train_loss=4.37e-5, test_loss=4.59e-5]\u001b[A\n",
      "Epoch 389: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.22it/s, loss=4.02e-07, v_num=23, train_loss=3.94e-5, test_loss=4.27e-5]\u001b[A\n",
      "Epoch 390:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.67it/s, loss=4.35e-07, v_num=23, train_loss=3.94e-5, test_loss=4.27e-5]\u001b[AAdjusting learning rate of group 0 to 3.7579e-03.\n",
      "Epoch 390:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.05it/s, loss=3.85e-07, v_num=23, train_loss=3.94e-5, test_loss=4.27e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 390:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.34it/s, loss=3.85e-07, v_num=23, train_loss=3.94e-5, test_loss=4.27e-5]\u001b[A\n",
      "Epoch 390: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.48it/s, loss=3.85e-07, v_num=23, train_loss=2.57e-5, test_loss=2.62e-5]\u001b[A\n",
      "Epoch 391:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.25it/s, loss=2.94e-07, v_num=23, train_loss=2.57e-5, test_loss=2.62e-5]\u001b[AAdjusting learning rate of group 0 to 3.7485e-03.\n",
      "Epoch 391:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.32it/s, loss=2.83e-07, v_num=23, train_loss=2.57e-5, test_loss=2.62e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 391:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.41it/s, loss=2.83e-07, v_num=23, train_loss=2.57e-5, test_loss=2.62e-5]\u001b[A\n",
      "Epoch 391: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.31it/s, loss=2.83e-07, v_num=23, train_loss=2.12e-5, test_loss=2.19e-5]\u001b[A\n",
      "Epoch 392:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.93it/s, loss=3.2e-07, v_num=23, train_loss=2.12e-5, test_loss=2.19e-5]\u001b[AAdjusting learning rate of group 0 to 3.7391e-03.\n",
      "Epoch 392:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.79it/s, loss=2.99e-07, v_num=23, train_loss=2.12e-5, test_loss=2.19e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.11it/s]\u001b[A\n",
      "Epoch 392: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 162.69it/s, loss=2.99e-07, v_num=23, train_loss=2.87e-5, test_loss=2.89e-5]\u001b[A\n",
      "Epoch 393:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.90it/s, loss=2.74e-07, v_num=23, train_loss=2.87e-5, test_loss=2.89e-5]\u001b[AAdjusting learning rate of group 0 to 3.7298e-03.\n",
      "Epoch 393:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.54it/s, loss=2.64e-07, v_num=23, train_loss=2.87e-5, test_loss=2.89e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 393:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.92it/s, loss=2.64e-07, v_num=23, train_loss=2.87e-5, test_loss=2.89e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.53it/s, loss=2.64e-07, v_num=23, train_loss=2.84e-5, test_loss=2.91e-5]\u001b[A\n",
      "Epoch 394:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.21it/s, loss=3.36e-07, v_num=23, train_loss=2.84e-5, test_loss=2.91e-5]\u001b[AAdjusting learning rate of group 0 to 3.7205e-03.\n",
      "Epoch 394:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.85it/s, loss=3.29e-07, v_num=23, train_loss=2.84e-5, test_loss=2.91e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 394:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.31it/s, loss=3.29e-07, v_num=23, train_loss=2.84e-5, test_loss=2.91e-5]\u001b[A\n",
      "Epoch 394: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.29it/s, loss=3.29e-07, v_num=23, train_loss=5.68e-5, test_loss=5.64e-5]\u001b[A\n",
      "Epoch 395:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 148.65it/s, loss=6e-07, v_num=23, train_loss=5.68e-5, test_loss=5.64e-5]\u001b[AAdjusting learning rate of group 0 to 3.7112e-03.\n",
      "Epoch 395:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.85it/s, loss=5.9e-07, v_num=23, train_loss=5.68e-5, test_loss=5.64e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 395:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.95it/s, loss=5.9e-07, v_num=23, train_loss=5.68e-5, test_loss=5.64e-5]\u001b[A\n",
      "Epoch 395: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.48it/s, loss=5.9e-07, v_num=23, train_loss=7.65e-5, test_loss=7.54e-5]\u001b[A\n",
      "Epoch 396:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.89it/s, loss=3.25e-07, v_num=23, train_loss=7.65e-5, test_loss=7.54e-5]\u001b[AAdjusting learning rate of group 0 to 3.7019e-03.\n",
      "Epoch 396:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.35it/s, loss=3.15e-07, v_num=23, train_loss=7.65e-5, test_loss=7.54e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 396:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.45it/s, loss=3.15e-07, v_num=23, train_loss=7.65e-5, test_loss=7.54e-5]\u001b[A\n",
      "Epoch 396: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.55it/s, loss=3.15e-07, v_num=23, train_loss=3.22e-5, test_loss=3.27e-5]\u001b[A\n",
      "Epoch 397:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.22it/s, loss=5.83e-07, v_num=23, train_loss=3.22e-5, test_loss=3.27e-5]\u001b[AAdjusting learning rate of group 0 to 3.6926e-03.\n",
      "Epoch 397:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.23it/s, loss=5.15e-07, v_num=23, train_loss=3.22e-5, test_loss=3.27e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 397:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.60it/s, loss=5.15e-07, v_num=23, train_loss=3.22e-5, test_loss=3.27e-5]\u001b[A\n",
      "Epoch 397: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.42it/s, loss=5.15e-07, v_num=23, train_loss=2.47e-5, test_loss=2.53e-5]\u001b[A\n",
      "Epoch 398:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.17it/s, loss=3.43e-07, v_num=23, train_loss=2.47e-5, test_loss=2.53e-5]\u001b[AAdjusting learning rate of group 0 to 3.6834e-03.\n",
      "Epoch 398:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.02it/s, loss=3.23e-07, v_num=23, train_loss=2.47e-5, test_loss=2.53e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 398:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.44it/s, loss=3.23e-07, v_num=23, train_loss=2.47e-5, test_loss=2.53e-5]\u001b[A\n",
      "Epoch 398: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.72it/s, loss=3.23e-07, v_num=23, train_loss=4.24e-5, test_loss=4.35e-5]\u001b[A\n",
      "Epoch 399:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.01it/s, loss=2.5e-07, v_num=23, train_loss=4.24e-5, test_loss=4.35e-5]\u001b[AAdjusting learning rate of group 0 to 3.6742e-03.\n",
      "Epoch 399:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.79it/s, loss=2.37e-07, v_num=23, train_loss=4.24e-5, test_loss=4.35e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 399:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.87it/s, loss=2.37e-07, v_num=23, train_loss=4.24e-5, test_loss=4.35e-5]\u001b[A\n",
      "Epoch 399: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.10it/s, loss=2.37e-07, v_num=23, train_loss=2.76e-5, test_loss=2.85e-5]\u001b[A\n",
      "Epoch 400:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.70it/s, loss=2.47e-07, v_num=23, train_loss=2.76e-5, test_loss=2.85e-5]\u001b[AAdjusting learning rate of group 0 to 3.6650e-03.\n",
      "Epoch 400:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.61it/s, loss=2.4e-07, v_num=23, train_loss=2.76e-5, test_loss=2.85e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 400:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.00it/s, loss=2.4e-07, v_num=23, train_loss=2.76e-5, test_loss=2.85e-5]\u001b[A\n",
      "Epoch 400: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.39it/s, loss=2.4e-07, v_num=23, train_loss=2.61e-5, test_loss=2.76e-5]\u001b[A\n",
      "Epoch 401:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.20it/s, loss=2.92e-07, v_num=23, train_loss=2.61e-5, test_loss=2.76e-5]\u001b[AAdjusting learning rate of group 0 to 3.6558e-03.\n",
      "Epoch 401:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.24it/s, loss=2.79e-07, v_num=23, train_loss=2.61e-5, test_loss=2.76e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 401:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.71it/s, loss=2.79e-07, v_num=23, train_loss=2.61e-5, test_loss=2.76e-5]\u001b[A\n",
      "Epoch 401: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.80it/s, loss=2.79e-07, v_num=23, train_loss=3.04e-5, test_loss=3.12e-5]\u001b[A\n",
      "Epoch 402:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.13it/s, loss=3.69e-07, v_num=23, train_loss=3.04e-5, test_loss=3.12e-5]\u001b[AAdjusting learning rate of group 0 to 3.6467e-03.\n",
      "Epoch 402:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.03it/s, loss=3.52e-07, v_num=23, train_loss=3.04e-5, test_loss=3.12e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 402:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.82it/s, loss=3.52e-07, v_num=23, train_loss=3.04e-5, test_loss=3.12e-5]\u001b[A\n",
      "Epoch 402: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.49it/s, loss=3.52e-07, v_num=23, train_loss=3.18e-5, test_loss=3.3e-5]\u001b[A\n",
      "Epoch 403:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.73it/s, loss=4.89e-07, v_num=23, train_loss=3.18e-5, test_loss=3.3e-5]\u001b[AAdjusting learning rate of group 0 to 3.6376e-03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.95it/s, loss=4.77e-07, v_num=23, train_loss=3.18e-5, test_loss=3.3e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 403:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 134.48it/s, loss=4.77e-07, v_num=23, train_loss=3.18e-5, test_loss=3.3e-5]\u001b[A\n",
      "Epoch 403: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.20it/s, loss=4.77e-07, v_num=23, train_loss=9.13e-5, test_loss=9.05e-5]\u001b[A\n",
      "Epoch 404:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.67it/s, loss=7.4e-07, v_num=23, train_loss=9.13e-5, test_loss=9.05e-5]\u001b[AAdjusting learning rate of group 0 to 3.6285e-03.\n",
      "Epoch 404:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.69it/s, loss=7.23e-07, v_num=23, train_loss=9.13e-5, test_loss=9.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 404:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.08it/s, loss=7.23e-07, v_num=23, train_loss=9.13e-5, test_loss=9.05e-5]\u001b[A\n",
      "Epoch 404: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.85it/s, loss=7.23e-07, v_num=23, train_loss=7.42e-5, test_loss=7.4e-5]\u001b[A\n",
      "Epoch 405:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.17it/s, loss=3.85e-07, v_num=23, train_loss=7.42e-5, test_loss=7.4e-5]\u001b[AAdjusting learning rate of group 0 to 3.6194e-03.\n",
      "Epoch 405:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.30it/s, loss=3.69e-07, v_num=23, train_loss=7.42e-5, test_loss=7.4e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 405:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.77it/s, loss=3.69e-07, v_num=23, train_loss=7.42e-5, test_loss=7.4e-5]\u001b[A\n",
      "Epoch 405: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.84it/s, loss=3.69e-07, v_num=23, train_loss=3.6e-5, test_loss=3.89e-5]\u001b[A\n",
      "Epoch 406:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.90it/s, loss=3.51e-07, v_num=23, train_loss=3.6e-5, test_loss=3.89e-5]\u001b[AAdjusting learning rate of group 0 to 3.6104e-03.\n",
      "Epoch 406:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.49it/s, loss=3.31e-07, v_num=23, train_loss=3.6e-5, test_loss=3.89e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 406:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 134.46it/s, loss=3.31e-07, v_num=23, train_loss=3.6e-5, test_loss=3.89e-5]\u001b[A\n",
      "Epoch 406: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.28it/s, loss=3.31e-07, v_num=23, train_loss=2.7e-5, test_loss=2.75e-5]\u001b[A\n",
      "Epoch 407:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.53it/s, loss=2.61e-07, v_num=23, train_loss=2.7e-5, test_loss=2.75e-5]\u001b[AAdjusting learning rate of group 0 to 3.6013e-03.\n",
      "Epoch 407:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.78it/s, loss=2.48e-07, v_num=23, train_loss=2.7e-5, test_loss=2.75e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 407:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.53it/s, loss=2.48e-07, v_num=23, train_loss=2.7e-5, test_loss=2.75e-5]\u001b[A\n",
      "Epoch 407: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 168.79it/s, loss=2.48e-07, v_num=23, train_loss=3e-5, test_loss=3.04e-5]\u001b[A\n",
      "Epoch 408:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 149.13it/s, loss=3.27e-07, v_num=23, train_loss=3e-5, test_loss=3.04e-5]\u001b[AAdjusting learning rate of group 0 to 3.5923e-03.\n",
      "Epoch 408:  50%|█████████████████████                     | 79/158 [00:00<00:00, 138.65it/s, loss=3.09e-07, v_num=23, train_loss=3e-5, test_loss=3.04e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 408:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 132.52it/s, loss=3.09e-07, v_num=23, train_loss=3e-5, test_loss=3.04e-5]\u001b[A\n",
      "Epoch 408: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.81it/s, loss=3.09e-07, v_num=23, train_loss=3.54e-5, test_loss=3.56e-5]\u001b[A\n",
      "Epoch 409:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.84it/s, loss=3.47e-07, v_num=23, train_loss=3.54e-5, test_loss=3.56e-5]\u001b[AAdjusting learning rate of group 0 to 3.5834e-03.\n",
      "Epoch 409:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.07it/s, loss=3.35e-07, v_num=23, train_loss=3.54e-5, test_loss=3.56e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 409:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.01it/s, loss=3.35e-07, v_num=23, train_loss=3.54e-5, test_loss=3.56e-5]\u001b[A\n",
      "Epoch 409: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.49it/s, loss=3.35e-07, v_num=23, train_loss=5.31e-5, test_loss=5.41e-5]\u001b[A\n",
      "Epoch 410:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.47it/s, loss=4.95e-07, v_num=23, train_loss=5.31e-5, test_loss=5.41e-5]\u001b[AAdjusting learning rate of group 0 to 3.5744e-03.\n",
      "Epoch 410:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.33it/s, loss=4.68e-07, v_num=23, train_loss=5.31e-5, test_loss=5.41e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 410:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.84it/s, loss=4.68e-07, v_num=23, train_loss=5.31e-5, test_loss=5.41e-5]\u001b[A\n",
      "Epoch 410: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.33it/s, loss=4.68e-07, v_num=23, train_loss=5.62e-5, test_loss=5.63e-5]\u001b[A\n",
      "Epoch 411:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.05it/s, loss=7.97e-07, v_num=23, train_loss=5.62e-5, test_loss=5.63e-5]\u001b[AAdjusting learning rate of group 0 to 3.5655e-03.\n",
      "Epoch 411:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.46it/s, loss=7.39e-07, v_num=23, train_loss=5.62e-5, test_loss=5.63e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 411:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.77it/s, loss=7.39e-07, v_num=23, train_loss=5.62e-5, test_loss=5.63e-5]\u001b[A\n",
      "Epoch 411: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.99it/s, loss=7.39e-07, v_num=23, train_loss=5.13e-5, test_loss=5.18e-5]\u001b[A\n",
      "Epoch 412:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.36it/s, loss=3.9e-07, v_num=23, train_loss=5.13e-5, test_loss=5.18e-5]\u001b[AAdjusting learning rate of group 0 to 3.5566e-03.\n",
      "Epoch 412:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.01it/s, loss=3.84e-07, v_num=23, train_loss=5.13e-5, test_loss=5.18e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.00it/s, loss=3.84e-07, v_num=23, train_loss=5.13e-5, test_loss=5.18e-5]\u001b[A\n",
      "Epoch 412: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.76it/s, loss=3.84e-07, v_num=23, train_loss=4.84e-5, test_loss=4.9e-5]\u001b[A\n",
      "Epoch 413:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.29it/s, loss=3.55e-07, v_num=23, train_loss=4.84e-5, test_loss=4.9e-5]\u001b[AAdjusting learning rate of group 0 to 3.5477e-03.\n",
      "Epoch 413:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.99it/s, loss=3.41e-07, v_num=23, train_loss=4.84e-5, test_loss=4.9e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 413:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.88it/s, loss=3.41e-07, v_num=23, train_loss=4.84e-5, test_loss=4.9e-5]\u001b[A\n",
      "Epoch 413: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.54it/s, loss=3.41e-07, v_num=23, train_loss=5.7e-5, test_loss=5.75e-5]\u001b[A\n",
      "Epoch 414:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.39it/s, loss=3.47e-07, v_num=23, train_loss=5.7e-5, test_loss=5.75e-5]\u001b[AAdjusting learning rate of group 0 to 3.5388e-03.\n",
      "Epoch 414:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.50it/s, loss=3.35e-07, v_num=23, train_loss=5.7e-5, test_loss=5.75e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 414:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 135.75it/s, loss=3.35e-07, v_num=23, train_loss=5.7e-5, test_loss=5.75e-5]\u001b[A\n",
      "Epoch 414: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 171.23it/s, loss=3.35e-07, v_num=23, train_loss=3.24e-5, test_loss=3.3e-5]\u001b[A\n",
      "Epoch 415:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.32it/s, loss=2.99e-07, v_num=23, train_loss=3.24e-5, test_loss=3.3e-5]\u001b[AAdjusting learning rate of group 0 to 3.5299e-03.\n",
      "Epoch 415:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.04it/s, loss=2.76e-07, v_num=23, train_loss=3.24e-5, test_loss=3.3e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 415:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.59it/s, loss=2.76e-07, v_num=23, train_loss=3.24e-5, test_loss=3.3e-5]\u001b[A\n",
      "Epoch 415: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.46it/s, loss=2.76e-07, v_num=23, train_loss=2.73e-5, test_loss=2.74e-5]\u001b[A\n",
      "Epoch 416:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.73it/s, loss=2.4e-07, v_num=23, train_loss=2.73e-5, test_loss=2.74e-5]\u001b[AAdjusting learning rate of group 0 to 3.5211e-03.\n",
      "Epoch 416:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.08it/s, loss=2.3e-07, v_num=23, train_loss=2.73e-5, test_loss=2.74e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 416:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.10it/s, loss=2.3e-07, v_num=23, train_loss=2.73e-5, test_loss=2.74e-5]\u001b[A\n",
      "Epoch 416: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 165.80it/s, loss=2.3e-07, v_num=23, train_loss=3.86e-5, test_loss=3.86e-5]\u001b[A\n",
      "Epoch 417:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.40it/s, loss=3.12e-07, v_num=23, train_loss=3.86e-5, test_loss=3.86e-5]\u001b[AAdjusting learning rate of group 0 to 3.5123e-03.\n",
      "Epoch 417:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.73it/s, loss=2.99e-07, v_num=23, train_loss=3.86e-5, test_loss=3.86e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 417:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.75it/s, loss=2.99e-07, v_num=23, train_loss=3.86e-5, test_loss=3.86e-5]\u001b[A\n",
      "Epoch 417: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.30it/s, loss=2.99e-07, v_num=23, train_loss=3.7e-5, test_loss=3.82e-5]\u001b[A\n",
      "Epoch 418:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.27it/s, loss=6.64e-07, v_num=23, train_loss=3.7e-5, test_loss=3.82e-5]\u001b[AAdjusting learning rate of group 0 to 3.5035e-03.\n",
      "Epoch 418:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.32it/s, loss=6.42e-07, v_num=23, train_loss=3.7e-5, test_loss=3.82e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 418:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 130.06it/s, loss=6.42e-07, v_num=23, train_loss=3.7e-5, test_loss=3.82e-5]\u001b[A\n",
      "Epoch 418: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.36it/s, loss=6.42e-07, v_num=23, train_loss=9.18e-5, test_loss=0.000101]\u001b[A\n",
      "Epoch 419:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.15it/s, loss=2.66e-07, v_num=23, train_loss=9.18e-5, test_loss=0.000101]\u001b[AAdjusting learning rate of group 0 to 3.4948e-03.\n",
      "Epoch 419:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.90it/s, loss=2.49e-07, v_num=23, train_loss=9.18e-5, test_loss=0.000101]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 419:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.22it/s, loss=2.49e-07, v_num=23, train_loss=9.18e-5, test_loss=0.000101]\u001b[A\n",
      "Epoch 419: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.98it/s, loss=2.49e-07, v_num=23, train_loss=2.55e-5, test_loss=2.65e-5]\u001b[A\n",
      "Epoch 420:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.15it/s, loss=2.49e-07, v_num=23, train_loss=2.55e-5, test_loss=2.65e-5]\u001b[AAdjusting learning rate of group 0 to 3.4860e-03.\n",
      "Epoch 420:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.56it/s, loss=2.44e-07, v_num=23, train_loss=2.55e-5, test_loss=2.65e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 420:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.74it/s, loss=2.44e-07, v_num=23, train_loss=2.55e-5, test_loss=2.65e-5]\u001b[A\n",
      "Epoch 420: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.39it/s, loss=2.44e-07, v_num=23, train_loss=3.99e-5, test_loss=4.03e-5]\u001b[A\n",
      "Epoch 421:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.17it/s, loss=2.43e-07, v_num=23, train_loss=3.99e-5, test_loss=4.03e-5]\u001b[AAdjusting learning rate of group 0 to 3.4773e-03.\n",
      "Epoch 421:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.31it/s, loss=2.3e-07, v_num=23, train_loss=3.99e-5, test_loss=4.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 421:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 134.35it/s, loss=2.3e-07, v_num=23, train_loss=3.99e-5, test_loss=4.03e-5]\u001b[A\n",
      "Epoch 421: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 171.23it/s, loss=2.3e-07, v_num=23, train_loss=2.13e-5, test_loss=2.18e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 422:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.90it/s, loss=2.2e-07, v_num=23, train_loss=2.13e-5, test_loss=2.18e-5]\u001b[AAdjusting learning rate of group 0 to 3.4686e-03.\n",
      "Epoch 422:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.00it/s, loss=2.12e-07, v_num=23, train_loss=2.13e-5, test_loss=2.18e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 422:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.92it/s, loss=2.12e-07, v_num=23, train_loss=2.13e-5, test_loss=2.18e-5]\u001b[A\n",
      "Epoch 422: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.13it/s, loss=2.12e-07, v_num=23, train_loss=4.08e-5, test_loss=4.23e-5]\u001b[A\n",
      "Epoch 423:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.27it/s, loss=3.47e-07, v_num=23, train_loss=4.08e-5, test_loss=4.23e-5]\u001b[AAdjusting learning rate of group 0 to 3.4600e-03.\n",
      "Epoch 423:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.99it/s, loss=3.36e-07, v_num=23, train_loss=4.08e-5, test_loss=4.23e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 423:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.91it/s, loss=3.36e-07, v_num=23, train_loss=4.08e-5, test_loss=4.23e-5]\u001b[A\n",
      "Epoch 423: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.27it/s, loss=3.36e-07, v_num=23, train_loss=4.72e-5, test_loss=4.73e-5]\u001b[A\n",
      "Epoch 424:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.22it/s, loss=3.16e-07, v_num=23, train_loss=4.72e-5, test_loss=4.73e-5]\u001b[AAdjusting learning rate of group 0 to 3.4513e-03.\n",
      "Epoch 424:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.45it/s, loss=3.02e-07, v_num=23, train_loss=4.72e-5, test_loss=4.73e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 424:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.96it/s, loss=3.02e-07, v_num=23, train_loss=4.72e-5, test_loss=4.73e-5]\u001b[A\n",
      "Epoch 424: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.23it/s, loss=3.02e-07, v_num=23, train_loss=2.23e-5, test_loss=2.29e-5]\u001b[A\n",
      "Epoch 425:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.28it/s, loss=6.2e-07, v_num=23, train_loss=2.23e-5, test_loss=2.29e-5]\u001b[AAdjusting learning rate of group 0 to 3.4427e-03.\n",
      "Epoch 425:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.56it/s, loss=5.81e-07, v_num=23, train_loss=2.23e-5, test_loss=2.29e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 425:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.18it/s, loss=5.81e-07, v_num=23, train_loss=2.23e-5, test_loss=2.29e-5]\u001b[A\n",
      "Epoch 425: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.56it/s, loss=5.81e-07, v_num=23, train_loss=8.5e-5, test_loss=8.53e-5]\u001b[A\n",
      "Epoch 426:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.96it/s, loss=4.06e-07, v_num=23, train_loss=8.5e-5, test_loss=8.53e-5]\u001b[AAdjusting learning rate of group 0 to 3.4341e-03.\n",
      "Epoch 426:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.88it/s, loss=3.99e-07, v_num=23, train_loss=8.5e-5, test_loss=8.53e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 426:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.72it/s, loss=3.99e-07, v_num=23, train_loss=8.5e-5, test_loss=8.53e-5]\u001b[A\n",
      "Epoch 426: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.56it/s, loss=3.99e-07, v_num=23, train_loss=3.95e-5, test_loss=3.95e-5]\u001b[A\n",
      "Epoch 427:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.62it/s, loss=5.37e-07, v_num=23, train_loss=3.95e-5, test_loss=3.95e-5]\u001b[AAdjusting learning rate of group 0 to 3.4255e-03.\n",
      "Epoch 427:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.49it/s, loss=5.08e-07, v_num=23, train_loss=3.95e-5, test_loss=3.95e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 427:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.25it/s, loss=5.08e-07, v_num=23, train_loss=3.95e-5, test_loss=3.95e-5]\u001b[A\n",
      "Epoch 427: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.89it/s, loss=5.08e-07, v_num=23, train_loss=5.6e-5, test_loss=5.67e-5]\u001b[A\n",
      "Epoch 428:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.33it/s, loss=4.72e-07, v_num=23, train_loss=5.6e-5, test_loss=5.67e-5]\u001b[AAdjusting learning rate of group 0 to 3.4169e-03.\n",
      "Epoch 428:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.78it/s, loss=4.39e-07, v_num=23, train_loss=5.6e-5, test_loss=5.67e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 428:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.94it/s, loss=4.39e-07, v_num=23, train_loss=5.6e-5, test_loss=5.67e-5]\u001b[A\n",
      "Epoch 428: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.34it/s, loss=4.39e-07, v_num=23, train_loss=7.24e-5, test_loss=7.2e-5]\u001b[A\n",
      "Epoch 429:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.36it/s, loss=3.08e-07, v_num=23, train_loss=7.24e-5, test_loss=7.2e-5]\u001b[AAdjusting learning rate of group 0 to 3.4084e-03.\n",
      "Epoch 429:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.67it/s, loss=2.99e-07, v_num=23, train_loss=7.24e-5, test_loss=7.2e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 429:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.62it/s, loss=2.99e-07, v_num=23, train_loss=7.24e-5, test_loss=7.2e-5]\u001b[A\n",
      "Epoch 429: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.42it/s, loss=2.99e-07, v_num=23, train_loss=4.69e-5, test_loss=4.8e-5]\u001b[A\n",
      "Epoch 430:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.19it/s, loss=3.96e-07, v_num=23, train_loss=4.69e-5, test_loss=4.8e-5]\u001b[AAdjusting learning rate of group 0 to 3.3999e-03.\n",
      "Epoch 430:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.36it/s, loss=3.76e-07, v_num=23, train_loss=4.69e-5, test_loss=4.8e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 430:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 134.52it/s, loss=3.76e-07, v_num=23, train_loss=4.69e-5, test_loss=4.8e-5]\u001b[A\n",
      "Epoch 430: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.16it/s, loss=3.76e-07, v_num=23, train_loss=5.22e-5, test_loss=5.35e-5]\u001b[A\n",
      "Epoch 431:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.30it/s, loss=2.87e-07, v_num=23, train_loss=5.22e-5, test_loss=5.35e-5]\u001b[AAdjusting learning rate of group 0 to 3.3914e-03.\n",
      "Epoch 431:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.87it/s, loss=2.79e-07, v_num=23, train_loss=5.22e-5, test_loss=5.35e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 431:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.11it/s, loss=2.79e-07, v_num=23, train_loss=5.22e-5, test_loss=5.35e-5]\u001b[A\n",
      "Epoch 431: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.11it/s, loss=2.79e-07, v_num=23, train_loss=2.71e-5, test_loss=2.83e-5]\u001b[A\n",
      "Epoch 432:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.27it/s, loss=2.36e-07, v_num=23, train_loss=2.71e-5, test_loss=2.83e-5]\u001b[AAdjusting learning rate of group 0 to 3.3829e-03.\n",
      "Epoch 432:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.14it/s, loss=2.26e-07, v_num=23, train_loss=2.71e-5, test_loss=2.83e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 432:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.31it/s, loss=2.26e-07, v_num=23, train_loss=2.71e-5, test_loss=2.83e-5]\u001b[A\n",
      "Epoch 432: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.26it/s, loss=2.26e-07, v_num=23, train_loss=2.87e-5, test_loss=2.95e-5]\u001b[A\n",
      "Epoch 433:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.09it/s, loss=5.45e-07, v_num=23, train_loss=2.87e-5, test_loss=2.95e-5]\u001b[AAdjusting learning rate of group 0 to 3.3744e-03.\n",
      "Epoch 433:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.71it/s, loss=5.32e-07, v_num=23, train_loss=2.87e-5, test_loss=2.95e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 433:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.09it/s, loss=5.32e-07, v_num=23, train_loss=2.87e-5, test_loss=2.95e-5]\u001b[A\n",
      "Epoch 433: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.94it/s, loss=5.32e-07, v_num=23, train_loss=7.09e-5, test_loss=7.13e-5]\u001b[A\n",
      "Epoch 434:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.08it/s, loss=2.97e-07, v_num=23, train_loss=7.09e-5, test_loss=7.13e-5]\u001b[AAdjusting learning rate of group 0 to 3.3660e-03.\n",
      "Epoch 434:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.04it/s, loss=2.74e-07, v_num=23, train_loss=7.09e-5, test_loss=7.13e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 434:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.50it/s, loss=2.74e-07, v_num=23, train_loss=7.09e-5, test_loss=7.13e-5]\u001b[A\n",
      "Epoch 434: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.92it/s, loss=2.74e-07, v_num=23, train_loss=2.28e-5, test_loss=2.34e-5]\u001b[A\n",
      "Epoch 435:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.27it/s, loss=2.29e-07, v_num=23, train_loss=2.28e-5, test_loss=2.34e-5]\u001b[AAdjusting learning rate of group 0 to 3.3576e-03.\n",
      "Epoch 435:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.16it/s, loss=2.15e-07, v_num=23, train_loss=2.28e-5, test_loss=2.34e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 435:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.04it/s, loss=2.15e-07, v_num=23, train_loss=2.28e-5, test_loss=2.34e-5]\u001b[A\n",
      "Epoch 435: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.09it/s, loss=2.15e-07, v_num=23, train_loss=2.09e-5, test_loss=2.17e-5]\u001b[A\n",
      "Epoch 436:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.33it/s, loss=2.87e-07, v_num=23, train_loss=2.09e-5, test_loss=2.17e-5]\u001b[AAdjusting learning rate of group 0 to 3.3492e-03.\n",
      "Epoch 436:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.25it/s, loss=2.77e-07, v_num=23, train_loss=2.09e-5, test_loss=2.17e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 436:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.11it/s, loss=2.77e-07, v_num=23, train_loss=2.09e-5, test_loss=2.17e-5]\u001b[A\n",
      "Epoch 436: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.22it/s, loss=2.77e-07, v_num=23, train_loss=2.68e-5, test_loss=2.74e-5]\u001b[A\n",
      "Epoch 437:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.28it/s, loss=4.45e-07, v_num=23, train_loss=2.68e-5, test_loss=2.74e-5]\u001b[AAdjusting learning rate of group 0 to 3.3408e-03.\n",
      "Epoch 437:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.88it/s, loss=4.29e-07, v_num=23, train_loss=2.68e-5, test_loss=2.74e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 437:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.16it/s, loss=4.29e-07, v_num=23, train_loss=2.68e-5, test_loss=2.74e-5]\u001b[A\n",
      "Epoch 437: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.41it/s, loss=4.29e-07, v_num=23, train_loss=3.31e-5, test_loss=3.44e-5]\u001b[A\n",
      "Epoch 438:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.13it/s, loss=4.87e-07, v_num=23, train_loss=3.31e-5, test_loss=3.44e-5]\u001b[AAdjusting learning rate of group 0 to 3.3325e-03.\n",
      "Epoch 438:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.08it/s, loss=4.75e-07, v_num=23, train_loss=3.31e-5, test_loss=3.44e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 438:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.35it/s, loss=4.75e-07, v_num=23, train_loss=3.31e-5, test_loss=3.44e-5]\u001b[A\n",
      "Epoch 438: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.89it/s, loss=4.75e-07, v_num=23, train_loss=9.21e-5, test_loss=9.41e-5]\u001b[A\n",
      "Epoch 439:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.48it/s, loss=3.31e-07, v_num=23, train_loss=9.21e-5, test_loss=9.41e-5]\u001b[AAdjusting learning rate of group 0 to 3.3241e-03.\n",
      "Epoch 439:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.45it/s, loss=2.82e-07, v_num=23, train_loss=9.21e-5, test_loss=9.41e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 439:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.56it/s, loss=2.82e-07, v_num=23, train_loss=9.21e-5, test_loss=9.41e-5]\u001b[A\n",
      "Epoch 439: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.79it/s, loss=2.82e-07, v_num=23, train_loss=3.34e-5, test_loss=3.36e-5]\u001b[A\n",
      "Epoch 440:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.92it/s, loss=4.14e-07, v_num=23, train_loss=3.34e-5, test_loss=3.36e-5]\u001b[AAdjusting learning rate of group 0 to 3.3158e-03.\n",
      "Epoch 440:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.41it/s, loss=3.92e-07, v_num=23, train_loss=3.34e-5, test_loss=3.36e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 440:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.54it/s, loss=3.92e-07, v_num=23, train_loss=3.34e-5, test_loss=3.36e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.45it/s, loss=3.92e-07, v_num=23, train_loss=8.3e-5, test_loss=8.32e-5]\u001b[A\n",
      "Epoch 441:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.99it/s, loss=2.54e-07, v_num=23, train_loss=8.3e-5, test_loss=8.32e-5]\u001b[AAdjusting learning rate of group 0 to 3.3075e-03.\n",
      "Epoch 441:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.47it/s, loss=2.39e-07, v_num=23, train_loss=8.3e-5, test_loss=8.32e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 441:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.39it/s, loss=2.39e-07, v_num=23, train_loss=8.3e-5, test_loss=8.32e-5]\u001b[A\n",
      "Epoch 441: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.67it/s, loss=2.39e-07, v_num=23, train_loss=2.63e-5, test_loss=2.69e-5]\u001b[A\n",
      "Epoch 442:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.28it/s, loss=4.8e-07, v_num=23, train_loss=2.63e-5, test_loss=2.69e-5]\u001b[AAdjusting learning rate of group 0 to 3.2993e-03.\n",
      "Epoch 442:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.54it/s, loss=4.68e-07, v_num=23, train_loss=2.63e-5, test_loss=2.69e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 442:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.05it/s, loss=4.68e-07, v_num=23, train_loss=2.63e-5, test_loss=2.69e-5]\u001b[A\n",
      "Epoch 442: 100%|█████████████████████████████████████████| 158/158 [00:01<00:00, 150.48it/s, loss=4.68e-07, v_num=23, train_loss=6e-5, test_loss=6.08e-5]\u001b[A\n",
      "Epoch 443:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 148.34it/s, loss=6.63e-07, v_num=23, train_loss=6e-5, test_loss=6.08e-5]\u001b[AAdjusting learning rate of group 0 to 3.2910e-03.\n",
      "Epoch 443:  50%|█████████████████████                     | 79/158 [00:00<00:00, 138.00it/s, loss=6.27e-07, v_num=23, train_loss=6e-5, test_loss=6.08e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 443:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 132.67it/s, loss=6.27e-07, v_num=23, train_loss=6e-5, test_loss=6.08e-5]\u001b[A\n",
      "Epoch 443: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.20it/s, loss=6.27e-07, v_num=23, train_loss=6.11e-5, test_loss=5.92e-5]\u001b[A\n",
      "Epoch 444:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.13it/s, loss=2.69e-07, v_num=23, train_loss=6.11e-5, test_loss=5.92e-5]\u001b[AAdjusting learning rate of group 0 to 3.2828e-03.\n",
      "Epoch 444:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.07it/s, loss=2.57e-07, v_num=23, train_loss=6.11e-5, test_loss=5.92e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 444:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.17it/s, loss=2.57e-07, v_num=23, train_loss=6.11e-5, test_loss=5.92e-5]\u001b[A\n",
      "Epoch 444: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.53it/s, loss=2.57e-07, v_num=23, train_loss=3.22e-5, test_loss=3.39e-5]\u001b[A\n",
      "Epoch 445:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.12it/s, loss=2.27e-07, v_num=23, train_loss=3.22e-5, test_loss=3.39e-5]\u001b[AAdjusting learning rate of group 0 to 3.2746e-03.\n",
      "Epoch 445:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.67it/s, loss=2.19e-07, v_num=23, train_loss=3.22e-5, test_loss=3.39e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 445:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.15it/s, loss=2.19e-07, v_num=23, train_loss=3.22e-5, test_loss=3.39e-5]\u001b[A\n",
      "Epoch 445: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.63it/s, loss=2.19e-07, v_num=23, train_loss=2.81e-5, test_loss=2.83e-5]\u001b[A\n",
      "Epoch 446:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 124.91it/s, loss=2.91e-07, v_num=23, train_loss=2.81e-5, test_loss=2.83e-5]\u001b[AAdjusting learning rate of group 0 to 3.2664e-03.\n",
      "Epoch 446:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 117.40it/s, loss=2.79e-07, v_num=23, train_loss=2.81e-5, test_loss=2.83e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 446:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 117.20it/s, loss=2.79e-07, v_num=23, train_loss=2.81e-5, test_loss=2.83e-5]\u001b[A\n",
      "Validating:  49%|██████████████████████████████████████████████████▊                                                    | 39/79 [00:00<00:00, 184.20it/s]\u001b[A\n",
      "Epoch 446: 100%|██████████████████████████████████████| 158/158 [00:01<00:00, 129.72it/s, loss=2.79e-07, v_num=23, train_loss=3.79e-5, test_loss=3.88e-5]\u001b[A\n",
      "Epoch 447:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 120.55it/s, loss=3.83e-07, v_num=23, train_loss=3.79e-5, test_loss=3.88e-5]\u001b[AAdjusting learning rate of group 0 to 3.2582e-03.\n",
      "Epoch 447:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 114.53it/s, loss=3.71e-07, v_num=23, train_loss=3.79e-5, test_loss=3.88e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 447:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 115.29it/s, loss=3.71e-07, v_num=23, train_loss=3.79e-5, test_loss=3.88e-5]\u001b[A\n",
      "Validating:  51%|████████████████████████████████████████████████████▏                                                  | 40/79 [00:00<00:00, 187.89it/s]\u001b[A\n",
      "Epoch 447: 100%|██████████████████████████████████████| 158/158 [00:01<00:00, 130.20it/s, loss=3.71e-07, v_num=23, train_loss=5.26e-5, test_loss=5.26e-5]\u001b[A\n",
      "Epoch 448:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 120.40it/s, loss=3.52e-07, v_num=23, train_loss=5.26e-5, test_loss=5.26e-5]\u001b[AAdjusting learning rate of group 0 to 3.2501e-03.\n",
      "Epoch 448:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 112.50it/s, loss=3.42e-07, v_num=23, train_loss=5.26e-5, test_loss=5.26e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 448:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 114.29it/s, loss=3.42e-07, v_num=23, train_loss=5.26e-5, test_loss=5.26e-5]\u001b[A\n",
      "Epoch 448: 100%|██████████████████████████████████████| 158/158 [00:01<00:00, 127.74it/s, loss=3.42e-07, v_num=23, train_loss=2.42e-5, test_loss=2.57e-5]\u001b[A\n",
      "Epoch 449:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 121.11it/s, loss=3.3e-07, v_num=23, train_loss=2.42e-5, test_loss=2.57e-5]\u001b[AAdjusting learning rate of group 0 to 3.2420e-03.\n",
      "Epoch 449:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 113.71it/s, loss=3.09e-07, v_num=23, train_loss=2.42e-5, test_loss=2.57e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.38it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   5%|█████▎                                                                                                   | 4/79 [00:00<00:06, 11.93it/s]\u001b[A\n",
      "Validating:   8%|███████▉                                                                                                 | 6/79 [00:00<00:05, 14.15it/s]\u001b[A\n",
      "Epoch 449:  67%|██████████████████████████▏            | 106/158 [00:01<00:00, 81.70it/s, loss=3.09e-07, v_num=23, train_loss=2.42e-5, test_loss=2.57e-5]\u001b[A\n",
      "Epoch 449: 100%|███████████████████████████████████████| 158/158 [00:01<00:00, 109.25it/s, loss=3.09e-07, v_num=23, train_loss=3.67e-5, test_loss=3.8e-5]\u001b[A\n",
      "Epoch 450:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 114.94it/s, loss=3.9e-07, v_num=23, train_loss=3.67e-5, test_loss=3.8e-5]\u001b[AAdjusting learning rate of group 0 to 3.2338e-03.\n",
      "Epoch 450:  50%|████████████████████                    | 79/158 [00:00<00:00, 107.82it/s, loss=3.62e-07, v_num=23, train_loss=3.67e-5, test_loss=3.8e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:24,  3.23it/s]\u001b[A\n",
      "Epoch 450:  67%|██████████████████████████▊             | 106/158 [00:01<00:00, 89.93it/s, loss=3.62e-07, v_num=23, train_loss=3.67e-5, test_loss=3.8e-5]\u001b[A\n",
      "Epoch 450: 100%|██████████████████████████████████████| 158/158 [00:01<00:00, 120.08it/s, loss=3.62e-07, v_num=23, train_loss=3.84e-5, test_loss=3.86e-5]\u001b[A\n",
      "Epoch 451:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.62it/s, loss=2.5e-07, v_num=23, train_loss=3.84e-5, test_loss=3.86e-5]\u001b[AAdjusting learning rate of group 0 to 3.2258e-03.\n",
      "Epoch 451:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.01it/s, loss=2.38e-07, v_num=23, train_loss=3.84e-5, test_loss=3.86e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 451:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.45it/s, loss=2.38e-07, v_num=23, train_loss=3.84e-5, test_loss=3.86e-5]\u001b[A\n",
      "Epoch 451: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.79it/s, loss=2.38e-07, v_num=23, train_loss=2.69e-5, test_loss=2.77e-5]\u001b[A\n",
      "Epoch 452:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.70it/s, loss=3.8e-07, v_num=23, train_loss=2.69e-5, test_loss=2.77e-5]\u001b[AAdjusting learning rate of group 0 to 3.2177e-03.\n",
      "Epoch 452:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.96it/s, loss=3.66e-07, v_num=23, train_loss=2.69e-5, test_loss=2.77e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 452:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.86it/s, loss=3.66e-07, v_num=23, train_loss=2.69e-5, test_loss=2.77e-5]\u001b[A\n",
      "Epoch 452: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.18it/s, loss=3.66e-07, v_num=23, train_loss=2.64e-5, test_loss=2.76e-5]\u001b[A\n",
      "Epoch 453:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.66it/s, loss=3.68e-07, v_num=23, train_loss=2.64e-5, test_loss=2.76e-5]\u001b[AAdjusting learning rate of group 0 to 3.2097e-03.\n",
      "Epoch 453:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.03it/s, loss=3.58e-07, v_num=23, train_loss=2.64e-5, test_loss=2.76e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 453:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.67it/s, loss=3.58e-07, v_num=23, train_loss=2.64e-5, test_loss=2.76e-5]\u001b[A\n",
      "Epoch 453: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.89it/s, loss=3.58e-07, v_num=23, train_loss=2.9e-5, test_loss=2.97e-5]\u001b[A\n",
      "Epoch 454:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.09it/s, loss=3.05e-07, v_num=23, train_loss=2.9e-5, test_loss=2.97e-5]\u001b[AAdjusting learning rate of group 0 to 3.2016e-03.\n",
      "Epoch 454:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.04it/s, loss=2.72e-07, v_num=23, train_loss=2.9e-5, test_loss=2.97e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 454:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.02it/s, loss=2.72e-07, v_num=23, train_loss=2.9e-5, test_loss=2.97e-5]\u001b[A\n",
      "Epoch 454: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.61it/s, loss=2.72e-07, v_num=23, train_loss=3.22e-5, test_loss=3.25e-5]\u001b[A\n",
      "Epoch 455:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.61it/s, loss=2.75e-07, v_num=23, train_loss=3.22e-5, test_loss=3.25e-5]\u001b[AAdjusting learning rate of group 0 to 3.1936e-03.\n",
      "Epoch 455:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.92it/s, loss=2.65e-07, v_num=23, train_loss=3.22e-5, test_loss=3.25e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 455:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.50it/s, loss=2.65e-07, v_num=23, train_loss=3.22e-5, test_loss=3.25e-5]\u001b[A\n",
      "Epoch 455: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.08it/s, loss=2.65e-07, v_num=23, train_loss=3.1e-5, test_loss=3.18e-5]\u001b[A\n",
      "Epoch 456:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.59it/s, loss=2.45e-07, v_num=23, train_loss=3.1e-5, test_loss=3.18e-5]\u001b[AAdjusting learning rate of group 0 to 3.1856e-03.\n",
      "Epoch 456:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.64it/s, loss=2.38e-07, v_num=23, train_loss=3.1e-5, test_loss=3.18e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 456:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.29it/s, loss=2.38e-07, v_num=23, train_loss=3.1e-5, test_loss=3.18e-5]\u001b[A\n",
      "Epoch 456: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.96it/s, loss=2.38e-07, v_num=23, train_loss=5.9e-5, test_loss=6.01e-5]\u001b[A\n",
      "Epoch 457:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 150.12it/s, loss=2.02e-07, v_num=23, train_loss=5.9e-5, test_loss=6.01e-5]\u001b[AAdjusting learning rate of group 0 to 3.1777e-03.\n",
      "Epoch 457:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.49it/s, loss=1.93e-07, v_num=23, train_loss=5.9e-5, test_loss=6.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 457:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.81it/s, loss=1.93e-07, v_num=23, train_loss=5.9e-5, test_loss=6.01e-5]\u001b[A\n",
      "Epoch 457: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.70it/s, loss=1.93e-07, v_num=23, train_loss=2.84e-5, test_loss=2.91e-5]\u001b[A\n",
      "Epoch 458:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.36it/s, loss=2.66e-07, v_num=23, train_loss=2.84e-5, test_loss=2.91e-5]\u001b[AAdjusting learning rate of group 0 to 3.1697e-03.\n",
      "Epoch 458:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.28it/s, loss=2.6e-07, v_num=23, train_loss=2.84e-5, test_loss=2.91e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 458:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 130.82it/s, loss=2.6e-07, v_num=23, train_loss=2.84e-5, test_loss=2.91e-5]\u001b[A\n",
      "Epoch 458: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.93it/s, loss=2.6e-07, v_num=23, train_loss=4.41e-5, test_loss=4.48e-5]\u001b[A\n",
      "Epoch 459:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.23it/s, loss=3.22e-07, v_num=23, train_loss=4.41e-5, test_loss=4.48e-5]\u001b[AAdjusting learning rate of group 0 to 3.1618e-03.\n",
      "Epoch 459:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.44it/s, loss=3.08e-07, v_num=23, train_loss=4.41e-5, test_loss=4.48e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 459:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.50it/s, loss=3.08e-07, v_num=23, train_loss=4.41e-5, test_loss=4.48e-5]\u001b[A\n",
      "Epoch 459: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.95it/s, loss=3.08e-07, v_num=23, train_loss=2.58e-5, test_loss=2.66e-5]\u001b[A\n",
      "Epoch 460:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.48it/s, loss=3.05e-07, v_num=23, train_loss=2.58e-5, test_loss=2.66e-5]\u001b[AAdjusting learning rate of group 0 to 3.1539e-03.\n",
      "Epoch 460:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.75it/s, loss=2.88e-07, v_num=23, train_loss=2.58e-5, test_loss=2.66e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 460:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.35it/s, loss=2.88e-07, v_num=23, train_loss=2.58e-5, test_loss=2.66e-5]\u001b[A\n",
      "Epoch 460: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.34it/s, loss=2.88e-07, v_num=23, train_loss=3.41e-5, test_loss=3.47e-5]\u001b[A\n",
      "Epoch 461:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.02it/s, loss=2.24e-07, v_num=23, train_loss=3.41e-5, test_loss=3.47e-5]\u001b[AAdjusting learning rate of group 0 to 3.1460e-03.\n",
      "Epoch 461:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.03it/s, loss=2.1e-07, v_num=23, train_loss=3.41e-5, test_loss=3.47e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 461:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.13it/s, loss=2.1e-07, v_num=23, train_loss=3.41e-5, test_loss=3.47e-5]\u001b[A\n",
      "Epoch 461: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.25it/s, loss=2.1e-07, v_num=23, train_loss=2.05e-5, test_loss=2.11e-5]\u001b[A\n",
      "Epoch 462:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.70it/s, loss=2.95e-07, v_num=23, train_loss=2.05e-5, test_loss=2.11e-5]\u001b[AAdjusting learning rate of group 0 to 3.1382e-03.\n",
      "Epoch 462:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.87it/s, loss=2.83e-07, v_num=23, train_loss=2.05e-5, test_loss=2.11e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 462:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.50it/s, loss=2.83e-07, v_num=23, train_loss=2.05e-5, test_loss=2.11e-5]\u001b[A\n",
      "Epoch 462: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.87it/s, loss=2.83e-07, v_num=23, train_loss=4.65e-5, test_loss=4.71e-5]\u001b[A\n",
      "Epoch 463:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.28it/s, loss=3.71e-07, v_num=23, train_loss=4.65e-5, test_loss=4.71e-5]\u001b[AAdjusting learning rate of group 0 to 3.1303e-03.\n",
      "Epoch 463:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.21it/s, loss=3.57e-07, v_num=23, train_loss=4.65e-5, test_loss=4.71e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 463:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.59it/s, loss=3.57e-07, v_num=23, train_loss=4.65e-5, test_loss=4.71e-5]\u001b[A\n",
      "Epoch 463: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.43it/s, loss=3.57e-07, v_num=23, train_loss=3.01e-5, test_loss=3.13e-5]\u001b[A\n",
      "Epoch 464:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.44it/s, loss=1.96e-07, v_num=23, train_loss=3.01e-5, test_loss=3.13e-5]\u001b[AAdjusting learning rate of group 0 to 3.1225e-03.\n",
      "Epoch 464:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.26it/s, loss=1.87e-07, v_num=23, train_loss=3.01e-5, test_loss=3.13e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 464:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.82it/s, loss=1.87e-07, v_num=23, train_loss=3.01e-5, test_loss=3.13e-5]\u001b[A\n",
      "Epoch 464: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.96it/s, loss=1.87e-07, v_num=23, train_loss=2.28e-5, test_loss=2.28e-5]\u001b[A\n",
      "Epoch 465:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.30it/s, loss=4.09e-07, v_num=23, train_loss=2.28e-5, test_loss=2.28e-5]\u001b[AAdjusting learning rate of group 0 to 3.1147e-03.\n",
      "Epoch 465:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.51it/s, loss=3.96e-07, v_num=23, train_loss=2.28e-5, test_loss=2.28e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 465:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.63it/s, loss=3.96e-07, v_num=23, train_loss=2.28e-5, test_loss=2.28e-5]\u001b[A\n",
      "Epoch 465: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.39it/s, loss=3.96e-07, v_num=23, train_loss=3.52e-5, test_loss=3.63e-5]\u001b[A\n",
      "Epoch 466:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.48it/s, loss=4.03e-07, v_num=23, train_loss=3.52e-5, test_loss=3.63e-5]\u001b[AAdjusting learning rate of group 0 to 3.1069e-03.\n",
      "Epoch 466:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.57it/s, loss=3.98e-07, v_num=23, train_loss=3.52e-5, test_loss=3.63e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 466:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.74it/s, loss=3.98e-07, v_num=23, train_loss=3.52e-5, test_loss=3.63e-5]\u001b[A\n",
      "Epoch 466: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.34it/s, loss=3.98e-07, v_num=23, train_loss=2.94e-5, test_loss=3.01e-5]\u001b[A\n",
      "Epoch 467:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.99it/s, loss=3.13e-07, v_num=23, train_loss=2.94e-5, test_loss=3.01e-5]\u001b[AAdjusting learning rate of group 0 to 3.0991e-03.\n",
      "Epoch 467:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.90it/s, loss=2.93e-07, v_num=23, train_loss=2.94e-5, test_loss=3.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 467:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.19it/s, loss=2.93e-07, v_num=23, train_loss=2.94e-5, test_loss=3.01e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 166.39it/s, loss=2.93e-07, v_num=23, train_loss=3.92e-5, test_loss=4e-5]\u001b[A\n",
      "Epoch 468:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 148.62it/s, loss=1.96e-07, v_num=23, train_loss=3.92e-5, test_loss=4e-5]\u001b[AAdjusting learning rate of group 0 to 3.0914e-03.\n",
      "Epoch 468:  50%|█████████████████████                     | 79/158 [00:00<00:00, 137.58it/s, loss=1.87e-07, v_num=23, train_loss=3.92e-5, test_loss=4e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 468:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 132.51it/s, loss=1.87e-07, v_num=23, train_loss=3.92e-5, test_loss=4e-5]\u001b[A\n",
      "Epoch 468: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.27it/s, loss=1.87e-07, v_num=23, train_loss=2.93e-5, test_loss=2.98e-5]\u001b[A\n",
      "Epoch 469:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.28it/s, loss=3.67e-07, v_num=23, train_loss=2.93e-5, test_loss=2.98e-5]\u001b[AAdjusting learning rate of group 0 to 3.0836e-03.\n",
      "Epoch 469:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.05it/s, loss=3.5e-07, v_num=23, train_loss=2.93e-5, test_loss=2.98e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 469:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.75it/s, loss=3.5e-07, v_num=23, train_loss=2.93e-5, test_loss=2.98e-5]\u001b[A\n",
      "Epoch 469: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.47it/s, loss=3.5e-07, v_num=23, train_loss=8.24e-5, test_loss=8.29e-5]\u001b[A\n",
      "Epoch 470:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.73it/s, loss=3.97e-07, v_num=23, train_loss=8.24e-5, test_loss=8.29e-5]\u001b[AAdjusting learning rate of group 0 to 3.0759e-03.\n",
      "Epoch 470:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.55it/s, loss=3.88e-07, v_num=23, train_loss=8.24e-5, test_loss=8.29e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 470:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.55it/s, loss=3.88e-07, v_num=23, train_loss=8.24e-5, test_loss=8.29e-5]\u001b[A\n",
      "Epoch 470: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.44it/s, loss=3.88e-07, v_num=23, train_loss=5.42e-5, test_loss=5.45e-5]\u001b[A\n",
      "Epoch 471:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.90it/s, loss=2.04e-07, v_num=23, train_loss=5.42e-5, test_loss=5.45e-5]\u001b[AAdjusting learning rate of group 0 to 3.0683e-03.\n",
      "Epoch 471:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.46it/s, loss=1.94e-07, v_num=23, train_loss=5.42e-5, test_loss=5.45e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 471:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.47it/s, loss=1.94e-07, v_num=23, train_loss=5.42e-5, test_loss=5.45e-5]\u001b[A\n",
      "Epoch 471: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.91it/s, loss=1.94e-07, v_num=23, train_loss=2.69e-5, test_loss=2.75e-5]\u001b[A\n",
      "Epoch 472:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.15it/s, loss=3.59e-07, v_num=23, train_loss=2.69e-5, test_loss=2.75e-5]\u001b[AAdjusting learning rate of group 0 to 3.0606e-03.\n",
      "Epoch 472:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.15it/s, loss=3.43e-07, v_num=23, train_loss=2.69e-5, test_loss=2.75e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 472:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.69it/s, loss=3.43e-07, v_num=23, train_loss=2.69e-5, test_loss=2.75e-5]\u001b[A\n",
      "Epoch 472: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.91it/s, loss=3.43e-07, v_num=23, train_loss=2.45e-5, test_loss=2.51e-5]\u001b[A\n",
      "Epoch 473:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.15it/s, loss=2.78e-07, v_num=23, train_loss=2.45e-5, test_loss=2.51e-5]\u001b[AAdjusting learning rate of group 0 to 3.0529e-03.\n",
      "Epoch 473:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.52it/s, loss=2.57e-07, v_num=23, train_loss=2.45e-5, test_loss=2.51e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 473:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.95it/s, loss=2.57e-07, v_num=23, train_loss=2.45e-5, test_loss=2.51e-5]\u001b[A\n",
      "Epoch 473: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.73it/s, loss=2.57e-07, v_num=23, train_loss=1.92e-5, test_loss=2.02e-5]\u001b[A\n",
      "Epoch 474:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.87it/s, loss=3.49e-07, v_num=23, train_loss=1.92e-5, test_loss=2.02e-5]\u001b[AAdjusting learning rate of group 0 to 3.0453e-03.\n",
      "Epoch 474:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.90it/s, loss=3.43e-07, v_num=23, train_loss=1.92e-5, test_loss=2.02e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 474:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.97it/s, loss=3.43e-07, v_num=23, train_loss=1.92e-5, test_loss=2.02e-5]\u001b[A\n",
      "Epoch 474: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.30it/s, loss=3.43e-07, v_num=23, train_loss=2.67e-5, test_loss=2.81e-5]\u001b[A\n",
      "Epoch 475:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.07it/s, loss=4.74e-07, v_num=23, train_loss=2.67e-5, test_loss=2.81e-5]\u001b[AAdjusting learning rate of group 0 to 3.0377e-03.\n",
      "Epoch 475:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.20it/s, loss=4.59e-07, v_num=23, train_loss=2.67e-5, test_loss=2.81e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 475:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.21it/s, loss=4.59e-07, v_num=23, train_loss=2.67e-5, test_loss=2.81e-5]\u001b[A\n",
      "Epoch 475: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.88it/s, loss=4.59e-07, v_num=23, train_loss=5.84e-5, test_loss=5.91e-5]\u001b[A\n",
      "Epoch 476:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 146.96it/s, loss=2.95e-07, v_num=23, train_loss=5.84e-5, test_loss=5.91e-5]\u001b[AAdjusting learning rate of group 0 to 3.0301e-03.\n",
      "Epoch 476:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.16it/s, loss=2.8e-07, v_num=23, train_loss=5.84e-5, test_loss=5.91e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 476:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.38it/s, loss=2.8e-07, v_num=23, train_loss=5.84e-5, test_loss=5.91e-5]\u001b[A\n",
      "Epoch 476: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 165.81it/s, loss=2.8e-07, v_num=23, train_loss=4.3e-5, test_loss=4.35e-5]\u001b[A\n",
      "Epoch 477:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.91it/s, loss=2.72e-07, v_num=23, train_loss=4.3e-5, test_loss=4.35e-5]\u001b[AAdjusting learning rate of group 0 to 3.0225e-03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.59it/s, loss=2.62e-07, v_num=23, train_loss=4.3e-5, test_loss=4.35e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 477:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.04it/s, loss=2.62e-07, v_num=23, train_loss=4.3e-5, test_loss=4.35e-5]\u001b[A\n",
      "Epoch 477: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.42it/s, loss=2.62e-07, v_num=23, train_loss=4.12e-5, test_loss=4.19e-5]\u001b[A\n",
      "Epoch 478:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.97it/s, loss=3.3e-07, v_num=23, train_loss=4.12e-5, test_loss=4.19e-5]\u001b[AAdjusting learning rate of group 0 to 3.0150e-03.\n",
      "Epoch 478:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.41it/s, loss=3.19e-07, v_num=23, train_loss=4.12e-5, test_loss=4.19e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 478:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.81it/s, loss=3.19e-07, v_num=23, train_loss=4.12e-5, test_loss=4.19e-5]\u001b[A\n",
      "Epoch 478: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.06it/s, loss=3.19e-07, v_num=23, train_loss=2.53e-5, test_loss=2.62e-5]\u001b[A\n",
      "Epoch 479:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.30it/s, loss=3.61e-07, v_num=23, train_loss=2.53e-5, test_loss=2.62e-5]\u001b[AAdjusting learning rate of group 0 to 3.0074e-03.\n",
      "Epoch 479:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.89it/s, loss=3.51e-07, v_num=23, train_loss=2.53e-5, test_loss=2.62e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 479:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.29it/s, loss=3.51e-07, v_num=23, train_loss=2.53e-5, test_loss=2.62e-5]\u001b[A\n",
      "Epoch 479: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.28it/s, loss=3.51e-07, v_num=23, train_loss=4.8e-5, test_loss=4.87e-5]\u001b[A\n",
      "Epoch 480:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.98it/s, loss=4.07e-07, v_num=23, train_loss=4.8e-5, test_loss=4.87e-5]\u001b[AAdjusting learning rate of group 0 to 2.9999e-03.\n",
      "Epoch 480:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.05it/s, loss=3.92e-07, v_num=23, train_loss=4.8e-5, test_loss=4.87e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 480:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 134.54it/s, loss=3.92e-07, v_num=23, train_loss=4.8e-5, test_loss=4.87e-5]\u001b[A\n",
      "Epoch 480: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.39it/s, loss=3.92e-07, v_num=23, train_loss=7.03e-5, test_loss=7.15e-5]\u001b[A\n",
      "Epoch 481:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.42it/s, loss=3.01e-07, v_num=23, train_loss=7.03e-5, test_loss=7.15e-5]\u001b[AAdjusting learning rate of group 0 to 2.9924e-03.\n",
      "Epoch 481:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.10it/s, loss=2.89e-07, v_num=23, train_loss=7.03e-5, test_loss=7.15e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 481:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.91it/s, loss=2.89e-07, v_num=23, train_loss=7.03e-5, test_loss=7.15e-5]\u001b[A\n",
      "Epoch 481: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.90it/s, loss=2.89e-07, v_num=23, train_loss=3.57e-5, test_loss=3.66e-5]\u001b[A\n",
      "Epoch 482:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.12it/s, loss=1.91e-07, v_num=23, train_loss=3.57e-5, test_loss=3.66e-5]\u001b[AAdjusting learning rate of group 0 to 2.9849e-03.\n",
      "Epoch 482:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.91it/s, loss=1.85e-07, v_num=23, train_loss=3.57e-5, test_loss=3.66e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 482:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.96it/s, loss=1.85e-07, v_num=23, train_loss=3.57e-5, test_loss=3.66e-5]\u001b[A\n",
      "Epoch 482: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.36it/s, loss=1.85e-07, v_num=23, train_loss=1.89e-5, test_loss=1.97e-5]\u001b[A\n",
      "Epoch 483:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.52it/s, loss=2.61e-07, v_num=23, train_loss=1.89e-5, test_loss=1.97e-5]\u001b[AAdjusting learning rate of group 0 to 2.9775e-03.\n",
      "Epoch 483:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.62it/s, loss=2.51e-07, v_num=23, train_loss=1.89e-5, test_loss=1.97e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 483:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.90it/s, loss=2.51e-07, v_num=23, train_loss=1.89e-5, test_loss=1.97e-5]\u001b[A\n",
      "Epoch 483: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.66it/s, loss=2.51e-07, v_num=23, train_loss=2.69e-5, test_loss=2.71e-5]\u001b[A\n",
      "Epoch 484:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.18it/s, loss=4.8e-07, v_num=23, train_loss=2.69e-5, test_loss=2.71e-5]\u001b[AAdjusting learning rate of group 0 to 2.9700e-03.\n",
      "Epoch 484:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.95it/s, loss=4.7e-07, v_num=23, train_loss=2.69e-5, test_loss=2.71e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 484:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.28it/s, loss=4.7e-07, v_num=23, train_loss=2.69e-5, test_loss=2.71e-5]\u001b[A\n",
      "Epoch 484: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.30it/s, loss=4.7e-07, v_num=23, train_loss=2.69e-5, test_loss=2.76e-5]\u001b[A\n",
      "Epoch 485:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.64it/s, loss=2.49e-07, v_num=23, train_loss=2.69e-5, test_loss=2.76e-5]\u001b[AAdjusting learning rate of group 0 to 2.9626e-03.\n",
      "Epoch 485:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.07it/s, loss=2.39e-07, v_num=23, train_loss=2.69e-5, test_loss=2.76e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 485:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.75it/s, loss=2.39e-07, v_num=23, train_loss=2.69e-5, test_loss=2.76e-5]\u001b[A\n",
      "Epoch 485: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.92it/s, loss=2.39e-07, v_num=23, train_loss=3.78e-5, test_loss=3.95e-5]\u001b[A\n",
      "Epoch 486:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.05it/s, loss=2.45e-07, v_num=23, train_loss=3.78e-5, test_loss=3.95e-5]\u001b[AAdjusting learning rate of group 0 to 2.9552e-03.\n",
      "Epoch 486:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.76it/s, loss=2.21e-07, v_num=23, train_loss=3.78e-5, test_loss=3.95e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 486:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.70it/s, loss=2.21e-07, v_num=23, train_loss=3.78e-5, test_loss=3.95e-5]\u001b[A\n",
      "Epoch 486: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.73it/s, loss=2.21e-07, v_num=23, train_loss=2.63e-5, test_loss=2.76e-5]\u001b[A\n",
      "Epoch 487:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.55it/s, loss=1.08e-06, v_num=23, train_loss=2.63e-5, test_loss=2.76e-5]\u001b[AAdjusting learning rate of group 0 to 2.9478e-03.\n",
      "Epoch 487:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.42it/s, loss=9.93e-07, v_num=23, train_loss=2.63e-5, test_loss=2.76e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 487:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.93it/s, loss=9.93e-07, v_num=23, train_loss=2.63e-5, test_loss=2.76e-5]\u001b[A\n",
      "Epoch 487: 100%|████████████████████████████████████| 158/158 [00:00<00:00, 169.43it/s, loss=9.93e-07, v_num=23, train_loss=0.000151, test_loss=0.000153]\u001b[A\n",
      "Epoch 488:  49%|██████████████████▎                  | 78/158 [00:00<00:00, 149.44it/s, loss=4.06e-07, v_num=23, train_loss=0.000151, test_loss=0.000153]\u001b[AAdjusting learning rate of group 0 to 2.9404e-03.\n",
      "Epoch 488:  50%|██████████████████▌                  | 79/158 [00:00<00:00, 138.00it/s, loss=3.93e-07, v_num=23, train_loss=0.000151, test_loss=0.000153]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 488:  67%|████████████████████████▏           | 106/158 [00:00<00:00, 133.13it/s, loss=3.93e-07, v_num=23, train_loss=0.000151, test_loss=0.000153]\u001b[A\n",
      "Epoch 488: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.43it/s, loss=3.93e-07, v_num=23, train_loss=5.86e-5, test_loss=5.78e-5]\u001b[A\n",
      "Epoch 489:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.50it/s, loss=3.23e-07, v_num=23, train_loss=5.86e-5, test_loss=5.78e-5]\u001b[AAdjusting learning rate of group 0 to 2.9331e-03.\n",
      "Epoch 489:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.62it/s, loss=3.08e-07, v_num=23, train_loss=5.86e-5, test_loss=5.78e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 489:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.24it/s, loss=3.08e-07, v_num=23, train_loss=5.86e-5, test_loss=5.78e-5]\u001b[A\n",
      "Epoch 489: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.24it/s, loss=3.08e-07, v_num=23, train_loss=3.79e-5, test_loss=3.9e-5]\u001b[A\n",
      "Epoch 490:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 150.07it/s, loss=2.65e-07, v_num=23, train_loss=3.79e-5, test_loss=3.9e-5]\u001b[AAdjusting learning rate of group 0 to 2.9257e-03.\n",
      "Epoch 490:  50%|████████████████████                    | 79/158 [00:00<00:00, 142.18it/s, loss=2.45e-07, v_num=23, train_loss=3.79e-5, test_loss=3.9e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 490:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 135.14it/s, loss=2.45e-07, v_num=23, train_loss=3.79e-5, test_loss=3.9e-5]\u001b[A\n",
      "Epoch 490: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.76it/s, loss=2.45e-07, v_num=23, train_loss=2.61e-5, test_loss=2.73e-5]\u001b[A\n",
      "Epoch 491:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.63it/s, loss=2.3e-07, v_num=23, train_loss=2.61e-5, test_loss=2.73e-5]\u001b[AAdjusting learning rate of group 0 to 2.9184e-03.\n",
      "Epoch 491:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.66it/s, loss=2.17e-07, v_num=23, train_loss=2.61e-5, test_loss=2.73e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 491:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.68it/s, loss=2.17e-07, v_num=23, train_loss=2.61e-5, test_loss=2.73e-5]\u001b[A\n",
      "Epoch 491: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.68it/s, loss=2.17e-07, v_num=23, train_loss=2.68e-5, test_loss=2.75e-5]\u001b[A\n",
      "Epoch 492:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.69it/s, loss=2.82e-07, v_num=23, train_loss=2.68e-5, test_loss=2.75e-5]\u001b[AAdjusting learning rate of group 0 to 2.9111e-03.\n",
      "Epoch 492:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.57it/s, loss=2.72e-07, v_num=23, train_loss=2.68e-5, test_loss=2.75e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.34it/s]\u001b[A\n",
      "Epoch 492: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 162.40it/s, loss=2.72e-07, v_num=23, train_loss=2.8e-5, test_loss=2.86e-5]\u001b[A\n",
      "Epoch 493:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 150.00it/s, loss=3.82e-07, v_num=23, train_loss=2.8e-5, test_loss=2.86e-5]\u001b[AAdjusting learning rate of group 0 to 2.9039e-03.\n",
      "Epoch 493:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.30it/s, loss=3.68e-07, v_num=23, train_loss=2.8e-5, test_loss=2.86e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 493:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.29it/s, loss=3.68e-07, v_num=23, train_loss=2.8e-5, test_loss=2.86e-5]\u001b[A\n",
      "Epoch 493: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.54it/s, loss=3.68e-07, v_num=23, train_loss=4.09e-5, test_loss=4.28e-5]\u001b[A\n",
      "Epoch 494:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.74it/s, loss=2.51e-07, v_num=23, train_loss=4.09e-5, test_loss=4.28e-5]\u001b[AAdjusting learning rate of group 0 to 2.8966e-03.\n",
      "Epoch 494:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.56it/s, loss=2.36e-07, v_num=23, train_loss=4.09e-5, test_loss=4.28e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 494:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.20it/s, loss=2.36e-07, v_num=23, train_loss=4.09e-5, test_loss=4.28e-5]\u001b[A\n",
      "Epoch 494: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.25it/s, loss=2.36e-07, v_num=23, train_loss=2.09e-5, test_loss=2.16e-5]\u001b[A\n",
      "Epoch 495:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.59it/s, loss=2.49e-07, v_num=23, train_loss=2.09e-5, test_loss=2.16e-5]\u001b[AAdjusting learning rate of group 0 to 2.8894e-03.\n",
      "Epoch 495:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.30it/s, loss=2.36e-07, v_num=23, train_loss=2.09e-5, test_loss=2.16e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 495:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.83it/s, loss=2.36e-07, v_num=23, train_loss=2.09e-5, test_loss=2.16e-5]\u001b[A\n",
      "Epoch 495: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.74it/s, loss=2.36e-07, v_num=23, train_loss=2.45e-5, test_loss=2.52e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.81it/s, loss=2.33e-07, v_num=23, train_loss=2.45e-5, test_loss=2.52e-5]\u001b[AAdjusting learning rate of group 0 to 2.8821e-03.\n",
      "Epoch 496:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.04it/s, loss=2.23e-07, v_num=23, train_loss=2.45e-5, test_loss=2.52e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 496:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.47it/s, loss=2.23e-07, v_num=23, train_loss=2.45e-5, test_loss=2.52e-5]\u001b[A\n",
      "Epoch 496: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.55it/s, loss=2.23e-07, v_num=23, train_loss=2.12e-5, test_loss=2.24e-5]\u001b[A\n",
      "Epoch 497:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.44it/s, loss=1.91e-07, v_num=23, train_loss=2.12e-5, test_loss=2.24e-5]\u001b[AAdjusting learning rate of group 0 to 2.8749e-03.\n",
      "Epoch 497:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.90it/s, loss=1.88e-07, v_num=23, train_loss=2.12e-5, test_loss=2.24e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 497:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 128.43it/s, loss=1.88e-07, v_num=23, train_loss=2.12e-5, test_loss=2.24e-5]\u001b[A\n",
      "Epoch 497: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 163.55it/s, loss=1.88e-07, v_num=23, train_loss=2e-5, test_loss=2.13e-5]\u001b[A\n",
      "Epoch 498:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 150.11it/s, loss=1.89e-07, v_num=23, train_loss=2e-5, test_loss=2.13e-5]\u001b[AAdjusting learning rate of group 0 to 2.8677e-03.\n",
      "Epoch 498:  50%|█████████████████████                     | 79/158 [00:00<00:00, 140.21it/s, loss=1.79e-07, v_num=23, train_loss=2e-5, test_loss=2.13e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 498:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 134.93it/s, loss=1.79e-07, v_num=23, train_loss=2e-5, test_loss=2.13e-5]\u001b[A\n",
      "Epoch 498: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.36it/s, loss=1.79e-07, v_num=23, train_loss=2.35e-5, test_loss=2.42e-5]\u001b[A\n",
      "Epoch 499:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.44it/s, loss=2.15e-07, v_num=23, train_loss=2.35e-5, test_loss=2.42e-5]\u001b[AAdjusting learning rate of group 0 to 2.8606e-03.\n",
      "Epoch 499:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.15it/s, loss=2.09e-07, v_num=23, train_loss=2.35e-5, test_loss=2.42e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 499:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.79it/s, loss=2.09e-07, v_num=23, train_loss=2.35e-5, test_loss=2.42e-5]\u001b[A\n",
      "Epoch 499: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.71it/s, loss=2.09e-07, v_num=23, train_loss=2.8e-5, test_loss=2.85e-5]\u001b[A\n",
      "Epoch 500:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.32it/s, loss=2.2e-07, v_num=23, train_loss=2.8e-5, test_loss=2.85e-5]\u001b[AAdjusting learning rate of group 0 to 2.8534e-03.\n",
      "Epoch 500:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 137.28it/s, loss=2.1e-07, v_num=23, train_loss=2.8e-5, test_loss=2.85e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 500:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 132.22it/s, loss=2.1e-07, v_num=23, train_loss=2.8e-5, test_loss=2.85e-5]\u001b[A\n",
      "Epoch 500: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.45it/s, loss=2.1e-07, v_num=23, train_loss=2.56e-5, test_loss=2.64e-5]\u001b[A\n",
      "Epoch 501:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.02it/s, loss=2.84e-07, v_num=23, train_loss=2.56e-5, test_loss=2.64e-5]\u001b[AAdjusting learning rate of group 0 to 2.8463e-03.\n",
      "Epoch 501:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.23it/s, loss=2.74e-07, v_num=23, train_loss=2.56e-5, test_loss=2.64e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 501:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.14it/s, loss=2.74e-07, v_num=23, train_loss=2.56e-5, test_loss=2.64e-5]\u001b[A\n",
      "Epoch 501: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.50it/s, loss=2.74e-07, v_num=23, train_loss=2.08e-5, test_loss=2.14e-5]\u001b[A\n",
      "Epoch 502:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.30it/s, loss=4.02e-07, v_num=23, train_loss=2.08e-5, test_loss=2.14e-5]\u001b[AAdjusting learning rate of group 0 to 2.8392e-03.\n",
      "Epoch 502:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.54it/s, loss=3.93e-07, v_num=23, train_loss=2.08e-5, test_loss=2.14e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 502:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.71it/s, loss=3.93e-07, v_num=23, train_loss=2.08e-5, test_loss=2.14e-5]\u001b[A\n",
      "Epoch 502: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.50it/s, loss=3.93e-07, v_num=23, train_loss=2.84e-5, test_loss=2.94e-5]\u001b[A\n",
      "Epoch 503:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.98it/s, loss=3.86e-07, v_num=23, train_loss=2.84e-5, test_loss=2.94e-5]\u001b[AAdjusting learning rate of group 0 to 2.8321e-03.\n",
      "Epoch 503:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.11it/s, loss=3.78e-07, v_num=23, train_loss=2.84e-5, test_loss=2.94e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 503:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.08it/s, loss=3.78e-07, v_num=23, train_loss=2.84e-5, test_loss=2.94e-5]\u001b[A\n",
      "Epoch 503: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.13it/s, loss=3.78e-07, v_num=23, train_loss=3.13e-5, test_loss=3.17e-5]\u001b[A\n",
      "Epoch 504:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.09it/s, loss=2.72e-07, v_num=23, train_loss=3.13e-5, test_loss=3.17e-5]\u001b[AAdjusting learning rate of group 0 to 2.8250e-03.\n",
      "Epoch 504:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.94it/s, loss=2.59e-07, v_num=23, train_loss=3.13e-5, test_loss=3.17e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 504:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.52it/s, loss=2.59e-07, v_num=23, train_loss=3.13e-5, test_loss=3.17e-5]\u001b[A\n",
      "Epoch 504: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.48it/s, loss=2.59e-07, v_num=23, train_loss=2.43e-5, test_loss=2.56e-5]\u001b[A\n",
      "Epoch 505:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.49it/s, loss=2.38e-07, v_num=23, train_loss=2.43e-5, test_loss=2.56e-5]\u001b[AAdjusting learning rate of group 0 to 2.8179e-03.\n",
      "Epoch 505:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.61it/s, loss=2.27e-07, v_num=23, train_loss=2.43e-5, test_loss=2.56e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 505:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.32it/s, loss=2.27e-07, v_num=23, train_loss=2.43e-5, test_loss=2.56e-5]\u001b[A\n",
      "Epoch 505: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.96it/s, loss=2.27e-07, v_num=23, train_loss=2.32e-5, test_loss=2.38e-5]\u001b[A\n",
      "Epoch 506:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.62it/s, loss=2.87e-07, v_num=23, train_loss=2.32e-5, test_loss=2.38e-5]\u001b[AAdjusting learning rate of group 0 to 2.8109e-03.\n",
      "Epoch 506:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.14it/s, loss=2.71e-07, v_num=23, train_loss=2.32e-5, test_loss=2.38e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 506:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.74it/s, loss=2.71e-07, v_num=23, train_loss=2.32e-5, test_loss=2.38e-5]\u001b[A\n",
      "Epoch 506: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.63it/s, loss=2.71e-07, v_num=23, train_loss=2.36e-5, test_loss=2.47e-5]\u001b[A\n",
      "Epoch 507:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.13it/s, loss=2.06e-07, v_num=23, train_loss=2.36e-5, test_loss=2.47e-5]\u001b[AAdjusting learning rate of group 0 to 2.8039e-03.\n",
      "Epoch 507:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.95it/s, loss=1.97e-07, v_num=23, train_loss=2.36e-5, test_loss=2.47e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 507:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.66it/s, loss=1.97e-07, v_num=23, train_loss=2.36e-5, test_loss=2.47e-5]\u001b[A\n",
      "Epoch 507: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.29it/s, loss=1.97e-07, v_num=23, train_loss=1.48e-5, test_loss=1.53e-5]\u001b[A\n",
      "Epoch 508:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.07it/s, loss=2.62e-07, v_num=23, train_loss=1.48e-5, test_loss=1.53e-5]\u001b[AAdjusting learning rate of group 0 to 2.7968e-03.\n",
      "Epoch 508:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.96it/s, loss=2.52e-07, v_num=23, train_loss=1.48e-5, test_loss=1.53e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 508:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.89it/s, loss=2.52e-07, v_num=23, train_loss=1.48e-5, test_loss=1.53e-5]\u001b[A\n",
      "Epoch 508: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.67it/s, loss=2.52e-07, v_num=23, train_loss=2.51e-5, test_loss=2.57e-5]\u001b[A\n",
      "Epoch 509:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.31it/s, loss=2.42e-07, v_num=23, train_loss=2.51e-5, test_loss=2.57e-5]\u001b[AAdjusting learning rate of group 0 to 2.7899e-03.\n",
      "Epoch 509:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.55it/s, loss=2.32e-07, v_num=23, train_loss=2.51e-5, test_loss=2.57e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 509:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.83it/s, loss=2.32e-07, v_num=23, train_loss=2.51e-5, test_loss=2.57e-5]\u001b[A\n",
      "Epoch 509: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 172.20it/s, loss=2.32e-07, v_num=23, train_loss=2.09e-5, test_loss=2.07e-5]\u001b[A\n",
      "Epoch 510:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.32it/s, loss=2.13e-07, v_num=23, train_loss=2.09e-5, test_loss=2.07e-5]\u001b[AAdjusting learning rate of group 0 to 2.7829e-03.\n",
      "Epoch 510:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.62it/s, loss=2.03e-07, v_num=23, train_loss=2.09e-5, test_loss=2.07e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 510:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.75it/s, loss=2.03e-07, v_num=23, train_loss=2.09e-5, test_loss=2.07e-5]\u001b[A\n",
      "Epoch 510: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.64it/s, loss=2.03e-07, v_num=23, train_loss=2.12e-5, test_loss=2.19e-5]\u001b[A\n",
      "Epoch 511:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.78it/s, loss=2.41e-07, v_num=23, train_loss=2.12e-5, test_loss=2.19e-5]\u001b[AAdjusting learning rate of group 0 to 2.7759e-03.\n",
      "Epoch 511:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.53it/s, loss=2.34e-07, v_num=23, train_loss=2.12e-5, test_loss=2.19e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 511:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.44it/s, loss=2.34e-07, v_num=23, train_loss=2.12e-5, test_loss=2.19e-5]\u001b[A\n",
      "Epoch 511: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.65it/s, loss=2.34e-07, v_num=23, train_loss=3.02e-5, test_loss=3.1e-5]\u001b[A\n",
      "Epoch 512:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.16it/s, loss=2.46e-07, v_num=23, train_loss=3.02e-5, test_loss=3.1e-5]\u001b[AAdjusting learning rate of group 0 to 2.7690e-03.\n",
      "Epoch 512:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.14it/s, loss=2.34e-07, v_num=23, train_loss=3.02e-5, test_loss=3.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 512:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.07it/s, loss=2.34e-07, v_num=23, train_loss=3.02e-5, test_loss=3.1e-5]\u001b[A\n",
      "Epoch 512: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.04it/s, loss=2.34e-07, v_num=23, train_loss=2.26e-5, test_loss=2.32e-5]\u001b[A\n",
      "Epoch 513:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.07it/s, loss=2.62e-07, v_num=23, train_loss=2.26e-5, test_loss=2.32e-5]\u001b[AAdjusting learning rate of group 0 to 2.7621e-03.\n",
      "Epoch 513:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.14it/s, loss=2.55e-07, v_num=23, train_loss=2.26e-5, test_loss=2.32e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 513:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.95it/s, loss=2.55e-07, v_num=23, train_loss=2.26e-5, test_loss=2.32e-5]\u001b[A\n",
      "Epoch 513: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.34it/s, loss=2.55e-07, v_num=23, train_loss=4.61e-5, test_loss=4.7e-5]\u001b[A\n",
      "Epoch 514:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.38it/s, loss=2.42e-07, v_num=23, train_loss=4.61e-5, test_loss=4.7e-5]\u001b[AAdjusting learning rate of group 0 to 2.7552e-03.\n",
      "Epoch 514:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.02it/s, loss=2.26e-07, v_num=23, train_loss=4.61e-5, test_loss=4.7e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 514:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.55it/s, loss=2.26e-07, v_num=23, train_loss=4.61e-5, test_loss=4.7e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.71it/s, loss=2.26e-07, v_num=23, train_loss=2.55e-5, test_loss=2.63e-5]\u001b[A\n",
      "Epoch 515:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.08it/s, loss=3.03e-07, v_num=23, train_loss=2.55e-5, test_loss=2.63e-5]\u001b[AAdjusting learning rate of group 0 to 2.7483e-03.\n",
      "Epoch 515:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.55it/s, loss=2.93e-07, v_num=23, train_loss=2.55e-5, test_loss=2.63e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 515:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.73it/s, loss=2.93e-07, v_num=23, train_loss=2.55e-5, test_loss=2.63e-5]\u001b[A\n",
      "Epoch 515: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.15it/s, loss=2.93e-07, v_num=23, train_loss=4.37e-5, test_loss=4.5e-5]\u001b[A\n",
      "Epoch 516:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.37it/s, loss=2.31e-07, v_num=23, train_loss=4.37e-5, test_loss=4.5e-5]\u001b[AAdjusting learning rate of group 0 to 2.7414e-03.\n",
      "Epoch 516:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.43it/s, loss=2.19e-07, v_num=23, train_loss=4.37e-5, test_loss=4.5e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 516:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.54it/s, loss=2.19e-07, v_num=23, train_loss=4.37e-5, test_loss=4.5e-5]\u001b[A\n",
      "Epoch 516: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.24it/s, loss=2.19e-07, v_num=23, train_loss=2.04e-5, test_loss=2.1e-5]\u001b[A\n",
      "Epoch 517:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.02it/s, loss=3.63e-07, v_num=23, train_loss=2.04e-5, test_loss=2.1e-5]\u001b[AAdjusting learning rate of group 0 to 2.7345e-03.\n",
      "Epoch 517:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.29it/s, loss=3.59e-07, v_num=23, train_loss=2.04e-5, test_loss=2.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 517:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.63it/s, loss=3.59e-07, v_num=23, train_loss=2.04e-5, test_loss=2.1e-5]\u001b[A\n",
      "Epoch 517: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.36it/s, loss=3.59e-07, v_num=23, train_loss=6.28e-5, test_loss=6.29e-5]\u001b[A\n",
      "Epoch 518:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.19it/s, loss=3.27e-07, v_num=23, train_loss=6.28e-5, test_loss=6.29e-5]\u001b[AAdjusting learning rate of group 0 to 2.7277e-03.\n",
      "Epoch 518:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.97it/s, loss=3.1e-07, v_num=23, train_loss=6.28e-5, test_loss=6.29e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 518:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.15it/s, loss=3.1e-07, v_num=23, train_loss=6.28e-5, test_loss=6.29e-5]\u001b[A\n",
      "Epoch 518: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.74it/s, loss=3.1e-07, v_num=23, train_loss=4.02e-5, test_loss=4.11e-5]\u001b[A\n",
      "Epoch 519:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.73it/s, loss=3.52e-07, v_num=23, train_loss=4.02e-5, test_loss=4.11e-5]\u001b[AAdjusting learning rate of group 0 to 2.7209e-03.\n",
      "Epoch 519:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.11it/s, loss=3.36e-07, v_num=23, train_loss=4.02e-5, test_loss=4.11e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 519:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.78it/s, loss=3.36e-07, v_num=23, train_loss=4.02e-5, test_loss=4.11e-5]\u001b[A\n",
      "Epoch 519: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.48it/s, loss=3.36e-07, v_num=23, train_loss=3.79e-5, test_loss=3.82e-5]\u001b[A\n",
      "Epoch 520:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.11it/s, loss=3.18e-07, v_num=23, train_loss=3.79e-5, test_loss=3.82e-5]\u001b[AAdjusting learning rate of group 0 to 2.7141e-03.\n",
      "Epoch 520:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.34it/s, loss=3.01e-07, v_num=23, train_loss=3.79e-5, test_loss=3.82e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 520:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.91it/s, loss=3.01e-07, v_num=23, train_loss=3.79e-5, test_loss=3.82e-5]\u001b[A\n",
      "Epoch 520: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.36it/s, loss=3.01e-07, v_num=23, train_loss=2.96e-5, test_loss=2.98e-5]\u001b[A\n",
      "Epoch 521:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.11it/s, loss=3.57e-07, v_num=23, train_loss=2.96e-5, test_loss=2.98e-5]\u001b[AAdjusting learning rate of group 0 to 2.7073e-03.\n",
      "Epoch 521:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.36it/s, loss=3.52e-07, v_num=23, train_loss=2.96e-5, test_loss=2.98e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 521:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.82it/s, loss=3.52e-07, v_num=23, train_loss=2.96e-5, test_loss=2.98e-5]\u001b[A\n",
      "Epoch 521: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.39it/s, loss=3.52e-07, v_num=23, train_loss=9.61e-5, test_loss=9.54e-5]\u001b[A\n",
      "Epoch 522:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.84it/s, loss=2.56e-07, v_num=23, train_loss=9.61e-5, test_loss=9.54e-5]\u001b[AAdjusting learning rate of group 0 to 2.7005e-03.\n",
      "Epoch 522:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.28it/s, loss=2.45e-07, v_num=23, train_loss=9.61e-5, test_loss=9.54e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 522:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.06it/s, loss=2.45e-07, v_num=23, train_loss=9.61e-5, test_loss=9.54e-5]\u001b[A\n",
      "Epoch 522: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.64it/s, loss=2.45e-07, v_num=23, train_loss=3.05e-5, test_loss=3.06e-5]\u001b[A\n",
      "Epoch 523:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 149.36it/s, loss=2e-07, v_num=23, train_loss=3.05e-5, test_loss=3.06e-5]\u001b[AAdjusting learning rate of group 0 to 2.6938e-03.\n",
      "Epoch 523:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.39it/s, loss=1.92e-07, v_num=23, train_loss=3.05e-5, test_loss=3.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 523:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.03it/s, loss=1.92e-07, v_num=23, train_loss=3.05e-5, test_loss=3.06e-5]\u001b[A\n",
      "Epoch 523: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.91it/s, loss=1.92e-07, v_num=23, train_loss=2.49e-5, test_loss=2.52e-5]\u001b[A\n",
      "Epoch 524:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.28it/s, loss=2.75e-07, v_num=23, train_loss=2.49e-5, test_loss=2.52e-5]\u001b[AAdjusting learning rate of group 0 to 2.6870e-03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 524:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.85it/s, loss=2.69e-07, v_num=23, train_loss=2.49e-5, test_loss=2.52e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 524:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.07it/s, loss=2.69e-07, v_num=23, train_loss=2.49e-5, test_loss=2.52e-5]\u001b[A\n",
      "Epoch 524: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.69it/s, loss=2.69e-07, v_num=23, train_loss=4.02e-5, test_loss=4.04e-5]\u001b[A\n",
      "Epoch 525:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.98it/s, loss=2.38e-07, v_num=23, train_loss=4.02e-5, test_loss=4.04e-5]\u001b[AAdjusting learning rate of group 0 to 2.6803e-03.\n",
      "Epoch 525:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.74it/s, loss=2.29e-07, v_num=23, train_loss=4.02e-5, test_loss=4.04e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 525:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.30it/s, loss=2.29e-07, v_num=23, train_loss=4.02e-5, test_loss=4.04e-5]\u001b[A\n",
      "Epoch 525: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.55it/s, loss=2.29e-07, v_num=23, train_loss=2.92e-5, test_loss=3.01e-5]\u001b[A\n",
      "Epoch 526:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 145.88it/s, loss=2.26e-07, v_num=23, train_loss=2.92e-5, test_loss=3.01e-5]\u001b[AAdjusting learning rate of group 0 to 2.6736e-03.\n",
      "Epoch 526:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.59it/s, loss=2.19e-07, v_num=23, train_loss=2.92e-5, test_loss=3.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 526:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.77it/s, loss=2.19e-07, v_num=23, train_loss=2.92e-5, test_loss=3.01e-5]\u001b[A\n",
      "Epoch 526: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.74it/s, loss=2.19e-07, v_num=23, train_loss=2.24e-5, test_loss=2.26e-5]\u001b[A\n",
      "Epoch 527:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.97it/s, loss=1.77e-07, v_num=23, train_loss=2.24e-5, test_loss=2.26e-5]\u001b[AAdjusting learning rate of group 0 to 2.6669e-03.\n",
      "Epoch 527:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.40it/s, loss=1.68e-07, v_num=23, train_loss=2.24e-5, test_loss=2.26e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 527:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.22it/s, loss=1.68e-07, v_num=23, train_loss=2.24e-5, test_loss=2.26e-5]\u001b[A\n",
      "Epoch 527: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.70it/s, loss=1.68e-07, v_num=23, train_loss=1.71e-5, test_loss=1.77e-5]\u001b[A\n",
      "Epoch 528:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.39it/s, loss=2.21e-07, v_num=23, train_loss=1.71e-5, test_loss=1.77e-5]\u001b[AAdjusting learning rate of group 0 to 2.6603e-03.\n",
      "Epoch 528:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.36it/s, loss=2.1e-07, v_num=23, train_loss=1.71e-5, test_loss=1.77e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 528:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.16it/s, loss=2.1e-07, v_num=23, train_loss=1.71e-5, test_loss=1.77e-5]\u001b[A\n",
      "Epoch 528: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.80it/s, loss=2.1e-07, v_num=23, train_loss=5.22e-5, test_loss=5.31e-5]\u001b[A\n",
      "Epoch 529:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.25it/s, loss=3.49e-07, v_num=23, train_loss=5.22e-5, test_loss=5.31e-5]\u001b[AAdjusting learning rate of group 0 to 2.6536e-03.\n",
      "Epoch 529:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.27it/s, loss=3.32e-07, v_num=23, train_loss=5.22e-5, test_loss=5.31e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 529:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.34it/s, loss=3.32e-07, v_num=23, train_loss=5.22e-5, test_loss=5.31e-5]\u001b[A\n",
      "Epoch 529: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.11it/s, loss=3.32e-07, v_num=23, train_loss=3.71e-5, test_loss=3.78e-5]\u001b[A\n",
      "Epoch 530:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.79it/s, loss=2.46e-07, v_num=23, train_loss=3.71e-5, test_loss=3.78e-5]\u001b[AAdjusting learning rate of group 0 to 2.6470e-03.\n",
      "Epoch 530:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.32it/s, loss=2.33e-07, v_num=23, train_loss=3.71e-5, test_loss=3.78e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 530:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.74it/s, loss=2.33e-07, v_num=23, train_loss=3.71e-5, test_loss=3.78e-5]\u001b[A\n",
      "Epoch 530: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.21it/s, loss=2.33e-07, v_num=23, train_loss=3.28e-5, test_loss=3.31e-5]\u001b[A\n",
      "Epoch 531:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.40it/s, loss=4.25e-07, v_num=23, train_loss=3.28e-5, test_loss=3.31e-5]\u001b[AAdjusting learning rate of group 0 to 2.6404e-03.\n",
      "Epoch 531:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.53it/s, loss=4.16e-07, v_num=23, train_loss=3.28e-5, test_loss=3.31e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 531:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.36it/s, loss=4.16e-07, v_num=23, train_loss=3.28e-5, test_loss=3.31e-5]\u001b[A\n",
      "Epoch 531: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.89it/s, loss=4.16e-07, v_num=23, train_loss=7.3e-5, test_loss=7.43e-5]\u001b[A\n",
      "Epoch 532:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.35it/s, loss=1.93e-07, v_num=23, train_loss=7.3e-5, test_loss=7.43e-5]\u001b[AAdjusting learning rate of group 0 to 2.6338e-03.\n",
      "Epoch 532:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.12it/s, loss=1.87e-07, v_num=23, train_loss=7.3e-5, test_loss=7.43e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 532:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 134.04it/s, loss=1.87e-07, v_num=23, train_loss=7.3e-5, test_loss=7.43e-5]\u001b[A\n",
      "Epoch 532: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.64it/s, loss=1.87e-07, v_num=23, train_loss=2.21e-5, test_loss=2.28e-5]\u001b[A\n",
      "Epoch 533:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.37it/s, loss=2.11e-07, v_num=23, train_loss=2.21e-5, test_loss=2.28e-5]\u001b[AAdjusting learning rate of group 0 to 2.6272e-03.\n",
      "Epoch 533:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.14it/s, loss=2.02e-07, v_num=23, train_loss=2.21e-5, test_loss=2.28e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 128.70it/s, loss=2.02e-07, v_num=23, train_loss=2.21e-5, test_loss=2.28e-5]\u001b[A\n",
      "Epoch 533: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.40it/s, loss=2.02e-07, v_num=23, train_loss=2.44e-5, test_loss=2.55e-5]\u001b[A\n",
      "Epoch 534:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.13it/s, loss=3.23e-07, v_num=23, train_loss=2.44e-5, test_loss=2.55e-5]\u001b[AAdjusting learning rate of group 0 to 2.6206e-03.\n",
      "Epoch 534:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.73it/s, loss=3.12e-07, v_num=23, train_loss=2.44e-5, test_loss=2.55e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 534:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.25it/s, loss=3.12e-07, v_num=23, train_loss=2.44e-5, test_loss=2.55e-5]\u001b[A\n",
      "Epoch 534: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.12it/s, loss=3.12e-07, v_num=23, train_loss=3.97e-5, test_loss=4.06e-5]\u001b[A\n",
      "Epoch 535:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.07it/s, loss=2.71e-07, v_num=23, train_loss=3.97e-5, test_loss=4.06e-5]\u001b[AAdjusting learning rate of group 0 to 2.6141e-03.\n",
      "Epoch 535:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.73it/s, loss=2.58e-07, v_num=23, train_loss=3.97e-5, test_loss=4.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 535:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.41it/s, loss=2.58e-07, v_num=23, train_loss=3.97e-5, test_loss=4.06e-5]\u001b[A\n",
      "Epoch 535: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.00it/s, loss=2.58e-07, v_num=23, train_loss=2.54e-5, test_loss=2.57e-5]\u001b[A\n",
      "Epoch 536:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.22it/s, loss=2.95e-07, v_num=23, train_loss=2.54e-5, test_loss=2.57e-5]\u001b[AAdjusting learning rate of group 0 to 2.6075e-03.\n",
      "Epoch 536:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.12it/s, loss=2.86e-07, v_num=23, train_loss=2.54e-5, test_loss=2.57e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 536:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.35it/s, loss=2.86e-07, v_num=23, train_loss=2.54e-5, test_loss=2.57e-5]\u001b[A\n",
      "Epoch 536: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.21it/s, loss=2.86e-07, v_num=23, train_loss=5.02e-5, test_loss=5.17e-5]\u001b[A\n",
      "Epoch 537:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.73it/s, loss=2.05e-07, v_num=23, train_loss=5.02e-5, test_loss=5.17e-5]\u001b[AAdjusting learning rate of group 0 to 2.6010e-03.\n",
      "Epoch 537:  50%|████████████████████                    | 79/158 [00:00<00:00, 142.73it/s, loss=1.9e-07, v_num=23, train_loss=5.02e-5, test_loss=5.17e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 537:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 135.78it/s, loss=1.9e-07, v_num=23, train_loss=5.02e-5, test_loss=5.17e-5]\u001b[A\n",
      "Epoch 537: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 171.60it/s, loss=1.9e-07, v_num=23, train_loss=2.95e-5, test_loss=2.99e-5]\u001b[A\n",
      "Epoch 538:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.26it/s, loss=2.59e-07, v_num=23, train_loss=2.95e-5, test_loss=2.99e-5]\u001b[AAdjusting learning rate of group 0 to 2.5945e-03.\n",
      "Epoch 538:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.35it/s, loss=2.51e-07, v_num=23, train_loss=2.95e-5, test_loss=2.99e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 538:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.01it/s, loss=2.51e-07, v_num=23, train_loss=2.95e-5, test_loss=2.99e-5]\u001b[A\n",
      "Epoch 538: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.98it/s, loss=2.51e-07, v_num=23, train_loss=2.46e-5, test_loss=2.55e-5]\u001b[A\n",
      "Epoch 539:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.24it/s, loss=2.42e-07, v_num=23, train_loss=2.46e-5, test_loss=2.55e-5]\u001b[AAdjusting learning rate of group 0 to 2.5880e-03.\n",
      "Epoch 539:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.02it/s, loss=2.29e-07, v_num=23, train_loss=2.46e-5, test_loss=2.55e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 539:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.64it/s, loss=2.29e-07, v_num=23, train_loss=2.46e-5, test_loss=2.55e-5]\u001b[A\n",
      "Epoch 539: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.97it/s, loss=2.29e-07, v_num=23, train_loss=2.26e-5, test_loss=2.25e-5]\u001b[A\n",
      "Epoch 540:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.49it/s, loss=2.1e-07, v_num=23, train_loss=2.26e-5, test_loss=2.25e-5]\u001b[AAdjusting learning rate of group 0 to 2.5816e-03.\n",
      "Epoch 540:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.36it/s, loss=2.03e-07, v_num=23, train_loss=2.26e-5, test_loss=2.25e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 540:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.94it/s, loss=2.03e-07, v_num=23, train_loss=2.26e-5, test_loss=2.25e-5]\u001b[A\n",
      "Epoch 540: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.77it/s, loss=2.03e-07, v_num=23, train_loss=1.92e-5, test_loss=1.95e-5]\u001b[A\n",
      "Epoch 541:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.78it/s, loss=2.79e-07, v_num=23, train_loss=1.92e-5, test_loss=1.95e-5]\u001b[AAdjusting learning rate of group 0 to 2.5751e-03.\n",
      "Epoch 541:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.67it/s, loss=2.71e-07, v_num=23, train_loss=1.92e-5, test_loss=1.95e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 541:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.87it/s, loss=2.71e-07, v_num=23, train_loss=1.92e-5, test_loss=1.95e-5]\u001b[A\n",
      "Epoch 541: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.20it/s, loss=2.71e-07, v_num=23, train_loss=2.94e-5, test_loss=3.02e-5]\u001b[A\n",
      "Epoch 542:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.70it/s, loss=3.52e-07, v_num=23, train_loss=2.94e-5, test_loss=3.02e-5]\u001b[AAdjusting learning rate of group 0 to 2.5687e-03.\n",
      "Epoch 542:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.40it/s, loss=3.21e-07, v_num=23, train_loss=2.94e-5, test_loss=3.02e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 542:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.32it/s, loss=3.21e-07, v_num=23, train_loss=2.94e-5, test_loss=3.02e-5]\u001b[A\n",
      "Epoch 542: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.58it/s, loss=3.21e-07, v_num=23, train_loss=3.46e-5, test_loss=3.5e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 543:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.98it/s, loss=2.05e-07, v_num=23, train_loss=3.46e-5, test_loss=3.5e-5]\u001b[AAdjusting learning rate of group 0 to 2.5622e-03.\n",
      "Epoch 543:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.20it/s, loss=1.97e-07, v_num=23, train_loss=3.46e-5, test_loss=3.5e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 543:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.11it/s, loss=1.97e-07, v_num=23, train_loss=3.46e-5, test_loss=3.5e-5]\u001b[A\n",
      "Epoch 543: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.98it/s, loss=1.97e-07, v_num=23, train_loss=1.95e-5, test_loss=2.01e-5]\u001b[A\n",
      "Epoch 544:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.78it/s, loss=2.41e-07, v_num=23, train_loss=1.95e-5, test_loss=2.01e-5]\u001b[AAdjusting learning rate of group 0 to 2.5558e-03.\n",
      "Epoch 544:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.53it/s, loss=2.27e-07, v_num=23, train_loss=1.95e-5, test_loss=2.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 544:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.54it/s, loss=2.27e-07, v_num=23, train_loss=1.95e-5, test_loss=2.01e-5]\u001b[A\n",
      "Epoch 544: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.91it/s, loss=2.27e-07, v_num=23, train_loss=2.27e-5, test_loss=2.34e-5]\u001b[A\n",
      "Epoch 545:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.54it/s, loss=2.46e-07, v_num=23, train_loss=2.27e-5, test_loss=2.34e-5]\u001b[AAdjusting learning rate of group 0 to 2.5494e-03.\n",
      "Epoch 545:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.60it/s, loss=2.37e-07, v_num=23, train_loss=2.27e-5, test_loss=2.34e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 545:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.67it/s, loss=2.37e-07, v_num=23, train_loss=2.27e-5, test_loss=2.34e-5]\u001b[A\n",
      "Epoch 545: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 171.32it/s, loss=2.37e-07, v_num=23, train_loss=1.84e-5, test_loss=1.9e-5]\u001b[A\n",
      "Epoch 546:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.49it/s, loss=1.82e-07, v_num=23, train_loss=1.84e-5, test_loss=1.9e-5]\u001b[AAdjusting learning rate of group 0 to 2.5431e-03.\n",
      "Epoch 546:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.12it/s, loss=1.74e-07, v_num=23, train_loss=1.84e-5, test_loss=1.9e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 546:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 130.43it/s, loss=1.74e-07, v_num=23, train_loss=1.84e-5, test_loss=1.9e-5]\u001b[A\n",
      "Epoch 546: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.92it/s, loss=1.74e-07, v_num=23, train_loss=1.93e-5, test_loss=2.02e-5]\u001b[A\n",
      "Epoch 547:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.85it/s, loss=2.03e-07, v_num=23, train_loss=1.93e-5, test_loss=2.02e-5]\u001b[AAdjusting learning rate of group 0 to 2.5367e-03.\n",
      "Epoch 547:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.75it/s, loss=1.96e-07, v_num=23, train_loss=1.93e-5, test_loss=2.02e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 547:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.59it/s, loss=1.96e-07, v_num=23, train_loss=1.93e-5, test_loss=2.02e-5]\u001b[A\n",
      "Epoch 547: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.51it/s, loss=1.96e-07, v_num=23, train_loss=2.36e-5, test_loss=2.45e-5]\u001b[A\n",
      "Epoch 548:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.18it/s, loss=2.52e-07, v_num=23, train_loss=2.36e-5, test_loss=2.45e-5]\u001b[AAdjusting learning rate of group 0 to 2.5304e-03.\n",
      "Epoch 548:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.25it/s, loss=2.4e-07, v_num=23, train_loss=2.36e-5, test_loss=2.45e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 548:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.18it/s, loss=2.4e-07, v_num=23, train_loss=2.36e-5, test_loss=2.45e-5]\u001b[A\n",
      "Epoch 548: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.16it/s, loss=2.4e-07, v_num=23, train_loss=3.36e-5, test_loss=3.48e-5]\u001b[A\n",
      "Epoch 549:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.48it/s, loss=2.54e-07, v_num=23, train_loss=3.36e-5, test_loss=3.48e-5]\u001b[AAdjusting learning rate of group 0 to 2.5240e-03.\n",
      "Epoch 549:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.48it/s, loss=2.43e-07, v_num=23, train_loss=3.36e-5, test_loss=3.48e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 549:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.80it/s, loss=2.43e-07, v_num=23, train_loss=3.36e-5, test_loss=3.48e-5]\u001b[A\n",
      "Epoch 549: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.71it/s, loss=2.43e-07, v_num=23, train_loss=3.89e-5, test_loss=3.9e-5]\u001b[A\n",
      "Epoch 550:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 145.79it/s, loss=2.34e-07, v_num=23, train_loss=3.89e-5, test_loss=3.9e-5]\u001b[AAdjusting learning rate of group 0 to 2.5177e-03.\n",
      "Epoch 550:  50%|████████████████████                    | 79/158 [00:00<00:00, 136.25it/s, loss=2.23e-07, v_num=23, train_loss=3.89e-5, test_loss=3.9e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 550:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 130.33it/s, loss=2.23e-07, v_num=23, train_loss=3.89e-5, test_loss=3.9e-5]\u001b[A\n",
      "Epoch 550: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.59it/s, loss=2.23e-07, v_num=23, train_loss=2.46e-5, test_loss=2.54e-5]\u001b[A\n",
      "Epoch 551:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.23it/s, loss=2.78e-07, v_num=23, train_loss=2.46e-5, test_loss=2.54e-5]\u001b[AAdjusting learning rate of group 0 to 2.5114e-03.\n",
      "Epoch 551:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.52it/s, loss=2.66e-07, v_num=23, train_loss=2.46e-5, test_loss=2.54e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 551:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.49it/s, loss=2.66e-07, v_num=23, train_loss=2.46e-5, test_loss=2.54e-5]\u001b[A\n",
      "Epoch 551: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.88it/s, loss=2.66e-07, v_num=23, train_loss=4.82e-5, test_loss=4.94e-5]\u001b[A\n",
      "Epoch 552:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.70it/s, loss=2.18e-07, v_num=23, train_loss=4.82e-5, test_loss=4.94e-5]\u001b[AAdjusting learning rate of group 0 to 2.5052e-03.\n",
      "Epoch 552:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.33it/s, loss=2.12e-07, v_num=23, train_loss=4.82e-5, test_loss=4.94e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 552:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.22it/s, loss=2.12e-07, v_num=23, train_loss=4.82e-5, test_loss=4.94e-5]\u001b[A\n",
      "Epoch 552: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.35it/s, loss=2.12e-07, v_num=23, train_loss=3.23e-5, test_loss=3.3e-5]\u001b[A\n",
      "Epoch 553:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.39it/s, loss=2.69e-07, v_num=23, train_loss=3.23e-5, test_loss=3.3e-5]\u001b[AAdjusting learning rate of group 0 to 2.4989e-03.\n",
      "Epoch 553:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 139.15it/s, loss=2.6e-07, v_num=23, train_loss=3.23e-5, test_loss=3.3e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 553:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 132.29it/s, loss=2.6e-07, v_num=23, train_loss=3.23e-5, test_loss=3.3e-5]\u001b[A\n",
      "Epoch 553: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.24it/s, loss=2.6e-07, v_num=23, train_loss=3.05e-5, test_loss=3.14e-5]\u001b[A\n",
      "Epoch 554:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.67it/s, loss=2.83e-07, v_num=23, train_loss=3.05e-5, test_loss=3.14e-5]\u001b[AAdjusting learning rate of group 0 to 2.4927e-03.\n",
      "Epoch 554:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.64it/s, loss=2.76e-07, v_num=23, train_loss=3.05e-5, test_loss=3.14e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 554:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.37it/s, loss=2.76e-07, v_num=23, train_loss=3.05e-5, test_loss=3.14e-5]\u001b[A\n",
      "Epoch 554: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.80it/s, loss=2.76e-07, v_num=23, train_loss=3.84e-5, test_loss=3.94e-5]\u001b[A\n",
      "Epoch 555:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.02it/s, loss=2.26e-07, v_num=23, train_loss=3.84e-5, test_loss=3.94e-5]\u001b[AAdjusting learning rate of group 0 to 2.4864e-03.\n",
      "Epoch 555:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.15it/s, loss=2.13e-07, v_num=23, train_loss=3.84e-5, test_loss=3.94e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 555:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.77it/s, loss=2.13e-07, v_num=23, train_loss=3.84e-5, test_loss=3.94e-5]\u001b[A\n",
      "Epoch 555: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.92it/s, loss=2.13e-07, v_num=23, train_loss=2.75e-5, test_loss=2.94e-5]\u001b[A\n",
      "Epoch 556:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.37it/s, loss=2.09e-07, v_num=23, train_loss=2.75e-5, test_loss=2.94e-5]\u001b[AAdjusting learning rate of group 0 to 2.4802e-03.\n",
      "Epoch 556:  50%|█████████████████████                     | 79/158 [00:00<00:00, 140.22it/s, loss=2e-07, v_num=23, train_loss=2.75e-5, test_loss=2.94e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 556:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 131.07it/s, loss=2e-07, v_num=23, train_loss=2.75e-5, test_loss=2.94e-5]\u001b[A\n",
      "Epoch 556: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 166.04it/s, loss=2e-07, v_num=23, train_loss=2.84e-5, test_loss=2.92e-5]\u001b[A\n",
      "Epoch 557:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.74it/s, loss=2.22e-07, v_num=23, train_loss=2.84e-5, test_loss=2.92e-5]\u001b[AAdjusting learning rate of group 0 to 2.4740e-03.\n",
      "Epoch 557:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.47it/s, loss=2.04e-07, v_num=23, train_loss=2.84e-5, test_loss=2.92e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 557:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.50it/s, loss=2.04e-07, v_num=23, train_loss=2.84e-5, test_loss=2.92e-5]\u001b[A\n",
      "Epoch 557: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.96it/s, loss=2.04e-07, v_num=23, train_loss=1.97e-5, test_loss=2.1e-5]\u001b[A\n",
      "Epoch 558:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.18it/s, loss=2.52e-07, v_num=23, train_loss=1.97e-5, test_loss=2.1e-5]\u001b[AAdjusting learning rate of group 0 to 2.4678e-03.\n",
      "Epoch 558:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.28it/s, loss=2.42e-07, v_num=23, train_loss=1.97e-5, test_loss=2.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 558:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.09it/s, loss=2.42e-07, v_num=23, train_loss=1.97e-5, test_loss=2.1e-5]\u001b[A\n",
      "Epoch 558: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 168.68it/s, loss=2.42e-07, v_num=23, train_loss=4.2e-5, test_loss=4.3e-5]\u001b[A\n",
      "Epoch 559:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.19it/s, loss=2.83e-07, v_num=23, train_loss=4.2e-5, test_loss=4.3e-5]\u001b[AAdjusting learning rate of group 0 to 2.4617e-03.\n",
      "Epoch 559:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 138.08it/s, loss=2.61e-07, v_num=23, train_loss=4.2e-5, test_loss=4.3e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 559:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 131.75it/s, loss=2.61e-07, v_num=23, train_loss=4.2e-5, test_loss=4.3e-5]\u001b[A\n",
      "Epoch 559: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.86it/s, loss=2.61e-07, v_num=23, train_loss=2.69e-5, test_loss=2.73e-5]\u001b[A\n",
      "Epoch 560:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.62it/s, loss=2.35e-07, v_num=23, train_loss=2.69e-5, test_loss=2.73e-5]\u001b[AAdjusting learning rate of group 0 to 2.4555e-03.\n",
      "Epoch 560:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.37it/s, loss=2.27e-07, v_num=23, train_loss=2.69e-5, test_loss=2.73e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 560:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.08it/s, loss=2.27e-07, v_num=23, train_loss=2.69e-5, test_loss=2.73e-5]\u001b[A\n",
      "Epoch 560: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.78it/s, loss=2.27e-07, v_num=23, train_loss=2.63e-5, test_loss=2.67e-5]\u001b[A\n",
      "Epoch 561:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.77it/s, loss=1.92e-07, v_num=23, train_loss=2.63e-5, test_loss=2.67e-5]\u001b[AAdjusting learning rate of group 0 to 2.4494e-03.\n",
      "Epoch 561:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.99it/s, loss=1.84e-07, v_num=23, train_loss=2.63e-5, test_loss=2.67e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 561:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.58it/s, loss=1.84e-07, v_num=23, train_loss=2.63e-5, test_loss=2.67e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.79it/s, loss=1.84e-07, v_num=23, train_loss=1.36e-5, test_loss=1.4e-5]\u001b[A\n",
      "Epoch 562:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.93it/s, loss=1.83e-07, v_num=23, train_loss=1.36e-5, test_loss=1.4e-5]\u001b[AAdjusting learning rate of group 0 to 2.4432e-03.\n",
      "Epoch 562:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.82it/s, loss=1.78e-07, v_num=23, train_loss=1.36e-5, test_loss=1.4e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 562:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 130.82it/s, loss=1.78e-07, v_num=23, train_loss=1.36e-5, test_loss=1.4e-5]\u001b[A\n",
      "Epoch 562: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.91it/s, loss=1.78e-07, v_num=23, train_loss=2.61e-5, test_loss=2.69e-5]\u001b[A\n",
      "Epoch 563:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.03it/s, loss=1.98e-07, v_num=23, train_loss=2.61e-5, test_loss=2.69e-5]\u001b[AAdjusting learning rate of group 0 to 2.4371e-03.\n",
      "Epoch 563:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.58it/s, loss=1.92e-07, v_num=23, train_loss=2.61e-5, test_loss=2.69e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 563:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.03it/s, loss=1.92e-07, v_num=23, train_loss=2.61e-5, test_loss=2.69e-5]\u001b[A\n",
      "Epoch 563: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.30it/s, loss=1.92e-07, v_num=23, train_loss=2.86e-5, test_loss=3.04e-5]\u001b[A\n",
      "Epoch 564:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.72it/s, loss=2.24e-07, v_num=23, train_loss=2.86e-5, test_loss=3.04e-5]\u001b[AAdjusting learning rate of group 0 to 2.4310e-03.\n",
      "Epoch 564:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.30it/s, loss=2.15e-07, v_num=23, train_loss=2.86e-5, test_loss=3.04e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 564:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.98it/s, loss=2.15e-07, v_num=23, train_loss=2.86e-5, test_loss=3.04e-5]\u001b[A\n",
      "Epoch 564: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.08it/s, loss=2.15e-07, v_num=23, train_loss=1.52e-5, test_loss=1.57e-5]\u001b[A\n",
      "Epoch 565:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.37it/s, loss=1.77e-07, v_num=23, train_loss=1.52e-5, test_loss=1.57e-5]\u001b[AAdjusting learning rate of group 0 to 2.4250e-03.\n",
      "Epoch 565:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.66it/s, loss=1.71e-07, v_num=23, train_loss=1.52e-5, test_loss=1.57e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 565:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.50it/s, loss=1.71e-07, v_num=23, train_loss=1.52e-5, test_loss=1.57e-5]\u001b[A\n",
      "Epoch 565: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.82it/s, loss=1.71e-07, v_num=23, train_loss=2.57e-5, test_loss=2.63e-5]\u001b[A\n",
      "Epoch 566:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.29it/s, loss=1.92e-07, v_num=23, train_loss=2.57e-5, test_loss=2.63e-5]\u001b[AAdjusting learning rate of group 0 to 2.4189e-03.\n",
      "Epoch 566:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.19it/s, loss=1.84e-07, v_num=23, train_loss=2.57e-5, test_loss=2.63e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 566:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.32it/s, loss=1.84e-07, v_num=23, train_loss=2.57e-5, test_loss=2.63e-5]\u001b[A\n",
      "Epoch 566: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.46it/s, loss=1.84e-07, v_num=23, train_loss=2.26e-5, test_loss=2.36e-5]\u001b[A\n",
      "Epoch 567:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.30it/s, loss=1.88e-07, v_num=23, train_loss=2.26e-5, test_loss=2.36e-5]\u001b[AAdjusting learning rate of group 0 to 2.4128e-03.\n",
      "Epoch 567:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.20it/s, loss=1.81e-07, v_num=23, train_loss=2.26e-5, test_loss=2.36e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 567:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.18it/s, loss=1.81e-07, v_num=23, train_loss=2.26e-5, test_loss=2.36e-5]\u001b[A\n",
      "Epoch 567: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.51it/s, loss=1.81e-07, v_num=23, train_loss=3.22e-5, test_loss=3.29e-5]\u001b[A\n",
      "Epoch 568:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.48it/s, loss=2.49e-07, v_num=23, train_loss=3.22e-5, test_loss=3.29e-5]\u001b[AAdjusting learning rate of group 0 to 2.4068e-03.\n",
      "Epoch 568:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.15it/s, loss=2.31e-07, v_num=23, train_loss=3.22e-5, test_loss=3.29e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 568:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.57it/s, loss=2.31e-07, v_num=23, train_loss=3.22e-5, test_loss=3.29e-5]\u001b[A\n",
      "Epoch 568: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.06it/s, loss=2.31e-07, v_num=23, train_loss=3.52e-5, test_loss=3.57e-5]\u001b[A\n",
      "Epoch 569:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.76it/s, loss=2.04e-07, v_num=23, train_loss=3.52e-5, test_loss=3.57e-5]\u001b[AAdjusting learning rate of group 0 to 2.4008e-03.\n",
      "Epoch 569:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.19it/s, loss=1.97e-07, v_num=23, train_loss=3.52e-5, test_loss=3.57e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 569:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.54it/s, loss=1.97e-07, v_num=23, train_loss=3.52e-5, test_loss=3.57e-5]\u001b[A\n",
      "Epoch 569: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.51it/s, loss=1.97e-07, v_num=23, train_loss=2.57e-5, test_loss=2.68e-5]\u001b[A\n",
      "Epoch 570:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.71it/s, loss=2.33e-07, v_num=23, train_loss=2.57e-5, test_loss=2.68e-5]\u001b[AAdjusting learning rate of group 0 to 2.3948e-03.\n",
      "Epoch 570:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.98it/s, loss=2.26e-07, v_num=23, train_loss=2.57e-5, test_loss=2.68e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 570:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.81it/s, loss=2.26e-07, v_num=23, train_loss=2.57e-5, test_loss=2.68e-5]\u001b[A\n",
      "Epoch 570: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.56it/s, loss=2.26e-07, v_num=23, train_loss=5.16e-5, test_loss=5.29e-5]\u001b[A\n",
      "Epoch 571:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.37it/s, loss=1.53e-07, v_num=23, train_loss=5.16e-5, test_loss=5.29e-5]\u001b[AAdjusting learning rate of group 0 to 2.3888e-03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.63it/s, loss=1.47e-07, v_num=23, train_loss=5.16e-5, test_loss=5.29e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 571:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.96it/s, loss=1.47e-07, v_num=23, train_loss=5.16e-5, test_loss=5.29e-5]\u001b[A\n",
      "Epoch 571: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.62it/s, loss=1.47e-07, v_num=23, train_loss=2.31e-5, test_loss=2.39e-5]\u001b[A\n",
      "Epoch 572:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.86it/s, loss=3.17e-07, v_num=23, train_loss=2.31e-5, test_loss=2.39e-5]\u001b[AAdjusting learning rate of group 0 to 2.3828e-03.\n",
      "Epoch 572:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.08it/s, loss=3.1e-07, v_num=23, train_loss=2.31e-5, test_loss=2.39e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 572:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 127.84it/s, loss=3.1e-07, v_num=23, train_loss=2.31e-5, test_loss=2.39e-5]\u001b[A\n",
      "Epoch 572: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 162.24it/s, loss=3.1e-07, v_num=23, train_loss=4.07e-5, test_loss=4.16e-5]\u001b[A\n",
      "Epoch 573:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.47it/s, loss=2.29e-07, v_num=23, train_loss=4.07e-5, test_loss=4.16e-5]\u001b[AAdjusting learning rate of group 0 to 2.3769e-03.\n",
      "Epoch 573:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.74it/s, loss=2.23e-07, v_num=23, train_loss=4.07e-5, test_loss=4.16e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 573:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.77it/s, loss=2.23e-07, v_num=23, train_loss=4.07e-5, test_loss=4.16e-5]\u001b[A\n",
      "Epoch 573: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.90it/s, loss=2.23e-07, v_num=23, train_loss=3.7e-5, test_loss=3.74e-5]\u001b[A\n",
      "Epoch 574:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.20it/s, loss=2.6e-07, v_num=23, train_loss=3.7e-5, test_loss=3.74e-5]\u001b[AAdjusting learning rate of group 0 to 2.3709e-03.\n",
      "Epoch 574:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.18it/s, loss=2.46e-07, v_num=23, train_loss=3.7e-5, test_loss=3.74e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 574:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.40it/s, loss=2.46e-07, v_num=23, train_loss=3.7e-5, test_loss=3.74e-5]\u001b[A\n",
      "Epoch 574: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.63it/s, loss=2.46e-07, v_num=23, train_loss=3.67e-5, test_loss=3.77e-5]\u001b[A\n",
      "Epoch 575:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.90it/s, loss=2.52e-07, v_num=23, train_loss=3.67e-5, test_loss=3.77e-5]\u001b[AAdjusting learning rate of group 0 to 2.3650e-03.\n",
      "Epoch 575:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.15it/s, loss=2.47e-07, v_num=23, train_loss=3.67e-5, test_loss=3.77e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 575:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.39it/s, loss=2.47e-07, v_num=23, train_loss=3.67e-5, test_loss=3.77e-5]\u001b[A\n",
      "Epoch 575: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.47it/s, loss=2.47e-07, v_num=23, train_loss=2.78e-5, test_loss=2.82e-5]\u001b[A\n",
      "Epoch 576:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.15it/s, loss=2.01e-07, v_num=23, train_loss=2.78e-5, test_loss=2.82e-5]\u001b[AAdjusting learning rate of group 0 to 2.3591e-03.\n",
      "Epoch 576:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.58it/s, loss=1.95e-07, v_num=23, train_loss=2.78e-5, test_loss=2.82e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 576:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.42it/s, loss=1.95e-07, v_num=23, train_loss=2.78e-5, test_loss=2.82e-5]\u001b[A\n",
      "Epoch 576: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.98it/s, loss=1.95e-07, v_num=23, train_loss=1.95e-5, test_loss=2.03e-5]\u001b[A\n",
      "Epoch 577:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.40it/s, loss=2.46e-07, v_num=23, train_loss=1.95e-5, test_loss=2.03e-5]\u001b[AAdjusting learning rate of group 0 to 2.3532e-03.\n",
      "Epoch 577:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.66it/s, loss=2.33e-07, v_num=23, train_loss=1.95e-5, test_loss=2.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.09it/s]\u001b[A\n",
      "Epoch 577:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 124.22it/s, loss=2.33e-07, v_num=23, train_loss=1.95e-5, test_loss=2.03e-5]\u001b[A\n",
      "Epoch 577: 100%|███████████████████████████████████████| 158/158 [00:01<00:00, 158.35it/s, loss=2.33e-07, v_num=23, train_loss=3.18e-5, test_loss=3.3e-5]\u001b[A\n",
      "Epoch 578:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.82it/s, loss=1.94e-07, v_num=23, train_loss=3.18e-5, test_loss=3.3e-5]\u001b[AAdjusting learning rate of group 0 to 2.3473e-03.\n",
      "Epoch 578:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.72it/s, loss=1.86e-07, v_num=23, train_loss=3.18e-5, test_loss=3.3e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 578:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.90it/s, loss=1.86e-07, v_num=23, train_loss=3.18e-5, test_loss=3.3e-5]\u001b[A\n",
      "Epoch 578: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.63it/s, loss=1.86e-07, v_num=23, train_loss=1.94e-5, test_loss=2.05e-5]\u001b[A\n",
      "Epoch 579:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.12it/s, loss=2.61e-07, v_num=23, train_loss=1.94e-5, test_loss=2.05e-5]\u001b[AAdjusting learning rate of group 0 to 2.3414e-03.\n",
      "Epoch 579:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 142.11it/s, loss=2.41e-07, v_num=23, train_loss=1.94e-5, test_loss=2.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 579:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.59it/s, loss=2.41e-07, v_num=23, train_loss=1.94e-5, test_loss=2.05e-5]\u001b[A\n",
      "Epoch 579: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.76it/s, loss=2.41e-07, v_num=23, train_loss=2.47e-5, test_loss=2.54e-5]\u001b[A\n",
      "Epoch 580:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.42it/s, loss=2.71e-07, v_num=23, train_loss=2.47e-5, test_loss=2.54e-5]\u001b[AAdjusting learning rate of group 0 to 2.3356e-03.\n",
      "Epoch 580:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.69it/s, loss=2.64e-07, v_num=23, train_loss=2.47e-5, test_loss=2.54e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 580:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.00it/s, loss=2.64e-07, v_num=23, train_loss=2.47e-5, test_loss=2.54e-5]\u001b[A\n",
      "Epoch 580: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.86it/s, loss=2.64e-07, v_num=23, train_loss=4.12e-5, test_loss=4.29e-5]\u001b[A\n",
      "Epoch 581:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 145.80it/s, loss=3.09e-07, v_num=23, train_loss=4.12e-5, test_loss=4.29e-5]\u001b[AAdjusting learning rate of group 0 to 2.3298e-03.\n",
      "Epoch 581:  50%|█████████████████████                     | 79/158 [00:00<00:00, 134.58it/s, loss=3e-07, v_num=23, train_loss=4.12e-5, test_loss=4.29e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 581:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 130.11it/s, loss=3e-07, v_num=23, train_loss=4.12e-5, test_loss=4.29e-5]\u001b[A\n",
      "Epoch 581: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 165.22it/s, loss=3e-07, v_num=23, train_loss=5.16e-5, test_loss=5.17e-5]\u001b[A\n",
      "Epoch 582:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.98it/s, loss=2.69e-07, v_num=23, train_loss=5.16e-5, test_loss=5.17e-5]\u001b[AAdjusting learning rate of group 0 to 2.3239e-03.\n",
      "Epoch 582:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.92it/s, loss=2.59e-07, v_num=23, train_loss=5.16e-5, test_loss=5.17e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 582:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.15it/s, loss=2.59e-07, v_num=23, train_loss=5.16e-5, test_loss=5.17e-5]\u001b[A\n",
      "Epoch 582: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 164.82it/s, loss=2.59e-07, v_num=23, train_loss=2.02e-5, test_loss=2.1e-5]\u001b[A\n",
      "Epoch 583:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.20it/s, loss=2.14e-07, v_num=23, train_loss=2.02e-5, test_loss=2.1e-5]\u001b[AAdjusting learning rate of group 0 to 2.3181e-03.\n",
      "Epoch 583:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.30it/s, loss=2.07e-07, v_num=23, train_loss=2.02e-5, test_loss=2.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 583:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.97it/s, loss=2.07e-07, v_num=23, train_loss=2.02e-5, test_loss=2.1e-5]\u001b[A\n",
      "Epoch 583: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.76it/s, loss=2.07e-07, v_num=23, train_loss=2.15e-5, test_loss=2.22e-5]\u001b[A\n",
      "Epoch 584:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.64it/s, loss=2.52e-07, v_num=23, train_loss=2.15e-5, test_loss=2.22e-5]\u001b[AAdjusting learning rate of group 0 to 2.3123e-03.\n",
      "Epoch 584:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.24it/s, loss=2.31e-07, v_num=23, train_loss=2.15e-5, test_loss=2.22e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 584:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.28it/s, loss=2.31e-07, v_num=23, train_loss=2.15e-5, test_loss=2.22e-5]\u001b[A\n",
      "Epoch 584: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.39it/s, loss=2.31e-07, v_num=23, train_loss=2.75e-5, test_loss=2.84e-5]\u001b[A\n",
      "Epoch 585:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.83it/s, loss=2.83e-07, v_num=23, train_loss=2.75e-5, test_loss=2.84e-5]\u001b[AAdjusting learning rate of group 0 to 2.3065e-03.\n",
      "Epoch 585:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.70it/s, loss=2.68e-07, v_num=23, train_loss=2.75e-5, test_loss=2.84e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 585:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.09it/s, loss=2.68e-07, v_num=23, train_loss=2.75e-5, test_loss=2.84e-5]\u001b[A\n",
      "Epoch 585: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.54it/s, loss=2.68e-07, v_num=23, train_loss=2.4e-5, test_loss=2.46e-5]\u001b[A\n",
      "Epoch 586:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.15it/s, loss=1.91e-07, v_num=23, train_loss=2.4e-5, test_loss=2.46e-5]\u001b[AAdjusting learning rate of group 0 to 2.3008e-03.\n",
      "Epoch 586:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.80it/s, loss=1.85e-07, v_num=23, train_loss=2.4e-5, test_loss=2.46e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 586:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 128.42it/s, loss=1.85e-07, v_num=23, train_loss=2.4e-5, test_loss=2.46e-5]\u001b[A\n",
      "Epoch 586: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.71it/s, loss=1.85e-07, v_num=23, train_loss=2.63e-5, test_loss=2.73e-5]\u001b[A\n",
      "Epoch 587:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.04it/s, loss=1.48e-07, v_num=23, train_loss=2.63e-5, test_loss=2.73e-5]\u001b[AAdjusting learning rate of group 0 to 2.2950e-03.\n",
      "Epoch 587:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.93it/s, loss=1.4e-07, v_num=23, train_loss=2.63e-5, test_loss=2.73e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 587:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.75it/s, loss=1.4e-07, v_num=23, train_loss=2.63e-5, test_loss=2.73e-5]\u001b[A\n",
      "Epoch 587: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.06it/s, loss=1.4e-07, v_num=23, train_loss=1.78e-5, test_loss=1.85e-5]\u001b[A\n",
      "Epoch 588:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.93it/s, loss=2.27e-07, v_num=23, train_loss=1.78e-5, test_loss=1.85e-5]\u001b[AAdjusting learning rate of group 0 to 2.2893e-03.\n",
      "Epoch 588:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.96it/s, loss=2.17e-07, v_num=23, train_loss=1.78e-5, test_loss=1.85e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 588:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.48it/s, loss=2.17e-07, v_num=23, train_loss=1.78e-5, test_loss=1.85e-5]\u001b[A\n",
      "Epoch 588: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.66it/s, loss=2.17e-07, v_num=23, train_loss=1.76e-5, test_loss=1.82e-5]\u001b[A\n",
      "Epoch 589:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.78it/s, loss=1.69e-07, v_num=23, train_loss=1.76e-5, test_loss=1.82e-5]\u001b[AAdjusting learning rate of group 0 to 2.2836e-03.\n",
      "Epoch 589:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.77it/s, loss=1.61e-07, v_num=23, train_loss=1.76e-5, test_loss=1.82e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 589:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.44it/s, loss=1.61e-07, v_num=23, train_loss=1.76e-5, test_loss=1.82e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 589: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.84it/s, loss=1.61e-07, v_num=23, train_loss=3.19e-5, test_loss=3.3e-5]\u001b[A\n",
      "Epoch 590:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.67it/s, loss=2.37e-07, v_num=23, train_loss=3.19e-5, test_loss=3.3e-5]\u001b[AAdjusting learning rate of group 0 to 2.2779e-03.\n",
      "Epoch 590:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 137.70it/s, loss=2.3e-07, v_num=23, train_loss=3.19e-5, test_loss=3.3e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 590:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 132.12it/s, loss=2.3e-07, v_num=23, train_loss=3.19e-5, test_loss=3.3e-5]\u001b[A\n",
      "Epoch 590: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.96it/s, loss=2.3e-07, v_num=23, train_loss=2.18e-5, test_loss=2.28e-5]\u001b[A\n",
      "Epoch 591:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.24it/s, loss=1.76e-07, v_num=23, train_loss=2.18e-5, test_loss=2.28e-5]\u001b[AAdjusting learning rate of group 0 to 2.2722e-03.\n",
      "Epoch 591:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.10it/s, loss=1.64e-07, v_num=23, train_loss=2.18e-5, test_loss=2.28e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 591:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.30it/s, loss=1.64e-07, v_num=23, train_loss=2.18e-5, test_loss=2.28e-5]\u001b[A\n",
      "Epoch 591: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.80it/s, loss=1.64e-07, v_num=23, train_loss=1.99e-5, test_loss=2.05e-5]\u001b[A\n",
      "Epoch 592:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.11it/s, loss=2.09e-07, v_num=23, train_loss=1.99e-5, test_loss=2.05e-5]\u001b[AAdjusting learning rate of group 0 to 2.2665e-03.\n",
      "Epoch 592:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.08it/s, loss=1.88e-07, v_num=23, train_loss=1.99e-5, test_loss=2.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 592:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.63it/s, loss=1.88e-07, v_num=23, train_loss=1.99e-5, test_loss=2.05e-5]\u001b[A\n",
      "Epoch 592: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.78it/s, loss=1.88e-07, v_num=23, train_loss=3.16e-5, test_loss=3.18e-5]\u001b[A\n",
      "Epoch 593:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.85it/s, loss=2.27e-07, v_num=23, train_loss=3.16e-5, test_loss=3.18e-5]\u001b[AAdjusting learning rate of group 0 to 2.2608e-03.\n",
      "Epoch 593:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.49it/s, loss=2.24e-07, v_num=23, train_loss=3.16e-5, test_loss=3.18e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 593:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.89it/s, loss=2.24e-07, v_num=23, train_loss=3.16e-5, test_loss=3.18e-5]\u001b[A\n",
      "Epoch 593: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.05it/s, loss=2.24e-07, v_num=23, train_loss=2.32e-5, test_loss=2.32e-5]\u001b[A\n",
      "Epoch 594:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.71it/s, loss=1.93e-07, v_num=23, train_loss=2.32e-5, test_loss=2.32e-5]\u001b[AAdjusting learning rate of group 0 to 2.2552e-03.\n",
      "Epoch 594:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.70it/s, loss=1.86e-07, v_num=23, train_loss=2.32e-5, test_loss=2.32e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 594:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.77it/s, loss=1.86e-07, v_num=23, train_loss=2.32e-5, test_loss=2.32e-5]\u001b[A\n",
      "Epoch 594: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.22it/s, loss=1.86e-07, v_num=23, train_loss=3.82e-5, test_loss=3.88e-5]\u001b[A\n",
      "Epoch 595:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.54it/s, loss=2.29e-07, v_num=23, train_loss=3.82e-5, test_loss=3.88e-5]\u001b[AAdjusting learning rate of group 0 to 2.2495e-03.\n",
      "Epoch 595:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.14it/s, loss=2.17e-07, v_num=23, train_loss=3.82e-5, test_loss=3.88e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 595:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.32it/s, loss=2.17e-07, v_num=23, train_loss=3.82e-5, test_loss=3.88e-5]\u001b[A\n",
      "Epoch 595: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 164.32it/s, loss=2.17e-07, v_num=23, train_loss=5.52e-5, test_loss=5.6e-5]\u001b[A\n",
      "Epoch 596:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.22it/s, loss=1.55e-07, v_num=23, train_loss=5.52e-5, test_loss=5.6e-5]\u001b[AAdjusting learning rate of group 0 to 2.2439e-03.\n",
      "Epoch 596:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 138.40it/s, loss=1.5e-07, v_num=23, train_loss=5.52e-5, test_loss=5.6e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 596:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 130.90it/s, loss=1.5e-07, v_num=23, train_loss=5.52e-5, test_loss=5.6e-5]\u001b[A\n",
      "Epoch 596: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 166.32it/s, loss=1.5e-07, v_num=23, train_loss=1.73e-5, test_loss=1.8e-5]\u001b[A\n",
      "Epoch 597:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.33it/s, loss=1.56e-07, v_num=23, train_loss=1.73e-5, test_loss=1.8e-5]\u001b[AAdjusting learning rate of group 0 to 2.2383e-03.\n",
      "Epoch 597:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.78it/s, loss=1.49e-07, v_num=23, train_loss=1.73e-5, test_loss=1.8e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 597:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.97it/s, loss=1.49e-07, v_num=23, train_loss=1.73e-5, test_loss=1.8e-5]\u001b[A\n",
      "Epoch 597: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.26it/s, loss=1.49e-07, v_num=23, train_loss=2.51e-5, test_loss=2.61e-5]\u001b[A\n",
      "Epoch 598:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.65it/s, loss=1.88e-07, v_num=23, train_loss=2.51e-5, test_loss=2.61e-5]\u001b[AAdjusting learning rate of group 0 to 2.2327e-03.\n",
      "Epoch 598:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.57it/s, loss=1.76e-07, v_num=23, train_loss=2.51e-5, test_loss=2.61e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 598:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.38it/s, loss=1.76e-07, v_num=23, train_loss=2.51e-5, test_loss=2.61e-5]\u001b[A\n",
      "Epoch 598: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.02it/s, loss=1.76e-07, v_num=23, train_loss=2.05e-5, test_loss=2.13e-5]\u001b[A\n",
      "Epoch 599:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.06it/s, loss=2.73e-07, v_num=23, train_loss=2.05e-5, test_loss=2.13e-5]\u001b[AAdjusting learning rate of group 0 to 2.2271e-03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 599:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.49it/s, loss=2.59e-07, v_num=23, train_loss=2.05e-5, test_loss=2.13e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 599:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.17it/s, loss=2.59e-07, v_num=23, train_loss=2.05e-5, test_loss=2.13e-5]\u001b[A\n",
      "Epoch 599: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.84it/s, loss=2.59e-07, v_num=23, train_loss=2.61e-5, test_loss=2.56e-5]\u001b[A\n",
      "Epoch 600:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.92it/s, loss=1.99e-07, v_num=23, train_loss=2.61e-5, test_loss=2.56e-5]\u001b[AAdjusting learning rate of group 0 to 2.2215e-03.\n",
      "Epoch 600:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.18it/s, loss=1.9e-07, v_num=23, train_loss=2.61e-5, test_loss=2.56e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 600:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.61it/s, loss=1.9e-07, v_num=23, train_loss=2.61e-5, test_loss=2.56e-5]\u001b[A\n",
      "Epoch 600: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 169.18it/s, loss=1.9e-07, v_num=23, train_loss=1.6e-5, test_loss=1.62e-5]\u001b[A\n",
      "Epoch 601:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.95it/s, loss=1.63e-07, v_num=23, train_loss=1.6e-5, test_loss=1.62e-5]\u001b[AAdjusting learning rate of group 0 to 2.2160e-03.\n",
      "Epoch 601:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.93it/s, loss=1.56e-07, v_num=23, train_loss=1.6e-5, test_loss=1.62e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 601:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.96it/s, loss=1.56e-07, v_num=23, train_loss=1.6e-5, test_loss=1.62e-5]\u001b[A\n",
      "Epoch 601: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.48it/s, loss=1.56e-07, v_num=23, train_loss=1.71e-5, test_loss=1.78e-5]\u001b[A\n",
      "Epoch 602:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.65it/s, loss=2.46e-07, v_num=23, train_loss=1.71e-5, test_loss=1.78e-5]\u001b[AAdjusting learning rate of group 0 to 2.2105e-03.\n",
      "Epoch 602:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.16it/s, loss=2.39e-07, v_num=23, train_loss=1.71e-5, test_loss=1.78e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 602:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.52it/s, loss=2.39e-07, v_num=23, train_loss=1.71e-5, test_loss=1.78e-5]\u001b[A\n",
      "Epoch 602: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.74it/s, loss=2.39e-07, v_num=23, train_loss=2.82e-5, test_loss=2.91e-5]\u001b[A\n",
      "Epoch 603:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.08it/s, loss=2.08e-07, v_num=23, train_loss=2.82e-5, test_loss=2.91e-5]\u001b[AAdjusting learning rate of group 0 to 2.2049e-03.\n",
      "Epoch 603:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.93it/s, loss=1.95e-07, v_num=23, train_loss=2.82e-5, test_loss=2.91e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 603:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.09it/s, loss=1.95e-07, v_num=23, train_loss=2.82e-5, test_loss=2.91e-5]\u001b[A\n",
      "Epoch 603: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.01it/s, loss=1.95e-07, v_num=23, train_loss=2.7e-5, test_loss=2.75e-5]\u001b[A\n",
      "Epoch 604:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 149.33it/s, loss=2.1e-07, v_num=23, train_loss=2.7e-5, test_loss=2.75e-5]\u001b[AAdjusting learning rate of group 0 to 2.1994e-03.\n",
      "Epoch 604:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.90it/s, loss=1.99e-07, v_num=23, train_loss=2.7e-5, test_loss=2.75e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 604:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.10it/s, loss=1.99e-07, v_num=23, train_loss=2.7e-5, test_loss=2.75e-5]\u001b[A\n",
      "Epoch 604: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.03it/s, loss=1.99e-07, v_num=23, train_loss=2.53e-5, test_loss=2.66e-5]\u001b[A\n",
      "Epoch 605:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 148.61it/s, loss=2e-07, v_num=23, train_loss=2.53e-5, test_loss=2.66e-5]\u001b[AAdjusting learning rate of group 0 to 2.1939e-03.\n",
      "Epoch 605:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.34it/s, loss=1.91e-07, v_num=23, train_loss=2.53e-5, test_loss=2.66e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 605:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.41it/s, loss=1.91e-07, v_num=23, train_loss=2.53e-5, test_loss=2.66e-5]\u001b[A\n",
      "Epoch 605: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.52it/s, loss=1.91e-07, v_num=23, train_loss=3.33e-5, test_loss=3.34e-5]\u001b[A\n",
      "Epoch 606:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.80it/s, loss=1.92e-07, v_num=23, train_loss=3.33e-5, test_loss=3.34e-5]\u001b[AAdjusting learning rate of group 0 to 2.1884e-03.\n",
      "Epoch 606:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.70it/s, loss=1.83e-07, v_num=23, train_loss=3.33e-5, test_loss=3.34e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 606:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.14it/s, loss=1.83e-07, v_num=23, train_loss=3.33e-5, test_loss=3.34e-5]\u001b[A\n",
      "Epoch 606: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.27it/s, loss=1.83e-07, v_num=23, train_loss=2.96e-5, test_loss=3.03e-5]\u001b[A\n",
      "Epoch 607:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 146.81it/s, loss=2.75e-07, v_num=23, train_loss=2.96e-5, test_loss=3.03e-5]\u001b[AAdjusting learning rate of group 0 to 2.1830e-03.\n",
      "Epoch 607:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.47it/s, loss=2.68e-07, v_num=23, train_loss=2.96e-5, test_loss=3.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 607:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.62it/s, loss=2.68e-07, v_num=23, train_loss=2.96e-5, test_loss=3.03e-5]\u001b[A\n",
      "Epoch 607: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.41it/s, loss=2.68e-07, v_num=23, train_loss=4.34e-5, test_loss=4.37e-5]\u001b[A\n",
      "Epoch 608:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.19it/s, loss=2.08e-07, v_num=23, train_loss=4.34e-5, test_loss=4.37e-5]\u001b[AAdjusting learning rate of group 0 to 2.1775e-03.\n",
      "Epoch 608:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.37it/s, loss=2.03e-07, v_num=23, train_loss=4.34e-5, test_loss=4.37e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 608:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.18it/s, loss=2.03e-07, v_num=23, train_loss=4.34e-5, test_loss=4.37e-5]\u001b[A\n",
      "Epoch 608: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.02it/s, loss=2.03e-07, v_num=23, train_loss=2.24e-5, test_loss=2.31e-5]\u001b[A\n",
      "Epoch 609:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.88it/s, loss=1.86e-07, v_num=23, train_loss=2.24e-5, test_loss=2.31e-5]\u001b[AAdjusting learning rate of group 0 to 2.1721e-03.\n",
      "Epoch 609:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.76it/s, loss=1.79e-07, v_num=23, train_loss=2.24e-5, test_loss=2.31e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 609:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.80it/s, loss=1.79e-07, v_num=23, train_loss=2.24e-5, test_loss=2.31e-5]\u001b[A\n",
      "Epoch 609: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 166.85it/s, loss=1.79e-07, v_num=23, train_loss=2.4e-5, test_loss=2.5e-5]\u001b[A\n",
      "Epoch 610:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 147.96it/s, loss=1.62e-07, v_num=23, train_loss=2.4e-5, test_loss=2.5e-5]\u001b[AAdjusting learning rate of group 0 to 2.1666e-03.\n",
      "Epoch 610:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 136.91it/s, loss=1.59e-07, v_num=23, train_loss=2.4e-5, test_loss=2.5e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 610:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 132.58it/s, loss=1.59e-07, v_num=23, train_loss=2.4e-5, test_loss=2.5e-5]\u001b[A\n",
      "Epoch 610: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.06it/s, loss=1.59e-07, v_num=23, train_loss=1.72e-5, test_loss=1.84e-5]\u001b[A\n",
      "Epoch 611:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.61it/s, loss=1.6e-07, v_num=23, train_loss=1.72e-5, test_loss=1.84e-5]\u001b[AAdjusting learning rate of group 0 to 2.1612e-03.\n",
      "Epoch 611:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.45it/s, loss=1.52e-07, v_num=23, train_loss=1.72e-5, test_loss=1.84e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 611:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.74it/s, loss=1.52e-07, v_num=23, train_loss=1.72e-5, test_loss=1.84e-5]\u001b[A\n",
      "Epoch 611: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.45it/s, loss=1.52e-07, v_num=23, train_loss=1.67e-5, test_loss=1.75e-5]\u001b[A\n",
      "Epoch 612:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.49it/s, loss=3.25e-07, v_num=23, train_loss=1.67e-5, test_loss=1.75e-5]\u001b[AAdjusting learning rate of group 0 to 2.1558e-03.\n",
      "Epoch 612:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.91it/s, loss=3.17e-07, v_num=23, train_loss=1.67e-5, test_loss=1.75e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 612:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.53it/s, loss=3.17e-07, v_num=23, train_loss=1.67e-5, test_loss=1.75e-5]\u001b[A\n",
      "Epoch 612: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 164.08it/s, loss=3.17e-07, v_num=23, train_loss=2.1e-5, test_loss=2.18e-5]\u001b[A\n",
      "Epoch 613:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.96it/s, loss=2.98e-07, v_num=23, train_loss=2.1e-5, test_loss=2.18e-5]\u001b[AAdjusting learning rate of group 0 to 2.1504e-03.\n",
      "Epoch 613:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.13it/s, loss=2.87e-07, v_num=23, train_loss=2.1e-5, test_loss=2.18e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 613:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.52it/s, loss=2.87e-07, v_num=23, train_loss=2.1e-5, test_loss=2.18e-5]\u001b[A\n",
      "Epoch 613: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.03it/s, loss=2.87e-07, v_num=23, train_loss=3.82e-5, test_loss=3.89e-5]\u001b[A\n",
      "Epoch 614:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.41it/s, loss=1.66e-07, v_num=23, train_loss=3.82e-5, test_loss=3.89e-5]\u001b[AAdjusting learning rate of group 0 to 2.1450e-03.\n",
      "Epoch 614:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.15it/s, loss=1.56e-07, v_num=23, train_loss=3.82e-5, test_loss=3.89e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 614:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.31it/s, loss=1.56e-07, v_num=23, train_loss=3.82e-5, test_loss=3.89e-5]\u001b[A\n",
      "Epoch 614: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.76it/s, loss=1.56e-07, v_num=23, train_loss=1.34e-5, test_loss=1.4e-5]\u001b[A\n",
      "Epoch 615:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.08it/s, loss=2.78e-07, v_num=23, train_loss=1.34e-5, test_loss=1.4e-5]\u001b[AAdjusting learning rate of group 0 to 2.1397e-03.\n",
      "Epoch 615:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.91it/s, loss=2.62e-07, v_num=23, train_loss=1.34e-5, test_loss=1.4e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 615:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.33it/s, loss=2.62e-07, v_num=23, train_loss=1.34e-5, test_loss=1.4e-5]\u001b[A\n",
      "Epoch 615: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.08it/s, loss=2.62e-07, v_num=23, train_loss=2.68e-5, test_loss=2.85e-5]\u001b[A\n",
      "Epoch 616:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.76it/s, loss=2.38e-07, v_num=23, train_loss=2.68e-5, test_loss=2.85e-5]\u001b[AAdjusting learning rate of group 0 to 2.1343e-03.\n",
      "Epoch 616:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.04it/s, loss=2.26e-07, v_num=23, train_loss=2.68e-5, test_loss=2.85e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 616:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.18it/s, loss=2.26e-07, v_num=23, train_loss=2.68e-5, test_loss=2.85e-5]\u001b[A\n",
      "Epoch 616: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.34it/s, loss=2.26e-07, v_num=23, train_loss=2.6e-5, test_loss=2.74e-5]\u001b[A\n",
      "Epoch 617:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 149.47it/s, loss=2.5e-07, v_num=23, train_loss=2.6e-5, test_loss=2.74e-5]\u001b[AAdjusting learning rate of group 0 to 2.1290e-03.\n",
      "Epoch 617:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.25it/s, loss=2.45e-07, v_num=23, train_loss=2.6e-5, test_loss=2.74e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 617:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.66it/s, loss=2.45e-07, v_num=23, train_loss=2.6e-5, test_loss=2.74e-5]\u001b[A\n",
      "Epoch 617: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.06it/s, loss=2.45e-07, v_num=23, train_loss=2.74e-5, test_loss=2.8e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 618:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.34it/s, loss=2.26e-07, v_num=23, train_loss=2.74e-5, test_loss=2.8e-5]\u001b[AAdjusting learning rate of group 0 to 2.1237e-03.\n",
      "Epoch 618:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.51it/s, loss=2.18e-07, v_num=23, train_loss=2.74e-5, test_loss=2.8e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 618:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.29it/s, loss=2.18e-07, v_num=23, train_loss=2.74e-5, test_loss=2.8e-5]\u001b[A\n",
      "Epoch 618: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.49it/s, loss=2.18e-07, v_num=23, train_loss=2.57e-5, test_loss=2.62e-5]\u001b[A\n",
      "Epoch 619:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.53it/s, loss=1.66e-07, v_num=23, train_loss=2.57e-5, test_loss=2.62e-5]\u001b[AAdjusting learning rate of group 0 to 2.1184e-03.\n",
      "Epoch 619:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.50it/s, loss=1.61e-07, v_num=23, train_loss=2.57e-5, test_loss=2.62e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 619:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.33it/s, loss=1.61e-07, v_num=23, train_loss=2.57e-5, test_loss=2.62e-5]\u001b[A\n",
      "Epoch 619: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.51it/s, loss=1.61e-07, v_num=23, train_loss=2.52e-5, test_loss=2.58e-5]\u001b[A\n",
      "Epoch 620:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.08it/s, loss=1.62e-07, v_num=23, train_loss=2.52e-5, test_loss=2.58e-5]\u001b[AAdjusting learning rate of group 0 to 2.1131e-03.\n",
      "Epoch 620:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.53it/s, loss=1.49e-07, v_num=23, train_loss=2.52e-5, test_loss=2.58e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 620:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.44it/s, loss=1.49e-07, v_num=23, train_loss=2.52e-5, test_loss=2.58e-5]\u001b[A\n",
      "Epoch 620: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.58it/s, loss=1.49e-07, v_num=23, train_loss=1.77e-5, test_loss=1.88e-5]\u001b[A\n",
      "Epoch 621:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.36it/s, loss=2.07e-07, v_num=23, train_loss=1.77e-5, test_loss=1.88e-5]\u001b[AAdjusting learning rate of group 0 to 2.1078e-03.\n",
      "Epoch 621:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.52it/s, loss=1.99e-07, v_num=23, train_loss=1.77e-5, test_loss=1.88e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 621:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.83it/s, loss=1.99e-07, v_num=23, train_loss=1.77e-5, test_loss=1.88e-5]\u001b[A\n",
      "Epoch 621: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.46it/s, loss=1.99e-07, v_num=23, train_loss=2.31e-5, test_loss=2.36e-5]\u001b[A\n",
      "Epoch 622:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.07it/s, loss=2.85e-07, v_num=23, train_loss=2.31e-5, test_loss=2.36e-5]\u001b[AAdjusting learning rate of group 0 to 2.1025e-03.\n",
      "Epoch 622:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.26it/s, loss=2.76e-07, v_num=23, train_loss=2.31e-5, test_loss=2.36e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 622:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.60it/s, loss=2.76e-07, v_num=23, train_loss=2.31e-5, test_loss=2.36e-5]\u001b[A\n",
      "Epoch 622: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.59it/s, loss=2.76e-07, v_num=23, train_loss=3.04e-5, test_loss=3.15e-5]\u001b[A\n",
      "Epoch 623:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.63it/s, loss=2.46e-07, v_num=23, train_loss=3.04e-5, test_loss=3.15e-5]\u001b[AAdjusting learning rate of group 0 to 2.0973e-03.\n",
      "Epoch 623:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.50it/s, loss=2.41e-07, v_num=23, train_loss=3.04e-5, test_loss=3.15e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 623:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.55it/s, loss=2.41e-07, v_num=23, train_loss=3.04e-5, test_loss=3.15e-5]\u001b[A\n",
      "Epoch 623: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.09it/s, loss=2.41e-07, v_num=23, train_loss=1.88e-5, test_loss=1.96e-5]\u001b[A\n",
      "Epoch 624:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.03it/s, loss=1.99e-07, v_num=23, train_loss=1.88e-5, test_loss=1.96e-5]\u001b[AAdjusting learning rate of group 0 to 2.0920e-03.\n",
      "Epoch 624:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.79it/s, loss=1.87e-07, v_num=23, train_loss=1.88e-5, test_loss=1.96e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.18it/s]\u001b[A\n",
      "Epoch 624: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 163.93it/s, loss=1.87e-07, v_num=23, train_loss=1.71e-5, test_loss=1.8e-5]\u001b[A\n",
      "Epoch 625:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.48it/s, loss=2.12e-07, v_num=23, train_loss=1.71e-5, test_loss=1.8e-5]\u001b[AAdjusting learning rate of group 0 to 2.0868e-03.\n",
      "Epoch 625:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.22it/s, loss=2.04e-07, v_num=23, train_loss=1.71e-5, test_loss=1.8e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 625:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.67it/s, loss=2.04e-07, v_num=23, train_loss=1.71e-5, test_loss=1.8e-5]\u001b[A\n",
      "Epoch 625: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.61it/s, loss=2.04e-07, v_num=23, train_loss=2.32e-5, test_loss=2.41e-5]\u001b[A\n",
      "Epoch 626:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.22it/s, loss=3.97e-07, v_num=23, train_loss=2.32e-5, test_loss=2.41e-5]\u001b[AAdjusting learning rate of group 0 to 2.0816e-03.\n",
      "Epoch 626:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.43it/s, loss=3.85e-07, v_num=23, train_loss=2.32e-5, test_loss=2.41e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 626:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.47it/s, loss=3.85e-07, v_num=23, train_loss=2.32e-5, test_loss=2.41e-5]\u001b[A\n",
      "Epoch 626: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.78it/s, loss=3.85e-07, v_num=23, train_loss=7.09e-5, test_loss=7.36e-5]\u001b[A\n",
      "Epoch 627:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.55it/s, loss=1.93e-07, v_num=23, train_loss=7.09e-5, test_loss=7.36e-5]\u001b[AAdjusting learning rate of group 0 to 2.0764e-03.\n",
      "Epoch 627:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.90it/s, loss=1.82e-07, v_num=23, train_loss=7.09e-5, test_loss=7.36e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 627:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.30it/s, loss=1.82e-07, v_num=23, train_loss=7.09e-5, test_loss=7.36e-5]\u001b[A\n",
      "Epoch 627: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.92it/s, loss=1.82e-07, v_num=23, train_loss=1.7e-5, test_loss=1.76e-5]\u001b[A\n",
      "Epoch 628:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.97it/s, loss=2.58e-07, v_num=23, train_loss=1.7e-5, test_loss=1.76e-5]\u001b[AAdjusting learning rate of group 0 to 2.0712e-03.\n",
      "Epoch 628:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.99it/s, loss=2.49e-07, v_num=23, train_loss=1.7e-5, test_loss=1.76e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 628:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.85it/s, loss=2.49e-07, v_num=23, train_loss=1.7e-5, test_loss=1.76e-5]\u001b[A\n",
      "Epoch 628: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.58it/s, loss=2.49e-07, v_num=23, train_loss=3.05e-5, test_loss=3.07e-5]\u001b[A\n",
      "Epoch 629:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.33it/s, loss=2.27e-07, v_num=23, train_loss=3.05e-5, test_loss=3.07e-5]\u001b[AAdjusting learning rate of group 0 to 2.0660e-03.\n",
      "Epoch 629:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.50it/s, loss=2.17e-07, v_num=23, train_loss=3.05e-5, test_loss=3.07e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 629:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.01it/s, loss=2.17e-07, v_num=23, train_loss=3.05e-5, test_loss=3.07e-5]\u001b[A\n",
      "Epoch 629: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.10it/s, loss=2.17e-07, v_num=23, train_loss=2.41e-5, test_loss=2.48e-5]\u001b[A\n",
      "Epoch 630:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.35it/s, loss=1.89e-07, v_num=23, train_loss=2.41e-5, test_loss=2.48e-5]\u001b[AAdjusting learning rate of group 0 to 2.0608e-03.\n",
      "Epoch 630:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.42it/s, loss=1.82e-07, v_num=23, train_loss=2.41e-5, test_loss=2.48e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 630:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.16it/s, loss=1.82e-07, v_num=23, train_loss=2.41e-5, test_loss=2.48e-5]\u001b[A\n",
      "Epoch 630: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.89it/s, loss=1.82e-07, v_num=23, train_loss=2.43e-5, test_loss=2.44e-5]\u001b[A\n",
      "Epoch 631:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.26it/s, loss=1.87e-07, v_num=23, train_loss=2.43e-5, test_loss=2.44e-5]\u001b[AAdjusting learning rate of group 0 to 2.0557e-03.\n",
      "Epoch 631:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.00it/s, loss=1.77e-07, v_num=23, train_loss=2.43e-5, test_loss=2.44e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 631:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.38it/s, loss=1.77e-07, v_num=23, train_loss=2.43e-5, test_loss=2.44e-5]\u001b[A\n",
      "Epoch 631: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.25it/s, loss=1.77e-07, v_num=23, train_loss=2.11e-5, test_loss=2.21e-5]\u001b[A\n",
      "Epoch 632:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.34it/s, loss=2.18e-07, v_num=23, train_loss=2.11e-5, test_loss=2.21e-5]\u001b[AAdjusting learning rate of group 0 to 2.0505e-03.\n",
      "Epoch 632:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.31it/s, loss=2.1e-07, v_num=23, train_loss=2.11e-5, test_loss=2.21e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 632:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.05it/s, loss=2.1e-07, v_num=23, train_loss=2.11e-5, test_loss=2.21e-5]\u001b[A\n",
      "Epoch 632: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.86it/s, loss=2.1e-07, v_num=23, train_loss=1.87e-5, test_loss=1.89e-5]\u001b[A\n",
      "Epoch 633:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.07it/s, loss=1.98e-07, v_num=23, train_loss=1.87e-5, test_loss=1.89e-5]\u001b[AAdjusting learning rate of group 0 to 2.0454e-03.\n",
      "Epoch 633:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.63it/s, loss=1.91e-07, v_num=23, train_loss=1.87e-5, test_loss=1.89e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 633:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.91it/s, loss=1.91e-07, v_num=23, train_loss=1.87e-5, test_loss=1.89e-5]\u001b[A\n",
      "Epoch 633: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.76it/s, loss=1.91e-07, v_num=23, train_loss=2.82e-5, test_loss=2.89e-5]\u001b[A\n",
      "Epoch 634:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.82it/s, loss=2.16e-07, v_num=23, train_loss=2.82e-5, test_loss=2.89e-5]\u001b[AAdjusting learning rate of group 0 to 2.0403e-03.\n",
      "Epoch 634:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.52it/s, loss=2.01e-07, v_num=23, train_loss=2.82e-5, test_loss=2.89e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 634:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.53it/s, loss=2.01e-07, v_num=23, train_loss=2.82e-5, test_loss=2.89e-5]\u001b[A\n",
      "Epoch 634: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.94it/s, loss=2.01e-07, v_num=23, train_loss=1.51e-5, test_loss=1.59e-5]\u001b[A\n",
      "Epoch 635:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.60it/s, loss=1.49e-07, v_num=23, train_loss=1.51e-5, test_loss=1.59e-5]\u001b[AAdjusting learning rate of group 0 to 2.0352e-03.\n",
      "Epoch 635:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.84it/s, loss=1.44e-07, v_num=23, train_loss=1.51e-5, test_loss=1.59e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 635:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.48it/s, loss=1.44e-07, v_num=23, train_loss=1.51e-5, test_loss=1.59e-5]\u001b[A\n",
      "Epoch 635: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.04it/s, loss=1.44e-07, v_num=23, train_loss=1.93e-5, test_loss=1.99e-5]\u001b[A\n",
      "Epoch 636:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.29it/s, loss=1.87e-07, v_num=23, train_loss=1.93e-5, test_loss=1.99e-5]\u001b[AAdjusting learning rate of group 0 to 2.0301e-03.\n",
      "Epoch 636:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.71it/s, loss=1.78e-07, v_num=23, train_loss=1.93e-5, test_loss=1.99e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 636:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.95it/s, loss=1.78e-07, v_num=23, train_loss=1.93e-5, test_loss=1.99e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 636: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.84it/s, loss=1.78e-07, v_num=23, train_loss=2.3e-5, test_loss=2.36e-5]\u001b[A\n",
      "Epoch 637:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.68it/s, loss=3.43e-07, v_num=23, train_loss=2.3e-5, test_loss=2.36e-5]\u001b[AAdjusting learning rate of group 0 to 2.0250e-03.\n",
      "Epoch 637:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.03it/s, loss=3.35e-07, v_num=23, train_loss=2.3e-5, test_loss=2.36e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 637:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.76it/s, loss=3.35e-07, v_num=23, train_loss=2.3e-5, test_loss=2.36e-5]\u001b[A\n",
      "Epoch 637: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.89it/s, loss=3.35e-07, v_num=23, train_loss=1.9e-5, test_loss=2.02e-5]\u001b[A\n",
      "Epoch 638:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 150.03it/s, loss=2.14e-07, v_num=23, train_loss=1.9e-5, test_loss=2.02e-5]\u001b[AAdjusting learning rate of group 0 to 2.0200e-03.\n",
      "Epoch 638:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.56it/s, loss=2.06e-07, v_num=23, train_loss=1.9e-5, test_loss=2.02e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 638:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.45it/s, loss=2.06e-07, v_num=23, train_loss=1.9e-5, test_loss=2.02e-5]\u001b[A\n",
      "Epoch 638: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.90it/s, loss=2.06e-07, v_num=23, train_loss=1.82e-5, test_loss=1.9e-5]\u001b[A\n",
      "Epoch 639:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.06it/s, loss=1.56e-07, v_num=23, train_loss=1.82e-5, test_loss=1.9e-5]\u001b[AAdjusting learning rate of group 0 to 2.0149e-03.\n",
      "Epoch 639:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.66it/s, loss=1.53e-07, v_num=23, train_loss=1.82e-5, test_loss=1.9e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 639:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.26it/s, loss=1.53e-07, v_num=23, train_loss=1.82e-5, test_loss=1.9e-5]\u001b[A\n",
      "Epoch 639: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.82it/s, loss=1.53e-07, v_num=23, train_loss=2.81e-5, test_loss=2.88e-5]\u001b[A\n",
      "Epoch 640:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.67it/s, loss=2.36e-07, v_num=23, train_loss=2.81e-5, test_loss=2.88e-5]\u001b[AAdjusting learning rate of group 0 to 2.0099e-03.\n",
      "Epoch 640:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.37it/s, loss=2.21e-07, v_num=23, train_loss=2.81e-5, test_loss=2.88e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 640:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.32it/s, loss=2.21e-07, v_num=23, train_loss=2.81e-5, test_loss=2.88e-5]\u001b[A\n",
      "Epoch 640: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.01it/s, loss=2.21e-07, v_num=23, train_loss=2.96e-5, test_loss=3.06e-5]\u001b[A\n",
      "Epoch 641:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.96it/s, loss=1.97e-07, v_num=23, train_loss=2.96e-5, test_loss=3.06e-5]\u001b[AAdjusting learning rate of group 0 to 2.0049e-03.\n",
      "Epoch 641:  50%|████████████████████                    | 79/158 [00:00<00:00, 136.89it/s, loss=1.9e-07, v_num=23, train_loss=2.96e-5, test_loss=3.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 641:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.62it/s, loss=1.9e-07, v_num=23, train_loss=2.96e-5, test_loss=3.06e-5]\u001b[A\n",
      "Epoch 641: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.98it/s, loss=1.9e-07, v_num=23, train_loss=2.49e-5, test_loss=2.59e-5]\u001b[A\n",
      "Epoch 642:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.68it/s, loss=1.75e-07, v_num=23, train_loss=2.49e-5, test_loss=2.59e-5]\u001b[AAdjusting learning rate of group 0 to 1.9999e-03.\n",
      "Epoch 642:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.67it/s, loss=1.65e-07, v_num=23, train_loss=2.49e-5, test_loss=2.59e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 642:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.60it/s, loss=1.65e-07, v_num=23, train_loss=2.49e-5, test_loss=2.59e-5]\u001b[A\n",
      "Epoch 642: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.29it/s, loss=1.65e-07, v_num=23, train_loss=1.72e-5, test_loss=1.78e-5]\u001b[A\n",
      "Epoch 643:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.14it/s, loss=1.63e-07, v_num=23, train_loss=1.72e-5, test_loss=1.78e-5]\u001b[AAdjusting learning rate of group 0 to 1.9949e-03.\n",
      "Epoch 643:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.76it/s, loss=1.57e-07, v_num=23, train_loss=1.72e-5, test_loss=1.78e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 643:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.94it/s, loss=1.57e-07, v_num=23, train_loss=1.72e-5, test_loss=1.78e-5]\u001b[A\n",
      "Epoch 643: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 163.91it/s, loss=1.57e-07, v_num=23, train_loss=3.84e-5, test_loss=3.88e-5]\u001b[A\n",
      "Epoch 644:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.36it/s, loss=2.04e-07, v_num=23, train_loss=3.84e-5, test_loss=3.88e-5]\u001b[AAdjusting learning rate of group 0 to 1.9899e-03.\n",
      "Epoch 644:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.91it/s, loss=1.96e-07, v_num=23, train_loss=3.84e-5, test_loss=3.88e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 644:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.28it/s, loss=1.96e-07, v_num=23, train_loss=3.84e-5, test_loss=3.88e-5]\u001b[A\n",
      "Epoch 644: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.17it/s, loss=1.96e-07, v_num=23, train_loss=2.15e-5, test_loss=2.2e-5]\u001b[A\n",
      "Epoch 645:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.33it/s, loss=1.49e-07, v_num=23, train_loss=2.15e-5, test_loss=2.2e-5]\u001b[AAdjusting learning rate of group 0 to 1.9849e-03.\n",
      "Epoch 645:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.46it/s, loss=1.43e-07, v_num=23, train_loss=2.15e-5, test_loss=2.2e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 645:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 135.66it/s, loss=1.43e-07, v_num=23, train_loss=2.15e-5, test_loss=2.2e-5]\u001b[A\n",
      "Epoch 645: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.20it/s, loss=1.43e-07, v_num=23, train_loss=2.34e-5, test_loss=2.44e-5]\u001b[A\n",
      "Epoch 646:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.99it/s, loss=1.87e-07, v_num=23, train_loss=2.34e-5, test_loss=2.44e-5]\u001b[AAdjusting learning rate of group 0 to 1.9799e-03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 646:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.67it/s, loss=1.74e-07, v_num=23, train_loss=2.34e-5, test_loss=2.44e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 646:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.30it/s, loss=1.74e-07, v_num=23, train_loss=2.34e-5, test_loss=2.44e-5]\u001b[A\n",
      "Epoch 646: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.89it/s, loss=1.74e-07, v_num=23, train_loss=1.49e-5, test_loss=1.51e-5]\u001b[A\n",
      "Epoch 647:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.18it/s, loss=2.01e-07, v_num=23, train_loss=1.49e-5, test_loss=1.51e-5]\u001b[AAdjusting learning rate of group 0 to 1.9750e-03.\n",
      "Epoch 647:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.92it/s, loss=1.97e-07, v_num=23, train_loss=1.49e-5, test_loss=1.51e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 647:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.64it/s, loss=1.97e-07, v_num=23, train_loss=1.49e-5, test_loss=1.51e-5]\u001b[A\n",
      "Epoch 647: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.72it/s, loss=1.97e-07, v_num=23, train_loss=1.24e-5, test_loss=1.3e-5]\u001b[A\n",
      "Epoch 648:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.33it/s, loss=1.75e-07, v_num=23, train_loss=1.24e-5, test_loss=1.3e-5]\u001b[AAdjusting learning rate of group 0 to 1.9700e-03.\n",
      "Epoch 648:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.89it/s, loss=1.66e-07, v_num=23, train_loss=1.24e-5, test_loss=1.3e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 648:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 130.68it/s, loss=1.66e-07, v_num=23, train_loss=1.24e-5, test_loss=1.3e-5]\u001b[A\n",
      "Epoch 648: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.23it/s, loss=1.66e-07, v_num=23, train_loss=1.91e-5, test_loss=1.96e-5]\u001b[A\n",
      "Epoch 649:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.57it/s, loss=1.61e-07, v_num=23, train_loss=1.91e-5, test_loss=1.96e-5]\u001b[AAdjusting learning rate of group 0 to 1.9651e-03.\n",
      "Epoch 649:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.17it/s, loss=1.54e-07, v_num=23, train_loss=1.91e-5, test_loss=1.96e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 649:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.63it/s, loss=1.54e-07, v_num=23, train_loss=1.91e-5, test_loss=1.96e-5]\u001b[A\n",
      "Epoch 649: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.45it/s, loss=1.54e-07, v_num=23, train_loss=1.82e-5, test_loss=1.88e-5]\u001b[A\n",
      "Epoch 650:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.45it/s, loss=1.73e-07, v_num=23, train_loss=1.82e-5, test_loss=1.88e-5]\u001b[AAdjusting learning rate of group 0 to 1.9602e-03.\n",
      "Epoch 650:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.25it/s, loss=1.67e-07, v_num=23, train_loss=1.82e-5, test_loss=1.88e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 650:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.10it/s, loss=1.67e-07, v_num=23, train_loss=1.82e-5, test_loss=1.88e-5]\u001b[A\n",
      "Epoch 650: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.80it/s, loss=1.67e-07, v_num=23, train_loss=1.74e-5, test_loss=1.8e-5]\u001b[A\n",
      "Epoch 651:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.76it/s, loss=1.51e-07, v_num=23, train_loss=1.74e-5, test_loss=1.8e-5]\u001b[AAdjusting learning rate of group 0 to 1.9553e-03.\n",
      "Epoch 651:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.30it/s, loss=1.44e-07, v_num=23, train_loss=1.74e-5, test_loss=1.8e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 651:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.41it/s, loss=1.44e-07, v_num=23, train_loss=1.74e-5, test_loss=1.8e-5]\u001b[A\n",
      "Epoch 651: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.69it/s, loss=1.44e-07, v_num=23, train_loss=1.99e-5, test_loss=2.1e-5]\u001b[A\n",
      "Epoch 652:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.42it/s, loss=1.76e-07, v_num=23, train_loss=1.99e-5, test_loss=2.1e-5]\u001b[AAdjusting learning rate of group 0 to 1.9504e-03.\n",
      "Epoch 652:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.17it/s, loss=1.66e-07, v_num=23, train_loss=1.99e-5, test_loss=2.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 652:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.57it/s, loss=1.66e-07, v_num=23, train_loss=1.99e-5, test_loss=2.1e-5]\u001b[A\n",
      "Epoch 652: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.21it/s, loss=1.66e-07, v_num=23, train_loss=2.1e-5, test_loss=2.16e-5]\u001b[A\n",
      "Epoch 653:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.58it/s, loss=1.64e-07, v_num=23, train_loss=2.1e-5, test_loss=2.16e-5]\u001b[AAdjusting learning rate of group 0 to 1.9455e-03.\n",
      "Epoch 653:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.10it/s, loss=1.55e-07, v_num=23, train_loss=2.1e-5, test_loss=2.16e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 653:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.56it/s, loss=1.55e-07, v_num=23, train_loss=2.1e-5, test_loss=2.16e-5]\u001b[A\n",
      "Epoch 653: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.35it/s, loss=1.55e-07, v_num=23, train_loss=2.06e-5, test_loss=2.14e-5]\u001b[A\n",
      "Epoch 654:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.17it/s, loss=1.68e-07, v_num=23, train_loss=2.06e-5, test_loss=2.14e-5]\u001b[AAdjusting learning rate of group 0 to 1.9407e-03.\n",
      "Epoch 654:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.86it/s, loss=1.51e-07, v_num=23, train_loss=2.06e-5, test_loss=2.14e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 654:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.95it/s, loss=1.51e-07, v_num=23, train_loss=2.06e-5, test_loss=2.14e-5]\u001b[A\n",
      "Epoch 654: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.87it/s, loss=1.51e-07, v_num=23, train_loss=1.67e-5, test_loss=1.73e-5]\u001b[A\n",
      "Epoch 655:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.58it/s, loss=1.69e-07, v_num=23, train_loss=1.67e-5, test_loss=1.73e-5]\u001b[AAdjusting learning rate of group 0 to 1.9358e-03.\n",
      "Epoch 655:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.52it/s, loss=1.6e-07, v_num=23, train_loss=1.67e-5, test_loss=1.73e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 655:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.33it/s, loss=1.6e-07, v_num=23, train_loss=1.67e-5, test_loss=1.73e-5]\u001b[A\n",
      "Epoch 655: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.11it/s, loss=1.6e-07, v_num=23, train_loss=1.98e-5, test_loss=2.03e-5]\u001b[A\n",
      "Epoch 656:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.20it/s, loss=1.48e-07, v_num=23, train_loss=1.98e-5, test_loss=2.03e-5]\u001b[AAdjusting learning rate of group 0 to 1.9310e-03.\n",
      "Epoch 656:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.14it/s, loss=1.44e-07, v_num=23, train_loss=1.98e-5, test_loss=2.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 656:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.69it/s, loss=1.44e-07, v_num=23, train_loss=1.98e-5, test_loss=2.03e-5]\u001b[A\n",
      "Epoch 656: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.98it/s, loss=1.44e-07, v_num=23, train_loss=1.76e-5, test_loss=1.81e-5]\u001b[A\n",
      "Epoch 657:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.77it/s, loss=1.75e-07, v_num=23, train_loss=1.76e-5, test_loss=1.81e-5]\u001b[AAdjusting learning rate of group 0 to 1.9262e-03.\n",
      "Epoch 657:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.76it/s, loss=1.69e-07, v_num=23, train_loss=1.76e-5, test_loss=1.81e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 657:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.86it/s, loss=1.69e-07, v_num=23, train_loss=1.76e-5, test_loss=1.81e-5]\u001b[A\n",
      "Epoch 657: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.44it/s, loss=1.69e-07, v_num=23, train_loss=2.39e-5, test_loss=2.41e-5]\u001b[A\n",
      "Epoch 658:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.93it/s, loss=1.73e-07, v_num=23, train_loss=2.39e-5, test_loss=2.41e-5]\u001b[AAdjusting learning rate of group 0 to 1.9213e-03.\n",
      "Epoch 658:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.62it/s, loss=1.66e-07, v_num=23, train_loss=2.39e-5, test_loss=2.41e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 658:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.26it/s, loss=1.66e-07, v_num=23, train_loss=2.39e-5, test_loss=2.41e-5]\u001b[A\n",
      "Epoch 658: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.61it/s, loss=1.66e-07, v_num=23, train_loss=1.55e-5, test_loss=1.61e-5]\u001b[A\n",
      "Epoch 659:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.95it/s, loss=1.7e-07, v_num=23, train_loss=1.55e-5, test_loss=1.61e-5]\u001b[AAdjusting learning rate of group 0 to 1.9165e-03.\n",
      "Epoch 659:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.92it/s, loss=1.64e-07, v_num=23, train_loss=1.55e-5, test_loss=1.61e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 659:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.96it/s, loss=1.64e-07, v_num=23, train_loss=1.55e-5, test_loss=1.61e-5]\u001b[A\n",
      "Epoch 659: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.94it/s, loss=1.64e-07, v_num=23, train_loss=1.55e-5, test_loss=1.6e-5]\u001b[A\n",
      "Epoch 660:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.07it/s, loss=1.34e-07, v_num=23, train_loss=1.55e-5, test_loss=1.6e-5]\u001b[AAdjusting learning rate of group 0 to 1.9117e-03.\n",
      "Epoch 660:  50%|████████████████████                    | 79/158 [00:00<00:00, 136.62it/s, loss=1.28e-07, v_num=23, train_loss=1.55e-5, test_loss=1.6e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 660:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 130.09it/s, loss=1.28e-07, v_num=23, train_loss=1.55e-5, test_loss=1.6e-5]\u001b[A\n",
      "Epoch 660: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.99it/s, loss=1.28e-07, v_num=23, train_loss=1.97e-5, test_loss=2.02e-5]\u001b[A\n",
      "Epoch 661:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.28it/s, loss=2.29e-07, v_num=23, train_loss=1.97e-5, test_loss=2.02e-5]\u001b[AAdjusting learning rate of group 0 to 1.9070e-03.\n",
      "Epoch 661:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.30it/s, loss=2.22e-07, v_num=23, train_loss=1.97e-5, test_loss=2.02e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 661:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.40it/s, loss=2.22e-07, v_num=23, train_loss=1.97e-5, test_loss=2.02e-5]\u001b[A\n",
      "Epoch 661: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.67it/s, loss=2.22e-07, v_num=23, train_loss=1.95e-5, test_loss=2.02e-5]\u001b[A\n",
      "Epoch 662:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 146.81it/s, loss=2.25e-07, v_num=23, train_loss=1.95e-5, test_loss=2.02e-5]\u001b[AAdjusting learning rate of group 0 to 1.9022e-03.\n",
      "Epoch 662:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.41it/s, loss=2.11e-07, v_num=23, train_loss=1.95e-5, test_loss=2.02e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 662:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.46it/s, loss=2.11e-07, v_num=23, train_loss=1.95e-5, test_loss=2.02e-5]\u001b[A\n",
      "Epoch 662: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.89it/s, loss=2.11e-07, v_num=23, train_loss=2.07e-5, test_loss=2.17e-5]\u001b[A\n",
      "Epoch 663:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.98it/s, loss=2.64e-07, v_num=23, train_loss=2.07e-5, test_loss=2.17e-5]\u001b[AAdjusting learning rate of group 0 to 1.8974e-03.\n",
      "Epoch 663:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.42it/s, loss=2.5e-07, v_num=23, train_loss=2.07e-5, test_loss=2.17e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 663:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.10it/s, loss=2.5e-07, v_num=23, train_loss=2.07e-5, test_loss=2.17e-5]\u001b[A\n",
      "Epoch 663: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.55it/s, loss=2.5e-07, v_num=23, train_loss=1.95e-5, test_loss=1.99e-5]\u001b[A\n",
      "Epoch 664:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.24it/s, loss=1.59e-07, v_num=23, train_loss=1.95e-5, test_loss=1.99e-5]\u001b[AAdjusting learning rate of group 0 to 1.8927e-03.\n",
      "Epoch 664:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.72it/s, loss=1.5e-07, v_num=23, train_loss=1.95e-5, test_loss=1.99e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 664:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.53it/s, loss=1.5e-07, v_num=23, train_loss=1.95e-5, test_loss=1.99e-5]\u001b[A\n",
      "Epoch 664: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.10it/s, loss=1.5e-07, v_num=23, train_loss=2.48e-5, test_loss=2.56e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 665:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.43it/s, loss=2.82e-07, v_num=23, train_loss=2.48e-5, test_loss=2.56e-5]\u001b[AAdjusting learning rate of group 0 to 1.8880e-03.\n",
      "Epoch 665:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.16it/s, loss=2.62e-07, v_num=23, train_loss=2.48e-5, test_loss=2.56e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 665:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.85it/s, loss=2.62e-07, v_num=23, train_loss=2.48e-5, test_loss=2.56e-5]\u001b[A\n",
      "Epoch 665: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.15it/s, loss=2.62e-07, v_num=23, train_loss=2.72e-5, test_loss=2.78e-5]\u001b[A\n",
      "Epoch 666:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.03it/s, loss=1.82e-07, v_num=23, train_loss=2.72e-5, test_loss=2.78e-5]\u001b[AAdjusting learning rate of group 0 to 1.8832e-03.\n",
      "Epoch 666:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 142.04it/s, loss=1.74e-07, v_num=23, train_loss=2.72e-5, test_loss=2.78e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 666:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.64it/s, loss=1.74e-07, v_num=23, train_loss=2.72e-5, test_loss=2.78e-5]\u001b[A\n",
      "Epoch 666: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.73it/s, loss=1.74e-07, v_num=23, train_loss=1.65e-5, test_loss=1.8e-5]\u001b[A\n",
      "Epoch 667:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 149.24it/s, loss=1.6e-07, v_num=23, train_loss=1.65e-5, test_loss=1.8e-5]\u001b[AAdjusting learning rate of group 0 to 1.8785e-03.\n",
      "Epoch 667:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.19it/s, loss=1.54e-07, v_num=23, train_loss=1.65e-5, test_loss=1.8e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 667:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.55it/s, loss=1.54e-07, v_num=23, train_loss=1.65e-5, test_loss=1.8e-5]\u001b[A\n",
      "Epoch 667: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.71it/s, loss=1.54e-07, v_num=23, train_loss=2.18e-5, test_loss=2.25e-5]\u001b[A\n",
      "Epoch 668:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.72it/s, loss=3.42e-07, v_num=23, train_loss=2.18e-5, test_loss=2.25e-5]\u001b[AAdjusting learning rate of group 0 to 1.8738e-03.\n",
      "Epoch 668:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.80it/s, loss=3.24e-07, v_num=23, train_loss=2.18e-5, test_loss=2.25e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 668:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.30it/s, loss=3.24e-07, v_num=23, train_loss=2.18e-5, test_loss=2.25e-5]\u001b[A\n",
      "Epoch 668: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.29it/s, loss=3.24e-07, v_num=23, train_loss=2.19e-5, test_loss=2.28e-5]\u001b[A\n",
      "Epoch 669:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.41it/s, loss=1.89e-07, v_num=23, train_loss=2.19e-5, test_loss=2.28e-5]\u001b[AAdjusting learning rate of group 0 to 1.8692e-03.\n",
      "Epoch 669:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.22it/s, loss=1.79e-07, v_num=23, train_loss=2.19e-5, test_loss=2.28e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 669:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.99it/s, loss=1.79e-07, v_num=23, train_loss=2.19e-5, test_loss=2.28e-5]\u001b[A\n",
      "Epoch 669: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.52it/s, loss=1.79e-07, v_num=23, train_loss=2.52e-5, test_loss=2.6e-5]\u001b[A\n",
      "Epoch 670:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.36it/s, loss=1.62e-07, v_num=23, train_loss=2.52e-5, test_loss=2.6e-5]\u001b[AAdjusting learning rate of group 0 to 1.8645e-03.\n",
      "Epoch 670:  50%|████████████████████                    | 79/158 [00:00<00:00, 136.86it/s, loss=1.57e-07, v_num=23, train_loss=2.52e-5, test_loss=2.6e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 670:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 130.59it/s, loss=1.57e-07, v_num=23, train_loss=2.52e-5, test_loss=2.6e-5]\u001b[A\n",
      "Epoch 670: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.97it/s, loss=1.57e-07, v_num=23, train_loss=2.08e-5, test_loss=2.17e-5]\u001b[A\n",
      "Epoch 671:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.12it/s, loss=2.31e-07, v_num=23, train_loss=2.08e-5, test_loss=2.17e-5]\u001b[AAdjusting learning rate of group 0 to 1.8598e-03.\n",
      "Epoch 671:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.82it/s, loss=2.19e-07, v_num=23, train_loss=2.08e-5, test_loss=2.17e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 671:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.87it/s, loss=2.19e-07, v_num=23, train_loss=2.08e-5, test_loss=2.17e-5]\u001b[A\n",
      "Epoch 671: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.50it/s, loss=2.19e-07, v_num=23, train_loss=1.56e-5, test_loss=1.62e-5]\u001b[A\n",
      "Epoch 672:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.35it/s, loss=1.48e-07, v_num=23, train_loss=1.56e-5, test_loss=1.62e-5]\u001b[AAdjusting learning rate of group 0 to 1.8552e-03.\n",
      "Epoch 672:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.25it/s, loss=1.44e-07, v_num=23, train_loss=1.56e-5, test_loss=1.62e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 672:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.59it/s, loss=1.44e-07, v_num=23, train_loss=1.56e-5, test_loss=1.62e-5]\u001b[A\n",
      "Epoch 672: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.95it/s, loss=1.44e-07, v_num=23, train_loss=1.41e-5, test_loss=1.48e-5]\u001b[A\n",
      "Epoch 673:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.86it/s, loss=1.96e-07, v_num=23, train_loss=1.41e-5, test_loss=1.48e-5]\u001b[AAdjusting learning rate of group 0 to 1.8505e-03.\n",
      "Epoch 673:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.44it/s, loss=1.86e-07, v_num=23, train_loss=1.41e-5, test_loss=1.48e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 673:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.62it/s, loss=1.86e-07, v_num=23, train_loss=1.41e-5, test_loss=1.48e-5]\u001b[A\n",
      "Epoch 673: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.19it/s, loss=1.86e-07, v_num=23, train_loss=2.93e-5, test_loss=2.99e-5]\u001b[A\n",
      "Epoch 674:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.24it/s, loss=2.76e-07, v_num=23, train_loss=2.93e-5, test_loss=2.99e-5]\u001b[AAdjusting learning rate of group 0 to 1.8459e-03.\n",
      "Epoch 674:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.43it/s, loss=2.63e-07, v_num=23, train_loss=2.93e-5, test_loss=2.99e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 674:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.30it/s, loss=2.63e-07, v_num=23, train_loss=2.93e-5, test_loss=2.99e-5]\u001b[A\n",
      "Epoch 674: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.98it/s, loss=2.63e-07, v_num=23, train_loss=4.74e-5, test_loss=4.85e-5]\u001b[A\n",
      "Epoch 675:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.78it/s, loss=1.93e-07, v_num=23, train_loss=4.74e-5, test_loss=4.85e-5]\u001b[AAdjusting learning rate of group 0 to 1.8413e-03.\n",
      "Epoch 675:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.63it/s, loss=1.86e-07, v_num=23, train_loss=4.74e-5, test_loss=4.85e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 675:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.05it/s, loss=1.86e-07, v_num=23, train_loss=4.74e-5, test_loss=4.85e-5]\u001b[A\n",
      "Epoch 675: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.30it/s, loss=1.86e-07, v_num=23, train_loss=1.65e-5, test_loss=1.71e-5]\u001b[A\n",
      "Epoch 676:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.39it/s, loss=1.54e-07, v_num=23, train_loss=1.65e-5, test_loss=1.71e-5]\u001b[AAdjusting learning rate of group 0 to 1.8367e-03.\n",
      "Epoch 676:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.28it/s, loss=1.43e-07, v_num=23, train_loss=1.65e-5, test_loss=1.71e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 676:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.86it/s, loss=1.43e-07, v_num=23, train_loss=1.65e-5, test_loss=1.71e-5]\u001b[A\n",
      "Epoch 676: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 167.56it/s, loss=1.43e-07, v_num=23, train_loss=2e-5, test_loss=2.05e-5]\u001b[A\n",
      "Epoch 677:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 147.57it/s, loss=1.56e-07, v_num=23, train_loss=2e-5, test_loss=2.05e-5]\u001b[AAdjusting learning rate of group 0 to 1.8321e-03.\n",
      "Epoch 677:  50%|█████████████████████                     | 79/158 [00:00<00:00, 136.87it/s, loss=1.52e-07, v_num=23, train_loss=2e-5, test_loss=2.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 677:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 131.84it/s, loss=1.52e-07, v_num=23, train_loss=2e-5, test_loss=2.05e-5]\u001b[A\n",
      "Epoch 677: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.37it/s, loss=1.52e-07, v_num=23, train_loss=1.98e-5, test_loss=2.04e-5]\u001b[A\n",
      "Epoch 678:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.25it/s, loss=2.02e-07, v_num=23, train_loss=1.98e-5, test_loss=2.04e-5]\u001b[AAdjusting learning rate of group 0 to 1.8275e-03.\n",
      "Epoch 678:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.06it/s, loss=1.96e-07, v_num=23, train_loss=1.98e-5, test_loss=2.04e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 678:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.35it/s, loss=1.96e-07, v_num=23, train_loss=1.98e-5, test_loss=2.04e-5]\u001b[A\n",
      "Epoch 678: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.64it/s, loss=1.96e-07, v_num=23, train_loss=1.76e-5, test_loss=1.88e-5]\u001b[A\n",
      "Epoch 679:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.54it/s, loss=1.36e-07, v_num=23, train_loss=1.76e-5, test_loss=1.88e-5]\u001b[AAdjusting learning rate of group 0 to 1.8230e-03.\n",
      "Epoch 679:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.40it/s, loss=1.31e-07, v_num=23, train_loss=1.76e-5, test_loss=1.88e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 679:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.64it/s, loss=1.31e-07, v_num=23, train_loss=1.76e-5, test_loss=1.88e-5]\u001b[A\n",
      "Epoch 679: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.37it/s, loss=1.31e-07, v_num=23, train_loss=1.88e-5, test_loss=1.91e-5]\u001b[A\n",
      "Epoch 680:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.01it/s, loss=2.12e-07, v_num=23, train_loss=1.88e-5, test_loss=1.91e-5]\u001b[AAdjusting learning rate of group 0 to 1.8184e-03.\n",
      "Epoch 680:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.98it/s, loss=2.07e-07, v_num=23, train_loss=1.88e-5, test_loss=1.91e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 680:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.93it/s, loss=2.07e-07, v_num=23, train_loss=1.88e-5, test_loss=1.91e-5]\u001b[A\n",
      "Epoch 680: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 167.26it/s, loss=2.07e-07, v_num=23, train_loss=2e-5, test_loss=2.05e-5]\u001b[A\n",
      "Epoch 681:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 149.08it/s, loss=1.86e-07, v_num=23, train_loss=2e-5, test_loss=2.05e-5]\u001b[AAdjusting learning rate of group 0 to 1.8138e-03.\n",
      "Epoch 681:  50%|█████████████████████                     | 79/158 [00:00<00:00, 140.49it/s, loss=1.78e-07, v_num=23, train_loss=2e-5, test_loss=2.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 681:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 133.22it/s, loss=1.78e-07, v_num=23, train_loss=2e-5, test_loss=2.05e-5]\u001b[A\n",
      "Epoch 681: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.00it/s, loss=1.78e-07, v_num=23, train_loss=1.69e-5, test_loss=1.76e-5]\u001b[A\n",
      "Epoch 682:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.95it/s, loss=2.21e-07, v_num=23, train_loss=1.69e-5, test_loss=1.76e-5]\u001b[AAdjusting learning rate of group 0 to 1.8093e-03.\n",
      "Epoch 682:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.64it/s, loss=2.14e-07, v_num=23, train_loss=1.69e-5, test_loss=1.76e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 682:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.54it/s, loss=2.14e-07, v_num=23, train_loss=1.69e-5, test_loss=1.76e-5]\u001b[A\n",
      "Epoch 682: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.94it/s, loss=2.14e-07, v_num=23, train_loss=2.11e-5, test_loss=2.15e-5]\u001b[A\n",
      "Epoch 683:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.02it/s, loss=1.6e-07, v_num=23, train_loss=2.11e-5, test_loss=2.15e-5]\u001b[AAdjusting learning rate of group 0 to 1.8048e-03.\n",
      "Epoch 683:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.21it/s, loss=1.46e-07, v_num=23, train_loss=2.11e-5, test_loss=2.15e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 683:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.65it/s, loss=1.46e-07, v_num=23, train_loss=2.11e-5, test_loss=2.15e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.47it/s, loss=1.46e-07, v_num=23, train_loss=1.68e-5, test_loss=1.75e-5]\u001b[A\n",
      "Epoch 684:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.98it/s, loss=1.97e-07, v_num=23, train_loss=1.68e-5, test_loss=1.75e-5]\u001b[AAdjusting learning rate of group 0 to 1.8003e-03.\n",
      "Epoch 684:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.33it/s, loss=1.88e-07, v_num=23, train_loss=1.68e-5, test_loss=1.75e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 684:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.39it/s, loss=1.88e-07, v_num=23, train_loss=1.68e-5, test_loss=1.75e-5]\u001b[A\n",
      "Epoch 684: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.96it/s, loss=1.88e-07, v_num=23, train_loss=1.65e-5, test_loss=1.75e-5]\u001b[A\n",
      "Epoch 685:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.11it/s, loss=1.55e-07, v_num=23, train_loss=1.65e-5, test_loss=1.75e-5]\u001b[AAdjusting learning rate of group 0 to 1.7958e-03.\n",
      "Epoch 685:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.28it/s, loss=1.46e-07, v_num=23, train_loss=1.65e-5, test_loss=1.75e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 685:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.44it/s, loss=1.46e-07, v_num=23, train_loss=1.65e-5, test_loss=1.75e-5]\u001b[A\n",
      "Epoch 685: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.10it/s, loss=1.46e-07, v_num=23, train_loss=1.76e-5, test_loss=1.86e-5]\u001b[A\n",
      "Epoch 686:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 146.96it/s, loss=1.69e-07, v_num=23, train_loss=1.76e-5, test_loss=1.86e-5]\u001b[AAdjusting learning rate of group 0 to 1.7913e-03.\n",
      "Epoch 686:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 135.71it/s, loss=1.59e-07, v_num=23, train_loss=1.76e-5, test_loss=1.86e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 686:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.84it/s, loss=1.59e-07, v_num=23, train_loss=1.76e-5, test_loss=1.86e-5]\u001b[A\n",
      "Epoch 686: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.86it/s, loss=1.59e-07, v_num=23, train_loss=1.98e-5, test_loss=2.03e-5]\u001b[A\n",
      "Epoch 687:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.27it/s, loss=2.58e-07, v_num=23, train_loss=1.98e-5, test_loss=2.03e-5]\u001b[AAdjusting learning rate of group 0 to 1.7868e-03.\n",
      "Epoch 687:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.65it/s, loss=2.49e-07, v_num=23, train_loss=1.98e-5, test_loss=2.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 687:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.74it/s, loss=2.49e-07, v_num=23, train_loss=1.98e-5, test_loss=2.03e-5]\u001b[A\n",
      "Epoch 687: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.41it/s, loss=2.49e-07, v_num=23, train_loss=2.76e-5, test_loss=2.82e-5]\u001b[A\n",
      "Epoch 688:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.77it/s, loss=1.45e-07, v_num=23, train_loss=2.76e-5, test_loss=2.82e-5]\u001b[AAdjusting learning rate of group 0 to 1.7823e-03.\n",
      "Epoch 688:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.92it/s, loss=1.37e-07, v_num=23, train_loss=2.76e-5, test_loss=2.82e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 688:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.43it/s, loss=1.37e-07, v_num=23, train_loss=2.76e-5, test_loss=2.82e-5]\u001b[A\n",
      "Epoch 688: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.28it/s, loss=1.37e-07, v_num=23, train_loss=1.92e-5, test_loss=1.98e-5]\u001b[A\n",
      "Epoch 689:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.04it/s, loss=2.07e-07, v_num=23, train_loss=1.92e-5, test_loss=1.98e-5]\u001b[AAdjusting learning rate of group 0 to 1.7779e-03.\n",
      "Epoch 689:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.42it/s, loss=1.98e-07, v_num=23, train_loss=1.92e-5, test_loss=1.98e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 689:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.60it/s, loss=1.98e-07, v_num=23, train_loss=1.92e-5, test_loss=1.98e-5]\u001b[A\n",
      "Epoch 689: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.72it/s, loss=1.98e-07, v_num=23, train_loss=2.35e-5, test_loss=2.41e-5]\u001b[A\n",
      "Epoch 690:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.22it/s, loss=1.86e-07, v_num=23, train_loss=2.35e-5, test_loss=2.41e-5]\u001b[AAdjusting learning rate of group 0 to 1.7734e-03.\n",
      "Epoch 690:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.50it/s, loss=1.72e-07, v_num=23, train_loss=2.35e-5, test_loss=2.41e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 690:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.91it/s, loss=1.72e-07, v_num=23, train_loss=2.35e-5, test_loss=2.41e-5]\u001b[A\n",
      "Epoch 690: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.53it/s, loss=1.72e-07, v_num=23, train_loss=2.38e-5, test_loss=2.41e-5]\u001b[A\n",
      "Epoch 691:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.39it/s, loss=1.48e-07, v_num=23, train_loss=2.38e-5, test_loss=2.41e-5]\u001b[AAdjusting learning rate of group 0 to 1.7690e-03.\n",
      "Epoch 691:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.41it/s, loss=1.44e-07, v_num=23, train_loss=2.38e-5, test_loss=2.41e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 691:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.05it/s, loss=1.44e-07, v_num=23, train_loss=2.38e-5, test_loss=2.41e-5]\u001b[A\n",
      "Epoch 691: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.97it/s, loss=1.44e-07, v_num=23, train_loss=1.46e-5, test_loss=1.52e-5]\u001b[A\n",
      "Epoch 692:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 148.82it/s, loss=2e-07, v_num=23, train_loss=1.46e-5, test_loss=1.52e-5]\u001b[AAdjusting learning rate of group 0 to 1.7646e-03.\n",
      "Epoch 692:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.66it/s, loss=1.81e-07, v_num=23, train_loss=1.46e-5, test_loss=1.52e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 692:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.76it/s, loss=1.81e-07, v_num=23, train_loss=1.46e-5, test_loss=1.52e-5]\u001b[A\n",
      "Epoch 692: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.24it/s, loss=1.81e-07, v_num=23, train_loss=3.07e-5, test_loss=3.15e-5]\u001b[A\n",
      "Epoch 693:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.66it/s, loss=1.56e-07, v_num=23, train_loss=3.07e-5, test_loss=3.15e-5]\u001b[AAdjusting learning rate of group 0 to 1.7602e-03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 693:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.36it/s, loss=1.5e-07, v_num=23, train_loss=3.07e-5, test_loss=3.15e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 693:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 134.44it/s, loss=1.5e-07, v_num=23, train_loss=3.07e-5, test_loss=3.15e-5]\u001b[A\n",
      "Epoch 693: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 170.78it/s, loss=1.5e-07, v_num=23, train_loss=1.7e-5, test_loss=1.75e-5]\u001b[A\n",
      "Epoch 694:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.51it/s, loss=1.44e-07, v_num=23, train_loss=1.7e-5, test_loss=1.75e-5]\u001b[AAdjusting learning rate of group 0 to 1.7558e-03.\n",
      "Epoch 694:  50%|████████████████████                    | 79/158 [00:00<00:00, 136.74it/s, loss=1.37e-07, v_num=23, train_loss=1.7e-5, test_loss=1.75e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 694:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.54it/s, loss=1.37e-07, v_num=23, train_loss=1.7e-5, test_loss=1.75e-5]\u001b[A\n",
      "Epoch 694: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.85it/s, loss=1.37e-07, v_num=23, train_loss=1.35e-5, test_loss=1.44e-5]\u001b[A\n",
      "Epoch 695:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.43it/s, loss=1.56e-07, v_num=23, train_loss=1.35e-5, test_loss=1.44e-5]\u001b[AAdjusting learning rate of group 0 to 1.7514e-03.\n",
      "Epoch 695:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.13it/s, loss=1.48e-07, v_num=23, train_loss=1.35e-5, test_loss=1.44e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 695:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.63it/s, loss=1.48e-07, v_num=23, train_loss=1.35e-5, test_loss=1.44e-5]\u001b[A\n",
      "Epoch 695: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.30it/s, loss=1.48e-07, v_num=23, train_loss=1.55e-5, test_loss=1.61e-5]\u001b[A\n",
      "Epoch 696:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.45it/s, loss=1.3e-07, v_num=23, train_loss=1.55e-5, test_loss=1.61e-5]\u001b[AAdjusting learning rate of group 0 to 1.7470e-03.\n",
      "Epoch 696:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.70it/s, loss=1.26e-07, v_num=23, train_loss=1.55e-5, test_loss=1.61e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 696:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.43it/s, loss=1.26e-07, v_num=23, train_loss=1.55e-5, test_loss=1.61e-5]\u001b[A\n",
      "Epoch 696: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.30it/s, loss=1.26e-07, v_num=23, train_loss=1.35e-5, test_loss=1.4e-5]\u001b[A\n",
      "Epoch 697:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.50it/s, loss=1.85e-07, v_num=23, train_loss=1.35e-5, test_loss=1.4e-5]\u001b[AAdjusting learning rate of group 0 to 1.7426e-03.\n",
      "Epoch 697:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.70it/s, loss=1.79e-07, v_num=23, train_loss=1.35e-5, test_loss=1.4e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 697:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.44it/s, loss=1.79e-07, v_num=23, train_loss=1.35e-5, test_loss=1.4e-5]\u001b[A\n",
      "Epoch 697: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.61it/s, loss=1.79e-07, v_num=23, train_loss=1.59e-5, test_loss=1.69e-5]\u001b[A\n",
      "Epoch 698:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.46it/s, loss=1.73e-07, v_num=23, train_loss=1.59e-5, test_loss=1.69e-5]\u001b[AAdjusting learning rate of group 0 to 1.7383e-03.\n",
      "Epoch 698:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.75it/s, loss=1.63e-07, v_num=23, train_loss=1.59e-5, test_loss=1.69e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 698:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.60it/s, loss=1.63e-07, v_num=23, train_loss=1.59e-5, test_loss=1.69e-5]\u001b[A\n",
      "Epoch 698: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.40it/s, loss=1.63e-07, v_num=23, train_loss=1.72e-5, test_loss=1.78e-5]\u001b[A\n",
      "Epoch 699:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.49it/s, loss=1.85e-07, v_num=23, train_loss=1.72e-5, test_loss=1.78e-5]\u001b[AAdjusting learning rate of group 0 to 1.7339e-03.\n",
      "Epoch 699:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.69it/s, loss=1.76e-07, v_num=23, train_loss=1.72e-5, test_loss=1.78e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 699:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.87it/s, loss=1.76e-07, v_num=23, train_loss=1.72e-5, test_loss=1.78e-5]\u001b[A\n",
      "Epoch 699: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.21it/s, loss=1.76e-07, v_num=23, train_loss=3.08e-5, test_loss=3.16e-5]\u001b[A\n",
      "Epoch 700:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.04it/s, loss=1.7e-07, v_num=23, train_loss=3.08e-5, test_loss=3.16e-5]\u001b[AAdjusting learning rate of group 0 to 1.7296e-03.\n",
      "Epoch 700:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.14it/s, loss=1.67e-07, v_num=23, train_loss=3.08e-5, test_loss=3.16e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 700:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.22it/s, loss=1.67e-07, v_num=23, train_loss=3.08e-5, test_loss=3.16e-5]\u001b[A\n",
      "Epoch 700: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 167.24it/s, loss=1.67e-07, v_num=23, train_loss=2.2e-5, test_loss=2.3e-5]\u001b[A\n",
      "Epoch 701:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.41it/s, loss=2.05e-07, v_num=23, train_loss=2.2e-5, test_loss=2.3e-5]\u001b[AAdjusting learning rate of group 0 to 1.7253e-03.\n",
      "Epoch 701:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 136.98it/s, loss=2.01e-07, v_num=23, train_loss=2.2e-5, test_loss=2.3e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 701:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 131.58it/s, loss=2.01e-07, v_num=23, train_loss=2.2e-5, test_loss=2.3e-5]\u001b[A\n",
      "Epoch 701: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.52it/s, loss=2.01e-07, v_num=23, train_loss=1.97e-5, test_loss=2.05e-5]\u001b[A\n",
      "Epoch 702:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.56it/s, loss=1.94e-07, v_num=23, train_loss=1.97e-5, test_loss=2.05e-5]\u001b[AAdjusting learning rate of group 0 to 1.7210e-03.\n",
      "Epoch 702:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.33it/s, loss=1.87e-07, v_num=23, train_loss=1.97e-5, test_loss=2.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 702:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.24it/s, loss=1.87e-07, v_num=23, train_loss=1.97e-5, test_loss=2.05e-5]\u001b[A\n",
      "Epoch 702: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.33it/s, loss=1.87e-07, v_num=23, train_loss=2.03e-5, test_loss=2.11e-5]\u001b[A\n",
      "Epoch 703:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.93it/s, loss=2.58e-07, v_num=23, train_loss=2.03e-5, test_loss=2.11e-5]\u001b[AAdjusting learning rate of group 0 to 1.7167e-03.\n",
      "Epoch 703:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.13it/s, loss=2.52e-07, v_num=23, train_loss=2.03e-5, test_loss=2.11e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 703:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.48it/s, loss=2.52e-07, v_num=23, train_loss=2.03e-5, test_loss=2.11e-5]\u001b[A\n",
      "Epoch 703: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.79it/s, loss=2.52e-07, v_num=23, train_loss=2.66e-5, test_loss=2.71e-5]\u001b[A\n",
      "Epoch 704:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.09it/s, loss=2.07e-07, v_num=23, train_loss=2.66e-5, test_loss=2.71e-5]\u001b[AAdjusting learning rate of group 0 to 1.7124e-03.\n",
      "Epoch 704:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.15it/s, loss=1.98e-07, v_num=23, train_loss=2.66e-5, test_loss=2.71e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 704:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.14it/s, loss=1.98e-07, v_num=23, train_loss=2.66e-5, test_loss=2.71e-5]\u001b[A\n",
      "Epoch 704: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.79it/s, loss=1.98e-07, v_num=23, train_loss=1.66e-5, test_loss=1.74e-5]\u001b[A\n",
      "Epoch 705:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.13it/s, loss=1.84e-07, v_num=23, train_loss=1.66e-5, test_loss=1.74e-5]\u001b[AAdjusting learning rate of group 0 to 1.7081e-03.\n",
      "Epoch 705:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.57it/s, loss=1.72e-07, v_num=23, train_loss=1.66e-5, test_loss=1.74e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 705:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.55it/s, loss=1.72e-07, v_num=23, train_loss=1.66e-5, test_loss=1.74e-5]\u001b[A\n",
      "Epoch 705: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.75it/s, loss=1.72e-07, v_num=23, train_loss=1.48e-5, test_loss=1.54e-5]\u001b[A\n",
      "Epoch 706:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.02it/s, loss=3.53e-07, v_num=23, train_loss=1.48e-5, test_loss=1.54e-5]\u001b[AAdjusting learning rate of group 0 to 1.7038e-03.\n",
      "Epoch 706:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.43it/s, loss=3.48e-07, v_num=23, train_loss=1.48e-5, test_loss=1.54e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 706:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.70it/s, loss=3.48e-07, v_num=23, train_loss=1.48e-5, test_loss=1.54e-5]\u001b[A\n",
      "Epoch 706: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.11it/s, loss=3.48e-07, v_num=23, train_loss=3.7e-5, test_loss=3.83e-5]\u001b[A\n",
      "Epoch 707:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.03it/s, loss=1.85e-07, v_num=23, train_loss=3.7e-5, test_loss=3.83e-5]\u001b[AAdjusting learning rate of group 0 to 1.6996e-03.\n",
      "Epoch 707:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.88it/s, loss=1.75e-07, v_num=23, train_loss=3.7e-5, test_loss=3.83e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 707:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 134.19it/s, loss=1.75e-07, v_num=23, train_loss=3.7e-5, test_loss=3.83e-5]\u001b[A\n",
      "Epoch 707: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.67it/s, loss=1.75e-07, v_num=23, train_loss=2.16e-5, test_loss=2.23e-5]\u001b[A\n",
      "Epoch 708:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.71it/s, loss=1.35e-07, v_num=23, train_loss=2.16e-5, test_loss=2.23e-5]\u001b[AAdjusting learning rate of group 0 to 1.6953e-03.\n",
      "Epoch 708:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.75it/s, loss=1.3e-07, v_num=23, train_loss=2.16e-5, test_loss=2.23e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 708:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.45it/s, loss=1.3e-07, v_num=23, train_loss=2.16e-5, test_loss=2.23e-5]\u001b[A\n",
      "Epoch 708: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.49it/s, loss=1.3e-07, v_num=23, train_loss=1.45e-5, test_loss=1.48e-5]\u001b[A\n",
      "Epoch 709:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.40it/s, loss=2.13e-07, v_num=23, train_loss=1.45e-5, test_loss=1.48e-5]\u001b[AAdjusting learning rate of group 0 to 1.6911e-03.\n",
      "Epoch 709:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.21it/s, loss=2.09e-07, v_num=23, train_loss=1.45e-5, test_loss=1.48e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 709:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.24it/s, loss=2.09e-07, v_num=23, train_loss=1.45e-5, test_loss=1.48e-5]\u001b[A\n",
      "Epoch 709: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.59it/s, loss=2.09e-07, v_num=23, train_loss=2.31e-5, test_loss=2.32e-5]\u001b[A\n",
      "Epoch 710:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.20it/s, loss=1.45e-07, v_num=23, train_loss=2.31e-5, test_loss=2.32e-5]\u001b[AAdjusting learning rate of group 0 to 1.6868e-03.\n",
      "Epoch 710:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.93it/s, loss=1.37e-07, v_num=23, train_loss=2.31e-5, test_loss=2.32e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 710:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.28it/s, loss=1.37e-07, v_num=23, train_loss=2.31e-5, test_loss=2.32e-5]\u001b[A\n",
      "Epoch 710: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.71it/s, loss=1.37e-07, v_num=23, train_loss=1.49e-5, test_loss=1.58e-5]\u001b[A\n",
      "Epoch 711:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.34it/s, loss=1.47e-07, v_num=23, train_loss=1.49e-5, test_loss=1.58e-5]\u001b[AAdjusting learning rate of group 0 to 1.6826e-03.\n",
      "Epoch 711:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.38it/s, loss=1.4e-07, v_num=23, train_loss=1.49e-5, test_loss=1.58e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 711:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.88it/s, loss=1.4e-07, v_num=23, train_loss=1.49e-5, test_loss=1.58e-5]\u001b[A\n",
      "Epoch 711: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.65it/s, loss=1.4e-07, v_num=23, train_loss=1.36e-5, test_loss=1.44e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 712:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.99it/s, loss=1.38e-07, v_num=23, train_loss=1.36e-5, test_loss=1.44e-5]\u001b[AAdjusting learning rate of group 0 to 1.6784e-03.\n",
      "Epoch 712:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.18it/s, loss=1.3e-07, v_num=23, train_loss=1.36e-5, test_loss=1.44e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 712:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.27it/s, loss=1.3e-07, v_num=23, train_loss=1.36e-5, test_loss=1.44e-5]\u001b[A\n",
      "Epoch 712: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.53it/s, loss=1.3e-07, v_num=23, train_loss=1.33e-5, test_loss=1.42e-5]\u001b[A\n",
      "Epoch 713:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.89it/s, loss=2.01e-07, v_num=23, train_loss=1.33e-5, test_loss=1.42e-5]\u001b[AAdjusting learning rate of group 0 to 1.6742e-03.\n",
      "Epoch 713:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.45it/s, loss=1.96e-07, v_num=23, train_loss=1.33e-5, test_loss=1.42e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 713:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.67it/s, loss=1.96e-07, v_num=23, train_loss=1.33e-5, test_loss=1.42e-5]\u001b[A\n",
      "Epoch 713: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.43it/s, loss=1.96e-07, v_num=23, train_loss=1.89e-5, test_loss=2.03e-5]\u001b[A\n",
      "Epoch 714:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.16it/s, loss=2.08e-07, v_num=23, train_loss=1.89e-5, test_loss=2.03e-5]\u001b[AAdjusting learning rate of group 0 to 1.6700e-03.\n",
      "Epoch 714:  50%|█████████████████████                     | 79/158 [00:00<00:00, 138.97it/s, loss=2e-07, v_num=23, train_loss=1.89e-5, test_loss=2.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 714:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 131.37it/s, loss=2e-07, v_num=23, train_loss=1.89e-5, test_loss=2.03e-5]\u001b[A\n",
      "Epoch 714: 100%|██████████████████████████████████████████| 158/158 [00:00<00:00, 168.27it/s, loss=2e-07, v_num=23, train_loss=2.01e-5, test_loss=2.1e-5]\u001b[A\n",
      "Epoch 715:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.76it/s, loss=2.13e-07, v_num=23, train_loss=2.01e-5, test_loss=2.1e-5]\u001b[AAdjusting learning rate of group 0 to 1.6659e-03.\n",
      "Epoch 715:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.51it/s, loss=2.02e-07, v_num=23, train_loss=2.01e-5, test_loss=2.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 715:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.43it/s, loss=2.02e-07, v_num=23, train_loss=2.01e-5, test_loss=2.1e-5]\u001b[A\n",
      "Epoch 715: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.73it/s, loss=2.02e-07, v_num=23, train_loss=1.92e-5, test_loss=2.01e-5]\u001b[A\n",
      "Epoch 716:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.05it/s, loss=1.63e-07, v_num=23, train_loss=1.92e-5, test_loss=2.01e-5]\u001b[AAdjusting learning rate of group 0 to 1.6617e-03.\n",
      "Epoch 716:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.44it/s, loss=1.55e-07, v_num=23, train_loss=1.92e-5, test_loss=2.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 716:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.87it/s, loss=1.55e-07, v_num=23, train_loss=1.92e-5, test_loss=2.01e-5]\u001b[A\n",
      "Epoch 716: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.32it/s, loss=1.55e-07, v_num=23, train_loss=1.38e-5, test_loss=1.45e-5]\u001b[A\n",
      "Epoch 717:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.73it/s, loss=2.4e-07, v_num=23, train_loss=1.38e-5, test_loss=1.45e-5]\u001b[AAdjusting learning rate of group 0 to 1.6575e-03.\n",
      "Epoch 717:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.02it/s, loss=2.34e-07, v_num=23, train_loss=1.38e-5, test_loss=1.45e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 717:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.58it/s, loss=2.34e-07, v_num=23, train_loss=1.38e-5, test_loss=1.45e-5]\u001b[A\n",
      "Epoch 717: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.15it/s, loss=2.34e-07, v_num=23, train_loss=1.85e-5, test_loss=1.96e-5]\u001b[A\n",
      "Epoch 718:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.35it/s, loss=1.69e-07, v_num=23, train_loss=1.85e-5, test_loss=1.96e-5]\u001b[AAdjusting learning rate of group 0 to 1.6534e-03.\n",
      "Epoch 718:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.62it/s, loss=1.62e-07, v_num=23, train_loss=1.85e-5, test_loss=1.96e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 718:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.82it/s, loss=1.62e-07, v_num=23, train_loss=1.85e-5, test_loss=1.96e-5]\u001b[A\n",
      "Epoch 718: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.17it/s, loss=1.62e-07, v_num=23, train_loss=2.36e-5, test_loss=2.42e-5]\u001b[A\n",
      "Epoch 719:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.76it/s, loss=1.85e-07, v_num=23, train_loss=2.36e-5, test_loss=2.42e-5]\u001b[AAdjusting learning rate of group 0 to 1.6493e-03.\n",
      "Epoch 719:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.75it/s, loss=1.81e-07, v_num=23, train_loss=2.36e-5, test_loss=2.42e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 719:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.25it/s, loss=1.81e-07, v_num=23, train_loss=2.36e-5, test_loss=2.42e-5]\u001b[A\n",
      "Epoch 719: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.04it/s, loss=1.81e-07, v_num=23, train_loss=3.15e-5, test_loss=3.17e-5]\u001b[A\n",
      "Epoch 720:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 146.46it/s, loss=1.7e-07, v_num=23, train_loss=3.15e-5, test_loss=3.17e-5]\u001b[AAdjusting learning rate of group 0 to 1.6451e-03.\n",
      "Epoch 720:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.50it/s, loss=1.59e-07, v_num=23, train_loss=3.15e-5, test_loss=3.17e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 720:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.75it/s, loss=1.59e-07, v_num=23, train_loss=3.15e-5, test_loss=3.17e-5]\u001b[A\n",
      "Epoch 720: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.11it/s, loss=1.59e-07, v_num=23, train_loss=2.53e-5, test_loss=2.61e-5]\u001b[A\n",
      "Epoch 721:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.75it/s, loss=1.52e-07, v_num=23, train_loss=2.53e-5, test_loss=2.61e-5]\u001b[AAdjusting learning rate of group 0 to 1.6410e-03.\n",
      "Epoch 721:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.87it/s, loss=1.45e-07, v_num=23, train_loss=2.53e-5, test_loss=2.61e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 721:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.21it/s, loss=1.45e-07, v_num=23, train_loss=2.53e-5, test_loss=2.61e-5]\u001b[A\n",
      "Epoch 721: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.84it/s, loss=1.45e-07, v_num=23, train_loss=2.42e-5, test_loss=2.43e-5]\u001b[A\n",
      "Epoch 722:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.58it/s, loss=1.86e-07, v_num=23, train_loss=2.42e-5, test_loss=2.43e-5]\u001b[AAdjusting learning rate of group 0 to 1.6369e-03.\n",
      "Epoch 722:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.70it/s, loss=1.74e-07, v_num=23, train_loss=2.42e-5, test_loss=2.43e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 722:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.42it/s, loss=1.74e-07, v_num=23, train_loss=2.42e-5, test_loss=2.43e-5]\u001b[A\n",
      "Epoch 722: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.43it/s, loss=1.74e-07, v_num=23, train_loss=2.39e-5, test_loss=2.43e-5]\u001b[A\n",
      "Epoch 723:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.11it/s, loss=1.57e-07, v_num=23, train_loss=2.39e-5, test_loss=2.43e-5]\u001b[AAdjusting learning rate of group 0 to 1.6328e-03.\n",
      "Epoch 723:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.02it/s, loss=1.53e-07, v_num=23, train_loss=2.39e-5, test_loss=2.43e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 723:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.62it/s, loss=1.53e-07, v_num=23, train_loss=2.39e-5, test_loss=2.43e-5]\u001b[A\n",
      "Epoch 723: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.19it/s, loss=1.53e-07, v_num=23, train_loss=1.67e-5, test_loss=1.72e-5]\u001b[A\n",
      "Epoch 724:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.08it/s, loss=1.48e-07, v_num=23, train_loss=1.67e-5, test_loss=1.72e-5]\u001b[AAdjusting learning rate of group 0 to 1.6288e-03.\n",
      "Epoch 724:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.85it/s, loss=1.42e-07, v_num=23, train_loss=1.67e-5, test_loss=1.72e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 724:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.68it/s, loss=1.42e-07, v_num=23, train_loss=1.67e-5, test_loss=1.72e-5]\u001b[A\n",
      "Epoch 724: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.06it/s, loss=1.42e-07, v_num=23, train_loss=1.69e-5, test_loss=1.73e-5]\u001b[A\n",
      "Epoch 725:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.92it/s, loss=1.43e-07, v_num=23, train_loss=1.69e-5, test_loss=1.73e-5]\u001b[AAdjusting learning rate of group 0 to 1.6247e-03.\n",
      "Epoch 725:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.73it/s, loss=1.34e-07, v_num=23, train_loss=1.69e-5, test_loss=1.73e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 725:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.00it/s, loss=1.34e-07, v_num=23, train_loss=1.69e-5, test_loss=1.73e-5]\u001b[A\n",
      "Epoch 725: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.07it/s, loss=1.34e-07, v_num=23, train_loss=1.37e-5, test_loss=1.44e-5]\u001b[A\n",
      "Epoch 726:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 146.46it/s, loss=1.65e-07, v_num=23, train_loss=1.37e-5, test_loss=1.44e-5]\u001b[AAdjusting learning rate of group 0 to 1.6206e-03.\n",
      "Epoch 726:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.23it/s, loss=1.55e-07, v_num=23, train_loss=1.37e-5, test_loss=1.44e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 726:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.90it/s, loss=1.55e-07, v_num=23, train_loss=1.37e-5, test_loss=1.44e-5]\u001b[A\n",
      "Epoch 726: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 165.95it/s, loss=1.55e-07, v_num=23, train_loss=1.4e-5, test_loss=1.46e-5]\u001b[A\n",
      "Epoch 727:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.75it/s, loss=1.78e-07, v_num=23, train_loss=1.4e-5, test_loss=1.46e-5]\u001b[AAdjusting learning rate of group 0 to 1.6166e-03.\n",
      "Epoch 727:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.00it/s, loss=1.72e-07, v_num=23, train_loss=1.4e-5, test_loss=1.46e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 727:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.48it/s, loss=1.72e-07, v_num=23, train_loss=1.4e-5, test_loss=1.46e-5]\u001b[A\n",
      "Epoch 727: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.30it/s, loss=1.72e-07, v_num=23, train_loss=3.39e-5, test_loss=3.47e-5]\u001b[A\n",
      "Epoch 728:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.19it/s, loss=1.99e-07, v_num=23, train_loss=3.39e-5, test_loss=3.47e-5]\u001b[AAdjusting learning rate of group 0 to 1.6125e-03.\n",
      "Epoch 728:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.64it/s, loss=1.93e-07, v_num=23, train_loss=3.39e-5, test_loss=3.47e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 728:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.63it/s, loss=1.93e-07, v_num=23, train_loss=3.39e-5, test_loss=3.47e-5]\u001b[A\n",
      "Epoch 728: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 164.41it/s, loss=1.93e-07, v_num=23, train_loss=1.56e-5, test_loss=1.6e-5]\u001b[A\n",
      "Epoch 729:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.37it/s, loss=1.21e-07, v_num=23, train_loss=1.56e-5, test_loss=1.6e-5]\u001b[AAdjusting learning rate of group 0 to 1.6085e-03.\n",
      "Epoch 729:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.62it/s, loss=1.15e-07, v_num=23, train_loss=1.56e-5, test_loss=1.6e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 729:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.09it/s, loss=1.15e-07, v_num=23, train_loss=1.56e-5, test_loss=1.6e-5]\u001b[A\n",
      "Epoch 729: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.11it/s, loss=1.15e-07, v_num=23, train_loss=1.77e-5, test_loss=1.79e-5]\u001b[A\n",
      "Epoch 730:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.62it/s, loss=1.64e-07, v_num=23, train_loss=1.77e-5, test_loss=1.79e-5]\u001b[AAdjusting learning rate of group 0 to 1.6045e-03.\n",
      "Epoch 730:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.12it/s, loss=1.58e-07, v_num=23, train_loss=1.77e-5, test_loss=1.79e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 730:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.07it/s, loss=1.58e-07, v_num=23, train_loss=1.77e-5, test_loss=1.79e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 730: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.38it/s, loss=1.58e-07, v_num=23, train_loss=2.06e-5, test_loss=2.1e-5]\u001b[A\n",
      "Epoch 731:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.29it/s, loss=1.3e-07, v_num=23, train_loss=2.06e-5, test_loss=2.1e-5]\u001b[AAdjusting learning rate of group 0 to 1.6005e-03.\n",
      "Epoch 731:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.28it/s, loss=1.24e-07, v_num=23, train_loss=2.06e-5, test_loss=2.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 731:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.79it/s, loss=1.24e-07, v_num=23, train_loss=2.06e-5, test_loss=2.1e-5]\u001b[A\n",
      "Epoch 731: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.70it/s, loss=1.24e-07, v_num=23, train_loss=2.01e-5, test_loss=2.1e-5]\u001b[A\n",
      "Epoch 732:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.98it/s, loss=1.92e-07, v_num=23, train_loss=2.01e-5, test_loss=2.1e-5]\u001b[AAdjusting learning rate of group 0 to 1.5965e-03.\n",
      "Epoch 732:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.15it/s, loss=1.81e-07, v_num=23, train_loss=2.01e-5, test_loss=2.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 732:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.97it/s, loss=1.81e-07, v_num=23, train_loss=2.01e-5, test_loss=2.1e-5]\u001b[A\n",
      "Epoch 732: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.06it/s, loss=1.81e-07, v_num=23, train_loss=2.41e-5, test_loss=2.5e-5]\u001b[A\n",
      "Epoch 733:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.98it/s, loss=2.02e-07, v_num=23, train_loss=2.41e-5, test_loss=2.5e-5]\u001b[AAdjusting learning rate of group 0 to 1.5925e-03.\n",
      "Epoch 733:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.99it/s, loss=1.91e-07, v_num=23, train_loss=2.41e-5, test_loss=2.5e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 733:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.94it/s, loss=1.91e-07, v_num=23, train_loss=2.41e-5, test_loss=2.5e-5]\u001b[A\n",
      "Epoch 733: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.73it/s, loss=1.91e-07, v_num=23, train_loss=1.52e-5, test_loss=1.59e-5]\u001b[A\n",
      "Epoch 734:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.41it/s, loss=1.38e-07, v_num=23, train_loss=1.52e-5, test_loss=1.59e-5]\u001b[AAdjusting learning rate of group 0 to 1.5885e-03.\n",
      "Epoch 734:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.60it/s, loss=1.31e-07, v_num=23, train_loss=1.52e-5, test_loss=1.59e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 734:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.84it/s, loss=1.31e-07, v_num=23, train_loss=1.52e-5, test_loss=1.59e-5]\u001b[A\n",
      "Epoch 734: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.07it/s, loss=1.31e-07, v_num=23, train_loss=1.28e-5, test_loss=1.36e-5]\u001b[A\n",
      "Epoch 735:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.00it/s, loss=1.35e-07, v_num=23, train_loss=1.28e-5, test_loss=1.36e-5]\u001b[AAdjusting learning rate of group 0 to 1.5845e-03.\n",
      "Epoch 735:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.70it/s, loss=1.31e-07, v_num=23, train_loss=1.28e-5, test_loss=1.36e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 735:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.33it/s, loss=1.31e-07, v_num=23, train_loss=1.28e-5, test_loss=1.36e-5]\u001b[A\n",
      "Epoch 735: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.85it/s, loss=1.31e-07, v_num=23, train_loss=1.09e-5, test_loss=1.15e-5]\u001b[A\n",
      "Epoch 736:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.56it/s, loss=1.23e-07, v_num=23, train_loss=1.09e-5, test_loss=1.15e-5]\u001b[AAdjusting learning rate of group 0 to 1.5806e-03.\n",
      "Epoch 736:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.80it/s, loss=1.16e-07, v_num=23, train_loss=1.09e-5, test_loss=1.15e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 736:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.87it/s, loss=1.16e-07, v_num=23, train_loss=1.09e-5, test_loss=1.15e-5]\u001b[A\n",
      "Epoch 736: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.73it/s, loss=1.16e-07, v_num=23, train_loss=1.4e-5, test_loss=1.44e-5]\u001b[A\n",
      "Epoch 737:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.62it/s, loss=1.68e-07, v_num=23, train_loss=1.4e-5, test_loss=1.44e-5]\u001b[AAdjusting learning rate of group 0 to 1.5766e-03.\n",
      "Epoch 737:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.04it/s, loss=1.63e-07, v_num=23, train_loss=1.4e-5, test_loss=1.44e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 737:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.23it/s, loss=1.63e-07, v_num=23, train_loss=1.4e-5, test_loss=1.44e-5]\u001b[A\n",
      "Epoch 737: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.29it/s, loss=1.63e-07, v_num=23, train_loss=1.39e-5, test_loss=1.49e-5]\u001b[A\n",
      "Epoch 738:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.82it/s, loss=1.7e-07, v_num=23, train_loss=1.39e-5, test_loss=1.49e-5]\u001b[AAdjusting learning rate of group 0 to 1.5727e-03.\n",
      "Epoch 738:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.16it/s, loss=1.62e-07, v_num=23, train_loss=1.39e-5, test_loss=1.49e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 738:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.73it/s, loss=1.62e-07, v_num=23, train_loss=1.39e-5, test_loss=1.49e-5]\u001b[A\n",
      "Epoch 738: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.50it/s, loss=1.62e-07, v_num=23, train_loss=1.68e-5, test_loss=1.73e-5]\u001b[A\n",
      "Epoch 739:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.67it/s, loss=1.52e-07, v_num=23, train_loss=1.68e-5, test_loss=1.73e-5]\u001b[AAdjusting learning rate of group 0 to 1.5687e-03.\n",
      "Epoch 739:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.36it/s, loss=1.48e-07, v_num=23, train_loss=1.68e-5, test_loss=1.73e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 739:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.85it/s, loss=1.48e-07, v_num=23, train_loss=1.68e-5, test_loss=1.73e-5]\u001b[A\n",
      "Epoch 739: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.91it/s, loss=1.48e-07, v_num=23, train_loss=2.58e-5, test_loss=2.65e-5]\u001b[A\n",
      "Epoch 740:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.42it/s, loss=1.97e-07, v_num=23, train_loss=2.58e-5, test_loss=2.65e-5]\u001b[AAdjusting learning rate of group 0 to 1.5648e-03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.36it/s, loss=1.89e-07, v_num=23, train_loss=2.58e-5, test_loss=2.65e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 740:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.19it/s, loss=1.89e-07, v_num=23, train_loss=2.58e-5, test_loss=2.65e-5]\u001b[A\n",
      "Epoch 740: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.64it/s, loss=1.89e-07, v_num=23, train_loss=1.94e-5, test_loss=2.08e-5]\u001b[A\n",
      "Epoch 741:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.87it/s, loss=1.48e-07, v_num=23, train_loss=1.94e-5, test_loss=2.08e-5]\u001b[AAdjusting learning rate of group 0 to 1.5609e-03.\n",
      "Epoch 741:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.56it/s, loss=1.43e-07, v_num=23, train_loss=1.94e-5, test_loss=2.08e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 741:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.74it/s, loss=1.43e-07, v_num=23, train_loss=1.94e-5, test_loss=2.08e-5]\u001b[A\n",
      "Epoch 741: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.82it/s, loss=1.43e-07, v_num=23, train_loss=2.79e-5, test_loss=2.88e-5]\u001b[A\n",
      "Epoch 742:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.65it/s, loss=1.43e-07, v_num=23, train_loss=2.79e-5, test_loss=2.88e-5]\u001b[AAdjusting learning rate of group 0 to 1.5570e-03.\n",
      "Epoch 742:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.74it/s, loss=1.39e-07, v_num=23, train_loss=2.79e-5, test_loss=2.88e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 742:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.38it/s, loss=1.39e-07, v_num=23, train_loss=2.79e-5, test_loss=2.88e-5]\u001b[A\n",
      "Epoch 742: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.38it/s, loss=1.39e-07, v_num=23, train_loss=1.68e-5, test_loss=1.77e-5]\u001b[A\n",
      "Epoch 743:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.76it/s, loss=1.23e-07, v_num=23, train_loss=1.68e-5, test_loss=1.77e-5]\u001b[AAdjusting learning rate of group 0 to 1.5531e-03.\n",
      "Epoch 743:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.61it/s, loss=1.19e-07, v_num=23, train_loss=1.68e-5, test_loss=1.77e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 743:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.65it/s, loss=1.19e-07, v_num=23, train_loss=1.68e-5, test_loss=1.77e-5]\u001b[A\n",
      "Epoch 743: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.76it/s, loss=1.19e-07, v_num=23, train_loss=1.62e-5, test_loss=1.67e-5]\u001b[A\n",
      "Epoch 744:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.67it/s, loss=1.45e-07, v_num=23, train_loss=1.62e-5, test_loss=1.67e-5]\u001b[AAdjusting learning rate of group 0 to 1.5492e-03.\n",
      "Epoch 744:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.94it/s, loss=1.42e-07, v_num=23, train_loss=1.62e-5, test_loss=1.67e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 744:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.04it/s, loss=1.42e-07, v_num=23, train_loss=1.62e-5, test_loss=1.67e-5]\u001b[A\n",
      "Epoch 744: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.17it/s, loss=1.42e-07, v_num=23, train_loss=1.33e-5, test_loss=1.38e-5]\u001b[A\n",
      "Epoch 745:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.67it/s, loss=1.54e-07, v_num=23, train_loss=1.33e-5, test_loss=1.38e-5]\u001b[AAdjusting learning rate of group 0 to 1.5453e-03.\n",
      "Epoch 745:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.96it/s, loss=1.48e-07, v_num=23, train_loss=1.33e-5, test_loss=1.38e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 745:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.34it/s, loss=1.48e-07, v_num=23, train_loss=1.33e-5, test_loss=1.38e-5]\u001b[A\n",
      "Epoch 745: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.62it/s, loss=1.48e-07, v_num=23, train_loss=2.46e-5, test_loss=2.55e-5]\u001b[A\n",
      "Epoch 746:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.69it/s, loss=1.76e-07, v_num=23, train_loss=2.46e-5, test_loss=2.55e-5]\u001b[AAdjusting learning rate of group 0 to 1.5415e-03.\n",
      "Epoch 746:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.10it/s, loss=1.65e-07, v_num=23, train_loss=2.46e-5, test_loss=2.55e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 746:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.47it/s, loss=1.65e-07, v_num=23, train_loss=2.46e-5, test_loss=2.55e-5]\u001b[A\n",
      "Epoch 746: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.51it/s, loss=1.65e-07, v_num=23, train_loss=2.29e-5, test_loss=2.38e-5]\u001b[A\n",
      "Epoch 747:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.97it/s, loss=1.69e-07, v_num=23, train_loss=2.29e-5, test_loss=2.38e-5]\u001b[AAdjusting learning rate of group 0 to 1.5376e-03.\n",
      "Epoch 747:  50%|████████████████████                    | 79/158 [00:00<00:00, 142.06it/s, loss=1.6e-07, v_num=23, train_loss=2.29e-5, test_loss=2.38e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 747:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 135.96it/s, loss=1.6e-07, v_num=23, train_loss=2.29e-5, test_loss=2.38e-5]\u001b[A\n",
      "Epoch 747: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 172.32it/s, loss=1.6e-07, v_num=23, train_loss=1.31e-5, test_loss=1.38e-5]\u001b[A\n",
      "Epoch 748:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.78it/s, loss=1.49e-07, v_num=23, train_loss=1.31e-5, test_loss=1.38e-5]\u001b[AAdjusting learning rate of group 0 to 1.5338e-03.\n",
      "Epoch 748:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.29it/s, loss=1.42e-07, v_num=23, train_loss=1.31e-5, test_loss=1.38e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 748:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.35it/s, loss=1.42e-07, v_num=23, train_loss=1.31e-5, test_loss=1.38e-5]\u001b[A\n",
      "Epoch 748: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.55it/s, loss=1.42e-07, v_num=23, train_loss=1.67e-5, test_loss=1.72e-5]\u001b[A\n",
      "Epoch 749:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.64it/s, loss=1.83e-07, v_num=23, train_loss=1.67e-5, test_loss=1.72e-5]\u001b[AAdjusting learning rate of group 0 to 1.5300e-03.\n",
      "Epoch 749:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.32it/s, loss=1.78e-07, v_num=23, train_loss=1.67e-5, test_loss=1.72e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 749:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.85it/s, loss=1.78e-07, v_num=23, train_loss=1.67e-5, test_loss=1.72e-5]\u001b[A\n",
      "Epoch 749: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.92it/s, loss=1.78e-07, v_num=23, train_loss=3.84e-5, test_loss=3.89e-5]\u001b[A\n",
      "Epoch 750:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.93it/s, loss=1.99e-07, v_num=23, train_loss=3.84e-5, test_loss=3.89e-5]\u001b[AAdjusting learning rate of group 0 to 1.5261e-03.\n",
      "Epoch 750:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.67it/s, loss=1.92e-07, v_num=23, train_loss=3.84e-5, test_loss=3.89e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 750:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.06it/s, loss=1.92e-07, v_num=23, train_loss=3.84e-5, test_loss=3.89e-5]\u001b[A\n",
      "Epoch 750: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.20it/s, loss=1.92e-07, v_num=23, train_loss=1.4e-5, test_loss=1.47e-5]\u001b[A\n",
      "Epoch 751:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.00it/s, loss=1.45e-07, v_num=23, train_loss=1.4e-5, test_loss=1.47e-5]\u001b[AAdjusting learning rate of group 0 to 1.5223e-03.\n",
      "Epoch 751:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 138.57it/s, loss=1.4e-07, v_num=23, train_loss=1.4e-5, test_loss=1.47e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 751:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 131.88it/s, loss=1.4e-07, v_num=23, train_loss=1.4e-5, test_loss=1.47e-5]\u001b[A\n",
      "Epoch 751: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.62it/s, loss=1.4e-07, v_num=23, train_loss=1.93e-5, test_loss=1.99e-5]\u001b[A\n",
      "Epoch 752:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.11it/s, loss=1.35e-07, v_num=23, train_loss=1.93e-5, test_loss=1.99e-5]\u001b[AAdjusting learning rate of group 0 to 1.5185e-03.\n",
      "Epoch 752:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.49it/s, loss=1.31e-07, v_num=23, train_loss=1.93e-5, test_loss=1.99e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 752:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.39it/s, loss=1.31e-07, v_num=23, train_loss=1.93e-5, test_loss=1.99e-5]\u001b[A\n",
      "Epoch 752: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.37it/s, loss=1.31e-07, v_num=23, train_loss=1.55e-5, test_loss=1.59e-5]\u001b[A\n",
      "Epoch 753:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.27it/s, loss=1.83e-07, v_num=23, train_loss=1.55e-5, test_loss=1.59e-5]\u001b[AAdjusting learning rate of group 0 to 1.5147e-03.\n",
      "Epoch 753:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.35it/s, loss=1.77e-07, v_num=23, train_loss=1.55e-5, test_loss=1.59e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 753:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.52it/s, loss=1.77e-07, v_num=23, train_loss=1.55e-5, test_loss=1.59e-5]\u001b[A\n",
      "Epoch 753: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.28it/s, loss=1.77e-07, v_num=23, train_loss=1.54e-5, test_loss=1.66e-5]\u001b[A\n",
      "Epoch 754:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.20it/s, loss=1.34e-07, v_num=23, train_loss=1.54e-5, test_loss=1.66e-5]\u001b[AAdjusting learning rate of group 0 to 1.5109e-03.\n",
      "Epoch 754:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.97it/s, loss=1.27e-07, v_num=23, train_loss=1.54e-5, test_loss=1.66e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 754:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.05it/s, loss=1.27e-07, v_num=23, train_loss=1.54e-5, test_loss=1.66e-5]\u001b[A\n",
      "Epoch 754: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 163.77it/s, loss=1.27e-07, v_num=23, train_loss=1.54e-5, test_loss=1.62e-5]\u001b[A\n",
      "Epoch 755:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.83it/s, loss=1.37e-07, v_num=23, train_loss=1.54e-5, test_loss=1.62e-5]\u001b[AAdjusting learning rate of group 0 to 1.5071e-03.\n",
      "Epoch 755:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.07it/s, loss=1.34e-07, v_num=23, train_loss=1.54e-5, test_loss=1.62e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 755:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.75it/s, loss=1.34e-07, v_num=23, train_loss=1.54e-5, test_loss=1.62e-5]\u001b[A\n",
      "Epoch 755: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.88it/s, loss=1.34e-07, v_num=23, train_loss=1.55e-5, test_loss=1.59e-5]\u001b[A\n",
      "Epoch 756:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.47it/s, loss=1.32e-07, v_num=23, train_loss=1.55e-5, test_loss=1.59e-5]\u001b[AAdjusting learning rate of group 0 to 1.5034e-03.\n",
      "Epoch 756:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.19it/s, loss=1.23e-07, v_num=23, train_loss=1.55e-5, test_loss=1.59e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 756:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.98it/s, loss=1.23e-07, v_num=23, train_loss=1.55e-5, test_loss=1.59e-5]\u001b[A\n",
      "Epoch 756: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.55it/s, loss=1.23e-07, v_num=23, train_loss=1.36e-5, test_loss=1.39e-5]\u001b[A\n",
      "Epoch 757:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.25it/s, loss=1.3e-07, v_num=23, train_loss=1.36e-5, test_loss=1.39e-5]\u001b[AAdjusting learning rate of group 0 to 1.4996e-03.\n",
      "Epoch 757:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.20it/s, loss=1.28e-07, v_num=23, train_loss=1.36e-5, test_loss=1.39e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 757:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.06it/s, loss=1.28e-07, v_num=23, train_loss=1.36e-5, test_loss=1.39e-5]\u001b[A\n",
      "Epoch 757: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.09it/s, loss=1.28e-07, v_num=23, train_loss=1.49e-5, test_loss=1.55e-5]\u001b[A\n",
      "Epoch 758:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.95it/s, loss=1.69e-07, v_num=23, train_loss=1.49e-5, test_loss=1.55e-5]\u001b[AAdjusting learning rate of group 0 to 1.4959e-03.\n",
      "Epoch 758:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.17it/s, loss=1.61e-07, v_num=23, train_loss=1.49e-5, test_loss=1.55e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 758:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.23it/s, loss=1.61e-07, v_num=23, train_loss=1.49e-5, test_loss=1.55e-5]\u001b[A\n",
      "Epoch 758: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.84it/s, loss=1.61e-07, v_num=23, train_loss=2.02e-5, test_loss=2.07e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 759:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.68it/s, loss=1.39e-07, v_num=23, train_loss=2.02e-5, test_loss=2.07e-5]\u001b[AAdjusting learning rate of group 0 to 1.4921e-03.\n",
      "Epoch 759:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.80it/s, loss=1.31e-07, v_num=23, train_loss=2.02e-5, test_loss=2.07e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 759:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.41it/s, loss=1.31e-07, v_num=23, train_loss=2.02e-5, test_loss=2.07e-5]\u001b[A\n",
      "Epoch 759: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 171.95it/s, loss=1.31e-07, v_num=23, train_loss=1.56e-5, test_loss=1.6e-5]\u001b[A\n",
      "Epoch 760:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.56it/s, loss=1.63e-07, v_num=23, train_loss=1.56e-5, test_loss=1.6e-5]\u001b[AAdjusting learning rate of group 0 to 1.4884e-03.\n",
      "Epoch 760:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.78it/s, loss=1.57e-07, v_num=23, train_loss=1.56e-5, test_loss=1.6e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 760:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.46it/s, loss=1.57e-07, v_num=23, train_loss=1.56e-5, test_loss=1.6e-5]\u001b[A\n",
      "Epoch 760: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.27it/s, loss=1.57e-07, v_num=23, train_loss=1.77e-5, test_loss=1.78e-5]\u001b[A\n",
      "Epoch 761:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.40it/s, loss=2.14e-07, v_num=23, train_loss=1.77e-5, test_loss=1.78e-5]\u001b[AAdjusting learning rate of group 0 to 1.4847e-03.\n",
      "Epoch 761:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.14it/s, loss=2.04e-07, v_num=23, train_loss=1.77e-5, test_loss=1.78e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 761:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.95it/s, loss=2.04e-07, v_num=23, train_loss=1.77e-5, test_loss=1.78e-5]\u001b[A\n",
      "Epoch 761: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 165.51it/s, loss=2.04e-07, v_num=23, train_loss=2.51e-5, test_loss=2.6e-5]\u001b[A\n",
      "Epoch 762:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.77it/s, loss=1.64e-07, v_num=23, train_loss=2.51e-5, test_loss=2.6e-5]\u001b[AAdjusting learning rate of group 0 to 1.4810e-03.\n",
      "Epoch 762:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.46it/s, loss=1.61e-07, v_num=23, train_loss=2.51e-5, test_loss=2.6e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 762:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.62it/s, loss=1.61e-07, v_num=23, train_loss=2.51e-5, test_loss=2.6e-5]\u001b[A\n",
      "Epoch 762: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.02it/s, loss=1.61e-07, v_num=23, train_loss=1.27e-5, test_loss=1.33e-5]\u001b[A\n",
      "Epoch 763:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.39it/s, loss=1.61e-07, v_num=23, train_loss=1.27e-5, test_loss=1.33e-5]\u001b[AAdjusting learning rate of group 0 to 1.4773e-03.\n",
      "Epoch 763:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 142.32it/s, loss=1.56e-07, v_num=23, train_loss=1.27e-5, test_loss=1.33e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 763:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.51it/s, loss=1.56e-07, v_num=23, train_loss=1.27e-5, test_loss=1.33e-5]\u001b[A\n",
      "Epoch 763: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.90it/s, loss=1.56e-07, v_num=23, train_loss=1.93e-5, test_loss=1.98e-5]\u001b[A\n",
      "Epoch 764:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.40it/s, loss=1.29e-07, v_num=23, train_loss=1.93e-5, test_loss=1.98e-5]\u001b[AAdjusting learning rate of group 0 to 1.4736e-03.\n",
      "Epoch 764:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 142.25it/s, loss=1.24e-07, v_num=23, train_loss=1.93e-5, test_loss=1.98e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 764:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.69it/s, loss=1.24e-07, v_num=23, train_loss=1.93e-5, test_loss=1.98e-5]\u001b[A\n",
      "Epoch 764: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.78it/s, loss=1.24e-07, v_num=23, train_loss=1.18e-5, test_loss=1.23e-5]\u001b[A\n",
      "Epoch 765:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.63it/s, loss=1.74e-07, v_num=23, train_loss=1.18e-5, test_loss=1.23e-5]\u001b[AAdjusting learning rate of group 0 to 1.4699e-03.\n",
      "Epoch 765:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.62it/s, loss=1.62e-07, v_num=23, train_loss=1.18e-5, test_loss=1.23e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 765:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.99it/s, loss=1.62e-07, v_num=23, train_loss=1.18e-5, test_loss=1.23e-5]\u001b[A\n",
      "Epoch 765: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.06it/s, loss=1.62e-07, v_num=23, train_loss=1.26e-5, test_loss=1.31e-5]\u001b[A\n",
      "Epoch 766:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.20it/s, loss=2.15e-07, v_num=23, train_loss=1.26e-5, test_loss=1.31e-5]\u001b[AAdjusting learning rate of group 0 to 1.4662e-03.\n",
      "Epoch 766:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.18it/s, loss=2.09e-07, v_num=23, train_loss=1.26e-5, test_loss=1.31e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 766:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.07it/s, loss=2.09e-07, v_num=23, train_loss=1.26e-5, test_loss=1.31e-5]\u001b[A\n",
      "Epoch 766: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.39it/s, loss=2.09e-07, v_num=23, train_loss=1.5e-5, test_loss=1.54e-5]\u001b[A\n",
      "Epoch 767:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 150.26it/s, loss=1.67e-07, v_num=23, train_loss=1.5e-5, test_loss=1.54e-5]\u001b[AAdjusting learning rate of group 0 to 1.4625e-03.\n",
      "Epoch 767:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 139.70it/s, loss=1.6e-07, v_num=23, train_loss=1.5e-5, test_loss=1.54e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 767:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 132.17it/s, loss=1.6e-07, v_num=23, train_loss=1.5e-5, test_loss=1.54e-5]\u001b[A\n",
      "Epoch 767: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.68it/s, loss=1.6e-07, v_num=23, train_loss=1.26e-5, test_loss=1.32e-5]\u001b[A\n",
      "Epoch 768:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.74it/s, loss=1.72e-07, v_num=23, train_loss=1.26e-5, test_loss=1.32e-5]\u001b[AAdjusting learning rate of group 0 to 1.4589e-03.\n",
      "Epoch 768:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.87it/s, loss=1.59e-07, v_num=23, train_loss=1.26e-5, test_loss=1.32e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 768:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.75it/s, loss=1.59e-07, v_num=23, train_loss=1.26e-5, test_loss=1.32e-5]\u001b[A\n",
      "Epoch 768: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.70it/s, loss=1.59e-07, v_num=23, train_loss=1.62e-5, test_loss=1.69e-5]\u001b[A\n",
      "Epoch 769:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.93it/s, loss=1.38e-07, v_num=23, train_loss=1.62e-5, test_loss=1.69e-5]\u001b[AAdjusting learning rate of group 0 to 1.4552e-03.\n",
      "Epoch 769:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 142.00it/s, loss=1.31e-07, v_num=23, train_loss=1.62e-5, test_loss=1.69e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 769:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.57it/s, loss=1.31e-07, v_num=23, train_loss=1.62e-5, test_loss=1.69e-5]\u001b[A\n",
      "Epoch 769: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 172.76it/s, loss=1.31e-07, v_num=23, train_loss=1.35e-5, test_loss=1.42e-5]\u001b[A\n",
      "Epoch 770:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.31it/s, loss=1.37e-07, v_num=23, train_loss=1.35e-5, test_loss=1.42e-5]\u001b[AAdjusting learning rate of group 0 to 1.4516e-03.\n",
      "Epoch 770:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.78it/s, loss=1.32e-07, v_num=23, train_loss=1.35e-5, test_loss=1.42e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 770:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.95it/s, loss=1.32e-07, v_num=23, train_loss=1.35e-5, test_loss=1.42e-5]\u001b[A\n",
      "Epoch 770: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.02it/s, loss=1.32e-07, v_num=23, train_loss=2.36e-5, test_loss=2.42e-5]\u001b[A\n",
      "Epoch 771:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.23it/s, loss=1.55e-07, v_num=23, train_loss=2.36e-5, test_loss=2.42e-5]\u001b[AAdjusting learning rate of group 0 to 1.4480e-03.\n",
      "Epoch 771:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.22it/s, loss=1.49e-07, v_num=23, train_loss=2.36e-5, test_loss=2.42e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 771:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.21it/s, loss=1.49e-07, v_num=23, train_loss=2.36e-5, test_loss=2.42e-5]\u001b[A\n",
      "Epoch 771: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.51it/s, loss=1.49e-07, v_num=23, train_loss=1.38e-5, test_loss=1.44e-5]\u001b[A\n",
      "Epoch 772:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.56it/s, loss=1.44e-07, v_num=23, train_loss=1.38e-5, test_loss=1.44e-5]\u001b[AAdjusting learning rate of group 0 to 1.4444e-03.\n",
      "Epoch 772:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.98it/s, loss=1.35e-07, v_num=23, train_loss=1.38e-5, test_loss=1.44e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 772:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 128.94it/s, loss=1.35e-07, v_num=23, train_loss=1.38e-5, test_loss=1.44e-5]\u001b[A\n",
      "Epoch 772: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 163.26it/s, loss=1.35e-07, v_num=23, train_loss=1.7e-5, test_loss=1.77e-5]\u001b[A\n",
      "Epoch 773:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.01it/s, loss=1.89e-07, v_num=23, train_loss=1.7e-5, test_loss=1.77e-5]\u001b[AAdjusting learning rate of group 0 to 1.4407e-03.\n",
      "Epoch 773:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.84it/s, loss=1.81e-07, v_num=23, train_loss=1.7e-5, test_loss=1.77e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 773:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.70it/s, loss=1.81e-07, v_num=23, train_loss=1.7e-5, test_loss=1.77e-5]\u001b[A\n",
      "Epoch 773: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 169.10it/s, loss=1.81e-07, v_num=23, train_loss=1.92e-5, test_loss=2e-5]\u001b[A\n",
      "Epoch 774:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 149.15it/s, loss=1.66e-07, v_num=23, train_loss=1.92e-5, test_loss=2e-5]\u001b[AAdjusting learning rate of group 0 to 1.4371e-03.\n",
      "Epoch 774:  50%|█████████████████████                     | 79/158 [00:00<00:00, 141.23it/s, loss=1.62e-07, v_num=23, train_loss=1.92e-5, test_loss=2e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 774:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 134.27it/s, loss=1.62e-07, v_num=23, train_loss=1.92e-5, test_loss=2e-5]\u001b[A\n",
      "Epoch 774: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.87it/s, loss=1.62e-07, v_num=23, train_loss=1.58e-5, test_loss=1.63e-5]\u001b[A\n",
      "Epoch 775:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.51it/s, loss=1.2e-07, v_num=23, train_loss=1.58e-5, test_loss=1.63e-5]\u001b[AAdjusting learning rate of group 0 to 1.4336e-03.\n",
      "Epoch 775:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.49it/s, loss=1.15e-07, v_num=23, train_loss=1.58e-5, test_loss=1.63e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 775:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.99it/s, loss=1.15e-07, v_num=23, train_loss=1.58e-5, test_loss=1.63e-5]\u001b[A\n",
      "Epoch 775: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.34it/s, loss=1.15e-07, v_num=23, train_loss=1.38e-5, test_loss=1.43e-5]\u001b[A\n",
      "Epoch 776:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.69it/s, loss=1.47e-07, v_num=23, train_loss=1.38e-5, test_loss=1.43e-5]\u001b[AAdjusting learning rate of group 0 to 1.4300e-03.\n",
      "Epoch 776:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.84it/s, loss=1.4e-07, v_num=23, train_loss=1.38e-5, test_loss=1.43e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 776:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 134.54it/s, loss=1.4e-07, v_num=23, train_loss=1.38e-5, test_loss=1.43e-5]\u001b[A\n",
      "Epoch 776: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 171.04it/s, loss=1.4e-07, v_num=23, train_loss=1.9e-5, test_loss=1.96e-5]\u001b[A\n",
      "Epoch 777:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.87it/s, loss=1.9e-07, v_num=23, train_loss=1.9e-5, test_loss=1.96e-5]\u001b[AAdjusting learning rate of group 0 to 1.4264e-03.\n",
      "Epoch 777:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.11it/s, loss=1.82e-07, v_num=23, train_loss=1.9e-5, test_loss=1.96e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 777:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.79it/s, loss=1.82e-07, v_num=23, train_loss=1.9e-5, test_loss=1.96e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 777: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.44it/s, loss=1.82e-07, v_num=23, train_loss=1.23e-5, test_loss=1.29e-5]\u001b[A\n",
      "Epoch 778:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.31it/s, loss=2.01e-07, v_num=23, train_loss=1.23e-5, test_loss=1.29e-5]\u001b[AAdjusting learning rate of group 0 to 1.4228e-03.\n",
      "Epoch 778:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.81it/s, loss=1.95e-07, v_num=23, train_loss=1.23e-5, test_loss=1.29e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 778:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.44it/s, loss=1.95e-07, v_num=23, train_loss=1.23e-5, test_loss=1.29e-5]\u001b[A\n",
      "Epoch 778: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.87it/s, loss=1.95e-07, v_num=23, train_loss=2.07e-5, test_loss=2.15e-5]\u001b[A\n",
      "Epoch 779:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.69it/s, loss=1.63e-07, v_num=23, train_loss=2.07e-5, test_loss=2.15e-5]\u001b[AAdjusting learning rate of group 0 to 1.4193e-03.\n",
      "Epoch 779:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.68it/s, loss=1.58e-07, v_num=23, train_loss=2.07e-5, test_loss=2.15e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 779:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.74it/s, loss=1.58e-07, v_num=23, train_loss=2.07e-5, test_loss=2.15e-5]\u001b[A\n",
      "Epoch 779: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.05it/s, loss=1.58e-07, v_num=23, train_loss=1.59e-5, test_loss=1.62e-5]\u001b[A\n",
      "Epoch 780:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.93it/s, loss=1.9e-07, v_num=23, train_loss=1.59e-5, test_loss=1.62e-5]\u001b[AAdjusting learning rate of group 0 to 1.4157e-03.\n",
      "Epoch 780:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.27it/s, loss=1.81e-07, v_num=23, train_loss=1.59e-5, test_loss=1.62e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 780:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.74it/s, loss=1.81e-07, v_num=23, train_loss=1.59e-5, test_loss=1.62e-5]\u001b[A\n",
      "Epoch 780: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.28it/s, loss=1.81e-07, v_num=23, train_loss=1.42e-5, test_loss=1.47e-5]\u001b[A\n",
      "Epoch 781:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.77it/s, loss=2.25e-07, v_num=23, train_loss=1.42e-5, test_loss=1.47e-5]\u001b[AAdjusting learning rate of group 0 to 1.4122e-03.\n",
      "Epoch 781:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.01it/s, loss=2.18e-07, v_num=23, train_loss=1.42e-5, test_loss=1.47e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 781:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.66it/s, loss=2.18e-07, v_num=23, train_loss=1.42e-5, test_loss=1.47e-5]\u001b[A\n",
      "Epoch 781: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.41it/s, loss=2.18e-07, v_num=23, train_loss=1.75e-5, test_loss=1.8e-5]\u001b[A\n",
      "Epoch 782:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.47it/s, loss=1.4e-07, v_num=23, train_loss=1.75e-5, test_loss=1.8e-5]\u001b[AAdjusting learning rate of group 0 to 1.4087e-03.\n",
      "Epoch 782:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.74it/s, loss=1.33e-07, v_num=23, train_loss=1.75e-5, test_loss=1.8e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 782:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.24it/s, loss=1.33e-07, v_num=23, train_loss=1.75e-5, test_loss=1.8e-5]\u001b[A\n",
      "Epoch 782: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.26it/s, loss=1.33e-07, v_num=23, train_loss=1.16e-5, test_loss=1.23e-5]\u001b[A\n",
      "Epoch 783:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.77it/s, loss=1.24e-07, v_num=23, train_loss=1.16e-5, test_loss=1.23e-5]\u001b[AAdjusting learning rate of group 0 to 1.4051e-03.\n",
      "Epoch 783:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.58it/s, loss=1.16e-07, v_num=23, train_loss=1.16e-5, test_loss=1.23e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 783:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.40it/s, loss=1.16e-07, v_num=23, train_loss=1.16e-5, test_loss=1.23e-5]\u001b[A\n",
      "Epoch 783: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.87it/s, loss=1.16e-07, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 784:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.66it/s, loss=1.32e-07, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\u001b[AAdjusting learning rate of group 0 to 1.4016e-03.\n",
      "Epoch 784:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.87it/s, loss=1.58e-07, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 784:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.72it/s, loss=1.58e-07, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 784: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.34it/s, loss=1.58e-07, v_num=23, train_loss=9.66e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 785:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.95it/s, loss=1.54e-07, v_num=23, train_loss=9.66e-6, test_loss=1.05e-5]\u001b[AAdjusting learning rate of group 0 to 1.3981e-03.\n",
      "Epoch 785:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.69it/s, loss=1.48e-07, v_num=23, train_loss=9.66e-6, test_loss=1.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 785:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.44it/s, loss=1.48e-07, v_num=23, train_loss=9.66e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 785: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.98it/s, loss=1.48e-07, v_num=23, train_loss=1.64e-5, test_loss=1.72e-5]\u001b[A\n",
      "Epoch 786:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.56it/s, loss=1.2e-07, v_num=23, train_loss=1.64e-5, test_loss=1.72e-5]\u001b[AAdjusting learning rate of group 0 to 1.3946e-03.\n",
      "Epoch 786:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.32it/s, loss=1.15e-07, v_num=23, train_loss=1.64e-5, test_loss=1.72e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 786:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.46it/s, loss=1.15e-07, v_num=23, train_loss=1.64e-5, test_loss=1.72e-5]\u001b[A\n",
      "Epoch 786: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.19it/s, loss=1.15e-07, v_num=23, train_loss=1.41e-5, test_loss=1.47e-5]\u001b[A\n",
      "Epoch 787:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.16it/s, loss=1.45e-07, v_num=23, train_loss=1.41e-5, test_loss=1.47e-5]\u001b[AAdjusting learning rate of group 0 to 1.3911e-03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 787:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.90it/s, loss=1.37e-07, v_num=23, train_loss=1.41e-5, test_loss=1.47e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 787:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.00it/s, loss=1.37e-07, v_num=23, train_loss=1.41e-5, test_loss=1.47e-5]\u001b[A\n",
      "Epoch 787: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.32it/s, loss=1.37e-07, v_num=23, train_loss=1.29e-5, test_loss=1.35e-5]\u001b[A\n",
      "Epoch 788:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.67it/s, loss=1.5e-07, v_num=23, train_loss=1.29e-5, test_loss=1.35e-5]\u001b[AAdjusting learning rate of group 0 to 1.3877e-03.\n",
      "Epoch 788:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.04it/s, loss=1.45e-07, v_num=23, train_loss=1.29e-5, test_loss=1.35e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 788:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.73it/s, loss=1.45e-07, v_num=23, train_loss=1.29e-5, test_loss=1.35e-5]\u001b[A\n",
      "Epoch 788: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.42it/s, loss=1.45e-07, v_num=23, train_loss=1.43e-5, test_loss=1.53e-5]\u001b[A\n",
      "Epoch 789:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.74it/s, loss=1.2e-07, v_num=23, train_loss=1.43e-5, test_loss=1.53e-5]\u001b[AAdjusting learning rate of group 0 to 1.3842e-03.\n",
      "Epoch 789:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.08it/s, loss=1.11e-07, v_num=23, train_loss=1.43e-5, test_loss=1.53e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 789:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.43it/s, loss=1.11e-07, v_num=23, train_loss=1.43e-5, test_loss=1.53e-5]\u001b[A\n",
      "Epoch 789: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.59it/s, loss=1.11e-07, v_num=23, train_loss=1.38e-5, test_loss=1.46e-5]\u001b[A\n",
      "Epoch 790:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.30it/s, loss=1.54e-07, v_num=23, train_loss=1.38e-5, test_loss=1.46e-5]\u001b[AAdjusting learning rate of group 0 to 1.3807e-03.\n",
      "Epoch 790:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.88it/s, loss=1.45e-07, v_num=23, train_loss=1.38e-5, test_loss=1.46e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 790:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.14it/s, loss=1.45e-07, v_num=23, train_loss=1.38e-5, test_loss=1.46e-5]\u001b[A\n",
      "Epoch 790: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.63it/s, loss=1.45e-07, v_num=23, train_loss=1.92e-5, test_loss=1.98e-5]\u001b[A\n",
      "Epoch 791:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.96it/s, loss=1.88e-07, v_num=23, train_loss=1.92e-5, test_loss=1.98e-5]\u001b[AAdjusting learning rate of group 0 to 1.3773e-03.\n",
      "Epoch 791:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.88it/s, loss=1.76e-07, v_num=23, train_loss=1.92e-5, test_loss=1.98e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 791:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.67it/s, loss=1.76e-07, v_num=23, train_loss=1.92e-5, test_loss=1.98e-5]\u001b[A\n",
      "Epoch 791: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.36it/s, loss=1.76e-07, v_num=23, train_loss=1.23e-5, test_loss=1.32e-5]\u001b[A\n",
      "Epoch 792:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.40it/s, loss=1.64e-07, v_num=23, train_loss=1.23e-5, test_loss=1.32e-5]\u001b[AAdjusting learning rate of group 0 to 1.3738e-03.\n",
      "Epoch 792:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.50it/s, loss=1.6e-07, v_num=23, train_loss=1.23e-5, test_loss=1.32e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 792:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.05it/s, loss=1.6e-07, v_num=23, train_loss=1.23e-5, test_loss=1.32e-5]\u001b[A\n",
      "Epoch 792: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.11it/s, loss=1.6e-07, v_num=23, train_loss=1.32e-5, test_loss=1.38e-5]\u001b[A\n",
      "Epoch 793:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.78it/s, loss=1.35e-07, v_num=23, train_loss=1.32e-5, test_loss=1.38e-5]\u001b[AAdjusting learning rate of group 0 to 1.3704e-03.\n",
      "Epoch 793:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.15it/s, loss=1.29e-07, v_num=23, train_loss=1.32e-5, test_loss=1.38e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 793:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.91it/s, loss=1.29e-07, v_num=23, train_loss=1.32e-5, test_loss=1.38e-5]\u001b[A\n",
      "Epoch 793: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.91it/s, loss=1.29e-07, v_num=23, train_loss=1.07e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 794:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.19it/s, loss=1.46e-07, v_num=23, train_loss=1.07e-5, test_loss=1.12e-5]\u001b[AAdjusting learning rate of group 0 to 1.3670e-03.\n",
      "Epoch 794:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.96it/s, loss=1.41e-07, v_num=23, train_loss=1.07e-5, test_loss=1.12e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 794:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.02it/s, loss=1.41e-07, v_num=23, train_loss=1.07e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 794: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.10it/s, loss=1.41e-07, v_num=23, train_loss=1.34e-5, test_loss=1.38e-5]\u001b[A\n",
      "Epoch 795:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.65it/s, loss=1.37e-07, v_num=23, train_loss=1.34e-5, test_loss=1.38e-5]\u001b[AAdjusting learning rate of group 0 to 1.3636e-03.\n",
      "Epoch 795:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.76it/s, loss=1.29e-07, v_num=23, train_loss=1.34e-5, test_loss=1.38e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 795:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.77it/s, loss=1.29e-07, v_num=23, train_loss=1.34e-5, test_loss=1.38e-5]\u001b[A\n",
      "Epoch 795: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.96it/s, loss=1.29e-07, v_num=23, train_loss=1.63e-5, test_loss=1.72e-5]\u001b[A\n",
      "Epoch 796:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.18it/s, loss=1.51e-07, v_num=23, train_loss=1.63e-5, test_loss=1.72e-5]\u001b[AAdjusting learning rate of group 0 to 1.3601e-03.\n",
      "Epoch 796:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.28it/s, loss=1.47e-07, v_num=23, train_loss=1.63e-5, test_loss=1.72e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 796:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.37it/s, loss=1.47e-07, v_num=23, train_loss=1.63e-5, test_loss=1.72e-5]\u001b[A\n",
      "Epoch 796: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.96it/s, loss=1.47e-07, v_num=23, train_loss=1.2e-5, test_loss=1.25e-5]\u001b[A\n",
      "Epoch 797:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.94it/s, loss=1.53e-07, v_num=23, train_loss=1.2e-5, test_loss=1.25e-5]\u001b[AAdjusting learning rate of group 0 to 1.3567e-03.\n",
      "Epoch 797:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 138.33it/s, loss=1.5e-07, v_num=23, train_loss=1.2e-5, test_loss=1.25e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 797:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 131.62it/s, loss=1.5e-07, v_num=23, train_loss=1.2e-5, test_loss=1.25e-5]\u001b[A\n",
      "Epoch 797: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 166.50it/s, loss=1.5e-07, v_num=23, train_loss=3.1e-5, test_loss=3.15e-5]\u001b[A\n",
      "Epoch 798:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.62it/s, loss=1.26e-07, v_num=23, train_loss=3.1e-5, test_loss=3.15e-5]\u001b[AAdjusting learning rate of group 0 to 1.3534e-03.\n",
      "Epoch 798:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.66it/s, loss=1.19e-07, v_num=23, train_loss=3.1e-5, test_loss=3.15e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 798:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 135.03it/s, loss=1.19e-07, v_num=23, train_loss=3.1e-5, test_loss=3.15e-5]\u001b[A\n",
      "Epoch 798: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 172.21it/s, loss=1.19e-07, v_num=23, train_loss=1.08e-5, test_loss=1.15e-5]\u001b[A\n",
      "Epoch 799:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.45it/s, loss=1.79e-07, v_num=23, train_loss=1.08e-5, test_loss=1.15e-5]\u001b[AAdjusting learning rate of group 0 to 1.3500e-03.\n",
      "Epoch 799:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 142.31it/s, loss=1.67e-07, v_num=23, train_loss=1.08e-5, test_loss=1.15e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 799:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.40it/s, loss=1.67e-07, v_num=23, train_loss=1.08e-5, test_loss=1.15e-5]\u001b[A\n",
      "Epoch 799: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.91it/s, loss=1.67e-07, v_num=23, train_loss=2.86e-5, test_loss=2.87e-5]\u001b[A\n",
      "Epoch 800:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.35it/s, loss=1.42e-07, v_num=23, train_loss=2.86e-5, test_loss=2.87e-5]\u001b[AAdjusting learning rate of group 0 to 1.3466e-03.\n",
      "Epoch 800:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.42it/s, loss=1.36e-07, v_num=23, train_loss=2.86e-5, test_loss=2.87e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 800:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.68it/s, loss=1.36e-07, v_num=23, train_loss=2.86e-5, test_loss=2.87e-5]\u001b[A\n",
      "Epoch 800: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.04it/s, loss=1.36e-07, v_num=23, train_loss=1.65e-5, test_loss=1.71e-5]\u001b[A\n",
      "Epoch 801:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.09it/s, loss=1.15e-07, v_num=23, train_loss=1.65e-5, test_loss=1.71e-5]\u001b[AAdjusting learning rate of group 0 to 1.3432e-03.\n",
      "Epoch 801:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.94it/s, loss=1.1e-07, v_num=23, train_loss=1.65e-5, test_loss=1.71e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 801:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.17it/s, loss=1.1e-07, v_num=23, train_loss=1.65e-5, test_loss=1.71e-5]\u001b[A\n",
      "Epoch 801: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.02it/s, loss=1.1e-07, v_num=23, train_loss=1.59e-5, test_loss=1.65e-5]\u001b[A\n",
      "Epoch 802:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.78it/s, loss=1.85e-07, v_num=23, train_loss=1.59e-5, test_loss=1.65e-5]\u001b[AAdjusting learning rate of group 0 to 1.3399e-03.\n",
      "Epoch 802:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.92it/s, loss=1.79e-07, v_num=23, train_loss=1.59e-5, test_loss=1.65e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 802:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.23it/s, loss=1.79e-07, v_num=23, train_loss=1.59e-5, test_loss=1.65e-5]\u001b[A\n",
      "Epoch 802: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.21it/s, loss=1.79e-07, v_num=23, train_loss=2.14e-5, test_loss=2.16e-5]\u001b[A\n",
      "Epoch 803:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.27it/s, loss=1.31e-07, v_num=23, train_loss=2.14e-5, test_loss=2.16e-5]\u001b[AAdjusting learning rate of group 0 to 1.3365e-03.\n",
      "Epoch 803:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.67it/s, loss=1.26e-07, v_num=23, train_loss=2.14e-5, test_loss=2.16e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 803:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.64it/s, loss=1.26e-07, v_num=23, train_loss=2.14e-5, test_loss=2.16e-5]\u001b[A\n",
      "Epoch 803: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.88it/s, loss=1.26e-07, v_num=23, train_loss=1.88e-5, test_loss=1.91e-5]\u001b[A\n",
      "Epoch 804:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.40it/s, loss=1.15e-07, v_num=23, train_loss=1.88e-5, test_loss=1.91e-5]\u001b[AAdjusting learning rate of group 0 to 1.3332e-03.\n",
      "Epoch 804:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.46it/s, loss=1.11e-07, v_num=23, train_loss=1.88e-5, test_loss=1.91e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 804:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.29it/s, loss=1.11e-07, v_num=23, train_loss=1.88e-5, test_loss=1.91e-5]\u001b[A\n",
      "Epoch 804: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.49it/s, loss=1.11e-07, v_num=23, train_loss=1.31e-5, test_loss=1.36e-5]\u001b[A\n",
      "Epoch 805:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.05it/s, loss=1.11e-07, v_num=23, train_loss=1.31e-5, test_loss=1.36e-5]\u001b[AAdjusting learning rate of group 0 to 1.3298e-03.\n",
      "Epoch 805:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.14it/s, loss=1.07e-07, v_num=23, train_loss=1.31e-5, test_loss=1.36e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 805:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.32it/s, loss=1.07e-07, v_num=23, train_loss=1.31e-5, test_loss=1.36e-5]\u001b[A\n",
      "Epoch 805: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.49it/s, loss=1.07e-07, v_num=23, train_loss=1.03e-5, test_loss=1.1e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 806:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.94it/s, loss=1.35e-07, v_num=23, train_loss=1.03e-5, test_loss=1.1e-5]\u001b[AAdjusting learning rate of group 0 to 1.3265e-03.\n",
      "Epoch 806:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.89it/s, loss=1.29e-07, v_num=23, train_loss=1.03e-5, test_loss=1.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 806:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.27it/s, loss=1.29e-07, v_num=23, train_loss=1.03e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 806: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.17it/s, loss=1.29e-07, v_num=23, train_loss=1.1e-5, test_loss=1.17e-5]\u001b[A\n",
      "Epoch 807:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.03it/s, loss=1.34e-07, v_num=23, train_loss=1.1e-5, test_loss=1.17e-5]\u001b[AAdjusting learning rate of group 0 to 1.3232e-03.\n",
      "Epoch 807:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.86it/s, loss=1.27e-07, v_num=23, train_loss=1.1e-5, test_loss=1.17e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 807:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.96it/s, loss=1.27e-07, v_num=23, train_loss=1.1e-5, test_loss=1.17e-5]\u001b[A\n",
      "Epoch 807: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.64it/s, loss=1.27e-07, v_num=23, train_loss=1.02e-5, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 808:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.45it/s, loss=1.55e-07, v_num=23, train_loss=1.02e-5, test_loss=1.06e-5]\u001b[AAdjusting learning rate of group 0 to 1.3199e-03.\n",
      "Epoch 808:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.46it/s, loss=1.5e-07, v_num=23, train_loss=1.02e-5, test_loss=1.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 808:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.93it/s, loss=1.5e-07, v_num=23, train_loss=1.02e-5, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 808: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.24it/s, loss=1.5e-07, v_num=23, train_loss=1.25e-5, test_loss=1.33e-5]\u001b[A\n",
      "Epoch 809:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.65it/s, loss=1.55e-07, v_num=23, train_loss=1.25e-5, test_loss=1.33e-5]\u001b[AAdjusting learning rate of group 0 to 1.3166e-03.\n",
      "Epoch 809:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.73it/s, loss=1.48e-07, v_num=23, train_loss=1.25e-5, test_loss=1.33e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 809:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.40it/s, loss=1.48e-07, v_num=23, train_loss=1.25e-5, test_loss=1.33e-5]\u001b[A\n",
      "Epoch 809: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.19it/s, loss=1.48e-07, v_num=23, train_loss=1.4e-5, test_loss=1.47e-5]\u001b[A\n",
      "Epoch 810:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.47it/s, loss=1.36e-07, v_num=23, train_loss=1.4e-5, test_loss=1.47e-5]\u001b[AAdjusting learning rate of group 0 to 1.3133e-03.\n",
      "Epoch 810:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.89it/s, loss=1.32e-07, v_num=23, train_loss=1.4e-5, test_loss=1.47e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 810:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 128.65it/s, loss=1.32e-07, v_num=23, train_loss=1.4e-5, test_loss=1.47e-5]\u001b[A\n",
      "Epoch 810: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.65it/s, loss=1.32e-07, v_num=23, train_loss=1.67e-5, test_loss=1.74e-5]\u001b[A\n",
      "Epoch 811:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.23it/s, loss=1.29e-07, v_num=23, train_loss=1.67e-5, test_loss=1.74e-5]\u001b[AAdjusting learning rate of group 0 to 1.3100e-03.\n",
      "Epoch 811:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.96it/s, loss=1.25e-07, v_num=23, train_loss=1.67e-5, test_loss=1.74e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 811:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.66it/s, loss=1.25e-07, v_num=23, train_loss=1.67e-5, test_loss=1.74e-5]\u001b[A\n",
      "Epoch 811: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 165.86it/s, loss=1.25e-07, v_num=23, train_loss=1.4e-5, test_loss=1.47e-5]\u001b[A\n",
      "Epoch 812:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.15it/s, loss=1.09e-07, v_num=23, train_loss=1.4e-5, test_loss=1.47e-5]\u001b[AAdjusting learning rate of group 0 to 1.3067e-03.\n",
      "Epoch 812:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.22it/s, loss=1.04e-07, v_num=23, train_loss=1.4e-5, test_loss=1.47e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 812:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 129.26it/s, loss=1.04e-07, v_num=23, train_loss=1.4e-5, test_loss=1.47e-5]\u001b[A\n",
      "Epoch 812: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 164.29it/s, loss=1.04e-07, v_num=23, train_loss=1.34e-5, test_loss=1.4e-5]\u001b[A\n",
      "Epoch 813:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.94it/s, loss=1.34e-07, v_num=23, train_loss=1.34e-5, test_loss=1.4e-5]\u001b[AAdjusting learning rate of group 0 to 1.3035e-03.\n",
      "Epoch 813:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.10it/s, loss=1.26e-07, v_num=23, train_loss=1.34e-5, test_loss=1.4e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 813:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.79it/s, loss=1.26e-07, v_num=23, train_loss=1.34e-5, test_loss=1.4e-5]\u001b[A\n",
      "Epoch 813: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.88it/s, loss=1.26e-07, v_num=23, train_loss=2.34e-5, test_loss=2.41e-5]\u001b[A\n",
      "Epoch 814:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.10it/s, loss=1.21e-07, v_num=23, train_loss=2.34e-5, test_loss=2.41e-5]\u001b[AAdjusting learning rate of group 0 to 1.3002e-03.\n",
      "Epoch 814:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.87it/s, loss=1.15e-07, v_num=23, train_loss=2.34e-5, test_loss=2.41e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 814:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.25it/s, loss=1.15e-07, v_num=23, train_loss=2.34e-5, test_loss=2.41e-5]\u001b[A\n",
      "Epoch 814: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.56it/s, loss=1.15e-07, v_num=23, train_loss=1.45e-5, test_loss=1.51e-5]\u001b[A\n",
      "Epoch 815:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.72it/s, loss=1.51e-07, v_num=23, train_loss=1.45e-5, test_loss=1.51e-5]\u001b[AAdjusting learning rate of group 0 to 1.2970e-03.\n",
      "Epoch 815:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.13it/s, loss=1.44e-07, v_num=23, train_loss=1.45e-5, test_loss=1.51e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 815:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.56it/s, loss=1.44e-07, v_num=23, train_loss=1.45e-5, test_loss=1.51e-5]\u001b[A\n",
      "Epoch 815: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.08it/s, loss=1.44e-07, v_num=23, train_loss=1.69e-5, test_loss=1.81e-5]\u001b[A\n",
      "Epoch 816:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.02it/s, loss=1.61e-07, v_num=23, train_loss=1.69e-5, test_loss=1.81e-5]\u001b[AAdjusting learning rate of group 0 to 1.2937e-03.\n",
      "Epoch 816:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.66it/s, loss=1.56e-07, v_num=23, train_loss=1.69e-5, test_loss=1.81e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 816:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.63it/s, loss=1.56e-07, v_num=23, train_loss=1.69e-5, test_loss=1.81e-5]\u001b[A\n",
      "Epoch 816: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.51it/s, loss=1.56e-07, v_num=23, train_loss=1.17e-5, test_loss=1.28e-5]\u001b[A\n",
      "Epoch 817:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.38it/s, loss=1.68e-07, v_num=23, train_loss=1.17e-5, test_loss=1.28e-5]\u001b[AAdjusting learning rate of group 0 to 1.2905e-03.\n",
      "Epoch 817:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.91it/s, loss=1.61e-07, v_num=23, train_loss=1.17e-5, test_loss=1.28e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 817:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.17it/s, loss=1.61e-07, v_num=23, train_loss=1.17e-5, test_loss=1.28e-5]\u001b[A\n",
      "Epoch 817: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.69it/s, loss=1.61e-07, v_num=23, train_loss=1.86e-5, test_loss=1.93e-5]\u001b[A\n",
      "Epoch 818:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.02it/s, loss=1.5e-07, v_num=23, train_loss=1.86e-5, test_loss=1.93e-5]\u001b[AAdjusting learning rate of group 0 to 1.2873e-03.\n",
      "Epoch 818:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.83it/s, loss=1.45e-07, v_num=23, train_loss=1.86e-5, test_loss=1.93e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 818:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.05it/s, loss=1.45e-07, v_num=23, train_loss=1.86e-5, test_loss=1.93e-5]\u001b[A\n",
      "Validating:  49%|██████████████████████████████████████████████████▊                                                    | 39/79 [00:00<00:00, 182.32it/s]\u001b[A\n",
      "Epoch 818: 100%|██████████████████████████████████████| 158/158 [00:01<00:00, 142.27it/s, loss=1.45e-07, v_num=23, train_loss=1.03e-5, test_loss=1.13e-5]\u001b[A\n",
      "Epoch 819:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 119.56it/s, loss=1.33e-07, v_num=23, train_loss=1.03e-5, test_loss=1.13e-5]\u001b[AAdjusting learning rate of group 0 to 1.2840e-03.\n",
      "Epoch 819:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 113.94it/s, loss=1.27e-07, v_num=23, train_loss=1.03e-5, test_loss=1.13e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 819:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 115.42it/s, loss=1.27e-07, v_num=23, train_loss=1.03e-5, test_loss=1.13e-5]\u001b[A\n",
      "Validating:  53%|██████████████████████████████████████████████████████▊                                                | 42/79 [00:00<00:00, 195.60it/s]\u001b[A\n",
      "Epoch 819: 100%|██████████████████████████████████████| 158/158 [00:01<00:00, 129.47it/s, loss=1.27e-07, v_num=23, train_loss=1.25e-5, test_loss=1.29e-5]\u001b[A\n",
      "Epoch 820:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 120.15it/s, loss=1.1e-07, v_num=23, train_loss=1.25e-5, test_loss=1.29e-5]\u001b[AAdjusting learning rate of group 0 to 1.2808e-03.\n",
      "Epoch 820:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 111.63it/s, loss=1.06e-07, v_num=23, train_loss=1.25e-5, test_loss=1.29e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 820:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 112.86it/s, loss=1.06e-07, v_num=23, train_loss=1.25e-5, test_loss=1.29e-5]\u001b[A\n",
      "Epoch 820: 100%|██████████████████████████████████████| 158/158 [00:01<00:00, 126.36it/s, loss=1.06e-07, v_num=23, train_loss=1.24e-5, test_loss=1.32e-5]\u001b[A\n",
      "Epoch 821:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 122.09it/s, loss=1.14e-07, v_num=23, train_loss=1.24e-5, test_loss=1.32e-5]\u001b[AAdjusting learning rate of group 0 to 1.2776e-03.\n",
      "Epoch 821:  50%|████████████████████                    | 79/158 [00:00<00:00, 114.35it/s, loss=1.1e-07, v_num=23, train_loss=1.24e-5, test_loss=1.32e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.16it/s]\u001b[A\n",
      "Validating:   8%|███████▉                                                                                                 | 6/79 [00:00<00:03, 22.12it/s]\u001b[A\n",
      "Validating:  14%|██████████████▍                                                                                         | 11/79 [00:00<00:02, 31.93it/s]\u001b[A\n",
      "Epoch 821:  67%|██████████████████████████▊             | 106/158 [00:01<00:00, 86.70it/s, loss=1.1e-07, v_num=23, train_loss=1.24e-5, test_loss=1.32e-5]\u001b[A\n",
      "Epoch 821: 100%|███████████████████████████████████████| 158/158 [00:01<00:00, 115.20it/s, loss=1.1e-07, v_num=23, train_loss=1.23e-5, test_loss=1.27e-5]\u001b[A\n",
      "Epoch 822:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.24it/s, loss=1.56e-07, v_num=23, train_loss=1.23e-5, test_loss=1.27e-5]\u001b[AAdjusting learning rate of group 0 to 1.2744e-03.\n",
      "Epoch 822:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.43it/s, loss=1.49e-07, v_num=23, train_loss=1.23e-5, test_loss=1.27e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 822:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.83it/s, loss=1.49e-07, v_num=23, train_loss=1.23e-5, test_loss=1.27e-5]\u001b[A\n",
      "Epoch 822: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 169.97it/s, loss=1.49e-07, v_num=23, train_loss=2e-5, test_loss=2.05e-5]\u001b[A\n",
      "Epoch 823:  49%|█████████████████████▏                     | 78/158 [00:00<00:00, 149.38it/s, loss=1.9e-07, v_num=23, train_loss=2e-5, test_loss=2.05e-5]\u001b[AAdjusting learning rate of group 0 to 1.2713e-03.\n",
      "Epoch 823:  50%|█████████████████████                     | 79/158 [00:00<00:00, 140.72it/s, loss=1.83e-07, v_num=23, train_loss=2e-5, test_loss=2.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 823:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 135.27it/s, loss=1.83e-07, v_num=23, train_loss=2e-5, test_loss=2.05e-5]\u001b[A\n",
      "Epoch 823: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.79it/s, loss=1.83e-07, v_num=23, train_loss=2.39e-5, test_loss=2.47e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 824:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 126.79it/s, loss=1.42e-07, v_num=23, train_loss=2.39e-5, test_loss=2.47e-5]\u001b[AAdjusting learning rate of group 0 to 1.2681e-03.\n",
      "Epoch 824:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 118.60it/s, loss=1.32e-07, v_num=23, train_loss=2.39e-5, test_loss=2.47e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 824:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 117.35it/s, loss=1.32e-07, v_num=23, train_loss=2.39e-5, test_loss=2.47e-5]\u001b[A\n",
      "Validating:  52%|█████████████████████████████████████████████████████▍                                                 | 41/79 [00:00<00:00, 189.51it/s]\u001b[A\n",
      "Epoch 824: 100%|██████████████████████████████████████| 158/158 [00:01<00:00, 130.82it/s, loss=1.32e-07, v_num=23, train_loss=1.52e-5, test_loss=1.63e-5]\u001b[A\n",
      "Epoch 825:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 120.62it/s, loss=1.3e-07, v_num=23, train_loss=1.52e-5, test_loss=1.63e-5]\u001b[AAdjusting learning rate of group 0 to 1.2649e-03.\n",
      "Epoch 825:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 112.57it/s, loss=1.26e-07, v_num=23, train_loss=1.52e-5, test_loss=1.63e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 825:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 113.26it/s, loss=1.26e-07, v_num=23, train_loss=1.52e-5, test_loss=1.63e-5]\u001b[A\n",
      "Validating:  53%|██████████████████████████████████████████████████████▊                                                | 42/79 [00:00<00:00, 196.01it/s]\u001b[A\n",
      "Epoch 825: 100%|██████████████████████████████████████| 158/158 [00:01<00:00, 128.33it/s, loss=1.26e-07, v_num=23, train_loss=1.56e-5, test_loss=1.61e-5]\u001b[A\n",
      "Epoch 826:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 119.28it/s, loss=1.59e-07, v_num=23, train_loss=1.56e-5, test_loss=1.61e-5]\u001b[AAdjusting learning rate of group 0 to 1.2617e-03.\n",
      "Epoch 826:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 113.40it/s, loss=1.53e-07, v_num=23, train_loss=1.56e-5, test_loss=1.61e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 826:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 113.25it/s, loss=1.53e-07, v_num=23, train_loss=1.56e-5, test_loss=1.61e-5]\u001b[A\n",
      "Validating:  39%|████████████████████████████████████████▍                                                              | 31/79 [00:00<00:00, 144.05it/s]\u001b[A\n",
      "Epoch 826: 100%|██████████████████████████████████████| 158/158 [00:01<00:00, 127.36it/s, loss=1.53e-07, v_num=23, train_loss=1.38e-5, test_loss=1.44e-5]\u001b[A\n",
      "Epoch 827:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 120.56it/s, loss=1.37e-07, v_num=23, train_loss=1.38e-5, test_loss=1.44e-5]\u001b[AAdjusting learning rate of group 0 to 1.2586e-03.\n",
      "Epoch 827:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 114.39it/s, loss=1.31e-07, v_num=23, train_loss=1.38e-5, test_loss=1.44e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.25it/s]\u001b[A\n",
      "Validating:   6%|██████▋                                                                                                  | 5/79 [00:00<00:03, 19.96it/s]\u001b[A\n",
      "Validating:  10%|██████████▋                                                                                              | 8/79 [00:00<00:03, 23.60it/s]\u001b[A\n",
      "Epoch 827:  67%|██████████████████████████▏            | 106/158 [00:01<00:00, 87.59it/s, loss=1.31e-07, v_num=23, train_loss=1.38e-5, test_loss=1.44e-5]\u001b[A\n",
      "Epoch 827: 100%|██████████████████████████████████████| 158/158 [00:01<00:00, 115.65it/s, loss=1.31e-07, v_num=23, train_loss=1.44e-5, test_loss=1.54e-5]\u001b[A\n",
      "Epoch 828:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 114.66it/s, loss=1.35e-07, v_num=23, train_loss=1.44e-5, test_loss=1.54e-5]\u001b[AAdjusting learning rate of group 0 to 1.2554e-03.\n",
      "Epoch 828:  50%|████████████████████                    | 79/158 [00:00<00:00, 109.29it/s, loss=1.3e-07, v_num=23, train_loss=1.44e-5, test_loss=1.54e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:24,  3.23it/s]\u001b[A\n",
      "Epoch 828:  67%|██████████████████████████▊             | 106/158 [00:01<00:00, 90.50it/s, loss=1.3e-07, v_num=23, train_loss=1.44e-5, test_loss=1.54e-5]\u001b[A\n",
      "Epoch 828: 100%|███████████████████████████████████████| 158/158 [00:01<00:00, 119.64it/s, loss=1.3e-07, v_num=23, train_loss=1.66e-5, test_loss=1.68e-5]\u001b[A\n",
      "Epoch 829:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.05it/s, loss=1.53e-07, v_num=23, train_loss=1.66e-5, test_loss=1.68e-5]\u001b[AAdjusting learning rate of group 0 to 1.2523e-03.\n",
      "Epoch 829:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.20it/s, loss=1.47e-07, v_num=23, train_loss=1.66e-5, test_loss=1.68e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 829:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.99it/s, loss=1.47e-07, v_num=23, train_loss=1.66e-5, test_loss=1.68e-5]\u001b[A\n",
      "Epoch 829: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.97it/s, loss=1.47e-07, v_num=23, train_loss=1.73e-5, test_loss=1.77e-5]\u001b[A\n",
      "Epoch 830:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.59it/s, loss=1.27e-07, v_num=23, train_loss=1.73e-5, test_loss=1.77e-5]\u001b[AAdjusting learning rate of group 0 to 1.2492e-03.\n",
      "Epoch 830:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.83it/s, loss=1.2e-07, v_num=23, train_loss=1.73e-5, test_loss=1.77e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 830:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 130.79it/s, loss=1.2e-07, v_num=23, train_loss=1.73e-5, test_loss=1.77e-5]\u001b[A\n",
      "Epoch 830: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 165.16it/s, loss=1.2e-07, v_num=23, train_loss=1.29e-5, test_loss=1.35e-5]\u001b[A\n",
      "Epoch 831:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.93it/s, loss=1.42e-07, v_num=23, train_loss=1.29e-5, test_loss=1.35e-5]\u001b[AAdjusting learning rate of group 0 to 1.2461e-03.\n",
      "Epoch 831:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.84it/s, loss=1.35e-07, v_num=23, train_loss=1.29e-5, test_loss=1.35e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 831:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.96it/s, loss=1.35e-07, v_num=23, train_loss=1.29e-5, test_loss=1.35e-5]\u001b[A\n",
      "Epoch 831: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.64it/s, loss=1.35e-07, v_num=23, train_loss=2.28e-5, test_loss=2.31e-5]\u001b[A\n",
      "Epoch 832:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.81it/s, loss=1.21e-07, v_num=23, train_loss=2.28e-5, test_loss=2.31e-5]\u001b[AAdjusting learning rate of group 0 to 1.2429e-03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 832:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.94it/s, loss=1.16e-07, v_num=23, train_loss=2.28e-5, test_loss=2.31e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 832:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.36it/s, loss=1.16e-07, v_num=23, train_loss=2.28e-5, test_loss=2.31e-5]\u001b[A\n",
      "Epoch 832: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.99it/s, loss=1.16e-07, v_num=23, train_loss=1.26e-5, test_loss=1.32e-5]\u001b[A\n",
      "Epoch 833:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.81it/s, loss=1.73e-07, v_num=23, train_loss=1.26e-5, test_loss=1.32e-5]\u001b[AAdjusting learning rate of group 0 to 1.2398e-03.\n",
      "Epoch 833:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.57it/s, loss=1.62e-07, v_num=23, train_loss=1.26e-5, test_loss=1.32e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 833:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.10it/s, loss=1.62e-07, v_num=23, train_loss=1.26e-5, test_loss=1.32e-5]\u001b[A\n",
      "Epoch 833: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.41it/s, loss=1.62e-07, v_num=23, train_loss=1.35e-5, test_loss=1.41e-5]\u001b[A\n",
      "Epoch 834:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.02it/s, loss=1.26e-07, v_num=23, train_loss=1.35e-5, test_loss=1.41e-5]\u001b[AAdjusting learning rate of group 0 to 1.2367e-03.\n",
      "Epoch 834:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.03it/s, loss=1.22e-07, v_num=23, train_loss=1.35e-5, test_loss=1.41e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 834:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.01it/s, loss=1.22e-07, v_num=23, train_loss=1.35e-5, test_loss=1.41e-5]\u001b[A\n",
      "Epoch 834: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.29it/s, loss=1.22e-07, v_num=23, train_loss=1.3e-5, test_loss=1.35e-5]\u001b[A\n",
      "Epoch 835:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.03it/s, loss=1.38e-07, v_num=23, train_loss=1.3e-5, test_loss=1.35e-5]\u001b[AAdjusting learning rate of group 0 to 1.2336e-03.\n",
      "Epoch 835:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.90it/s, loss=1.31e-07, v_num=23, train_loss=1.3e-5, test_loss=1.35e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 835:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.99it/s, loss=1.31e-07, v_num=23, train_loss=1.3e-5, test_loss=1.35e-5]\u001b[A\n",
      "Epoch 835: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.08it/s, loss=1.31e-07, v_num=23, train_loss=1.08e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 836:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.50it/s, loss=1.46e-07, v_num=23, train_loss=1.08e-5, test_loss=1.14e-5]\u001b[AAdjusting learning rate of group 0 to 1.2306e-03.\n",
      "Epoch 836:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.92it/s, loss=1.36e-07, v_num=23, train_loss=1.08e-5, test_loss=1.14e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 836:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.86it/s, loss=1.36e-07, v_num=23, train_loss=1.08e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 836: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.67it/s, loss=1.36e-07, v_num=23, train_loss=1.55e-5, test_loss=1.6e-5]\u001b[A\n",
      "Epoch 837:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.39it/s, loss=1.43e-07, v_num=23, train_loss=1.55e-5, test_loss=1.6e-5]\u001b[AAdjusting learning rate of group 0 to 1.2275e-03.\n",
      "Epoch 837:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.04it/s, loss=1.38e-07, v_num=23, train_loss=1.55e-5, test_loss=1.6e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 837:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.16it/s, loss=1.38e-07, v_num=23, train_loss=1.55e-5, test_loss=1.6e-5]\u001b[A\n",
      "Epoch 837: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.79it/s, loss=1.38e-07, v_num=23, train_loss=1.39e-5, test_loss=1.44e-5]\u001b[A\n",
      "Epoch 838:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.91it/s, loss=1.22e-07, v_num=23, train_loss=1.39e-5, test_loss=1.44e-5]\u001b[AAdjusting learning rate of group 0 to 1.2244e-03.\n",
      "Epoch 838:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.84it/s, loss=1.18e-07, v_num=23, train_loss=1.39e-5, test_loss=1.44e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 838:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.86it/s, loss=1.18e-07, v_num=23, train_loss=1.39e-5, test_loss=1.44e-5]\u001b[A\n",
      "Epoch 838: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.74it/s, loss=1.18e-07, v_num=23, train_loss=1.59e-5, test_loss=1.67e-5]\u001b[A\n",
      "Epoch 839:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.31it/s, loss=1.61e-07, v_num=23, train_loss=1.59e-5, test_loss=1.67e-5]\u001b[AAdjusting learning rate of group 0 to 1.2213e-03.\n",
      "Epoch 839:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.83it/s, loss=1.54e-07, v_num=23, train_loss=1.59e-5, test_loss=1.67e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 839:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.47it/s, loss=1.54e-07, v_num=23, train_loss=1.59e-5, test_loss=1.67e-5]\u001b[A\n",
      "Epoch 839: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.55it/s, loss=1.54e-07, v_num=23, train_loss=1.86e-5, test_loss=1.88e-5]\u001b[A\n",
      "Epoch 840:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.12it/s, loss=1.32e-07, v_num=23, train_loss=1.86e-5, test_loss=1.88e-5]\u001b[AAdjusting learning rate of group 0 to 1.2183e-03.\n",
      "Epoch 840:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.10it/s, loss=1.22e-07, v_num=23, train_loss=1.86e-5, test_loss=1.88e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 840:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.68it/s, loss=1.22e-07, v_num=23, train_loss=1.86e-5, test_loss=1.88e-5]\u001b[A\n",
      "Epoch 840: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.30it/s, loss=1.22e-07, v_num=23, train_loss=1.68e-5, test_loss=1.73e-5]\u001b[A\n",
      "Epoch 841:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.79it/s, loss=1.36e-07, v_num=23, train_loss=1.68e-5, test_loss=1.73e-5]\u001b[AAdjusting learning rate of group 0 to 1.2152e-03.\n",
      "Epoch 841:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.50it/s, loss=1.24e-07, v_num=23, train_loss=1.68e-5, test_loss=1.73e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.51it/s, loss=1.24e-07, v_num=23, train_loss=1.68e-5, test_loss=1.73e-5]\u001b[A\n",
      "Epoch 841: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.95it/s, loss=1.24e-07, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\u001b[A\n",
      "Epoch 842:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.44it/s, loss=1.38e-07, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\u001b[AAdjusting learning rate of group 0 to 1.2122e-03.\n",
      "Epoch 842:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.11it/s, loss=1.34e-07, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 842:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.15it/s, loss=1.34e-07, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\u001b[A\n",
      "Epoch 842: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.09it/s, loss=1.34e-07, v_num=23, train_loss=1.25e-5, test_loss=1.3e-5]\u001b[A\n",
      "Epoch 843:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 150.05it/s, loss=1.25e-07, v_num=23, train_loss=1.25e-5, test_loss=1.3e-5]\u001b[AAdjusting learning rate of group 0 to 1.2092e-03.\n",
      "Epoch 843:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.89it/s, loss=1.15e-07, v_num=23, train_loss=1.25e-5, test_loss=1.3e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 843:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 134.80it/s, loss=1.15e-07, v_num=23, train_loss=1.25e-5, test_loss=1.3e-5]\u001b[A\n",
      "Epoch 843: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.61it/s, loss=1.15e-07, v_num=23, train_loss=1.75e-5, test_loss=1.79e-5]\u001b[A\n",
      "Epoch 844:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.24it/s, loss=1.11e-07, v_num=23, train_loss=1.75e-5, test_loss=1.79e-5]\u001b[AAdjusting learning rate of group 0 to 1.2062e-03.\n",
      "Epoch 844:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.91it/s, loss=1.07e-07, v_num=23, train_loss=1.75e-5, test_loss=1.79e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 844:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.88it/s, loss=1.07e-07, v_num=23, train_loss=1.75e-5, test_loss=1.79e-5]\u001b[A\n",
      "Epoch 844: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.47it/s, loss=1.07e-07, v_num=23, train_loss=1.41e-5, test_loss=1.45e-5]\u001b[A\n",
      "Epoch 845:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.14it/s, loss=1.33e-07, v_num=23, train_loss=1.41e-5, test_loss=1.45e-5]\u001b[AAdjusting learning rate of group 0 to 1.2031e-03.\n",
      "Epoch 845:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.13it/s, loss=1.22e-07, v_num=23, train_loss=1.41e-5, test_loss=1.45e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 845:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.51it/s, loss=1.22e-07, v_num=23, train_loss=1.41e-5, test_loss=1.45e-5]\u001b[A\n",
      "Epoch 845: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.88it/s, loss=1.22e-07, v_num=23, train_loss=1.41e-5, test_loss=1.47e-5]\u001b[A\n",
      "Epoch 846:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.73it/s, loss=1.25e-07, v_num=23, train_loss=1.41e-5, test_loss=1.47e-5]\u001b[AAdjusting learning rate of group 0 to 1.2001e-03.\n",
      "Epoch 846:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.34it/s, loss=1.19e-07, v_num=23, train_loss=1.41e-5, test_loss=1.47e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 846:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.02it/s, loss=1.19e-07, v_num=23, train_loss=1.41e-5, test_loss=1.47e-5]\u001b[A\n",
      "Epoch 846: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.95it/s, loss=1.19e-07, v_num=23, train_loss=1.39e-5, test_loss=1.48e-5]\u001b[A\n",
      "Epoch 847:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.83it/s, loss=1.19e-07, v_num=23, train_loss=1.39e-5, test_loss=1.48e-5]\u001b[AAdjusting learning rate of group 0 to 1.1971e-03.\n",
      "Epoch 847:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.46it/s, loss=1.14e-07, v_num=23, train_loss=1.39e-5, test_loss=1.48e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 847:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.49it/s, loss=1.14e-07, v_num=23, train_loss=1.39e-5, test_loss=1.48e-5]\u001b[A\n",
      "Epoch 847: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.96it/s, loss=1.14e-07, v_num=23, train_loss=1.36e-5, test_loss=1.47e-5]\u001b[A\n",
      "Epoch 848:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.08it/s, loss=1.88e-07, v_num=23, train_loss=1.36e-5, test_loss=1.47e-5]\u001b[AAdjusting learning rate of group 0 to 1.1941e-03.\n",
      "Epoch 848:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.04it/s, loss=1.83e-07, v_num=23, train_loss=1.36e-5, test_loss=1.47e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 848:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.29it/s, loss=1.83e-07, v_num=23, train_loss=1.36e-5, test_loss=1.47e-5]\u001b[A\n",
      "Epoch 848: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.39it/s, loss=1.83e-07, v_num=23, train_loss=1.56e-5, test_loss=1.64e-5]\u001b[A\n",
      "Epoch 849:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.42it/s, loss=1.74e-07, v_num=23, train_loss=1.56e-5, test_loss=1.64e-5]\u001b[AAdjusting learning rate of group 0 to 1.1912e-03.\n",
      "Epoch 849:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.65it/s, loss=1.65e-07, v_num=23, train_loss=1.56e-5, test_loss=1.64e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 849:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.90it/s, loss=1.65e-07, v_num=23, train_loss=1.56e-5, test_loss=1.64e-5]\u001b[A\n",
      "Epoch 849: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.63it/s, loss=1.65e-07, v_num=23, train_loss=1.77e-5, test_loss=1.82e-5]\u001b[A\n",
      "Epoch 850:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.61it/s, loss=1.77e-07, v_num=23, train_loss=1.77e-5, test_loss=1.82e-5]\u001b[AAdjusting learning rate of group 0 to 1.1882e-03.\n",
      "Epoch 850:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.70it/s, loss=1.69e-07, v_num=23, train_loss=1.77e-5, test_loss=1.82e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 850:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.06it/s, loss=1.69e-07, v_num=23, train_loss=1.77e-5, test_loss=1.82e-5]\u001b[A\n",
      "Epoch 850: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.09it/s, loss=1.69e-07, v_num=23, train_loss=1.61e-5, test_loss=1.7e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 851:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.73it/s, loss=1.79e-07, v_num=23, train_loss=1.61e-5, test_loss=1.7e-5]\u001b[AAdjusting learning rate of group 0 to 1.1852e-03.\n",
      "Epoch 851:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.15it/s, loss=1.74e-07, v_num=23, train_loss=1.61e-5, test_loss=1.7e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 851:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.73it/s, loss=1.74e-07, v_num=23, train_loss=1.61e-5, test_loss=1.7e-5]\u001b[A\n",
      "Epoch 851: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.37it/s, loss=1.74e-07, v_num=23, train_loss=1.84e-5, test_loss=1.91e-5]\u001b[A\n",
      "Epoch 852:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.14it/s, loss=1.6e-07, v_num=23, train_loss=1.84e-5, test_loss=1.91e-5]\u001b[AAdjusting learning rate of group 0 to 1.1822e-03.\n",
      "Epoch 852:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.29it/s, loss=1.53e-07, v_num=23, train_loss=1.84e-5, test_loss=1.91e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 852:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.40it/s, loss=1.53e-07, v_num=23, train_loss=1.84e-5, test_loss=1.91e-5]\u001b[A\n",
      "Epoch 852: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.91it/s, loss=1.53e-07, v_num=23, train_loss=1.23e-5, test_loss=1.25e-5]\u001b[A\n",
      "Epoch 853:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.71it/s, loss=1.16e-07, v_num=23, train_loss=1.23e-5, test_loss=1.25e-5]\u001b[AAdjusting learning rate of group 0 to 1.1793e-03.\n",
      "Epoch 853:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.84it/s, loss=1.12e-07, v_num=23, train_loss=1.23e-5, test_loss=1.25e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 853:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.48it/s, loss=1.12e-07, v_num=23, train_loss=1.23e-5, test_loss=1.25e-5]\u001b[A\n",
      "Epoch 853: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.12it/s, loss=1.12e-07, v_num=23, train_loss=1.26e-5, test_loss=1.32e-5]\u001b[A\n",
      "Epoch 854:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.79it/s, loss=1.28e-07, v_num=23, train_loss=1.26e-5, test_loss=1.32e-5]\u001b[AAdjusting learning rate of group 0 to 1.1763e-03.\n",
      "Epoch 854:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.66it/s, loss=1.23e-07, v_num=23, train_loss=1.26e-5, test_loss=1.32e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 854:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.60it/s, loss=1.23e-07, v_num=23, train_loss=1.26e-5, test_loss=1.32e-5]\u001b[A\n",
      "Epoch 854: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.73it/s, loss=1.23e-07, v_num=23, train_loss=2.33e-5, test_loss=2.42e-5]\u001b[A\n",
      "Epoch 855:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.90it/s, loss=1.41e-07, v_num=23, train_loss=2.33e-5, test_loss=2.42e-5]\u001b[AAdjusting learning rate of group 0 to 1.1734e-03.\n",
      "Epoch 855:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.02it/s, loss=1.37e-07, v_num=23, train_loss=2.33e-5, test_loss=2.42e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 855:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.46it/s, loss=1.37e-07, v_num=23, train_loss=2.33e-5, test_loss=2.42e-5]\u001b[A\n",
      "Epoch 855: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.76it/s, loss=1.37e-07, v_num=23, train_loss=1.57e-5, test_loss=1.61e-5]\u001b[A\n",
      "Epoch 856:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.72it/s, loss=1.46e-07, v_num=23, train_loss=1.57e-5, test_loss=1.61e-5]\u001b[AAdjusting learning rate of group 0 to 1.1705e-03.\n",
      "Epoch 856:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.19it/s, loss=1.4e-07, v_num=23, train_loss=1.57e-5, test_loss=1.61e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 856:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 129.09it/s, loss=1.4e-07, v_num=23, train_loss=1.57e-5, test_loss=1.61e-5]\u001b[A\n",
      "Epoch 856: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 163.80it/s, loss=1.4e-07, v_num=23, train_loss=1.39e-5, test_loss=1.45e-5]\u001b[A\n",
      "Epoch 857:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.35it/s, loss=1.48e-07, v_num=23, train_loss=1.39e-5, test_loss=1.45e-5]\u001b[AAdjusting learning rate of group 0 to 1.1675e-03.\n",
      "Epoch 857:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.10it/s, loss=1.42e-07, v_num=23, train_loss=1.39e-5, test_loss=1.45e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 857:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.86it/s, loss=1.42e-07, v_num=23, train_loss=1.39e-5, test_loss=1.45e-5]\u001b[A\n",
      "Epoch 857: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.99it/s, loss=1.42e-07, v_num=23, train_loss=1.56e-5, test_loss=1.63e-5]\u001b[A\n",
      "Epoch 858:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 146.79it/s, loss=1.41e-07, v_num=23, train_loss=1.56e-5, test_loss=1.63e-5]\u001b[AAdjusting learning rate of group 0 to 1.1646e-03.\n",
      "Epoch 858:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.14it/s, loss=1.34e-07, v_num=23, train_loss=1.56e-5, test_loss=1.63e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 858:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.28it/s, loss=1.34e-07, v_num=23, train_loss=1.56e-5, test_loss=1.63e-5]\u001b[A\n",
      "Epoch 858: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.58it/s, loss=1.34e-07, v_num=23, train_loss=1.44e-5, test_loss=1.49e-5]\u001b[A\n",
      "Epoch 859:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.89it/s, loss=1.08e-07, v_num=23, train_loss=1.44e-5, test_loss=1.49e-5]\u001b[AAdjusting learning rate of group 0 to 1.1617e-03.\n",
      "Epoch 859:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.83it/s, loss=1.02e-07, v_num=23, train_loss=1.44e-5, test_loss=1.49e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 859:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.72it/s, loss=1.02e-07, v_num=23, train_loss=1.44e-5, test_loss=1.49e-5]\u001b[A\n",
      "Epoch 859: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.39it/s, loss=1.02e-07, v_num=23, train_loss=1.18e-5, test_loss=1.24e-5]\u001b[A\n",
      "Epoch 860:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.57it/s, loss=1.51e-07, v_num=23, train_loss=1.18e-5, test_loss=1.24e-5]\u001b[AAdjusting learning rate of group 0 to 1.1588e-03.\n",
      "Epoch 860:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.74it/s, loss=1.42e-07, v_num=23, train_loss=1.18e-5, test_loss=1.24e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 860:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.79it/s, loss=1.42e-07, v_num=23, train_loss=1.18e-5, test_loss=1.24e-5]\u001b[A\n",
      "Epoch 860: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.59it/s, loss=1.42e-07, v_num=23, train_loss=1.05e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 861:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.04it/s, loss=1.16e-07, v_num=23, train_loss=1.05e-5, test_loss=1.1e-5]\u001b[AAdjusting learning rate of group 0 to 1.1559e-03.\n",
      "Epoch 861:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.13it/s, loss=1.08e-07, v_num=23, train_loss=1.05e-5, test_loss=1.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 861:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.67it/s, loss=1.08e-07, v_num=23, train_loss=1.05e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 861: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.85it/s, loss=1.08e-07, v_num=23, train_loss=1.01e-5, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 862:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.37it/s, loss=1.16e-07, v_num=23, train_loss=1.01e-5, test_loss=1.06e-5]\u001b[AAdjusting learning rate of group 0 to 1.1530e-03.\n",
      "Epoch 862:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.60it/s, loss=1.06e-07, v_num=23, train_loss=1.01e-5, test_loss=1.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 862:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.55it/s, loss=1.06e-07, v_num=23, train_loss=1.01e-5, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 862: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.69it/s, loss=1.06e-07, v_num=23, train_loss=1.69e-5, test_loss=1.77e-5]\u001b[A\n",
      "Epoch 863:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.67it/s, loss=1.19e-07, v_num=23, train_loss=1.69e-5, test_loss=1.77e-5]\u001b[AAdjusting learning rate of group 0 to 1.1501e-03.\n",
      "Epoch 863:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.55it/s, loss=1.15e-07, v_num=23, train_loss=1.69e-5, test_loss=1.77e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 863:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.42it/s, loss=1.15e-07, v_num=23, train_loss=1.69e-5, test_loss=1.77e-5]\u001b[A\n",
      "Epoch 863: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 165.11it/s, loss=1.15e-07, v_num=23, train_loss=1.2e-5, test_loss=1.26e-5]\u001b[A\n",
      "Epoch 864:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.82it/s, loss=1.31e-07, v_num=23, train_loss=1.2e-5, test_loss=1.26e-5]\u001b[AAdjusting learning rate of group 0 to 1.1473e-03.\n",
      "Epoch 864:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.28it/s, loss=1.26e-07, v_num=23, train_loss=1.2e-5, test_loss=1.26e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 864:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.71it/s, loss=1.26e-07, v_num=23, train_loss=1.2e-5, test_loss=1.26e-5]\u001b[A\n",
      "Epoch 864: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.19it/s, loss=1.26e-07, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\u001b[A\n",
      "Epoch 865:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.40it/s, loss=1.17e-07, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\u001b[AAdjusting learning rate of group 0 to 1.1444e-03.\n",
      "Epoch 865:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.47it/s, loss=1.13e-07, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 865:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.66it/s, loss=1.13e-07, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\u001b[A\n",
      "Epoch 865: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.41it/s, loss=1.13e-07, v_num=23, train_loss=1.24e-5, test_loss=1.3e-5]\u001b[A\n",
      "Epoch 866:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.86it/s, loss=1.79e-07, v_num=23, train_loss=1.24e-5, test_loss=1.3e-5]\u001b[AAdjusting learning rate of group 0 to 1.1415e-03.\n",
      "Epoch 866:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.75it/s, loss=1.74e-07, v_num=23, train_loss=1.24e-5, test_loss=1.3e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 866:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.93it/s, loss=1.74e-07, v_num=23, train_loss=1.24e-5, test_loss=1.3e-5]\u001b[A\n",
      "Epoch 866: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.89it/s, loss=1.74e-07, v_num=23, train_loss=2.41e-5, test_loss=2.51e-5]\u001b[A\n",
      "Epoch 867:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.83it/s, loss=1.26e-07, v_num=23, train_loss=2.41e-5, test_loss=2.51e-5]\u001b[AAdjusting learning rate of group 0 to 1.1387e-03.\n",
      "Epoch 867:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.90it/s, loss=1.22e-07, v_num=23, train_loss=2.41e-5, test_loss=2.51e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 867:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.33it/s, loss=1.22e-07, v_num=23, train_loss=2.41e-5, test_loss=2.51e-5]\u001b[A\n",
      "Epoch 867: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.51it/s, loss=1.22e-07, v_num=23, train_loss=1.28e-5, test_loss=1.35e-5]\u001b[A\n",
      "Epoch 868:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.07it/s, loss=1.22e-07, v_num=23, train_loss=1.28e-5, test_loss=1.35e-5]\u001b[AAdjusting learning rate of group 0 to 1.1358e-03.\n",
      "Epoch 868:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.04it/s, loss=1.15e-07, v_num=23, train_loss=1.28e-5, test_loss=1.35e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 868:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.93it/s, loss=1.15e-07, v_num=23, train_loss=1.28e-5, test_loss=1.35e-5]\u001b[A\n",
      "Epoch 868: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.78it/s, loss=1.15e-07, v_num=23, train_loss=1.37e-5, test_loss=1.39e-5]\u001b[A\n",
      "Epoch 869:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.48it/s, loss=1.32e-07, v_num=23, train_loss=1.37e-5, test_loss=1.39e-5]\u001b[AAdjusting learning rate of group 0 to 1.1330e-03.\n",
      "Epoch 869:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.38it/s, loss=1.24e-07, v_num=23, train_loss=1.37e-5, test_loss=1.39e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 869:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 128.82it/s, loss=1.24e-07, v_num=23, train_loss=1.37e-5, test_loss=1.39e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 869: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 163.72it/s, loss=1.24e-07, v_num=23, train_loss=1.36e-5, test_loss=1.41e-5]\u001b[A\n",
      "Epoch 870:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.49it/s, loss=1.76e-07, v_num=23, train_loss=1.36e-5, test_loss=1.41e-5]\u001b[AAdjusting learning rate of group 0 to 1.1302e-03.\n",
      "Epoch 870:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.98it/s, loss=1.7e-07, v_num=23, train_loss=1.36e-5, test_loss=1.41e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 870:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.53it/s, loss=1.7e-07, v_num=23, train_loss=1.36e-5, test_loss=1.41e-5]\u001b[A\n",
      "Epoch 870: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 169.37it/s, loss=1.7e-07, v_num=23, train_loss=1.63e-5, test_loss=1.7e-5]\u001b[A\n",
      "Epoch 871:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.81it/s, loss=1.29e-07, v_num=23, train_loss=1.63e-5, test_loss=1.7e-5]\u001b[AAdjusting learning rate of group 0 to 1.1273e-03.\n",
      "Epoch 871:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.78it/s, loss=1.25e-07, v_num=23, train_loss=1.63e-5, test_loss=1.7e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 871:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 130.47it/s, loss=1.25e-07, v_num=23, train_loss=1.63e-5, test_loss=1.7e-5]\u001b[A\n",
      "Epoch 871: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.27it/s, loss=1.25e-07, v_num=23, train_loss=1.33e-5, test_loss=1.41e-5]\u001b[A\n",
      "Epoch 872:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.72it/s, loss=1.04e-07, v_num=23, train_loss=1.33e-5, test_loss=1.41e-5]\u001b[AAdjusting learning rate of group 0 to 1.1245e-03.\n",
      "Epoch 872:  50%|█████████████████████                     | 79/158 [00:00<00:00, 138.33it/s, loss=1e-07, v_num=23, train_loss=1.33e-5, test_loss=1.41e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 872:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 132.93it/s, loss=1e-07, v_num=23, train_loss=1.33e-5, test_loss=1.41e-5]\u001b[A\n",
      "Epoch 872: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 168.42it/s, loss=1e-07, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 873:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.06it/s, loss=1.21e-07, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\u001b[AAdjusting learning rate of group 0 to 1.1217e-03.\n",
      "Epoch 873:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.68it/s, loss=1.18e-07, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 873:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.86it/s, loss=1.18e-07, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 873: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.55it/s, loss=1.18e-07, v_num=23, train_loss=1.21e-5, test_loss=1.26e-5]\u001b[A\n",
      "Epoch 874:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.60it/s, loss=1.41e-07, v_num=23, train_loss=1.21e-5, test_loss=1.26e-5]\u001b[AAdjusting learning rate of group 0 to 1.1189e-03.\n",
      "Epoch 874:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.59it/s, loss=1.37e-07, v_num=23, train_loss=1.21e-5, test_loss=1.26e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 874:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.56it/s, loss=1.37e-07, v_num=23, train_loss=1.21e-5, test_loss=1.26e-5]\u001b[A\n",
      "Epoch 874: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.60it/s, loss=1.37e-07, v_num=23, train_loss=1.28e-5, test_loss=1.33e-5]\u001b[A\n",
      "Epoch 875:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.87it/s, loss=1.29e-07, v_num=23, train_loss=1.28e-5, test_loss=1.33e-5]\u001b[AAdjusting learning rate of group 0 to 1.1161e-03.\n",
      "Epoch 875:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.16it/s, loss=1.25e-07, v_num=23, train_loss=1.28e-5, test_loss=1.33e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 875:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.48it/s, loss=1.25e-07, v_num=23, train_loss=1.28e-5, test_loss=1.33e-5]\u001b[A\n",
      "Epoch 875: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.92it/s, loss=1.25e-07, v_num=23, train_loss=1.25e-5, test_loss=1.32e-5]\u001b[A\n",
      "Epoch 876:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.18it/s, loss=9.53e-08, v_num=23, train_loss=1.25e-5, test_loss=1.32e-5]\u001b[AAdjusting learning rate of group 0 to 1.1133e-03.\n",
      "Epoch 876:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.94it/s, loss=9.24e-08, v_num=23, train_loss=1.25e-5, test_loss=1.32e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 876:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.88it/s, loss=9.24e-08, v_num=23, train_loss=1.25e-5, test_loss=1.32e-5]\u001b[A\n",
      "Epoch 876: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 171.01it/s, loss=9.24e-08, v_num=23, train_loss=1e-5, test_loss=1.07e-5]\u001b[A\n",
      "Epoch 877:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 149.70it/s, loss=1.47e-07, v_num=23, train_loss=1e-5, test_loss=1.07e-5]\u001b[AAdjusting learning rate of group 0 to 1.1105e-03.\n",
      "Epoch 877:  50%|█████████████████████                     | 79/158 [00:00<00:00, 139.36it/s, loss=1.43e-07, v_num=23, train_loss=1e-5, test_loss=1.07e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 877:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 132.89it/s, loss=1.43e-07, v_num=23, train_loss=1e-5, test_loss=1.07e-5]\u001b[A\n",
      "Epoch 877: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.02it/s, loss=1.43e-07, v_num=23, train_loss=1.32e-5, test_loss=1.37e-5]\u001b[A\n",
      "Epoch 878:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.35it/s, loss=1.19e-07, v_num=23, train_loss=1.32e-5, test_loss=1.37e-5]\u001b[AAdjusting learning rate of group 0 to 1.1078e-03.\n",
      "Epoch 878:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.06it/s, loss=1.13e-07, v_num=23, train_loss=1.32e-5, test_loss=1.37e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 878:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.37it/s, loss=1.13e-07, v_num=23, train_loss=1.32e-5, test_loss=1.37e-5]\u001b[A\n",
      "Epoch 878: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.73it/s, loss=1.13e-07, v_num=23, train_loss=1.14e-5, test_loss=1.23e-5]\u001b[A\n",
      "Epoch 879:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.47it/s, loss=1.31e-07, v_num=23, train_loss=1.14e-5, test_loss=1.23e-5]\u001b[AAdjusting learning rate of group 0 to 1.1050e-03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 879:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.48it/s, loss=1.27e-07, v_num=23, train_loss=1.14e-5, test_loss=1.23e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 879:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.52it/s, loss=1.27e-07, v_num=23, train_loss=1.14e-5, test_loss=1.23e-5]\u001b[A\n",
      "Epoch 879: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.56it/s, loss=1.27e-07, v_num=23, train_loss=1.55e-5, test_loss=1.6e-5]\u001b[A\n",
      "Epoch 880:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.97it/s, loss=1.24e-07, v_num=23, train_loss=1.55e-5, test_loss=1.6e-5]\u001b[AAdjusting learning rate of group 0 to 1.1022e-03.\n",
      "Epoch 880:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.17it/s, loss=1.18e-07, v_num=23, train_loss=1.55e-5, test_loss=1.6e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 880:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.63it/s, loss=1.18e-07, v_num=23, train_loss=1.55e-5, test_loss=1.6e-5]\u001b[A\n",
      "Epoch 880: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.70it/s, loss=1.18e-07, v_num=23, train_loss=1.35e-5, test_loss=1.41e-5]\u001b[A\n",
      "Epoch 881:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.77it/s, loss=1.16e-07, v_num=23, train_loss=1.35e-5, test_loss=1.41e-5]\u001b[AAdjusting learning rate of group 0 to 1.0995e-03.\n",
      "Epoch 881:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.96it/s, loss=1.11e-07, v_num=23, train_loss=1.35e-5, test_loss=1.41e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 881:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.42it/s, loss=1.11e-07, v_num=23, train_loss=1.35e-5, test_loss=1.41e-5]\u001b[A\n",
      "Epoch 881: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.96it/s, loss=1.11e-07, v_num=23, train_loss=1.58e-5, test_loss=1.6e-5]\u001b[A\n",
      "Epoch 882:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.03it/s, loss=9.77e-08, v_num=23, train_loss=1.58e-5, test_loss=1.6e-5]\u001b[AAdjusting learning rate of group 0 to 1.0967e-03.\n",
      "Epoch 882:  50%|████████████████████                    | 79/158 [00:00<00:00, 136.91it/s, loss=9.36e-08, v_num=23, train_loss=1.58e-5, test_loss=1.6e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 882:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 130.72it/s, loss=9.36e-08, v_num=23, train_loss=1.58e-5, test_loss=1.6e-5]\u001b[A\n",
      "Epoch 882: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.86it/s, loss=9.36e-08, v_num=23, train_loss=1.12e-5, test_loss=1.17e-5]\u001b[A\n",
      "Epoch 883:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.76it/s, loss=1.2e-07, v_num=23, train_loss=1.12e-5, test_loss=1.17e-5]\u001b[AAdjusting learning rate of group 0 to 1.0940e-03.\n",
      "Epoch 883:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.21it/s, loss=1.16e-07, v_num=23, train_loss=1.12e-5, test_loss=1.17e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 883:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.73it/s, loss=1.16e-07, v_num=23, train_loss=1.12e-5, test_loss=1.17e-5]\u001b[A\n",
      "Epoch 883: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.27it/s, loss=1.16e-07, v_num=23, train_loss=1.31e-5, test_loss=1.37e-5]\u001b[A\n",
      "Epoch 884:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.73it/s, loss=1.21e-07, v_num=23, train_loss=1.31e-5, test_loss=1.37e-5]\u001b[AAdjusting learning rate of group 0 to 1.0912e-03.\n",
      "Epoch 884:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.96it/s, loss=1.15e-07, v_num=23, train_loss=1.31e-5, test_loss=1.37e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 884:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.15it/s, loss=1.15e-07, v_num=23, train_loss=1.31e-5, test_loss=1.37e-5]\u001b[A\n",
      "Epoch 884: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.30it/s, loss=1.15e-07, v_num=23, train_loss=1.38e-5, test_loss=1.45e-5]\u001b[A\n",
      "Epoch 885:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.42it/s, loss=1.18e-07, v_num=23, train_loss=1.38e-5, test_loss=1.45e-5]\u001b[AAdjusting learning rate of group 0 to 1.0885e-03.\n",
      "Epoch 885:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.98it/s, loss=1.12e-07, v_num=23, train_loss=1.38e-5, test_loss=1.45e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 885:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.49it/s, loss=1.12e-07, v_num=23, train_loss=1.38e-5, test_loss=1.45e-5]\u001b[A\n",
      "Epoch 885: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.59it/s, loss=1.12e-07, v_num=23, train_loss=1.2e-5, test_loss=1.24e-5]\u001b[A\n",
      "Epoch 886:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.13it/s, loss=1.31e-07, v_num=23, train_loss=1.2e-5, test_loss=1.24e-5]\u001b[AAdjusting learning rate of group 0 to 1.0858e-03.\n",
      "Epoch 886:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.35it/s, loss=1.25e-07, v_num=23, train_loss=1.2e-5, test_loss=1.24e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 886:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.30it/s, loss=1.25e-07, v_num=23, train_loss=1.2e-5, test_loss=1.24e-5]\u001b[A\n",
      "Epoch 886: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.71it/s, loss=1.25e-07, v_num=23, train_loss=1.59e-5, test_loss=1.65e-5]\u001b[A\n",
      "Epoch 887:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.02it/s, loss=1.36e-07, v_num=23, train_loss=1.59e-5, test_loss=1.65e-5]\u001b[AAdjusting learning rate of group 0 to 1.0831e-03.\n",
      "Epoch 887:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.72it/s, loss=1.31e-07, v_num=23, train_loss=1.59e-5, test_loss=1.65e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 887:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.56it/s, loss=1.31e-07, v_num=23, train_loss=1.59e-5, test_loss=1.65e-5]\u001b[A\n",
      "Epoch 887: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.84it/s, loss=1.31e-07, v_num=23, train_loss=1.36e-5, test_loss=1.42e-5]\u001b[A\n",
      "Epoch 888:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.79it/s, loss=1.5e-07, v_num=23, train_loss=1.36e-5, test_loss=1.42e-5]\u001b[AAdjusting learning rate of group 0 to 1.0804e-03.\n",
      "Epoch 888:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.36it/s, loss=1.45e-07, v_num=23, train_loss=1.36e-5, test_loss=1.42e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 888:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.21it/s, loss=1.45e-07, v_num=23, train_loss=1.36e-5, test_loss=1.42e-5]\u001b[A\n",
      "Epoch 888: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.91it/s, loss=1.45e-07, v_num=23, train_loss=1.03e-5, test_loss=1.07e-5]\u001b[A\n",
      "Epoch 889:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.99it/s, loss=1.61e-07, v_num=23, train_loss=1.03e-5, test_loss=1.07e-5]\u001b[AAdjusting learning rate of group 0 to 1.0777e-03.\n",
      "Epoch 889:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.07it/s, loss=1.54e-07, v_num=23, train_loss=1.03e-5, test_loss=1.07e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 889:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.66it/s, loss=1.54e-07, v_num=23, train_loss=1.03e-5, test_loss=1.07e-5]\u001b[A\n",
      "Epoch 889: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.78it/s, loss=1.54e-07, v_num=23, train_loss=1.47e-5, test_loss=1.54e-5]\u001b[A\n",
      "Epoch 890:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.65it/s, loss=1.84e-07, v_num=23, train_loss=1.47e-5, test_loss=1.54e-5]\u001b[AAdjusting learning rate of group 0 to 1.0750e-03.\n",
      "Epoch 890:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.72it/s, loss=1.7e-07, v_num=23, train_loss=1.47e-5, test_loss=1.54e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 890:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.96it/s, loss=1.7e-07, v_num=23, train_loss=1.47e-5, test_loss=1.54e-5]\u001b[A\n",
      "Epoch 890: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.86it/s, loss=1.7e-07, v_num=23, train_loss=1.92e-5, test_loss=1.94e-5]\u001b[A\n",
      "Epoch 891:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.07it/s, loss=1.69e-07, v_num=23, train_loss=1.92e-5, test_loss=1.94e-5]\u001b[AAdjusting learning rate of group 0 to 1.0723e-03.\n",
      "Epoch 891:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.52it/s, loss=1.64e-07, v_num=23, train_loss=1.92e-5, test_loss=1.94e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 891:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.31it/s, loss=1.64e-07, v_num=23, train_loss=1.92e-5, test_loss=1.94e-5]\u001b[A\n",
      "Epoch 891: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.46it/s, loss=1.64e-07, v_num=23, train_loss=1.8e-5, test_loss=1.86e-5]\u001b[A\n",
      "Epoch 892:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.96it/s, loss=1.07e-07, v_num=23, train_loss=1.8e-5, test_loss=1.86e-5]\u001b[AAdjusting learning rate of group 0 to 1.0696e-03.\n",
      "Epoch 892:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.36it/s, loss=9.96e-08, v_num=23, train_loss=1.8e-5, test_loss=1.86e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 892:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.44it/s, loss=9.96e-08, v_num=23, train_loss=1.8e-5, test_loss=1.86e-5]\u001b[A\n",
      "Epoch 892: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.96it/s, loss=9.96e-08, v_num=23, train_loss=9.47e-6, test_loss=9.91e-6]\u001b[A\n",
      "Epoch 893:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.22it/s, loss=1.2e-07, v_num=23, train_loss=9.47e-6, test_loss=9.91e-6]\u001b[AAdjusting learning rate of group 0 to 1.0669e-03.\n",
      "Epoch 893:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.76it/s, loss=1.13e-07, v_num=23, train_loss=9.47e-6, test_loss=9.91e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 893:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.81it/s, loss=1.13e-07, v_num=23, train_loss=9.47e-6, test_loss=9.91e-6]\u001b[A\n",
      "Epoch 893: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.48it/s, loss=1.13e-07, v_num=23, train_loss=1.16e-5, test_loss=1.22e-5]\u001b[A\n",
      "Epoch 894:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.07it/s, loss=1.26e-07, v_num=23, train_loss=1.16e-5, test_loss=1.22e-5]\u001b[AAdjusting learning rate of group 0 to 1.0643e-03.\n",
      "Epoch 894:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.76it/s, loss=1.2e-07, v_num=23, train_loss=1.16e-5, test_loss=1.22e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 894:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.70it/s, loss=1.2e-07, v_num=23, train_loss=1.16e-5, test_loss=1.22e-5]\u001b[A\n",
      "Epoch 894: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.07it/s, loss=1.2e-07, v_num=23, train_loss=1.28e-5, test_loss=1.34e-5]\u001b[A\n",
      "Epoch 895:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.79it/s, loss=1.36e-07, v_num=23, train_loss=1.28e-5, test_loss=1.34e-5]\u001b[AAdjusting learning rate of group 0 to 1.0616e-03.\n",
      "Epoch 895:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.56it/s, loss=1.3e-07, v_num=23, train_loss=1.28e-5, test_loss=1.34e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 895:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 135.81it/s, loss=1.3e-07, v_num=23, train_loss=1.28e-5, test_loss=1.34e-5]\u001b[A\n",
      "Epoch 895: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 171.62it/s, loss=1.3e-07, v_num=23, train_loss=1.47e-5, test_loss=1.55e-5]\u001b[A\n",
      "Epoch 896:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.44it/s, loss=1.23e-07, v_num=23, train_loss=1.47e-5, test_loss=1.55e-5]\u001b[AAdjusting learning rate of group 0 to 1.0589e-03.\n",
      "Epoch 896:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.89it/s, loss=1.18e-07, v_num=23, train_loss=1.47e-5, test_loss=1.55e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 896:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.73it/s, loss=1.18e-07, v_num=23, train_loss=1.47e-5, test_loss=1.55e-5]\u001b[A\n",
      "Epoch 896: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.39it/s, loss=1.18e-07, v_num=23, train_loss=2.01e-5, test_loss=2.07e-5]\u001b[A\n",
      "Epoch 897:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.84it/s, loss=1.14e-07, v_num=23, train_loss=2.01e-5, test_loss=2.07e-5]\u001b[AAdjusting learning rate of group 0 to 1.0563e-03.\n",
      "Epoch 897:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.77it/s, loss=1.11e-07, v_num=23, train_loss=2.01e-5, test_loss=2.07e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 897:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.11it/s, loss=1.11e-07, v_num=23, train_loss=2.01e-5, test_loss=2.07e-5]\u001b[A\n",
      "Epoch 897: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.99it/s, loss=1.11e-07, v_num=23, train_loss=1.04e-5, test_loss=1.1e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 898:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.26it/s, loss=1.35e-07, v_num=23, train_loss=1.04e-5, test_loss=1.1e-5]\u001b[AAdjusting learning rate of group 0 to 1.0537e-03.\n",
      "Epoch 898:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.39it/s, loss=1.31e-07, v_num=23, train_loss=1.04e-5, test_loss=1.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 898:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.19it/s, loss=1.31e-07, v_num=23, train_loss=1.04e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 898: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.59it/s, loss=1.31e-07, v_num=23, train_loss=1.3e-5, test_loss=1.37e-5]\u001b[A\n",
      "Epoch 899:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.90it/s, loss=1.1e-07, v_num=23, train_loss=1.3e-5, test_loss=1.37e-5]\u001b[AAdjusting learning rate of group 0 to 1.0510e-03.\n",
      "Epoch 899:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.64it/s, loss=1.06e-07, v_num=23, train_loss=1.3e-5, test_loss=1.37e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 899:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.49it/s, loss=1.06e-07, v_num=23, train_loss=1.3e-5, test_loss=1.37e-5]\u001b[A\n",
      "Epoch 899: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.91it/s, loss=1.06e-07, v_num=23, train_loss=1.1e-5, test_loss=1.16e-5]\u001b[A\n",
      "Epoch 900:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.77it/s, loss=1.34e-07, v_num=23, train_loss=1.1e-5, test_loss=1.16e-5]\u001b[AAdjusting learning rate of group 0 to 1.0484e-03.\n",
      "Epoch 900:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 138.06it/s, loss=1.3e-07, v_num=23, train_loss=1.1e-5, test_loss=1.16e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 900:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 131.54it/s, loss=1.3e-07, v_num=23, train_loss=1.1e-5, test_loss=1.16e-5]\u001b[A\n",
      "Epoch 900: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.33it/s, loss=1.3e-07, v_num=23, train_loss=1.68e-5, test_loss=1.76e-5]\u001b[A\n",
      "Epoch 901:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.64it/s, loss=1.29e-07, v_num=23, train_loss=1.68e-5, test_loss=1.76e-5]\u001b[AAdjusting learning rate of group 0 to 1.0458e-03.\n",
      "Epoch 901:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.63it/s, loss=1.24e-07, v_num=23, train_loss=1.68e-5, test_loss=1.76e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 901:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.32it/s, loss=1.24e-07, v_num=23, train_loss=1.68e-5, test_loss=1.76e-5]\u001b[A\n",
      "Epoch 901: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 166.95it/s, loss=1.24e-07, v_num=23, train_loss=2e-5, test_loss=2.03e-5]\u001b[A\n",
      "Epoch 902:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 148.25it/s, loss=1.22e-07, v_num=23, train_loss=2e-5, test_loss=2.03e-5]\u001b[AAdjusting learning rate of group 0 to 1.0432e-03.\n",
      "Epoch 902:  50%|█████████████████████                     | 79/158 [00:00<00:00, 140.52it/s, loss=1.15e-07, v_num=23, train_loss=2e-5, test_loss=2.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 902:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 132.55it/s, loss=1.15e-07, v_num=23, train_loss=2e-5, test_loss=2.03e-5]\u001b[A\n",
      "Epoch 902: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.01it/s, loss=1.15e-07, v_num=23, train_loss=1.24e-5, test_loss=1.28e-5]\u001b[A\n",
      "Epoch 903:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.40it/s, loss=1.19e-07, v_num=23, train_loss=1.24e-5, test_loss=1.28e-5]\u001b[AAdjusting learning rate of group 0 to 1.0406e-03.\n",
      "Epoch 903:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.33it/s, loss=1.16e-07, v_num=23, train_loss=1.24e-5, test_loss=1.28e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 903:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.11it/s, loss=1.16e-07, v_num=23, train_loss=1.24e-5, test_loss=1.28e-5]\u001b[A\n",
      "Epoch 903: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.72it/s, loss=1.16e-07, v_num=23, train_loss=1.13e-5, test_loss=1.17e-5]\u001b[A\n",
      "Epoch 904:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.76it/s, loss=1.24e-07, v_num=23, train_loss=1.13e-5, test_loss=1.17e-5]\u001b[AAdjusting learning rate of group 0 to 1.0380e-03.\n",
      "Epoch 904:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.85it/s, loss=1.18e-07, v_num=23, train_loss=1.13e-5, test_loss=1.17e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 904:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.45it/s, loss=1.18e-07, v_num=23, train_loss=1.13e-5, test_loss=1.17e-5]\u001b[A\n",
      "Epoch 904: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.98it/s, loss=1.18e-07, v_num=23, train_loss=1.35e-5, test_loss=1.42e-5]\u001b[A\n",
      "Epoch 905:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.24it/s, loss=1.22e-07, v_num=23, train_loss=1.35e-5, test_loss=1.42e-5]\u001b[AAdjusting learning rate of group 0 to 1.0354e-03.\n",
      "Epoch 905:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.14it/s, loss=1.16e-07, v_num=23, train_loss=1.35e-5, test_loss=1.42e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 905:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.05it/s, loss=1.16e-07, v_num=23, train_loss=1.35e-5, test_loss=1.42e-5]\u001b[A\n",
      "Epoch 905: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.81it/s, loss=1.16e-07, v_num=23, train_loss=1.31e-5, test_loss=1.36e-5]\u001b[A\n",
      "Epoch 906:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.42it/s, loss=1.37e-07, v_num=23, train_loss=1.31e-5, test_loss=1.36e-5]\u001b[AAdjusting learning rate of group 0 to 1.0328e-03.\n",
      "Epoch 906:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.10it/s, loss=1.33e-07, v_num=23, train_loss=1.31e-5, test_loss=1.36e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 906:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.98it/s, loss=1.33e-07, v_num=23, train_loss=1.31e-5, test_loss=1.36e-5]\u001b[A\n",
      "Epoch 906: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.97it/s, loss=1.33e-07, v_num=23, train_loss=1.75e-5, test_loss=1.82e-5]\u001b[A\n",
      "Epoch 907:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.19it/s, loss=1.2e-07, v_num=23, train_loss=1.75e-5, test_loss=1.82e-5]\u001b[AAdjusting learning rate of group 0 to 1.0302e-03.\n",
      "Epoch 907:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.46it/s, loss=1.15e-07, v_num=23, train_loss=1.75e-5, test_loss=1.82e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 907:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.49it/s, loss=1.15e-07, v_num=23, train_loss=1.75e-5, test_loss=1.82e-5]\u001b[A\n",
      "Epoch 907: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.63it/s, loss=1.15e-07, v_num=23, train_loss=1.66e-5, test_loss=1.74e-5]\u001b[A\n",
      "Epoch 908:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.23it/s, loss=1.3e-07, v_num=23, train_loss=1.66e-5, test_loss=1.74e-5]\u001b[AAdjusting learning rate of group 0 to 1.0276e-03.\n",
      "Epoch 908:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.69it/s, loss=1.25e-07, v_num=23, train_loss=1.66e-5, test_loss=1.74e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 908:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 128.34it/s, loss=1.25e-07, v_num=23, train_loss=1.66e-5, test_loss=1.74e-5]\u001b[A\n",
      "Epoch 908: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.13it/s, loss=1.25e-07, v_num=23, train_loss=1.26e-5, test_loss=1.36e-5]\u001b[A\n",
      "Epoch 909:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.55it/s, loss=1.07e-07, v_num=23, train_loss=1.26e-5, test_loss=1.36e-5]\u001b[AAdjusting learning rate of group 0 to 1.0250e-03.\n",
      "Epoch 909:  50%|█████████████████████                     | 79/158 [00:00<00:00, 136.45it/s, loss=1e-07, v_num=23, train_loss=1.26e-5, test_loss=1.36e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 909:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 127.73it/s, loss=1e-07, v_num=23, train_loss=1.26e-5, test_loss=1.36e-5]\u001b[A\n",
      "Epoch 909: 100%|██████████████████████████████████████████| 158/158 [00:00<00:00, 162.63it/s, loss=1e-07, v_num=23, train_loss=1.2e-5, test_loss=1.27e-5]\u001b[A\n",
      "Epoch 910:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.11it/s, loss=1.08e-07, v_num=23, train_loss=1.2e-5, test_loss=1.27e-5]\u001b[AAdjusting learning rate of group 0 to 1.0225e-03.\n",
      "Epoch 910:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.08it/s, loss=1.02e-07, v_num=23, train_loss=1.2e-5, test_loss=1.27e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 910:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.01it/s, loss=1.02e-07, v_num=23, train_loss=1.2e-5, test_loss=1.27e-5]\u001b[A\n",
      "Epoch 910: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.44it/s, loss=1.02e-07, v_num=23, train_loss=1.22e-5, test_loss=1.29e-5]\u001b[A\n",
      "Epoch 911:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.79it/s, loss=1.3e-07, v_num=23, train_loss=1.22e-5, test_loss=1.29e-5]\u001b[AAdjusting learning rate of group 0 to 1.0199e-03.\n",
      "Epoch 911:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.61it/s, loss=1.26e-07, v_num=23, train_loss=1.22e-5, test_loss=1.29e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 911:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.45it/s, loss=1.26e-07, v_num=23, train_loss=1.22e-5, test_loss=1.29e-5]\u001b[A\n",
      "Epoch 911: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.41it/s, loss=1.26e-07, v_num=23, train_loss=1.28e-5, test_loss=1.32e-5]\u001b[A\n",
      "Epoch 912:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.21it/s, loss=1.16e-07, v_num=23, train_loss=1.28e-5, test_loss=1.32e-5]\u001b[AAdjusting learning rate of group 0 to 1.0174e-03.\n",
      "Epoch 912:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.19it/s, loss=1.13e-07, v_num=23, train_loss=1.28e-5, test_loss=1.32e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 912:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.15it/s, loss=1.13e-07, v_num=23, train_loss=1.28e-5, test_loss=1.32e-5]\u001b[A\n",
      "Epoch 912: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.87it/s, loss=1.13e-07, v_num=23, train_loss=1.58e-5, test_loss=1.65e-5]\u001b[A\n",
      "Epoch 913:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.91it/s, loss=1.23e-07, v_num=23, train_loss=1.58e-5, test_loss=1.65e-5]\u001b[AAdjusting learning rate of group 0 to 1.0148e-03.\n",
      "Epoch 913:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.16it/s, loss=1.18e-07, v_num=23, train_loss=1.58e-5, test_loss=1.65e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 913:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.89it/s, loss=1.18e-07, v_num=23, train_loss=1.58e-5, test_loss=1.65e-5]\u001b[A\n",
      "Epoch 913: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.08it/s, loss=1.18e-07, v_num=23, train_loss=1.27e-5, test_loss=1.34e-5]\u001b[A\n",
      "Epoch 914:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.62it/s, loss=1.33e-07, v_num=23, train_loss=1.27e-5, test_loss=1.34e-5]\u001b[AAdjusting learning rate of group 0 to 1.0123e-03.\n",
      "Epoch 914:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.77it/s, loss=1.25e-07, v_num=23, train_loss=1.27e-5, test_loss=1.34e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 914:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.24it/s, loss=1.25e-07, v_num=23, train_loss=1.27e-5, test_loss=1.34e-5]\u001b[A\n",
      "Epoch 914: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.69it/s, loss=1.25e-07, v_num=23, train_loss=1.96e-5, test_loss=2.03e-5]\u001b[A\n",
      "Epoch 915:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.69it/s, loss=1.16e-07, v_num=23, train_loss=1.96e-5, test_loss=2.03e-5]\u001b[AAdjusting learning rate of group 0 to 1.0098e-03.\n",
      "Epoch 915:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.53it/s, loss=1.13e-07, v_num=23, train_loss=1.96e-5, test_loss=2.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 915:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.05it/s, loss=1.13e-07, v_num=23, train_loss=1.96e-5, test_loss=2.03e-5]\u001b[A\n",
      "Epoch 915: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.99it/s, loss=1.13e-07, v_num=23, train_loss=1.48e-5, test_loss=1.53e-5]\u001b[A\n",
      "Epoch 916:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.96it/s, loss=9.85e-08, v_num=23, train_loss=1.48e-5, test_loss=1.53e-5]\u001b[AAdjusting learning rate of group 0 to 1.0072e-03.\n",
      "Epoch 916:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.42it/s, loss=9.52e-08, v_num=23, train_loss=1.48e-5, test_loss=1.53e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 916:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.59it/s, loss=9.52e-08, v_num=23, train_loss=1.48e-5, test_loss=1.53e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 916: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.50it/s, loss=9.52e-08, v_num=23, train_loss=1.2e-5, test_loss=1.28e-5]\u001b[A\n",
      "Epoch 917:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.24it/s, loss=1.21e-07, v_num=23, train_loss=1.2e-5, test_loss=1.28e-5]\u001b[AAdjusting learning rate of group 0 to 1.0047e-03.\n",
      "Epoch 917:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.40it/s, loss=1.18e-07, v_num=23, train_loss=1.2e-5, test_loss=1.28e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 917:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.85it/s, loss=1.18e-07, v_num=23, train_loss=1.2e-5, test_loss=1.28e-5]\u001b[A\n",
      "Epoch 917: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.61it/s, loss=1.18e-07, v_num=23, train_loss=1.69e-5, test_loss=1.76e-5]\u001b[A\n",
      "Epoch 918:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 150.69it/s, loss=1.1e-07, v_num=23, train_loss=1.69e-5, test_loss=1.76e-5]\u001b[AAdjusting learning rate of group 0 to 1.0022e-03.\n",
      "Epoch 918:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.39it/s, loss=9.97e-08, v_num=23, train_loss=1.69e-5, test_loss=1.76e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 918:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.13it/s, loss=9.97e-08, v_num=23, train_loss=1.69e-5, test_loss=1.76e-5]\u001b[A\n",
      "Epoch 918: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.69it/s, loss=9.97e-08, v_num=23, train_loss=1.24e-5, test_loss=1.3e-5]\u001b[A\n",
      "Epoch 919:  49%|█████████████████████▏                     | 78/158 [00:00<00:00, 149.45it/s, loss=1e-07, v_num=23, train_loss=1.24e-5, test_loss=1.3e-5]\u001b[AAdjusting learning rate of group 0 to 9.9971e-04.\n",
      "Epoch 919:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.80it/s, loss=9.54e-08, v_num=23, train_loss=1.24e-5, test_loss=1.3e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 919:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.80it/s, loss=9.54e-08, v_num=23, train_loss=1.24e-5, test_loss=1.3e-5]\u001b[A\n",
      "Epoch 919: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.62it/s, loss=9.54e-08, v_num=23, train_loss=1.08e-5, test_loss=1.15e-5]\u001b[A\n",
      "Epoch 920:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.00it/s, loss=1.39e-07, v_num=23, train_loss=1.08e-5, test_loss=1.15e-5]\u001b[AAdjusting learning rate of group 0 to 9.9721e-04.\n",
      "Epoch 920:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.80it/s, loss=1.35e-07, v_num=23, train_loss=1.08e-5, test_loss=1.15e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 920:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.08it/s, loss=1.35e-07, v_num=23, train_loss=1.08e-5, test_loss=1.15e-5]\u001b[A\n",
      "Epoch 920: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.26it/s, loss=1.35e-07, v_num=23, train_loss=1.45e-5, test_loss=1.52e-5]\u001b[A\n",
      "Epoch 921:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.83it/s, loss=1.52e-07, v_num=23, train_loss=1.45e-5, test_loss=1.52e-5]\u001b[AAdjusting learning rate of group 0 to 9.9471e-04.\n",
      "Epoch 921:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.98it/s, loss=1.44e-07, v_num=23, train_loss=1.45e-5, test_loss=1.52e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 921:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.67it/s, loss=1.44e-07, v_num=23, train_loss=1.45e-5, test_loss=1.52e-5]\u001b[A\n",
      "Epoch 921: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.03it/s, loss=1.44e-07, v_num=23, train_loss=1.74e-5, test_loss=1.85e-5]\u001b[A\n",
      "Epoch 922:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.14it/s, loss=1.47e-07, v_num=23, train_loss=1.74e-5, test_loss=1.85e-5]\u001b[AAdjusting learning rate of group 0 to 9.9223e-04.\n",
      "Epoch 922:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.78it/s, loss=1.44e-07, v_num=23, train_loss=1.74e-5, test_loss=1.85e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 922:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.09it/s, loss=1.44e-07, v_num=23, train_loss=1.74e-5, test_loss=1.85e-5]\u001b[A\n",
      "Epoch 922: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.19it/s, loss=1.44e-07, v_num=23, train_loss=2.07e-5, test_loss=2.14e-5]\u001b[A\n",
      "Epoch 923:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.06it/s, loss=1.37e-07, v_num=23, train_loss=2.07e-5, test_loss=2.14e-5]\u001b[AAdjusting learning rate of group 0 to 9.8975e-04.\n",
      "Epoch 923:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.67it/s, loss=1.32e-07, v_num=23, train_loss=2.07e-5, test_loss=2.14e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 923:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.77it/s, loss=1.32e-07, v_num=23, train_loss=2.07e-5, test_loss=2.14e-5]\u001b[A\n",
      "Epoch 923: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.30it/s, loss=1.32e-07, v_num=23, train_loss=1.1e-5, test_loss=1.17e-5]\u001b[A\n",
      "Epoch 924:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.50it/s, loss=1.27e-07, v_num=23, train_loss=1.1e-5, test_loss=1.17e-5]\u001b[AAdjusting learning rate of group 0 to 9.8727e-04.\n",
      "Epoch 924:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.34it/s, loss=1.19e-07, v_num=23, train_loss=1.1e-5, test_loss=1.17e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 924:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.64it/s, loss=1.19e-07, v_num=23, train_loss=1.1e-5, test_loss=1.17e-5]\u001b[A\n",
      "Epoch 924: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.56it/s, loss=1.19e-07, v_num=23, train_loss=1.28e-5, test_loss=1.35e-5]\u001b[A\n",
      "Epoch 925:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.05it/s, loss=1.01e-07, v_num=23, train_loss=1.28e-5, test_loss=1.35e-5]\u001b[AAdjusting learning rate of group 0 to 9.8480e-04.\n",
      "Epoch 925:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.84it/s, loss=9.71e-08, v_num=23, train_loss=1.28e-5, test_loss=1.35e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 925:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.78it/s, loss=9.71e-08, v_num=23, train_loss=1.28e-5, test_loss=1.35e-5]\u001b[A\n",
      "Epoch 925: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.89it/s, loss=9.71e-08, v_num=23, train_loss=1.2e-5, test_loss=1.25e-5]\u001b[A\n",
      "Epoch 926:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.19it/s, loss=1.52e-07, v_num=23, train_loss=1.2e-5, test_loss=1.25e-5]\u001b[AAdjusting learning rate of group 0 to 9.8234e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 926:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.75it/s, loss=1.47e-07, v_num=23, train_loss=1.2e-5, test_loss=1.25e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 926:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.69it/s, loss=1.47e-07, v_num=23, train_loss=1.2e-5, test_loss=1.25e-5]\u001b[A\n",
      "Epoch 926: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.88it/s, loss=1.47e-07, v_num=23, train_loss=2.01e-5, test_loss=2.07e-5]\u001b[A\n",
      "Epoch 927:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.62it/s, loss=9.95e-08, v_num=23, train_loss=2.01e-5, test_loss=2.07e-5]\u001b[AAdjusting learning rate of group 0 to 9.7989e-04.\n",
      "Epoch 927:  50%|████████████████████                    | 79/158 [00:00<00:00, 136.93it/s, loss=9.5e-08, v_num=23, train_loss=2.01e-5, test_loss=2.07e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 927:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.29it/s, loss=9.5e-08, v_num=23, train_loss=2.01e-5, test_loss=2.07e-5]\u001b[A\n",
      "Epoch 927: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.29it/s, loss=9.5e-08, v_num=23, train_loss=9.87e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 928:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.81it/s, loss=1.29e-07, v_num=23, train_loss=9.87e-6, test_loss=1.05e-5]\u001b[AAdjusting learning rate of group 0 to 9.7744e-04.\n",
      "Epoch 928:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.01it/s, loss=1.24e-07, v_num=23, train_loss=9.87e-6, test_loss=1.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 928:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.65it/s, loss=1.24e-07, v_num=23, train_loss=9.87e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 928: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.75it/s, loss=1.24e-07, v_num=23, train_loss=1.1e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 929:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.31it/s, loss=1.2e-07, v_num=23, train_loss=1.1e-5, test_loss=1.14e-5]\u001b[AAdjusting learning rate of group 0 to 9.7499e-04.\n",
      "Epoch 929:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.30it/s, loss=1.14e-07, v_num=23, train_loss=1.1e-5, test_loss=1.14e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 929:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.62it/s, loss=1.14e-07, v_num=23, train_loss=1.1e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 929: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.51it/s, loss=1.14e-07, v_num=23, train_loss=1.95e-5, test_loss=2.01e-5]\u001b[A\n",
      "Epoch 930:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.79it/s, loss=1.33e-07, v_num=23, train_loss=1.95e-5, test_loss=2.01e-5]\u001b[AAdjusting learning rate of group 0 to 9.7255e-04.\n",
      "Epoch 930:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.85it/s, loss=1.27e-07, v_num=23, train_loss=1.95e-5, test_loss=2.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 930:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.34it/s, loss=1.27e-07, v_num=23, train_loss=1.95e-5, test_loss=2.01e-5]\u001b[A\n",
      "Epoch 930: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.23it/s, loss=1.27e-07, v_num=23, train_loss=1.23e-5, test_loss=1.31e-5]\u001b[A\n",
      "Epoch 931:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.30it/s, loss=1.14e-07, v_num=23, train_loss=1.23e-5, test_loss=1.31e-5]\u001b[AAdjusting learning rate of group 0 to 9.7012e-04.\n",
      "Epoch 931:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.50it/s, loss=1.08e-07, v_num=23, train_loss=1.23e-5, test_loss=1.31e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 931:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.62it/s, loss=1.08e-07, v_num=23, train_loss=1.23e-5, test_loss=1.31e-5]\u001b[A\n",
      "Epoch 931: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.58it/s, loss=1.08e-07, v_num=23, train_loss=1.71e-5, test_loss=1.79e-5]\u001b[A\n",
      "Epoch 932:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.55it/s, loss=1.06e-07, v_num=23, train_loss=1.71e-5, test_loss=1.79e-5]\u001b[AAdjusting learning rate of group 0 to 9.6770e-04.\n",
      "Epoch 932:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.31it/s, loss=9.96e-08, v_num=23, train_loss=1.71e-5, test_loss=1.79e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 932:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.95it/s, loss=9.96e-08, v_num=23, train_loss=1.71e-5, test_loss=1.79e-5]\u001b[A\n",
      "Epoch 932: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.33it/s, loss=9.96e-08, v_num=23, train_loss=1.17e-5, test_loss=1.24e-5]\u001b[A\n",
      "Epoch 933:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.92it/s, loss=1.15e-07, v_num=23, train_loss=1.17e-5, test_loss=1.24e-5]\u001b[AAdjusting learning rate of group 0 to 9.6528e-04.\n",
      "Epoch 933:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.22it/s, loss=1.07e-07, v_num=23, train_loss=1.17e-5, test_loss=1.24e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 933:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.66it/s, loss=1.07e-07, v_num=23, train_loss=1.17e-5, test_loss=1.24e-5]\u001b[A\n",
      "Epoch 933: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.95it/s, loss=1.07e-07, v_num=23, train_loss=1.14e-5, test_loss=1.2e-5]\u001b[A\n",
      "Epoch 934:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.25it/s, loss=1.43e-07, v_num=23, train_loss=1.14e-5, test_loss=1.2e-5]\u001b[AAdjusting learning rate of group 0 to 9.6287e-04.\n",
      "Epoch 934:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.12it/s, loss=1.33e-07, v_num=23, train_loss=1.14e-5, test_loss=1.2e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 934:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.04it/s, loss=1.33e-07, v_num=23, train_loss=1.14e-5, test_loss=1.2e-5]\u001b[A\n",
      "Epoch 934: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.39it/s, loss=1.33e-07, v_num=23, train_loss=1.19e-5, test_loss=1.25e-5]\u001b[A\n",
      "Epoch 935:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.97it/s, loss=1.24e-07, v_num=23, train_loss=1.19e-5, test_loss=1.25e-5]\u001b[AAdjusting learning rate of group 0 to 9.6046e-04.\n",
      "Epoch 935:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.13it/s, loss=1.2e-07, v_num=23, train_loss=1.19e-5, test_loss=1.25e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 935:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.86it/s, loss=1.2e-07, v_num=23, train_loss=1.19e-5, test_loss=1.25e-5]\u001b[A\n",
      "Epoch 935: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.50it/s, loss=1.2e-07, v_num=23, train_loss=1.83e-5, test_loss=1.88e-5]\u001b[A\n",
      "Epoch 936:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.88it/s, loss=1.63e-07, v_num=23, train_loss=1.83e-5, test_loss=1.88e-5]\u001b[AAdjusting learning rate of group 0 to 9.5806e-04.\n",
      "Epoch 936:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.75it/s, loss=1.57e-07, v_num=23, train_loss=1.83e-5, test_loss=1.88e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 936:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.47it/s, loss=1.57e-07, v_num=23, train_loss=1.83e-5, test_loss=1.88e-5]\u001b[A\n",
      "Epoch 936: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.20it/s, loss=1.57e-07, v_num=23, train_loss=1.7e-5, test_loss=1.73e-5]\u001b[A\n",
      "Epoch 937:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.46it/s, loss=1.17e-07, v_num=23, train_loss=1.7e-5, test_loss=1.73e-5]\u001b[AAdjusting learning rate of group 0 to 9.5566e-04.\n",
      "Epoch 937:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.57it/s, loss=1.11e-07, v_num=23, train_loss=1.7e-5, test_loss=1.73e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 937:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.87it/s, loss=1.11e-07, v_num=23, train_loss=1.7e-5, test_loss=1.73e-5]\u001b[A\n",
      "Epoch 937: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.40it/s, loss=1.11e-07, v_num=23, train_loss=1.15e-5, test_loss=1.21e-5]\u001b[A\n",
      "Epoch 938:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.35it/s, loss=1.21e-07, v_num=23, train_loss=1.15e-5, test_loss=1.21e-5]\u001b[AAdjusting learning rate of group 0 to 9.5327e-04.\n",
      "Epoch 938:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.27it/s, loss=1.15e-07, v_num=23, train_loss=1.15e-5, test_loss=1.21e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 938:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.83it/s, loss=1.15e-07, v_num=23, train_loss=1.15e-5, test_loss=1.21e-5]\u001b[A\n",
      "Epoch 938: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.00it/s, loss=1.15e-07, v_num=23, train_loss=1.12e-5, test_loss=1.18e-5]\u001b[A\n",
      "Epoch 939:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.50it/s, loss=1.21e-07, v_num=23, train_loss=1.12e-5, test_loss=1.18e-5]\u001b[AAdjusting learning rate of group 0 to 9.5089e-04.\n",
      "Epoch 939:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.49it/s, loss=1.16e-07, v_num=23, train_loss=1.12e-5, test_loss=1.18e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 939:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.59it/s, loss=1.16e-07, v_num=23, train_loss=1.12e-5, test_loss=1.18e-5]\u001b[A\n",
      "Epoch 939: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.46it/s, loss=1.16e-07, v_num=23, train_loss=1.08e-5, test_loss=1.16e-5]\u001b[A\n",
      "Epoch 940:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.76it/s, loss=1.09e-07, v_num=23, train_loss=1.08e-5, test_loss=1.16e-5]\u001b[AAdjusting learning rate of group 0 to 9.4851e-04.\n",
      "Epoch 940:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.84it/s, loss=1.03e-07, v_num=23, train_loss=1.08e-5, test_loss=1.16e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 940:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.02it/s, loss=1.03e-07, v_num=23, train_loss=1.08e-5, test_loss=1.16e-5]\u001b[A\n",
      "Epoch 940: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.21it/s, loss=1.03e-07, v_num=23, train_loss=1.39e-5, test_loss=1.45e-5]\u001b[A\n",
      "Epoch 941:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.77it/s, loss=1.24e-07, v_num=23, train_loss=1.39e-5, test_loss=1.45e-5]\u001b[AAdjusting learning rate of group 0 to 9.4614e-04.\n",
      "Epoch 941:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.79it/s, loss=1.18e-07, v_num=23, train_loss=1.39e-5, test_loss=1.45e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 941:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.37it/s, loss=1.18e-07, v_num=23, train_loss=1.39e-5, test_loss=1.45e-5]\u001b[A\n",
      "Epoch 941: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.11it/s, loss=1.18e-07, v_num=23, train_loss=1.05e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 942:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.91it/s, loss=1.04e-07, v_num=23, train_loss=1.05e-5, test_loss=1.1e-5]\u001b[AAdjusting learning rate of group 0 to 9.4378e-04.\n",
      "Epoch 942:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.06it/s, loss=9.83e-08, v_num=23, train_loss=1.05e-5, test_loss=1.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 942:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.88it/s, loss=9.83e-08, v_num=23, train_loss=1.05e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 942: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.92it/s, loss=9.83e-08, v_num=23, train_loss=1.23e-5, test_loss=1.32e-5]\u001b[A\n",
      "Epoch 943:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.94it/s, loss=1.05e-07, v_num=23, train_loss=1.23e-5, test_loss=1.32e-5]\u001b[AAdjusting learning rate of group 0 to 9.4142e-04.\n",
      "Epoch 943:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.48it/s, loss=9.94e-08, v_num=23, train_loss=1.23e-5, test_loss=1.32e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 943:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.63it/s, loss=9.94e-08, v_num=23, train_loss=1.23e-5, test_loss=1.32e-5]\u001b[A\n",
      "Epoch 943: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.79it/s, loss=9.94e-08, v_num=23, train_loss=1.25e-5, test_loss=1.33e-5]\u001b[A\n",
      "Epoch 944:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.58it/s, loss=1.07e-07, v_num=23, train_loss=1.25e-5, test_loss=1.33e-5]\u001b[AAdjusting learning rate of group 0 to 9.3906e-04.\n",
      "Epoch 944:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.91it/s, loss=1.01e-07, v_num=23, train_loss=1.25e-5, test_loss=1.33e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 944:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.36it/s, loss=1.01e-07, v_num=23, train_loss=1.25e-5, test_loss=1.33e-5]\u001b[A\n",
      "Epoch 944: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 165.75it/s, loss=1.01e-07, v_num=23, train_loss=1.2e-5, test_loss=1.29e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 945:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 146.74it/s, loss=1.2e-07, v_num=23, train_loss=1.2e-5, test_loss=1.29e-5]\u001b[AAdjusting learning rate of group 0 to 9.3672e-04.\n",
      "Epoch 945:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.13it/s, loss=1.16e-07, v_num=23, train_loss=1.2e-5, test_loss=1.29e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 945:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.21it/s, loss=1.16e-07, v_num=23, train_loss=1.2e-5, test_loss=1.29e-5]\u001b[A\n",
      "Epoch 945: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.42it/s, loss=1.16e-07, v_num=23, train_loss=1.21e-5, test_loss=1.28e-5]\u001b[A\n",
      "Epoch 946:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.51it/s, loss=1.28e-07, v_num=23, train_loss=1.21e-5, test_loss=1.28e-5]\u001b[AAdjusting learning rate of group 0 to 9.3437e-04.\n",
      "Epoch 946:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.10it/s, loss=1.24e-07, v_num=23, train_loss=1.21e-5, test_loss=1.28e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 946:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.02it/s, loss=1.24e-07, v_num=23, train_loss=1.21e-5, test_loss=1.28e-5]\u001b[A\n",
      "Epoch 946: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.89it/s, loss=1.24e-07, v_num=23, train_loss=1.72e-5, test_loss=1.77e-5]\u001b[A\n",
      "Epoch 947:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.54it/s, loss=1.46e-07, v_num=23, train_loss=1.72e-5, test_loss=1.77e-5]\u001b[AAdjusting learning rate of group 0 to 9.3204e-04.\n",
      "Epoch 947:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.71it/s, loss=1.41e-07, v_num=23, train_loss=1.72e-5, test_loss=1.77e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 947:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.66it/s, loss=1.41e-07, v_num=23, train_loss=1.72e-5, test_loss=1.77e-5]\u001b[A\n",
      "Epoch 947: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.00it/s, loss=1.41e-07, v_num=23, train_loss=1.59e-5, test_loss=1.69e-5]\u001b[A\n",
      "Epoch 948:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.77it/s, loss=1.15e-07, v_num=23, train_loss=1.59e-5, test_loss=1.69e-5]\u001b[AAdjusting learning rate of group 0 to 9.2971e-04.\n",
      "Epoch 948:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.36it/s, loss=1.1e-07, v_num=23, train_loss=1.59e-5, test_loss=1.69e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 948:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.81it/s, loss=1.1e-07, v_num=23, train_loss=1.59e-5, test_loss=1.69e-5]\u001b[A\n",
      "Epoch 948: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.69it/s, loss=1.1e-07, v_num=23, train_loss=1.19e-5, test_loss=1.23e-5]\u001b[A\n",
      "Epoch 949:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.27it/s, loss=1.18e-07, v_num=23, train_loss=1.19e-5, test_loss=1.23e-5]\u001b[AAdjusting learning rate of group 0 to 9.2738e-04.\n",
      "Epoch 949:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.32it/s, loss=1.08e-07, v_num=23, train_loss=1.19e-5, test_loss=1.23e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 949:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.30it/s, loss=1.08e-07, v_num=23, train_loss=1.19e-5, test_loss=1.23e-5]\u001b[A\n",
      "Epoch 949: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.43it/s, loss=1.08e-07, v_num=23, train_loss=1.02e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 950:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.92it/s, loss=1.07e-07, v_num=23, train_loss=1.02e-5, test_loss=1.09e-5]\u001b[AAdjusting learning rate of group 0 to 9.2506e-04.\n",
      "Epoch 950:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.18it/s, loss=1.02e-07, v_num=23, train_loss=1.02e-5, test_loss=1.09e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 950:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.83it/s, loss=1.02e-07, v_num=23, train_loss=1.02e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 950: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.19it/s, loss=1.02e-07, v_num=23, train_loss=9.07e-6, test_loss=9.56e-6]\u001b[A\n",
      "Epoch 951:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.94it/s, loss=1.08e-07, v_num=23, train_loss=9.07e-6, test_loss=9.56e-6]\u001b[AAdjusting learning rate of group 0 to 9.2275e-04.\n",
      "Epoch 951:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.07it/s, loss=1.04e-07, v_num=23, train_loss=9.07e-6, test_loss=9.56e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 951:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.86it/s, loss=1.04e-07, v_num=23, train_loss=9.07e-6, test_loss=9.56e-6]\u001b[A\n",
      "Epoch 951: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.02it/s, loss=1.04e-07, v_num=23, train_loss=1.01e-5, test_loss=1.07e-5]\u001b[A\n",
      "Epoch 952:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.96it/s, loss=1.14e-07, v_num=23, train_loss=1.01e-5, test_loss=1.07e-5]\u001b[AAdjusting learning rate of group 0 to 9.2045e-04.\n",
      "Epoch 952:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.74it/s, loss=1.05e-07, v_num=23, train_loss=1.01e-5, test_loss=1.07e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 952:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.21it/s, loss=1.05e-07, v_num=23, train_loss=1.01e-5, test_loss=1.07e-5]\u001b[A\n",
      "Epoch 952: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.53it/s, loss=1.05e-07, v_num=23, train_loss=1.27e-5, test_loss=1.32e-5]\u001b[A\n",
      "Epoch 953:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.47it/s, loss=1.47e-07, v_num=23, train_loss=1.27e-5, test_loss=1.32e-5]\u001b[AAdjusting learning rate of group 0 to 9.1814e-04.\n",
      "Epoch 953:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.21it/s, loss=1.41e-07, v_num=23, train_loss=1.27e-5, test_loss=1.32e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 953:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 126.19it/s, loss=1.41e-07, v_num=23, train_loss=1.27e-5, test_loss=1.32e-5]\u001b[A\n",
      "Epoch 953: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 160.59it/s, loss=1.41e-07, v_num=23, train_loss=1.37e-5, test_loss=1.42e-5]\u001b[A\n",
      "Epoch 954:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.55it/s, loss=1.12e-07, v_num=23, train_loss=1.37e-5, test_loss=1.42e-5]\u001b[AAdjusting learning rate of group 0 to 9.1585e-04.\n",
      "Epoch 954:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.57it/s, loss=1.07e-07, v_num=23, train_loss=1.37e-5, test_loss=1.42e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 954:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.42it/s, loss=1.07e-07, v_num=23, train_loss=1.37e-5, test_loss=1.42e-5]\u001b[A\n",
      "Epoch 954: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.81it/s, loss=1.07e-07, v_num=23, train_loss=1.11e-5, test_loss=1.17e-5]\u001b[A\n",
      "Epoch 955:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.68it/s, loss=1.02e-07, v_num=23, train_loss=1.11e-5, test_loss=1.17e-5]\u001b[AAdjusting learning rate of group 0 to 9.1356e-04.\n",
      "Epoch 955:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.71it/s, loss=9.81e-08, v_num=23, train_loss=1.11e-5, test_loss=1.17e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 955:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.18it/s, loss=9.81e-08, v_num=23, train_loss=1.11e-5, test_loss=1.17e-5]\u001b[A\n",
      "Epoch 955: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.20it/s, loss=9.81e-08, v_num=23, train_loss=1.13e-5, test_loss=1.18e-5]\u001b[A\n",
      "Epoch 956:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.29it/s, loss=1.21e-07, v_num=23, train_loss=1.13e-5, test_loss=1.18e-5]\u001b[AAdjusting learning rate of group 0 to 9.1128e-04.\n",
      "Epoch 956:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.34it/s, loss=1.15e-07, v_num=23, train_loss=1.13e-5, test_loss=1.18e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 956:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.41it/s, loss=1.15e-07, v_num=23, train_loss=1.13e-5, test_loss=1.18e-5]\u001b[A\n",
      "Epoch 956: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.27it/s, loss=1.15e-07, v_num=23, train_loss=9.97e-6, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 957:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.79it/s, loss=1.18e-07, v_num=23, train_loss=9.97e-6, test_loss=1.06e-5]\u001b[AAdjusting learning rate of group 0 to 9.0900e-04.\n",
      "Epoch 957:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.81it/s, loss=1.14e-07, v_num=23, train_loss=9.97e-6, test_loss=1.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 957:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.23it/s, loss=1.14e-07, v_num=23, train_loss=9.97e-6, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 957: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.61it/s, loss=1.14e-07, v_num=23, train_loss=1.05e-5, test_loss=1.11e-5]\u001b[A\n",
      "Epoch 958:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.36it/s, loss=1.12e-07, v_num=23, train_loss=1.05e-5, test_loss=1.11e-5]\u001b[AAdjusting learning rate of group 0 to 9.0672e-04.\n",
      "Epoch 958:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.31it/s, loss=1.09e-07, v_num=23, train_loss=1.05e-5, test_loss=1.11e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 958:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.92it/s, loss=1.09e-07, v_num=23, train_loss=1.05e-5, test_loss=1.11e-5]\u001b[A\n",
      "Epoch 958: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.96it/s, loss=1.09e-07, v_num=23, train_loss=1.15e-5, test_loss=1.21e-5]\u001b[A\n",
      "Epoch 959:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.73it/s, loss=1.31e-07, v_num=23, train_loss=1.15e-5, test_loss=1.21e-5]\u001b[AAdjusting learning rate of group 0 to 9.0446e-04.\n",
      "Epoch 959:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.20it/s, loss=1.28e-07, v_num=23, train_loss=1.15e-5, test_loss=1.21e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 959:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.78it/s, loss=1.28e-07, v_num=23, train_loss=1.15e-5, test_loss=1.21e-5]\u001b[A\n",
      "Epoch 959: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.70it/s, loss=1.28e-07, v_num=23, train_loss=2.02e-5, test_loss=2.09e-5]\u001b[A\n",
      "Epoch 960:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.19it/s, loss=1.24e-07, v_num=23, train_loss=2.02e-5, test_loss=2.09e-5]\u001b[AAdjusting learning rate of group 0 to 9.0220e-04.\n",
      "Epoch 960:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.60it/s, loss=1.2e-07, v_num=23, train_loss=2.02e-5, test_loss=2.09e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 960:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.39it/s, loss=1.2e-07, v_num=23, train_loss=2.02e-5, test_loss=2.09e-5]\u001b[A\n",
      "Epoch 960: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.73it/s, loss=1.2e-07, v_num=23, train_loss=1.28e-5, test_loss=1.33e-5]\u001b[A\n",
      "Epoch 961:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.10it/s, loss=1.13e-07, v_num=23, train_loss=1.28e-5, test_loss=1.33e-5]\u001b[AAdjusting learning rate of group 0 to 8.9994e-04.\n",
      "Epoch 961:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.23it/s, loss=1.07e-07, v_num=23, train_loss=1.28e-5, test_loss=1.33e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 961:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.07it/s, loss=1.07e-07, v_num=23, train_loss=1.28e-5, test_loss=1.33e-5]\u001b[A\n",
      "Epoch 961: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.26it/s, loss=1.07e-07, v_num=23, train_loss=1.21e-5, test_loss=1.28e-5]\u001b[A\n",
      "Epoch 962:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.32it/s, loss=1.12e-07, v_num=23, train_loss=1.21e-5, test_loss=1.28e-5]\u001b[AAdjusting learning rate of group 0 to 8.9769e-04.\n",
      "Epoch 962:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.33it/s, loss=1.07e-07, v_num=23, train_loss=1.21e-5, test_loss=1.28e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 962:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.61it/s, loss=1.07e-07, v_num=23, train_loss=1.21e-5, test_loss=1.28e-5]\u001b[A\n",
      "Epoch 962: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.74it/s, loss=1.07e-07, v_num=23, train_loss=1.32e-5, test_loss=1.37e-5]\u001b[A\n",
      "Epoch 963:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.20it/s, loss=1.24e-07, v_num=23, train_loss=1.32e-5, test_loss=1.37e-5]\u001b[AAdjusting learning rate of group 0 to 8.9545e-04.\n",
      "Epoch 963:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.85it/s, loss=1.18e-07, v_num=23, train_loss=1.32e-5, test_loss=1.37e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 963:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.08it/s, loss=1.18e-07, v_num=23, train_loss=1.32e-5, test_loss=1.37e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 963: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.49it/s, loss=1.18e-07, v_num=23, train_loss=1.3e-5, test_loss=1.33e-5]\u001b[A\n",
      "Epoch 964:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.69it/s, loss=1.21e-07, v_num=23, train_loss=1.3e-5, test_loss=1.33e-5]\u001b[AAdjusting learning rate of group 0 to 8.9321e-04.\n",
      "Epoch 964:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.60it/s, loss=1.15e-07, v_num=23, train_loss=1.3e-5, test_loss=1.33e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 964:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.44it/s, loss=1.15e-07, v_num=23, train_loss=1.3e-5, test_loss=1.33e-5]\u001b[A\n",
      "Epoch 964: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.01it/s, loss=1.15e-07, v_num=23, train_loss=1.52e-5, test_loss=1.6e-5]\u001b[A\n",
      "Epoch 965:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.50it/s, loss=1.03e-07, v_num=23, train_loss=1.52e-5, test_loss=1.6e-5]\u001b[AAdjusting learning rate of group 0 to 8.9098e-04.\n",
      "Epoch 965:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.53it/s, loss=9.93e-08, v_num=23, train_loss=1.52e-5, test_loss=1.6e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 965:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.43it/s, loss=9.93e-08, v_num=23, train_loss=1.52e-5, test_loss=1.6e-5]\u001b[A\n",
      "Epoch 965: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.75it/s, loss=9.93e-08, v_num=23, train_loss=1.44e-5, test_loss=1.51e-5]\u001b[A\n",
      "Epoch 966:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.73it/s, loss=1.15e-07, v_num=23, train_loss=1.44e-5, test_loss=1.51e-5]\u001b[AAdjusting learning rate of group 0 to 8.8875e-04.\n",
      "Epoch 966:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.73it/s, loss=1.12e-07, v_num=23, train_loss=1.44e-5, test_loss=1.51e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 966:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.40it/s, loss=1.12e-07, v_num=23, train_loss=1.44e-5, test_loss=1.51e-5]\u001b[A\n",
      "Epoch 966: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.38it/s, loss=1.12e-07, v_num=23, train_loss=1.29e-5, test_loss=1.36e-5]\u001b[A\n",
      "Epoch 967:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.20it/s, loss=1.11e-07, v_num=23, train_loss=1.29e-5, test_loss=1.36e-5]\u001b[AAdjusting learning rate of group 0 to 8.8653e-04.\n",
      "Epoch 967:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.35it/s, loss=1.08e-07, v_num=23, train_loss=1.29e-5, test_loss=1.36e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 967:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.79it/s, loss=1.08e-07, v_num=23, train_loss=1.29e-5, test_loss=1.36e-5]\u001b[A\n",
      "Epoch 967: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.78it/s, loss=1.08e-07, v_num=23, train_loss=1.14e-5, test_loss=1.2e-5]\u001b[A\n",
      "Epoch 968:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.63it/s, loss=1.03e-07, v_num=23, train_loss=1.14e-5, test_loss=1.2e-5]\u001b[AAdjusting learning rate of group 0 to 8.8431e-04.\n",
      "Epoch 968:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.37it/s, loss=9.95e-08, v_num=23, train_loss=1.14e-5, test_loss=1.2e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 968:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 128.33it/s, loss=9.95e-08, v_num=23, train_loss=1.14e-5, test_loss=1.2e-5]\u001b[A\n",
      "Epoch 968: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 163.24it/s, loss=9.95e-08, v_num=23, train_loss=9.32e-6, test_loss=9.97e-6]\u001b[A\n",
      "Epoch 969:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.71it/s, loss=1.18e-07, v_num=23, train_loss=9.32e-6, test_loss=9.97e-6]\u001b[AAdjusting learning rate of group 0 to 8.8210e-04.\n",
      "Epoch 969:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.83it/s, loss=1.12e-07, v_num=23, train_loss=9.32e-6, test_loss=9.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 969:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.59it/s, loss=1.12e-07, v_num=23, train_loss=9.32e-6, test_loss=9.97e-6]\u001b[A\n",
      "Epoch 969: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.14it/s, loss=1.12e-07, v_num=23, train_loss=1.49e-5, test_loss=1.54e-5]\u001b[A\n",
      "Epoch 970:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.05it/s, loss=9.24e-08, v_num=23, train_loss=1.49e-5, test_loss=1.54e-5]\u001b[AAdjusting learning rate of group 0 to 8.7989e-04.\n",
      "Epoch 970:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.45it/s, loss=8.84e-08, v_num=23, train_loss=1.49e-5, test_loss=1.54e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 970:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.09it/s, loss=8.84e-08, v_num=23, train_loss=1.49e-5, test_loss=1.54e-5]\u001b[A\n",
      "Epoch 970: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.50it/s, loss=8.84e-08, v_num=23, train_loss=9.89e-6, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 971:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.05it/s, loss=9.24e-08, v_num=23, train_loss=9.89e-6, test_loss=1.06e-5]\u001b[AAdjusting learning rate of group 0 to 8.7769e-04.\n",
      "Epoch 971:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.87it/s, loss=8.77e-08, v_num=23, train_loss=9.89e-6, test_loss=1.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 971:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.81it/s, loss=8.77e-08, v_num=23, train_loss=9.89e-6, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 971: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.96it/s, loss=8.77e-08, v_num=23, train_loss=1.21e-5, test_loss=1.26e-5]\u001b[A\n",
      "Epoch 972:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.03it/s, loss=1.19e-07, v_num=23, train_loss=1.21e-5, test_loss=1.26e-5]\u001b[AAdjusting learning rate of group 0 to 8.7550e-04.\n",
      "Epoch 972:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.55it/s, loss=1.12e-07, v_num=23, train_loss=1.21e-5, test_loss=1.26e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 972:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.86it/s, loss=1.12e-07, v_num=23, train_loss=1.21e-5, test_loss=1.26e-5]\u001b[A\n",
      "Epoch 972: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.35it/s, loss=1.12e-07, v_num=23, train_loss=1.24e-5, test_loss=1.27e-5]\u001b[A\n",
      "Epoch 973:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.56it/s, loss=1.91e-07, v_num=23, train_loss=1.24e-5, test_loss=1.27e-5]\u001b[AAdjusting learning rate of group 0 to 8.7331e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 973:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.35it/s, loss=1.85e-07, v_num=23, train_loss=1.24e-5, test_loss=1.27e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 973:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.42it/s, loss=1.85e-07, v_num=23, train_loss=1.24e-5, test_loss=1.27e-5]\u001b[A\n",
      "Epoch 973: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.02it/s, loss=1.85e-07, v_num=23, train_loss=2.3e-5, test_loss=2.35e-5]\u001b[A\n",
      "Epoch 974:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.31it/s, loss=9.72e-08, v_num=23, train_loss=2.3e-5, test_loss=2.35e-5]\u001b[AAdjusting learning rate of group 0 to 8.7113e-04.\n",
      "Epoch 974:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.04it/s, loss=9.22e-08, v_num=23, train_loss=2.3e-5, test_loss=2.35e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 974:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.55it/s, loss=9.22e-08, v_num=23, train_loss=2.3e-5, test_loss=2.35e-5]\u001b[A\n",
      "Epoch 974: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.61it/s, loss=9.22e-08, v_num=23, train_loss=1.03e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 975:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.22it/s, loss=1.14e-07, v_num=23, train_loss=1.03e-5, test_loss=1.09e-5]\u001b[AAdjusting learning rate of group 0 to 8.6895e-04.\n",
      "Epoch 975:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.69it/s, loss=1.09e-07, v_num=23, train_loss=1.03e-5, test_loss=1.09e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 975:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.18it/s, loss=1.09e-07, v_num=23, train_loss=1.03e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 975: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.20it/s, loss=1.09e-07, v_num=23, train_loss=1.21e-5, test_loss=1.27e-5]\u001b[A\n",
      "Epoch 976:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 146.94it/s, loss=1.12e-07, v_num=23, train_loss=1.21e-5, test_loss=1.27e-5]\u001b[AAdjusting learning rate of group 0 to 8.6678e-04.\n",
      "Epoch 976:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.75it/s, loss=1.08e-07, v_num=23, train_loss=1.21e-5, test_loss=1.27e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 976:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.96it/s, loss=1.08e-07, v_num=23, train_loss=1.21e-5, test_loss=1.27e-5]\u001b[A\n",
      "Epoch 976: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.94it/s, loss=1.08e-07, v_num=23, train_loss=9.76e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 977:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.82it/s, loss=1.07e-07, v_num=23, train_loss=9.76e-6, test_loss=1.05e-5]\u001b[AAdjusting learning rate of group 0 to 8.6461e-04.\n",
      "Epoch 977:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.10it/s, loss=1.04e-07, v_num=23, train_loss=9.76e-6, test_loss=1.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 977:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.74it/s, loss=1.04e-07, v_num=23, train_loss=9.76e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 977: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.76it/s, loss=1.04e-07, v_num=23, train_loss=1.46e-5, test_loss=1.53e-5]\u001b[A\n",
      "Epoch 978:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.25it/s, loss=1.36e-07, v_num=23, train_loss=1.46e-5, test_loss=1.53e-5]\u001b[AAdjusting learning rate of group 0 to 8.6245e-04.\n",
      "Epoch 978:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.42it/s, loss=1.33e-07, v_num=23, train_loss=1.46e-5, test_loss=1.53e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 978:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.13it/s, loss=1.33e-07, v_num=23, train_loss=1.46e-5, test_loss=1.53e-5]\u001b[A\n",
      "Epoch 978: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.89it/s, loss=1.33e-07, v_num=23, train_loss=1.06e-5, test_loss=1.17e-5]\u001b[A\n",
      "Epoch 979:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.93it/s, loss=1.1e-07, v_num=23, train_loss=1.06e-5, test_loss=1.17e-5]\u001b[AAdjusting learning rate of group 0 to 8.6029e-04.\n",
      "Epoch 979:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.93it/s, loss=1.06e-07, v_num=23, train_loss=1.06e-5, test_loss=1.17e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 979:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.42it/s, loss=1.06e-07, v_num=23, train_loss=1.06e-5, test_loss=1.17e-5]\u001b[A\n",
      "Epoch 979: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.89it/s, loss=1.06e-07, v_num=23, train_loss=1.37e-5, test_loss=1.45e-5]\u001b[A\n",
      "Epoch 980:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.84it/s, loss=1.18e-07, v_num=23, train_loss=1.37e-5, test_loss=1.45e-5]\u001b[AAdjusting learning rate of group 0 to 8.5814e-04.\n",
      "Epoch 980:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.15it/s, loss=1.11e-07, v_num=23, train_loss=1.37e-5, test_loss=1.45e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 980:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.64it/s, loss=1.11e-07, v_num=23, train_loss=1.37e-5, test_loss=1.45e-5]\u001b[A\n",
      "Epoch 980: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 164.92it/s, loss=1.11e-07, v_num=23, train_loss=1.41e-5, test_loss=1.5e-5]\u001b[A\n",
      "Epoch 981:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.75it/s, loss=1.27e-07, v_num=23, train_loss=1.41e-5, test_loss=1.5e-5]\u001b[AAdjusting learning rate of group 0 to 8.5600e-04.\n",
      "Epoch 981:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.81it/s, loss=1.21e-07, v_num=23, train_loss=1.41e-5, test_loss=1.5e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 981:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 130.68it/s, loss=1.21e-07, v_num=23, train_loss=1.41e-5, test_loss=1.5e-5]\u001b[A\n",
      "Epoch 981: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.82it/s, loss=1.21e-07, v_num=23, train_loss=1.31e-5, test_loss=1.35e-5]\u001b[A\n",
      "Epoch 982:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.55it/s, loss=1.19e-07, v_num=23, train_loss=1.31e-5, test_loss=1.35e-5]\u001b[AAdjusting learning rate of group 0 to 8.5386e-04.\n",
      "Epoch 982:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.20it/s, loss=1.13e-07, v_num=23, train_loss=1.31e-5, test_loss=1.35e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 982:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.56it/s, loss=1.13e-07, v_num=23, train_loss=1.31e-5, test_loss=1.35e-5]\u001b[A\n",
      "Epoch 982: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.65it/s, loss=1.13e-07, v_num=23, train_loss=1.11e-5, test_loss=1.16e-5]\u001b[A\n",
      "Epoch 983:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.26it/s, loss=1.04e-07, v_num=23, train_loss=1.11e-5, test_loss=1.16e-5]\u001b[AAdjusting learning rate of group 0 to 8.5172e-04.\n",
      "Epoch 983:  50%|█████████████████████                     | 79/158 [00:00<00:00, 136.56it/s, loss=1e-07, v_num=23, train_loss=1.11e-5, test_loss=1.16e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 983:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 130.12it/s, loss=1e-07, v_num=23, train_loss=1.11e-5, test_loss=1.16e-5]\u001b[A\n",
      "Epoch 983: 100%|████████████████████████████████████████████| 158/158 [00:00<00:00, 165.56it/s, loss=1e-07, v_num=23, train_loss=1e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 984:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 148.99it/s, loss=1.08e-07, v_num=23, train_loss=1e-5, test_loss=1.08e-5]\u001b[AAdjusting learning rate of group 0 to 8.4959e-04.\n",
      "Epoch 984:  50%|█████████████████████                     | 79/158 [00:00<00:00, 138.03it/s, loss=1.03e-07, v_num=23, train_loss=1e-5, test_loss=1.08e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 984:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 131.11it/s, loss=1.03e-07, v_num=23, train_loss=1e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 984: 100%|██████████████████████████████████████████| 158/158 [00:00<00:00, 167.70it/s, loss=1.03e-07, v_num=23, train_loss=1e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 985:  49%|█████████████████████▏                     | 78/158 [00:00<00:00, 149.30it/s, loss=1.79e-07, v_num=23, train_loss=1e-5, test_loss=1.1e-5]\u001b[AAdjusting learning rate of group 0 to 8.4747e-04.\n",
      "Epoch 985:  50%|█████████████████████▌                     | 79/158 [00:00<00:00, 140.42it/s, loss=1.76e-07, v_num=23, train_loss=1e-5, test_loss=1.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 985:  67%|████████████████████████████▏             | 106/158 [00:00<00:00, 133.21it/s, loss=1.76e-07, v_num=23, train_loss=1e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 985: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.67it/s, loss=1.76e-07, v_num=23, train_loss=1.01e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 986:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.86it/s, loss=1.02e-07, v_num=23, train_loss=1.01e-5, test_loss=1.09e-5]\u001b[AAdjusting learning rate of group 0 to 8.4535e-04.\n",
      "Epoch 986:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.03it/s, loss=9.84e-08, v_num=23, train_loss=1.01e-5, test_loss=1.09e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 986:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 128.42it/s, loss=9.84e-08, v_num=23, train_loss=1.01e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 986: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.34it/s, loss=9.84e-08, v_num=23, train_loss=1.04e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 987:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.72it/s, loss=1.75e-07, v_num=23, train_loss=1.04e-5, test_loss=1.12e-5]\u001b[AAdjusting learning rate of group 0 to 8.4324e-04.\n",
      "Epoch 987:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.38it/s, loss=1.69e-07, v_num=23, train_loss=1.04e-5, test_loss=1.12e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 987:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.82it/s, loss=1.69e-07, v_num=23, train_loss=1.04e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 987: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.53it/s, loss=1.69e-07, v_num=23, train_loss=1.67e-5, test_loss=1.73e-5]\u001b[A\n",
      "Epoch 988:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.40it/s, loss=1.1e-07, v_num=23, train_loss=1.67e-5, test_loss=1.73e-5]\u001b[AAdjusting learning rate of group 0 to 8.4113e-04.\n",
      "Epoch 988:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.46it/s, loss=1.04e-07, v_num=23, train_loss=1.67e-5, test_loss=1.73e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 988:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.92it/s, loss=1.04e-07, v_num=23, train_loss=1.67e-5, test_loss=1.73e-5]\u001b[A\n",
      "Epoch 988: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.27it/s, loss=1.04e-07, v_num=23, train_loss=1.33e-5, test_loss=1.41e-5]\u001b[A\n",
      "Epoch 989:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.16it/s, loss=9.4e-08, v_num=23, train_loss=1.33e-5, test_loss=1.41e-5]\u001b[AAdjusting learning rate of group 0 to 8.3903e-04.\n",
      "Epoch 989:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.47it/s, loss=8.62e-08, v_num=23, train_loss=1.33e-5, test_loss=1.41e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 989:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.37it/s, loss=8.62e-08, v_num=23, train_loss=1.33e-5, test_loss=1.41e-5]\u001b[A\n",
      "Epoch 989: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 167.73it/s, loss=8.62e-08, v_num=23, train_loss=9.51e-6, test_loss=1e-5]\u001b[A\n",
      "Epoch 990:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 146.17it/s, loss=1.13e-07, v_num=23, train_loss=9.51e-6, test_loss=1e-5]\u001b[AAdjusting learning rate of group 0 to 8.3693e-04.\n",
      "Epoch 990:  50%|█████████████████████                     | 79/158 [00:00<00:00, 136.37it/s, loss=1.09e-07, v_num=23, train_loss=9.51e-6, test_loss=1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 990:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 128.90it/s, loss=1.09e-07, v_num=23, train_loss=9.51e-6, test_loss=1e-5]\u001b[A\n",
      "Epoch 990: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.31it/s, loss=1.09e-07, v_num=23, train_loss=9.66e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 991:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.60it/s, loss=1.13e-07, v_num=23, train_loss=9.66e-6, test_loss=1.03e-5]\u001b[AAdjusting learning rate of group 0 to 8.3484e-04.\n",
      "Epoch 991:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.77it/s, loss=1.08e-07, v_num=23, train_loss=9.66e-6, test_loss=1.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 991:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.71it/s, loss=1.08e-07, v_num=23, train_loss=9.66e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 991: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.35it/s, loss=1.08e-07, v_num=23, train_loss=1.64e-5, test_loss=1.7e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 992:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.91it/s, loss=1.23e-07, v_num=23, train_loss=1.64e-5, test_loss=1.7e-5]\u001b[AAdjusting learning rate of group 0 to 8.3275e-04.\n",
      "Epoch 992:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.56it/s, loss=1.19e-07, v_num=23, train_loss=1.64e-5, test_loss=1.7e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 992:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.69it/s, loss=1.19e-07, v_num=23, train_loss=1.64e-5, test_loss=1.7e-5]\u001b[A\n",
      "Epoch 992: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.74it/s, loss=1.19e-07, v_num=23, train_loss=9.21e-6, test_loss=9.88e-6]\u001b[A\n",
      "Epoch 993:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.61it/s, loss=1.13e-07, v_num=23, train_loss=9.21e-6, test_loss=9.88e-6]\u001b[AAdjusting learning rate of group 0 to 8.3067e-04.\n",
      "Epoch 993:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.45it/s, loss=1.09e-07, v_num=23, train_loss=9.21e-6, test_loss=9.88e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.30it/s]\u001b[A\n",
      "Epoch 993:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 126.54it/s, loss=1.09e-07, v_num=23, train_loss=9.21e-6, test_loss=9.88e-6]\u001b[A\n",
      "Epoch 993: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 160.91it/s, loss=1.09e-07, v_num=23, train_loss=9.6e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 994:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.88it/s, loss=1.11e-07, v_num=23, train_loss=9.6e-6, test_loss=1.03e-5]\u001b[AAdjusting learning rate of group 0 to 8.2859e-04.\n",
      "Epoch 994:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.04it/s, loss=1.07e-07, v_num=23, train_loss=9.6e-6, test_loss=1.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 994:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 130.29it/s, loss=1.07e-07, v_num=23, train_loss=9.6e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 994: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.39it/s, loss=1.07e-07, v_num=23, train_loss=9.21e-6, test_loss=9.72e-6]\u001b[A\n",
      "Epoch 995:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.17it/s, loss=1.06e-07, v_num=23, train_loss=9.21e-6, test_loss=9.72e-6]\u001b[AAdjusting learning rate of group 0 to 8.2652e-04.\n",
      "Epoch 995:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.56it/s, loss=1.01e-07, v_num=23, train_loss=9.21e-6, test_loss=9.72e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 995:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.31it/s, loss=1.01e-07, v_num=23, train_loss=9.21e-6, test_loss=9.72e-6]\u001b[A\n",
      "Epoch 995: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.36it/s, loss=1.01e-07, v_num=23, train_loss=1.05e-5, test_loss=1.11e-5]\u001b[A\n",
      "Epoch 996:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.70it/s, loss=1.27e-07, v_num=23, train_loss=1.05e-5, test_loss=1.11e-5]\u001b[AAdjusting learning rate of group 0 to 8.2445e-04.\n",
      "Epoch 996:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.32it/s, loss=1.21e-07, v_num=23, train_loss=1.05e-5, test_loss=1.11e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 996:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.17it/s, loss=1.21e-07, v_num=23, train_loss=1.05e-5, test_loss=1.11e-5]\u001b[A\n",
      "Epoch 996: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.61it/s, loss=1.21e-07, v_num=23, train_loss=1.18e-5, test_loss=1.26e-5]\u001b[A\n",
      "Epoch 997:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.83it/s, loss=1.19e-07, v_num=23, train_loss=1.18e-5, test_loss=1.26e-5]\u001b[AAdjusting learning rate of group 0 to 8.2239e-04.\n",
      "Epoch 997:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.76it/s, loss=1.15e-07, v_num=23, train_loss=1.18e-5, test_loss=1.26e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 997:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.85it/s, loss=1.15e-07, v_num=23, train_loss=1.18e-5, test_loss=1.26e-5]\u001b[A\n",
      "Epoch 997: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.61it/s, loss=1.15e-07, v_num=23, train_loss=1.23e-5, test_loss=1.27e-5]\u001b[A\n",
      "Epoch 998:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.20it/s, loss=9.7e-08, v_num=23, train_loss=1.23e-5, test_loss=1.27e-5]\u001b[AAdjusting learning rate of group 0 to 8.2034e-04.\n",
      "Epoch 998:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.01it/s, loss=9.11e-08, v_num=23, train_loss=1.23e-5, test_loss=1.27e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 998:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.86it/s, loss=9.11e-08, v_num=23, train_loss=1.23e-5, test_loss=1.27e-5]\u001b[A\n",
      "Epoch 998: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.75it/s, loss=9.11e-08, v_num=23, train_loss=1.02e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 999:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.23it/s, loss=9.33e-08, v_num=23, train_loss=1.02e-5, test_loss=1.08e-5]\u001b[AAdjusting learning rate of group 0 to 8.1828e-04.\n",
      "Epoch 999:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.46it/s, loss=9.03e-08, v_num=23, train_loss=1.02e-5, test_loss=1.08e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 999:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.22it/s, loss=9.03e-08, v_num=23, train_loss=1.02e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 999: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.74it/s, loss=9.03e-08, v_num=23, train_loss=1.02e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 1000:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.00it/s, loss=1.06e-07, v_num=23, train_loss=1.02e-5, test_loss=1.08e-5]\u001b[AAdjusting learning rate of group 0 to 8.1624e-04.\n",
      "Epoch 1000:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.43it/s, loss=1.01e-07, v_num=23, train_loss=1.02e-5, test_loss=1.08e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1000:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.60it/s, loss=1.01e-07, v_num=23, train_loss=1.02e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 1000: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.98it/s, loss=1.01e-07, v_num=23, train_loss=9.6e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1001:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.55it/s, loss=9.89e-08, v_num=23, train_loss=9.6e-6, test_loss=1.01e-5]\u001b[AAdjusting learning rate of group 0 to 8.1420e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1001:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.49it/s, loss=9.46e-08, v_num=23, train_loss=9.6e-6, test_loss=1.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1001:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.67it/s, loss=9.46e-08, v_num=23, train_loss=9.6e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1001: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.33it/s, loss=9.46e-08, v_num=23, train_loss=1.18e-5, test_loss=1.23e-5]\u001b[A\n",
      "Epoch 1002:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.52it/s, loss=1.03e-07, v_num=23, train_loss=1.18e-5, test_loss=1.23e-5]\u001b[AAdjusting learning rate of group 0 to 8.1216e-04.\n",
      "Epoch 1002:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.82it/s, loss=9.74e-08, v_num=23, train_loss=1.18e-5, test_loss=1.23e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1002:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.64it/s, loss=9.74e-08, v_num=23, train_loss=1.18e-5, test_loss=1.23e-5]\u001b[A\n",
      "Epoch 1002: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.52it/s, loss=9.74e-08, v_num=23, train_loss=1.1e-5, test_loss=1.15e-5]\u001b[A\n",
      "Epoch 1003:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.19it/s, loss=1.43e-07, v_num=23, train_loss=1.1e-5, test_loss=1.15e-5]\u001b[AAdjusting learning rate of group 0 to 8.1013e-04.\n",
      "Epoch 1003:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.37it/s, loss=1.35e-07, v_num=23, train_loss=1.1e-5, test_loss=1.15e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1003:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.93it/s, loss=1.35e-07, v_num=23, train_loss=1.1e-5, test_loss=1.15e-5]\u001b[A\n",
      "Epoch 1003: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.81it/s, loss=1.35e-07, v_num=23, train_loss=1.12e-5, test_loss=1.15e-5]\u001b[A\n",
      "Epoch 1004:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.06it/s, loss=1.02e-07, v_num=23, train_loss=1.12e-5, test_loss=1.15e-5]\u001b[AAdjusting learning rate of group 0 to 8.0811e-04.\n",
      "Epoch 1004:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.79it/s, loss=9.61e-08, v_num=23, train_loss=1.12e-5, test_loss=1.15e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1004:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.15it/s, loss=9.61e-08, v_num=23, train_loss=1.12e-5, test_loss=1.15e-5]\u001b[A\n",
      "Epoch 1004: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.03it/s, loss=9.61e-08, v_num=23, train_loss=1.12e-5, test_loss=1.19e-5]\u001b[A\n",
      "Epoch 1005:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.66it/s, loss=1.11e-07, v_num=23, train_loss=1.12e-5, test_loss=1.19e-5]\u001b[AAdjusting learning rate of group 0 to 8.0609e-04.\n",
      "Epoch 1005:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.77it/s, loss=1.03e-07, v_num=23, train_loss=1.12e-5, test_loss=1.19e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1005:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.16it/s, loss=1.03e-07, v_num=23, train_loss=1.12e-5, test_loss=1.19e-5]\u001b[A\n",
      "Epoch 1005: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.65it/s, loss=1.03e-07, v_num=23, train_loss=1.14e-5, test_loss=1.17e-5]\u001b[A\n",
      "Epoch 1006:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.33it/s, loss=1.01e-07, v_num=23, train_loss=1.14e-5, test_loss=1.17e-5]\u001b[AAdjusting learning rate of group 0 to 8.0407e-04.\n",
      "Epoch 1006:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.03it/s, loss=9.61e-08, v_num=23, train_loss=1.14e-5, test_loss=1.17e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1006:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.04it/s, loss=9.61e-08, v_num=23, train_loss=1.14e-5, test_loss=1.17e-5]\u001b[A\n",
      "Epoch 1006: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.08it/s, loss=9.61e-08, v_num=23, train_loss=1.47e-5, test_loss=1.54e-5]\u001b[A\n",
      "Epoch 1007:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.80it/s, loss=1.09e-07, v_num=23, train_loss=1.47e-5, test_loss=1.54e-5]\u001b[AAdjusting learning rate of group 0 to 8.0206e-04.\n",
      "Epoch 1007:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.61it/s, loss=1.04e-07, v_num=23, train_loss=1.47e-5, test_loss=1.54e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1007:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.70it/s, loss=1.04e-07, v_num=23, train_loss=1.47e-5, test_loss=1.54e-5]\u001b[A\n",
      "Epoch 1007: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.97it/s, loss=1.04e-07, v_num=23, train_loss=1.28e-5, test_loss=1.36e-5]\u001b[A\n",
      "Epoch 1008:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.29it/s, loss=1.05e-07, v_num=23, train_loss=1.28e-5, test_loss=1.36e-5]\u001b[AAdjusting learning rate of group 0 to 8.0006e-04.\n",
      "Epoch 1008:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 137.79it/s, loss=1e-07, v_num=23, train_loss=1.28e-5, test_loss=1.36e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1008:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 131.47it/s, loss=1e-07, v_num=23, train_loss=1.28e-5, test_loss=1.36e-5]\u001b[A\n",
      "Epoch 1008: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 166.64it/s, loss=1e-07, v_num=23, train_loss=1.39e-5, test_loss=1.43e-5]\u001b[A\n",
      "Epoch 1009:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.13it/s, loss=1.18e-07, v_num=23, train_loss=1.39e-5, test_loss=1.43e-5]\u001b[AAdjusting learning rate of group 0 to 7.9806e-04.\n",
      "Epoch 1009:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.78it/s, loss=1.13e-07, v_num=23, train_loss=1.39e-5, test_loss=1.43e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1009:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.79it/s, loss=1.13e-07, v_num=23, train_loss=1.39e-5, test_loss=1.43e-5]\u001b[A\n",
      "Epoch 1009: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.84it/s, loss=1.13e-07, v_num=23, train_loss=9.69e-6, test_loss=1.04e-5]\u001b[A\n",
      "Epoch 1010:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.10it/s, loss=1.59e-07, v_num=23, train_loss=9.69e-6, test_loss=1.04e-5]\u001b[AAdjusting learning rate of group 0 to 7.9606e-04.\n",
      "Epoch 1010:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.63it/s, loss=1.37e-07, v_num=23, train_loss=9.69e-6, test_loss=1.04e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1010:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.28it/s, loss=1.37e-07, v_num=23, train_loss=9.69e-6, test_loss=1.04e-5]\u001b[A\n",
      "Epoch 1010: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.16it/s, loss=1.37e-07, v_num=23, train_loss=1.61e-5, test_loss=1.72e-5]\u001b[A\n",
      "Epoch 1011:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.82it/s, loss=1.22e-07, v_num=23, train_loss=1.61e-5, test_loss=1.72e-5]\u001b[AAdjusting learning rate of group 0 to 7.9407e-04.\n",
      "Epoch 1011:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.59it/s, loss=1.16e-07, v_num=23, train_loss=1.61e-5, test_loss=1.72e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1011:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.56it/s, loss=1.16e-07, v_num=23, train_loss=1.61e-5, test_loss=1.72e-5]\u001b[A\n",
      "Epoch 1011: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.06it/s, loss=1.16e-07, v_num=23, train_loss=9.13e-6, test_loss=9.77e-6]\u001b[A\n",
      "Epoch 1012:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.83it/s, loss=1.52e-07, v_num=23, train_loss=9.13e-6, test_loss=9.77e-6]\u001b[AAdjusting learning rate of group 0 to 7.9209e-04.\n",
      "Epoch 1012:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.90it/s, loss=1.48e-07, v_num=23, train_loss=9.13e-6, test_loss=9.77e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1012:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.34it/s, loss=1.48e-07, v_num=23, train_loss=9.13e-6, test_loss=9.77e-6]\u001b[A\n",
      "Epoch 1012: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.95it/s, loss=1.48e-07, v_num=23, train_loss=1.26e-5, test_loss=1.34e-5]\u001b[A\n",
      "Epoch 1013:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.76it/s, loss=1.42e-07, v_num=23, train_loss=1.26e-5, test_loss=1.34e-5]\u001b[AAdjusting learning rate of group 0 to 7.9011e-04.\n",
      "Epoch 1013:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.29it/s, loss=1.35e-07, v_num=23, train_loss=1.26e-5, test_loss=1.34e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1013:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.47it/s, loss=1.35e-07, v_num=23, train_loss=1.26e-5, test_loss=1.34e-5]\u001b[A\n",
      "Epoch 1013: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.10it/s, loss=1.35e-07, v_num=23, train_loss=1.32e-5, test_loss=1.37e-5]\u001b[A\n",
      "Epoch 1014:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.15it/s, loss=1.09e-07, v_num=23, train_loss=1.32e-5, test_loss=1.37e-5]\u001b[AAdjusting learning rate of group 0 to 7.8813e-04.\n",
      "Epoch 1014:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.44it/s, loss=1.03e-07, v_num=23, train_loss=1.32e-5, test_loss=1.37e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1014:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.57it/s, loss=1.03e-07, v_num=23, train_loss=1.32e-5, test_loss=1.37e-5]\u001b[A\n",
      "Epoch 1014: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.82it/s, loss=1.03e-07, v_num=23, train_loss=8.7e-6, test_loss=9.13e-6]\u001b[A\n",
      "Epoch 1015:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.12it/s, loss=1.12e-07, v_num=23, train_loss=8.7e-6, test_loss=9.13e-6]\u001b[AAdjusting learning rate of group 0 to 7.8616e-04.\n",
      "Epoch 1015:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.54it/s, loss=9.79e-08, v_num=23, train_loss=8.7e-6, test_loss=9.13e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1015:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.74it/s, loss=9.79e-08, v_num=23, train_loss=8.7e-6, test_loss=9.13e-6]\u001b[A\n",
      "Epoch 1015: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.91it/s, loss=9.79e-08, v_num=23, train_loss=1.02e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 1016:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.51it/s, loss=1.06e-07, v_num=23, train_loss=1.02e-5, test_loss=1.08e-5]\u001b[AAdjusting learning rate of group 0 to 7.8419e-04.\n",
      "Epoch 1016:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 138.52it/s, loss=1e-07, v_num=23, train_loss=1.02e-5, test_loss=1.08e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1016:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 131.55it/s, loss=1e-07, v_num=23, train_loss=1.02e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 1016: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 167.16it/s, loss=1e-07, v_num=23, train_loss=1.01e-5, test_loss=1.04e-5]\u001b[A\n",
      "Epoch 1017:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.36it/s, loss=1.17e-07, v_num=23, train_loss=1.01e-5, test_loss=1.04e-5]\u001b[AAdjusting learning rate of group 0 to 7.8223e-04.\n",
      "Epoch 1017:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.33it/s, loss=1.11e-07, v_num=23, train_loss=1.01e-5, test_loss=1.04e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1017:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.81it/s, loss=1.11e-07, v_num=23, train_loss=1.01e-5, test_loss=1.04e-5]\u001b[A\n",
      "Epoch 1017: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.09it/s, loss=1.11e-07, v_num=23, train_loss=1.39e-5, test_loss=1.43e-5]\u001b[A\n",
      "Epoch 1018:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.56it/s, loss=1.08e-07, v_num=23, train_loss=1.39e-5, test_loss=1.43e-5]\u001b[AAdjusting learning rate of group 0 to 7.8028e-04.\n",
      "Epoch 1018:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.25it/s, loss=1.04e-07, v_num=23, train_loss=1.39e-5, test_loss=1.43e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1018:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.14it/s, loss=1.04e-07, v_num=23, train_loss=1.39e-5, test_loss=1.43e-5]\u001b[A\n",
      "Epoch 1018: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.82it/s, loss=1.04e-07, v_num=23, train_loss=1.15e-5, test_loss=1.21e-5]\u001b[A\n",
      "Epoch 1019:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.19it/s, loss=2.41e-07, v_num=23, train_loss=1.15e-5, test_loss=1.21e-5]\u001b[AAdjusting learning rate of group 0 to 7.7833e-04.\n",
      "Epoch 1019:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.83it/s, loss=2.38e-07, v_num=23, train_loss=1.15e-5, test_loss=1.21e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1019:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.09it/s, loss=2.38e-07, v_num=23, train_loss=1.15e-5, test_loss=1.21e-5]\u001b[A\n",
      "Epoch 1019: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.88it/s, loss=2.38e-07, v_num=23, train_loss=1.39e-5, test_loss=1.46e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1020:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.93it/s, loss=1.31e-07, v_num=23, train_loss=1.39e-5, test_loss=1.46e-5]\u001b[AAdjusting learning rate of group 0 to 7.7638e-04.\n",
      "Epoch 1020:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.31it/s, loss=1.27e-07, v_num=23, train_loss=1.39e-5, test_loss=1.46e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1020:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.19it/s, loss=1.27e-07, v_num=23, train_loss=1.39e-5, test_loss=1.46e-5]\u001b[A\n",
      "Epoch 1020: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.82it/s, loss=1.27e-07, v_num=23, train_loss=1.69e-5, test_loss=1.76e-5]\u001b[A\n",
      "Epoch 1021:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.62it/s, loss=9.77e-08, v_num=23, train_loss=1.69e-5, test_loss=1.76e-5]\u001b[AAdjusting learning rate of group 0 to 7.7444e-04.\n",
      "Epoch 1021:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.21it/s, loss=9.24e-08, v_num=23, train_loss=1.69e-5, test_loss=1.76e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1021:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.55it/s, loss=9.24e-08, v_num=23, train_loss=1.69e-5, test_loss=1.76e-5]\u001b[A\n",
      "Epoch 1021: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.64it/s, loss=9.24e-08, v_num=23, train_loss=1.04e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 1022:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.51it/s, loss=9.69e-08, v_num=23, train_loss=1.04e-5, test_loss=1.09e-5]\u001b[AAdjusting learning rate of group 0 to 7.7250e-04.\n",
      "Epoch 1022:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.51it/s, loss=9.33e-08, v_num=23, train_loss=1.04e-5, test_loss=1.09e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1022:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.09it/s, loss=9.33e-08, v_num=23, train_loss=1.04e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 1022: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.63it/s, loss=9.33e-08, v_num=23, train_loss=9.85e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1023:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.18it/s, loss=9.82e-08, v_num=23, train_loss=9.85e-6, test_loss=1.03e-5]\u001b[AAdjusting learning rate of group 0 to 7.7057e-04.\n",
      "Epoch 1023:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.79it/s, loss=9.33e-08, v_num=23, train_loss=9.85e-6, test_loss=1.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1023:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.68it/s, loss=9.33e-08, v_num=23, train_loss=9.85e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1023: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.03it/s, loss=9.33e-08, v_num=23, train_loss=9.42e-6, test_loss=9.99e-6]\u001b[A\n",
      "Epoch 1024:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.16it/s, loss=1.05e-07, v_num=23, train_loss=9.42e-6, test_loss=9.99e-6]\u001b[AAdjusting learning rate of group 0 to 7.6865e-04.\n",
      "Epoch 1024:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.03it/s, loss=9.53e-08, v_num=23, train_loss=9.42e-6, test_loss=9.99e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1024:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.73it/s, loss=9.53e-08, v_num=23, train_loss=9.42e-6, test_loss=9.99e-6]\u001b[A\n",
      "Epoch 1024: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.22it/s, loss=9.53e-08, v_num=23, train_loss=1.06e-5, test_loss=1.13e-5]\u001b[A\n",
      "Epoch 1025:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.67it/s, loss=1.05e-07, v_num=23, train_loss=1.06e-5, test_loss=1.13e-5]\u001b[AAdjusting learning rate of group 0 to 7.6673e-04.\n",
      "Epoch 1025:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.74it/s, loss=1.01e-07, v_num=23, train_loss=1.06e-5, test_loss=1.13e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1025:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.05it/s, loss=1.01e-07, v_num=23, train_loss=1.06e-5, test_loss=1.13e-5]\u001b[A\n",
      "Epoch 1025: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.88it/s, loss=1.01e-07, v_num=23, train_loss=9.61e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1026:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.86it/s, loss=1.17e-07, v_num=23, train_loss=9.61e-6, test_loss=1.02e-5]\u001b[AAdjusting learning rate of group 0 to 7.6481e-04.\n",
      "Epoch 1026:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.89it/s, loss=1.13e-07, v_num=23, train_loss=9.61e-6, test_loss=1.02e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1026:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.30it/s, loss=1.13e-07, v_num=23, train_loss=9.61e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1026: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.16it/s, loss=1.13e-07, v_num=23, train_loss=1.02e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 1027:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.06it/s, loss=1.27e-07, v_num=23, train_loss=1.02e-5, test_loss=1.12e-5]\u001b[AAdjusting learning rate of group 0 to 7.6290e-04.\n",
      "Epoch 1027:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.00it/s, loss=1.24e-07, v_num=23, train_loss=1.02e-5, test_loss=1.12e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1027:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.82it/s, loss=1.24e-07, v_num=23, train_loss=1.02e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 1027: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.71it/s, loss=1.24e-07, v_num=23, train_loss=1.05e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 1028:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.43it/s, loss=9.55e-08, v_num=23, train_loss=1.05e-5, test_loss=1.08e-5]\u001b[AAdjusting learning rate of group 0 to 7.6099e-04.\n",
      "Epoch 1028:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.04it/s, loss=9.21e-08, v_num=23, train_loss=1.05e-5, test_loss=1.08e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1028:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.48it/s, loss=9.21e-08, v_num=23, train_loss=1.05e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 1028: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.73it/s, loss=9.21e-08, v_num=23, train_loss=1.21e-5, test_loss=1.27e-5]\u001b[A\n",
      "Epoch 1029:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.51it/s, loss=1.02e-07, v_num=23, train_loss=1.21e-5, test_loss=1.27e-5]\u001b[AAdjusting learning rate of group 0 to 7.5909e-04.\n",
      "Epoch 1029:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.60it/s, loss=9.73e-08, v_num=23, train_loss=1.21e-5, test_loss=1.27e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1029:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.78it/s, loss=9.73e-08, v_num=23, train_loss=1.21e-5, test_loss=1.27e-5]\u001b[A\n",
      "Epoch 1029: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.03it/s, loss=9.73e-08, v_num=23, train_loss=9.96e-6, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1030:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.48it/s, loss=1.09e-07, v_num=23, train_loss=9.96e-6, test_loss=1.06e-5]\u001b[AAdjusting learning rate of group 0 to 7.5719e-04.\n",
      "Epoch 1030:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.05it/s, loss=1.05e-07, v_num=23, train_loss=9.96e-6, test_loss=1.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1030:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.47it/s, loss=1.05e-07, v_num=23, train_loss=9.96e-6, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1030: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.79it/s, loss=1.05e-07, v_num=23, train_loss=9.83e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 1031:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.51it/s, loss=9.44e-08, v_num=23, train_loss=9.83e-6, test_loss=1.05e-5]\u001b[AAdjusting learning rate of group 0 to 7.5530e-04.\n",
      "Epoch 1031:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.62it/s, loss=9.1e-08, v_num=23, train_loss=9.83e-6, test_loss=1.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1031:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.47it/s, loss=9.1e-08, v_num=23, train_loss=9.83e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 1031: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.29it/s, loss=9.1e-08, v_num=23, train_loss=9.71e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1032:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.14it/s, loss=1.01e-07, v_num=23, train_loss=9.71e-6, test_loss=1.02e-5]\u001b[AAdjusting learning rate of group 0 to 7.5341e-04.\n",
      "Epoch 1032:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.18it/s, loss=9.54e-08, v_num=23, train_loss=9.71e-6, test_loss=1.02e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1032:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.64it/s, loss=9.54e-08, v_num=23, train_loss=9.71e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1032: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.97it/s, loss=9.54e-08, v_num=23, train_loss=1.22e-5, test_loss=1.28e-5]\u001b[A\n",
      "Epoch 1033:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.42it/s, loss=1.28e-07, v_num=23, train_loss=1.22e-5, test_loss=1.28e-5]\u001b[AAdjusting learning rate of group 0 to 7.5152e-04.\n",
      "Epoch 1033:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.54it/s, loss=1.23e-07, v_num=23, train_loss=1.22e-5, test_loss=1.28e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1033:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 135.01it/s, loss=1.23e-07, v_num=23, train_loss=1.22e-5, test_loss=1.28e-5]\u001b[A\n",
      "Epoch 1033: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.89it/s, loss=1.23e-07, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 1034:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.66it/s, loss=1.36e-07, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\u001b[AAdjusting learning rate of group 0 to 7.4965e-04.\n",
      "Epoch 1034:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.57it/s, loss=1.31e-07, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1034:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.68it/s, loss=1.31e-07, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 1034: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.45it/s, loss=1.31e-07, v_num=23, train_loss=9.17e-6, test_loss=9.91e-6]\u001b[A\n",
      "Epoch 1035:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.34it/s, loss=1.09e-07, v_num=23, train_loss=9.17e-6, test_loss=9.91e-6]\u001b[AAdjusting learning rate of group 0 to 7.4777e-04.\n",
      "Epoch 1035:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.13it/s, loss=1.08e-07, v_num=23, train_loss=9.17e-6, test_loss=9.91e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1035:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.34it/s, loss=1.08e-07, v_num=23, train_loss=9.17e-6, test_loss=9.91e-6]\u001b[A\n",
      "Epoch 1035: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.93it/s, loss=1.08e-07, v_num=23, train_loss=1.38e-5, test_loss=1.45e-5]\u001b[A\n",
      "Epoch 1036:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.02it/s, loss=1.11e-07, v_num=23, train_loss=1.38e-5, test_loss=1.45e-5]\u001b[AAdjusting learning rate of group 0 to 7.4590e-04.\n",
      "Epoch 1036:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.59it/s, loss=1.06e-07, v_num=23, train_loss=1.38e-5, test_loss=1.45e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1036:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.80it/s, loss=1.06e-07, v_num=23, train_loss=1.38e-5, test_loss=1.45e-5]\u001b[A\n",
      "Epoch 1036: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.88it/s, loss=1.06e-07, v_num=23, train_loss=1.02e-5, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1037:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.51it/s, loss=9.81e-08, v_num=23, train_loss=1.02e-5, test_loss=1.06e-5]\u001b[AAdjusting learning rate of group 0 to 7.4404e-04.\n",
      "Epoch 1037:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.57it/s, loss=9.29e-08, v_num=23, train_loss=1.02e-5, test_loss=1.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1037:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.35it/s, loss=9.29e-08, v_num=23, train_loss=1.02e-5, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1037: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.41it/s, loss=9.29e-08, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\u001b[A\n",
      "Epoch 1038:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.57it/s, loss=1.26e-07, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\u001b[AAdjusting learning rate of group 0 to 7.4218e-04.\n",
      "Epoch 1038:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.79it/s, loss=1.08e-07, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1038:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.58it/s, loss=1.08e-07, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1038: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.02it/s, loss=1.08e-07, v_num=23, train_loss=9.59e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1039:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.09it/s, loss=9.93e-08, v_num=23, train_loss=9.59e-6, test_loss=1.03e-5]\u001b[AAdjusting learning rate of group 0 to 7.4032e-04.\n",
      "Epoch 1039:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.52it/s, loss=9.64e-08, v_num=23, train_loss=9.59e-6, test_loss=1.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1039:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.24it/s, loss=9.64e-08, v_num=23, train_loss=9.59e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1039: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 171.44it/s, loss=9.64e-08, v_num=23, train_loss=1e-5, test_loss=1.04e-5]\u001b[A\n",
      "Epoch 1040:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.16it/s, loss=1.31e-07, v_num=23, train_loss=1e-5, test_loss=1.04e-5]\u001b[AAdjusting learning rate of group 0 to 7.3847e-04.\n",
      "Epoch 1040:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 137.59it/s, loss=1.28e-07, v_num=23, train_loss=1e-5, test_loss=1.04e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1040:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 132.91it/s, loss=1.28e-07, v_num=23, train_loss=1e-5, test_loss=1.04e-5]\u001b[A\n",
      "Epoch 1040: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.06it/s, loss=1.28e-07, v_num=23, train_loss=1.44e-5, test_loss=1.51e-5]\u001b[A\n",
      "Epoch 1041:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.40it/s, loss=1.08e-07, v_num=23, train_loss=1.44e-5, test_loss=1.51e-5]\u001b[AAdjusting learning rate of group 0 to 7.3662e-04.\n",
      "Epoch 1041:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.75it/s, loss=1.04e-07, v_num=23, train_loss=1.44e-5, test_loss=1.51e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1041:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.60it/s, loss=1.04e-07, v_num=23, train_loss=1.44e-5, test_loss=1.51e-5]\u001b[A\n",
      "Epoch 1041: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.11it/s, loss=1.04e-07, v_num=23, train_loss=1.03e-5, test_loss=1.07e-5]\u001b[A\n",
      "Epoch 1042:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.92it/s, loss=1.16e-07, v_num=23, train_loss=1.03e-5, test_loss=1.07e-5]\u001b[AAdjusting learning rate of group 0 to 7.3478e-04.\n",
      "Epoch 1042:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.38it/s, loss=1.06e-07, v_num=23, train_loss=1.03e-5, test_loss=1.07e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1042:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.51it/s, loss=1.06e-07, v_num=23, train_loss=1.03e-5, test_loss=1.07e-5]\u001b[A\n",
      "Epoch 1042: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.55it/s, loss=1.06e-07, v_num=23, train_loss=1.02e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 1043:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.76it/s, loss=1.03e-07, v_num=23, train_loss=1.02e-5, test_loss=1.08e-5]\u001b[AAdjusting learning rate of group 0 to 7.3295e-04.\n",
      "Epoch 1043:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.43it/s, loss=9.83e-08, v_num=23, train_loss=1.02e-5, test_loss=1.08e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1043:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.36it/s, loss=9.83e-08, v_num=23, train_loss=1.02e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 1043: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.18it/s, loss=9.83e-08, v_num=23, train_loss=1.12e-5, test_loss=1.2e-5]\u001b[A\n",
      "Epoch 1044:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.34it/s, loss=1.31e-07, v_num=23, train_loss=1.12e-5, test_loss=1.2e-5]\u001b[AAdjusting learning rate of group 0 to 7.3111e-04.\n",
      "Epoch 1044:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.78it/s, loss=1.23e-07, v_num=23, train_loss=1.12e-5, test_loss=1.2e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1044:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.49it/s, loss=1.23e-07, v_num=23, train_loss=1.12e-5, test_loss=1.2e-5]\u001b[A\n",
      "Epoch 1044: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.52it/s, loss=1.23e-07, v_num=23, train_loss=1.49e-5, test_loss=1.54e-5]\u001b[A\n",
      "Epoch 1045:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.42it/s, loss=9.42e-08, v_num=23, train_loss=1.49e-5, test_loss=1.54e-5]\u001b[AAdjusting learning rate of group 0 to 7.2929e-04.\n",
      "Epoch 1045:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.90it/s, loss=8.95e-08, v_num=23, train_loss=1.49e-5, test_loss=1.54e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1045:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.25it/s, loss=8.95e-08, v_num=23, train_loss=1.49e-5, test_loss=1.54e-5]\u001b[A\n",
      "Epoch 1045: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 167.89it/s, loss=8.95e-08, v_num=23, train_loss=1e-5, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1046:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 148.35it/s, loss=1.1e-07, v_num=23, train_loss=1e-5, test_loss=1.06e-5]\u001b[AAdjusting learning rate of group 0 to 7.2746e-04.\n",
      "Epoch 1046:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 140.52it/s, loss=1.03e-07, v_num=23, train_loss=1e-5, test_loss=1.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1046:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 130.73it/s, loss=1.03e-07, v_num=23, train_loss=1e-5, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1046: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.00it/s, loss=1.03e-07, v_num=23, train_loss=8.2e-6, test_loss=8.91e-6]\u001b[A\n",
      "Epoch 1047:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.80it/s, loss=9.85e-08, v_num=23, train_loss=8.2e-6, test_loss=8.91e-6]\u001b[AAdjusting learning rate of group 0 to 7.2564e-04.\n",
      "Epoch 1047:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.88it/s, loss=9.22e-08, v_num=23, train_loss=8.2e-6, test_loss=8.91e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1047:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.90it/s, loss=9.22e-08, v_num=23, train_loss=8.2e-6, test_loss=8.91e-6]\u001b[A\n",
      "Epoch 1047: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 168.03it/s, loss=9.22e-08, v_num=23, train_loss=9.42e-6, test_loss=1e-5]\u001b[A\n",
      "Epoch 1048:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.54it/s, loss=9.36e-08, v_num=23, train_loss=9.42e-6, test_loss=1e-5]\u001b[AAdjusting learning rate of group 0 to 7.2383e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1048:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 138.40it/s, loss=8.87e-08, v_num=23, train_loss=9.42e-6, test_loss=1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1048:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 130.95it/s, loss=8.87e-08, v_num=23, train_loss=9.42e-6, test_loss=1e-5]\u001b[A\n",
      "Epoch 1048: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.57it/s, loss=8.87e-08, v_num=23, train_loss=9.33e-6, test_loss=9.83e-6]\u001b[A\n",
      "Epoch 1049:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.02it/s, loss=1.06e-07, v_num=23, train_loss=9.33e-6, test_loss=9.83e-6]\u001b[AAdjusting learning rate of group 0 to 7.2202e-04.\n",
      "Epoch 1049:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.17it/s, loss=1.03e-07, v_num=23, train_loss=9.33e-6, test_loss=9.83e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1049:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.68it/s, loss=1.03e-07, v_num=23, train_loss=9.33e-6, test_loss=9.83e-6]\u001b[A\n",
      "Epoch 1049: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 168.76it/s, loss=1.03e-07, v_num=23, train_loss=9.36e-6, test_loss=1e-5]\u001b[A\n",
      "Epoch 1050:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 146.74it/s, loss=1.28e-07, v_num=23, train_loss=9.36e-6, test_loss=1e-5]\u001b[AAdjusting learning rate of group 0 to 7.2022e-04.\n",
      "Epoch 1050:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 135.80it/s, loss=1.25e-07, v_num=23, train_loss=9.36e-6, test_loss=1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.07it/s]\u001b[A\n",
      "Epoch 1050: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 160.83it/s, loss=1.25e-07, v_num=23, train_loss=1.17e-5, test_loss=1.23e-5]\u001b[A\n",
      "Epoch 1051:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.63it/s, loss=1.07e-07, v_num=23, train_loss=1.17e-5, test_loss=1.23e-5]\u001b[AAdjusting learning rate of group 0 to 7.1841e-04.\n",
      "Epoch 1051:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.71it/s, loss=1.02e-07, v_num=23, train_loss=1.17e-5, test_loss=1.23e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1051:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 128.99it/s, loss=1.02e-07, v_num=23, train_loss=1.17e-5, test_loss=1.23e-5]\u001b[A\n",
      "Epoch 1051: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 163.83it/s, loss=1.02e-07, v_num=23, train_loss=1.59e-5, test_loss=1.62e-5]\u001b[A\n",
      "Epoch 1052:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.46it/s, loss=8.76e-08, v_num=23, train_loss=1.59e-5, test_loss=1.62e-5]\u001b[AAdjusting learning rate of group 0 to 7.1662e-04.\n",
      "Epoch 1052:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.97it/s, loss=8.42e-08, v_num=23, train_loss=1.59e-5, test_loss=1.62e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1052:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.03it/s, loss=8.42e-08, v_num=23, train_loss=1.59e-5, test_loss=1.62e-5]\u001b[A\n",
      "Epoch 1052: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.16it/s, loss=8.42e-08, v_num=23, train_loss=1.06e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 1053:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.69it/s, loss=9.57e-08, v_num=23, train_loss=1.06e-5, test_loss=1.1e-5]\u001b[AAdjusting learning rate of group 0 to 7.1483e-04.\n",
      "Epoch 1053:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.77it/s, loss=9.14e-08, v_num=23, train_loss=1.06e-5, test_loss=1.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1053:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.14it/s, loss=9.14e-08, v_num=23, train_loss=1.06e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 1053: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.80it/s, loss=9.14e-08, v_num=23, train_loss=1.07e-5, test_loss=1.15e-5]\u001b[A\n",
      "Epoch 1054:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.45it/s, loss=1.01e-07, v_num=23, train_loss=1.07e-5, test_loss=1.15e-5]\u001b[AAdjusting learning rate of group 0 to 7.1304e-04.\n",
      "Epoch 1054:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.67it/s, loss=9.92e-08, v_num=23, train_loss=1.07e-5, test_loss=1.15e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1054:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.09it/s, loss=9.92e-08, v_num=23, train_loss=1.07e-5, test_loss=1.15e-5]\u001b[A\n",
      "Epoch 1054: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.66it/s, loss=9.92e-08, v_num=23, train_loss=1.08e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 1055:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.57it/s, loss=1.01e-07, v_num=23, train_loss=1.08e-5, test_loss=1.14e-5]\u001b[AAdjusting learning rate of group 0 to 7.1126e-04.\n",
      "Epoch 1055:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.85it/s, loss=9.68e-08, v_num=23, train_loss=1.08e-5, test_loss=1.14e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1055:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.23it/s, loss=9.68e-08, v_num=23, train_loss=1.08e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 1055: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.32it/s, loss=9.68e-08, v_num=23, train_loss=9.88e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 1056:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 144.86it/s, loss=9.47e-08, v_num=23, train_loss=9.88e-6, test_loss=1.05e-5]\u001b[AAdjusting learning rate of group 0 to 7.0948e-04.\n",
      "Epoch 1056:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.62it/s, loss=8.92e-08, v_num=23, train_loss=9.88e-6, test_loss=1.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1056:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.45it/s, loss=8.92e-08, v_num=23, train_loss=9.88e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 1056: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.18it/s, loss=8.92e-08, v_num=23, train_loss=9.27e-6, test_loss=9.83e-6]\u001b[A\n",
      "Epoch 1057:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.53it/s, loss=1.22e-07, v_num=23, train_loss=9.27e-6, test_loss=9.83e-6]\u001b[AAdjusting learning rate of group 0 to 7.0771e-04.\n",
      "Epoch 1057:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.49it/s, loss=1.19e-07, v_num=23, train_loss=9.27e-6, test_loss=9.83e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1057:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.54it/s, loss=1.19e-07, v_num=23, train_loss=9.27e-6, test_loss=9.83e-6]\u001b[A\n",
      "Epoch 1057: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.63it/s, loss=1.19e-07, v_num=23, train_loss=9.38e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1058:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.95it/s, loss=8.55e-08, v_num=23, train_loss=9.38e-6, test_loss=1.01e-5]\u001b[AAdjusting learning rate of group 0 to 7.0594e-04.\n",
      "Epoch 1058:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.77it/s, loss=8.08e-08, v_num=23, train_loss=9.38e-6, test_loss=1.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1058:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.90it/s, loss=8.08e-08, v_num=23, train_loss=9.38e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1058: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.44it/s, loss=8.08e-08, v_num=23, train_loss=8.67e-6, test_loss=9.31e-6]\u001b[A\n",
      "Epoch 1059:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.64it/s, loss=1.01e-07, v_num=23, train_loss=8.67e-6, test_loss=9.31e-6]\u001b[AAdjusting learning rate of group 0 to 7.0417e-04.\n",
      "Epoch 1059:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.64it/s, loss=9.61e-08, v_num=23, train_loss=8.67e-6, test_loss=9.31e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1059:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.89it/s, loss=9.61e-08, v_num=23, train_loss=8.67e-6, test_loss=9.31e-6]\u001b[A\n",
      "Epoch 1059: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.44it/s, loss=9.61e-08, v_num=23, train_loss=9.23e-6, test_loss=9.98e-6]\u001b[A\n",
      "Epoch 1060:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.21it/s, loss=1.05e-07, v_num=23, train_loss=9.23e-6, test_loss=9.98e-6]\u001b[AAdjusting learning rate of group 0 to 7.0241e-04.\n",
      "Epoch 1060:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.48it/s, loss=1.01e-07, v_num=23, train_loss=9.23e-6, test_loss=9.98e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1060:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.92it/s, loss=1.01e-07, v_num=23, train_loss=9.23e-6, test_loss=9.98e-6]\u001b[A\n",
      "Epoch 1060: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.03it/s, loss=1.01e-07, v_num=23, train_loss=1.09e-5, test_loss=1.16e-5]\u001b[A\n",
      "Epoch 1061:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.25it/s, loss=8.62e-08, v_num=23, train_loss=1.09e-5, test_loss=1.16e-5]\u001b[AAdjusting learning rate of group 0 to 7.0066e-04.\n",
      "Epoch 1061:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.58it/s, loss=8.76e-08, v_num=23, train_loss=1.09e-5, test_loss=1.16e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1061:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.14it/s, loss=8.76e-08, v_num=23, train_loss=1.09e-5, test_loss=1.16e-5]\u001b[A\n",
      "Epoch 1061: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 166.48it/s, loss=8.76e-08, v_num=23, train_loss=1e-5, test_loss=1.07e-5]\u001b[A\n",
      "Epoch 1062:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.61it/s, loss=1.02e-07, v_num=23, train_loss=1e-5, test_loss=1.07e-5]\u001b[AAdjusting learning rate of group 0 to 6.9890e-04.\n",
      "Epoch 1062:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 140.95it/s, loss=9.85e-08, v_num=23, train_loss=1e-5, test_loss=1.07e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1062:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 134.04it/s, loss=9.85e-08, v_num=23, train_loss=1e-5, test_loss=1.07e-5]\u001b[A\n",
      "Epoch 1062: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.30it/s, loss=9.85e-08, v_num=23, train_loss=8.68e-6, test_loss=9.33e-6]\u001b[A\n",
      "Epoch 1063:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.92it/s, loss=1.12e-07, v_num=23, train_loss=8.68e-6, test_loss=9.33e-6]\u001b[AAdjusting learning rate of group 0 to 6.9716e-04.\n",
      "Epoch 1063:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.65it/s, loss=1.08e-07, v_num=23, train_loss=8.68e-6, test_loss=9.33e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1063:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.40it/s, loss=1.08e-07, v_num=23, train_loss=8.68e-6, test_loss=9.33e-6]\u001b[A\n",
      "Epoch 1063: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.57it/s, loss=1.08e-07, v_num=23, train_loss=8.87e-6, test_loss=9.49e-6]\u001b[A\n",
      "Epoch 1064:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.32it/s, loss=9.57e-08, v_num=23, train_loss=8.87e-6, test_loss=9.49e-6]\u001b[AAdjusting learning rate of group 0 to 6.9541e-04.\n",
      "Epoch 1064:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.83it/s, loss=9.25e-08, v_num=23, train_loss=8.87e-6, test_loss=9.49e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1064:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.98it/s, loss=9.25e-08, v_num=23, train_loss=8.87e-6, test_loss=9.49e-6]\u001b[A\n",
      "Epoch 1064: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.53it/s, loss=9.25e-08, v_num=23, train_loss=1.15e-5, test_loss=1.21e-5]\u001b[A\n",
      "Epoch 1065:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.18it/s, loss=9.99e-08, v_num=23, train_loss=1.15e-5, test_loss=1.21e-5]\u001b[AAdjusting learning rate of group 0 to 6.9368e-04.\n",
      "Epoch 1065:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.44it/s, loss=9.68e-08, v_num=23, train_loss=1.15e-5, test_loss=1.21e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1065:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.54it/s, loss=9.68e-08, v_num=23, train_loss=1.15e-5, test_loss=1.21e-5]\u001b[A\n",
      "Epoch 1065: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.71it/s, loss=9.68e-08, v_num=23, train_loss=9.03e-6, test_loss=9.43e-6]\u001b[A\n",
      "Epoch 1066:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.98it/s, loss=1.1e-07, v_num=23, train_loss=9.03e-6, test_loss=9.43e-6]\u001b[AAdjusting learning rate of group 0 to 6.9194e-04.\n",
      "Epoch 1066:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.17it/s, loss=1.06e-07, v_num=23, train_loss=9.03e-6, test_loss=9.43e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1066:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 135.10it/s, loss=1.06e-07, v_num=23, train_loss=9.03e-6, test_loss=9.43e-6]\u001b[A\n",
      "Epoch 1066: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.15it/s, loss=1.06e-07, v_num=23, train_loss=9.91e-6, test_loss=1.04e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1067:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.53it/s, loss=1.2e-07, v_num=23, train_loss=9.91e-6, test_loss=1.04e-5]\u001b[AAdjusting learning rate of group 0 to 6.9021e-04.\n",
      "Epoch 1067:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.63it/s, loss=1.15e-07, v_num=23, train_loss=9.91e-6, test_loss=1.04e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1067:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.55it/s, loss=1.15e-07, v_num=23, train_loss=9.91e-6, test_loss=1.04e-5]\u001b[A\n",
      "Epoch 1067: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.90it/s, loss=1.15e-07, v_num=23, train_loss=1.16e-5, test_loss=1.2e-5]\u001b[A\n",
      "Epoch 1068:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.92it/s, loss=9.84e-08, v_num=23, train_loss=1.16e-5, test_loss=1.2e-5]\u001b[AAdjusting learning rate of group 0 to 6.8849e-04.\n",
      "Epoch 1068:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.68it/s, loss=9.51e-08, v_num=23, train_loss=1.16e-5, test_loss=1.2e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1068:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.80it/s, loss=9.51e-08, v_num=23, train_loss=1.16e-5, test_loss=1.2e-5]\u001b[A\n",
      "Epoch 1068: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.25it/s, loss=9.51e-08, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 1069:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.37it/s, loss=1.2e-07, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\u001b[AAdjusting learning rate of group 0 to 6.8676e-04.\n",
      "Epoch 1069:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.96it/s, loss=1.13e-07, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1069:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.80it/s, loss=1.13e-07, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 1069: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.41it/s, loss=1.13e-07, v_num=23, train_loss=9.25e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1070:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.02it/s, loss=1.11e-07, v_num=23, train_loss=9.25e-6, test_loss=1.01e-5]\u001b[AAdjusting learning rate of group 0 to 6.8505e-04.\n",
      "Epoch 1070:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.69it/s, loss=1.07e-07, v_num=23, train_loss=9.25e-6, test_loss=1.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1070:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.77it/s, loss=1.07e-07, v_num=23, train_loss=9.25e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1070: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.52it/s, loss=1.07e-07, v_num=23, train_loss=8.41e-6, test_loss=9.07e-6]\u001b[A\n",
      "Epoch 1071:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.96it/s, loss=9.29e-08, v_num=23, train_loss=8.41e-6, test_loss=9.07e-6]\u001b[AAdjusting learning rate of group 0 to 6.8333e-04.\n",
      "Epoch 1071:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.02it/s, loss=8.85e-08, v_num=23, train_loss=8.41e-6, test_loss=9.07e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1071:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.06it/s, loss=8.85e-08, v_num=23, train_loss=8.41e-6, test_loss=9.07e-6]\u001b[A\n",
      "Epoch 1071: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.83it/s, loss=8.85e-08, v_num=23, train_loss=9.46e-6, test_loss=9.9e-6]\u001b[A\n",
      "Epoch 1072:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.78it/s, loss=9.4e-08, v_num=23, train_loss=9.46e-6, test_loss=9.9e-6]\u001b[AAdjusting learning rate of group 0 to 6.8163e-04.\n",
      "Epoch 1072:  50%|█████████████████████                     | 79/158 [00:00<00:00, 137.12it/s, loss=9e-08, v_num=23, train_loss=9.46e-6, test_loss=9.9e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1072:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 130.59it/s, loss=9e-08, v_num=23, train_loss=9.46e-6, test_loss=9.9e-6]\u001b[A\n",
      "Epoch 1072: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 165.50it/s, loss=9e-08, v_num=23, train_loss=1.01e-5, test_loss=1.07e-5]\u001b[A\n",
      "Epoch 1073:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.41it/s, loss=1.19e-07, v_num=23, train_loss=1.01e-5, test_loss=1.07e-5]\u001b[AAdjusting learning rate of group 0 to 6.7992e-04.\n",
      "Epoch 1073:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.42it/s, loss=1.16e-07, v_num=23, train_loss=1.01e-5, test_loss=1.07e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1073:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 128.85it/s, loss=1.16e-07, v_num=23, train_loss=1.01e-5, test_loss=1.07e-5]\u001b[A\n",
      "Epoch 1073: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.79it/s, loss=1.16e-07, v_num=23, train_loss=1.07e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 1074:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.71it/s, loss=8.88e-08, v_num=23, train_loss=1.07e-5, test_loss=1.14e-5]\u001b[AAdjusting learning rate of group 0 to 6.7822e-04.\n",
      "Epoch 1074:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.11it/s, loss=8.54e-08, v_num=23, train_loss=1.07e-5, test_loss=1.14e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1074:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.19it/s, loss=8.54e-08, v_num=23, train_loss=1.07e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 1074: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.57it/s, loss=8.54e-08, v_num=23, train_loss=9.91e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1075:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.12it/s, loss=9.78e-08, v_num=23, train_loss=9.91e-6, test_loss=1.03e-5]\u001b[AAdjusting learning rate of group 0 to 6.7653e-04.\n",
      "Epoch 1075:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.61it/s, loss=9.18e-08, v_num=23, train_loss=9.91e-6, test_loss=1.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1075:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.56it/s, loss=9.18e-08, v_num=23, train_loss=9.91e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1075: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.69it/s, loss=9.18e-08, v_num=23, train_loss=1.04e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 1076:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.08it/s, loss=1.11e-07, v_num=23, train_loss=1.04e-5, test_loss=1.09e-5]\u001b[AAdjusting learning rate of group 0 to 6.7484e-04.\n",
      "Epoch 1076:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.89it/s, loss=1.05e-07, v_num=23, train_loss=1.04e-5, test_loss=1.09e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1076:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.68it/s, loss=1.05e-07, v_num=23, train_loss=1.04e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 1076: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.70it/s, loss=1.05e-07, v_num=23, train_loss=9.21e-6, test_loss=9.97e-6]\u001b[A\n",
      "Epoch 1077:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.59it/s, loss=1.14e-07, v_num=23, train_loss=9.21e-6, test_loss=9.97e-6]\u001b[AAdjusting learning rate of group 0 to 6.7315e-04.\n",
      "Epoch 1077:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.85it/s, loss=1.1e-07, v_num=23, train_loss=9.21e-6, test_loss=9.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1077:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.45it/s, loss=1.1e-07, v_num=23, train_loss=9.21e-6, test_loss=9.97e-6]\u001b[A\n",
      "Epoch 1077: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.57it/s, loss=1.1e-07, v_num=23, train_loss=1.01e-5, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1078:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.01it/s, loss=1.62e-07, v_num=23, train_loss=1.01e-5, test_loss=1.06e-5]\u001b[AAdjusting learning rate of group 0 to 6.7147e-04.\n",
      "Epoch 1078:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.17it/s, loss=1.61e-07, v_num=23, train_loss=1.01e-5, test_loss=1.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1078:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.65it/s, loss=1.61e-07, v_num=23, train_loss=1.01e-5, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1078: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.93it/s, loss=1.61e-07, v_num=23, train_loss=1.19e-5, test_loss=1.24e-5]\u001b[A\n",
      "Epoch 1079:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 146.91it/s, loss=9.4e-08, v_num=23, train_loss=1.19e-5, test_loss=1.24e-5]\u001b[AAdjusting learning rate of group 0 to 6.6979e-04.\n",
      "Epoch 1079:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.20it/s, loss=9.1e-08, v_num=23, train_loss=1.19e-5, test_loss=1.24e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1079:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.96it/s, loss=9.1e-08, v_num=23, train_loss=1.19e-5, test_loss=1.24e-5]\u001b[A\n",
      "Epoch 1079: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.90it/s, loss=9.1e-08, v_num=23, train_loss=1.07e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 1080:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.89it/s, loss=8.34e-08, v_num=23, train_loss=1.07e-5, test_loss=1.12e-5]\u001b[AAdjusting learning rate of group 0 to 6.6811e-04.\n",
      "Epoch 1080:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.59it/s, loss=8.05e-08, v_num=23, train_loss=1.07e-5, test_loss=1.12e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1080:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.59it/s, loss=8.05e-08, v_num=23, train_loss=1.07e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 1080: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.22it/s, loss=8.05e-08, v_num=23, train_loss=9.38e-6, test_loss=9.87e-6]\u001b[A\n",
      "Epoch 1081:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.07it/s, loss=1.09e-07, v_num=23, train_loss=9.38e-6, test_loss=9.87e-6]\u001b[AAdjusting learning rate of group 0 to 6.6644e-04.\n",
      "Epoch 1081:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.85it/s, loss=1.04e-07, v_num=23, train_loss=9.38e-6, test_loss=9.87e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1081:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.39it/s, loss=1.04e-07, v_num=23, train_loss=9.38e-6, test_loss=9.87e-6]\u001b[A\n",
      "Epoch 1081: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.62it/s, loss=1.04e-07, v_num=23, train_loss=9.2e-6, test_loss=9.81e-6]\u001b[A\n",
      "Epoch 1082:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.35it/s, loss=9.48e-08, v_num=23, train_loss=9.2e-6, test_loss=9.81e-6]\u001b[AAdjusting learning rate of group 0 to 6.6478e-04.\n",
      "Epoch 1082:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.47it/s, loss=9.08e-08, v_num=23, train_loss=9.2e-6, test_loss=9.81e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1082:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.72it/s, loss=9.08e-08, v_num=23, train_loss=9.2e-6, test_loss=9.81e-6]\u001b[A\n",
      "Epoch 1082: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.25it/s, loss=9.08e-08, v_num=23, train_loss=1.14e-5, test_loss=1.2e-5]\u001b[A\n",
      "Epoch 1083:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.50it/s, loss=8.93e-08, v_num=23, train_loss=1.14e-5, test_loss=1.2e-5]\u001b[AAdjusting learning rate of group 0 to 6.6311e-04.\n",
      "Epoch 1083:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.99it/s, loss=8.67e-08, v_num=23, train_loss=1.14e-5, test_loss=1.2e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1083:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.34it/s, loss=8.67e-08, v_num=23, train_loss=1.14e-5, test_loss=1.2e-5]\u001b[A\n",
      "Epoch 1083: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.85it/s, loss=8.67e-08, v_num=23, train_loss=1.03e-5, test_loss=1.07e-5]\u001b[A\n",
      "Epoch 1084:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.52it/s, loss=1.13e-07, v_num=23, train_loss=1.03e-5, test_loss=1.07e-5]\u001b[AAdjusting learning rate of group 0 to 6.6146e-04.\n",
      "Epoch 1084:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.71it/s, loss=1.1e-07, v_num=23, train_loss=1.03e-5, test_loss=1.07e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1084:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.46it/s, loss=1.1e-07, v_num=23, train_loss=1.03e-5, test_loss=1.07e-5]\u001b[A\n",
      "Epoch 1084: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.79it/s, loss=1.1e-07, v_num=23, train_loss=1.17e-5, test_loss=1.22e-5]\u001b[A\n",
      "Epoch 1085:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.47it/s, loss=8.55e-08, v_num=23, train_loss=1.17e-5, test_loss=1.22e-5]\u001b[AAdjusting learning rate of group 0 to 6.5980e-04.\n",
      "Epoch 1085:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.58it/s, loss=8.38e-08, v_num=23, train_loss=1.17e-5, test_loss=1.22e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1085:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.32it/s, loss=8.38e-08, v_num=23, train_loss=1.17e-5, test_loss=1.22e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1085: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.73it/s, loss=8.38e-08, v_num=23, train_loss=9.38e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1086:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.83it/s, loss=1.24e-07, v_num=23, train_loss=9.38e-6, test_loss=1.01e-5]\u001b[AAdjusting learning rate of group 0 to 6.5815e-04.\n",
      "Epoch 1086:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.73it/s, loss=1.21e-07, v_num=23, train_loss=9.38e-6, test_loss=1.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1086:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.25it/s, loss=1.21e-07, v_num=23, train_loss=9.38e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1086: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.79it/s, loss=1.21e-07, v_num=23, train_loss=1.01e-5, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 1087:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.98it/s, loss=9.56e-08, v_num=23, train_loss=1.01e-5, test_loss=1.05e-5]\u001b[AAdjusting learning rate of group 0 to 6.5651e-04.\n",
      "Epoch 1087:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.42it/s, loss=9.25e-08, v_num=23, train_loss=1.01e-5, test_loss=1.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1087:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.62it/s, loss=9.25e-08, v_num=23, train_loss=1.01e-5, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 1087: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.45it/s, loss=9.25e-08, v_num=23, train_loss=1.31e-5, test_loss=1.38e-5]\u001b[A\n",
      "Epoch 1088:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.35it/s, loss=1.08e-07, v_num=23, train_loss=1.31e-5, test_loss=1.38e-5]\u001b[AAdjusting learning rate of group 0 to 6.5487e-04.\n",
      "Epoch 1088:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.95it/s, loss=1.02e-07, v_num=23, train_loss=1.31e-5, test_loss=1.38e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1088:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.62it/s, loss=1.02e-07, v_num=23, train_loss=1.31e-5, test_loss=1.38e-5]\u001b[A\n",
      "Epoch 1088: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.87it/s, loss=1.02e-07, v_num=23, train_loss=1.08e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 1089:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.81it/s, loss=9.66e-08, v_num=23, train_loss=1.08e-5, test_loss=1.14e-5]\u001b[AAdjusting learning rate of group 0 to 6.5323e-04.\n",
      "Epoch 1089:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.76it/s, loss=9.31e-08, v_num=23, train_loss=1.08e-5, test_loss=1.14e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1089:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.44it/s, loss=9.31e-08, v_num=23, train_loss=1.08e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 1089: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.65it/s, loss=9.31e-08, v_num=23, train_loss=9.51e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1090:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.56it/s, loss=9.07e-08, v_num=23, train_loss=9.51e-6, test_loss=1.01e-5]\u001b[AAdjusting learning rate of group 0 to 6.5160e-04.\n",
      "Epoch 1090:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.99it/s, loss=8.74e-08, v_num=23, train_loss=9.51e-6, test_loss=1.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1090:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.61it/s, loss=8.74e-08, v_num=23, train_loss=9.51e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1090: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.23it/s, loss=8.74e-08, v_num=23, train_loss=7.8e-6, test_loss=8.46e-6]\u001b[A\n",
      "Epoch 1091:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.07it/s, loss=1.13e-07, v_num=23, train_loss=7.8e-6, test_loss=8.46e-6]\u001b[AAdjusting learning rate of group 0 to 6.4997e-04.\n",
      "Epoch 1091:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.53it/s, loss=1.08e-07, v_num=23, train_loss=7.8e-6, test_loss=8.46e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1091:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.55it/s, loss=1.08e-07, v_num=23, train_loss=7.8e-6, test_loss=8.46e-6]\u001b[A\n",
      "Epoch 1091: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.41it/s, loss=1.08e-07, v_num=23, train_loss=9.84e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 1092:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.49it/s, loss=9.19e-08, v_num=23, train_loss=9.84e-6, test_loss=1.05e-5]\u001b[AAdjusting learning rate of group 0 to 6.4834e-04.\n",
      "Epoch 1092:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.31it/s, loss=8.89e-08, v_num=23, train_loss=9.84e-6, test_loss=1.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1092:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.71it/s, loss=8.89e-08, v_num=23, train_loss=9.84e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 1092: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.88it/s, loss=8.89e-08, v_num=23, train_loss=1.07e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 1093:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.68it/s, loss=1.27e-07, v_num=23, train_loss=1.07e-5, test_loss=1.12e-5]\u001b[AAdjusting learning rate of group 0 to 6.4672e-04.\n",
      "Epoch 1093:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.74it/s, loss=1.23e-07, v_num=23, train_loss=1.07e-5, test_loss=1.12e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1093:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.84it/s, loss=1.23e-07, v_num=23, train_loss=1.07e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 1093: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.70it/s, loss=1.23e-07, v_num=23, train_loss=1.15e-5, test_loss=1.2e-5]\u001b[A\n",
      "Epoch 1094:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.29it/s, loss=1.01e-07, v_num=23, train_loss=1.15e-5, test_loss=1.2e-5]\u001b[AAdjusting learning rate of group 0 to 6.4510e-04.\n",
      "Epoch 1094:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.22it/s, loss=9.58e-08, v_num=23, train_loss=1.15e-5, test_loss=1.2e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1094:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.87it/s, loss=9.58e-08, v_num=23, train_loss=1.15e-5, test_loss=1.2e-5]\u001b[A\n",
      "Epoch 1094: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.10it/s, loss=9.58e-08, v_num=23, train_loss=9.78e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 1095:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.72it/s, loss=1.08e-07, v_num=23, train_loss=9.78e-6, test_loss=1.05e-5]\u001b[AAdjusting learning rate of group 0 to 6.4349e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1095:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.16it/s, loss=1.05e-07, v_num=23, train_loss=9.78e-6, test_loss=1.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1095:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.70it/s, loss=1.05e-07, v_num=23, train_loss=9.78e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 1095: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.82it/s, loss=1.05e-07, v_num=23, train_loss=9.29e-6, test_loss=9.88e-6]\u001b[A\n",
      "Epoch 1096:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.13it/s, loss=9.72e-08, v_num=23, train_loss=9.29e-6, test_loss=9.88e-6]\u001b[AAdjusting learning rate of group 0 to 6.4188e-04.\n",
      "Epoch 1096:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.98it/s, loss=9.35e-08, v_num=23, train_loss=9.29e-6, test_loss=9.88e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1096:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.82it/s, loss=9.35e-08, v_num=23, train_loss=9.29e-6, test_loss=9.88e-6]\u001b[A\n",
      "Epoch 1096: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.21it/s, loss=9.35e-08, v_num=23, train_loss=8.95e-6, test_loss=9.65e-6]\u001b[A\n",
      "Epoch 1097:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.58it/s, loss=8.94e-08, v_num=23, train_loss=8.95e-6, test_loss=9.65e-6]\u001b[AAdjusting learning rate of group 0 to 6.4028e-04.\n",
      "Epoch 1097:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.54it/s, loss=8.73e-08, v_num=23, train_loss=8.95e-6, test_loss=9.65e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1097:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.69it/s, loss=8.73e-08, v_num=23, train_loss=8.95e-6, test_loss=9.65e-6]\u001b[A\n",
      "Epoch 1097: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.17it/s, loss=8.73e-08, v_num=23, train_loss=1.12e-5, test_loss=1.16e-5]\u001b[A\n",
      "Epoch 1098:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.23it/s, loss=8.93e-08, v_num=23, train_loss=1.12e-5, test_loss=1.16e-5]\u001b[AAdjusting learning rate of group 0 to 6.3868e-04.\n",
      "Epoch 1098:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.91it/s, loss=8.62e-08, v_num=23, train_loss=1.12e-5, test_loss=1.16e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1098:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.14it/s, loss=8.62e-08, v_num=23, train_loss=1.12e-5, test_loss=1.16e-5]\u001b[A\n",
      "Epoch 1098: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.18it/s, loss=8.62e-08, v_num=23, train_loss=1.14e-5, test_loss=1.19e-5]\u001b[A\n",
      "Epoch 1099:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.69it/s, loss=1.01e-07, v_num=23, train_loss=1.14e-5, test_loss=1.19e-5]\u001b[AAdjusting learning rate of group 0 to 6.3708e-04.\n",
      "Epoch 1099:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.33it/s, loss=9.83e-08, v_num=23, train_loss=1.14e-5, test_loss=1.19e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1099:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.99it/s, loss=9.83e-08, v_num=23, train_loss=1.14e-5, test_loss=1.19e-5]\u001b[A\n",
      "Epoch 1099: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.36it/s, loss=9.83e-08, v_num=23, train_loss=1.12e-5, test_loss=1.17e-5]\u001b[A\n",
      "Epoch 1100:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.31it/s, loss=1.18e-07, v_num=23, train_loss=1.12e-5, test_loss=1.17e-5]\u001b[AAdjusting learning rate of group 0 to 6.3549e-04.\n",
      "Epoch 1100:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.17it/s, loss=1.11e-07, v_num=23, train_loss=1.12e-5, test_loss=1.17e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1100:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.64it/s, loss=1.11e-07, v_num=23, train_loss=1.12e-5, test_loss=1.17e-5]\u001b[A\n",
      "Epoch 1100: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 164.75it/s, loss=1.11e-07, v_num=23, train_loss=9.25e-6, test_loss=1e-5]\u001b[A\n",
      "Epoch 1101:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 149.20it/s, loss=1.02e-07, v_num=23, train_loss=9.25e-6, test_loss=1e-5]\u001b[AAdjusting learning rate of group 0 to 6.3390e-04.\n",
      "Epoch 1101:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 141.10it/s, loss=9.62e-08, v_num=23, train_loss=9.25e-6, test_loss=1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1101:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 134.73it/s, loss=9.62e-08, v_num=23, train_loss=9.25e-6, test_loss=1e-5]\u001b[A\n",
      "Epoch 1101: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.77it/s, loss=9.62e-08, v_num=23, train_loss=1.4e-5, test_loss=1.49e-5]\u001b[A\n",
      "Epoch 1102:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.92it/s, loss=9.45e-08, v_num=23, train_loss=1.4e-5, test_loss=1.49e-5]\u001b[AAdjusting learning rate of group 0 to 6.3232e-04.\n",
      "Epoch 1102:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.89it/s, loss=8.96e-08, v_num=23, train_loss=1.4e-5, test_loss=1.49e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1102:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.97it/s, loss=8.96e-08, v_num=23, train_loss=1.4e-5, test_loss=1.49e-5]\u001b[A\n",
      "Epoch 1102: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.19it/s, loss=8.96e-08, v_num=23, train_loss=1.23e-5, test_loss=1.28e-5]\u001b[A\n",
      "Epoch 1103:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.61it/s, loss=9.17e-08, v_num=23, train_loss=1.23e-5, test_loss=1.28e-5]\u001b[AAdjusting learning rate of group 0 to 6.3073e-04.\n",
      "Epoch 1103:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.39it/s, loss=8.82e-08, v_num=23, train_loss=1.23e-5, test_loss=1.28e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1103:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.19it/s, loss=8.82e-08, v_num=23, train_loss=1.23e-5, test_loss=1.28e-5]\u001b[A\n",
      "Epoch 1103: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.51it/s, loss=8.82e-08, v_num=23, train_loss=9.33e-6, test_loss=9.97e-6]\u001b[A\n",
      "Epoch 1104:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.69it/s, loss=9.65e-08, v_num=23, train_loss=9.33e-6, test_loss=9.97e-6]\u001b[AAdjusting learning rate of group 0 to 6.2916e-04.\n",
      "Epoch 1104:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.08it/s, loss=9.31e-08, v_num=23, train_loss=9.33e-6, test_loss=9.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1104:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.46it/s, loss=9.31e-08, v_num=23, train_loss=9.33e-6, test_loss=9.97e-6]\u001b[A\n",
      "Epoch 1104: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.02it/s, loss=9.31e-08, v_num=23, train_loss=9.27e-6, test_loss=9.98e-6]\u001b[A\n",
      "Epoch 1105:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.82it/s, loss=9.94e-08, v_num=23, train_loss=9.27e-6, test_loss=9.98e-6]\u001b[AAdjusting learning rate of group 0 to 6.2758e-04.\n",
      "Epoch 1105:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.94it/s, loss=9.57e-08, v_num=23, train_loss=9.27e-6, test_loss=9.98e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1105:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.39it/s, loss=9.57e-08, v_num=23, train_loss=9.27e-6, test_loss=9.98e-6]\u001b[A\n",
      "Epoch 1105: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.98it/s, loss=9.57e-08, v_num=23, train_loss=9.58e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1106:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.09it/s, loss=9.57e-08, v_num=23, train_loss=9.58e-6, test_loss=1.02e-5]\u001b[AAdjusting learning rate of group 0 to 6.2602e-04.\n",
      "Epoch 1106:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.27it/s, loss=9.08e-08, v_num=23, train_loss=9.58e-6, test_loss=1.02e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1106:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 135.33it/s, loss=9.08e-08, v_num=23, train_loss=9.58e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1106: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.87it/s, loss=9.08e-08, v_num=23, train_loss=9.58e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1107:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.44it/s, loss=9.96e-08, v_num=23, train_loss=9.58e-6, test_loss=1.01e-5]\u001b[AAdjusting learning rate of group 0 to 6.2445e-04.\n",
      "Epoch 1107:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.65it/s, loss=9.53e-08, v_num=23, train_loss=9.58e-6, test_loss=1.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1107:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.41it/s, loss=9.53e-08, v_num=23, train_loss=9.58e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1107: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.15it/s, loss=9.53e-08, v_num=23, train_loss=9.55e-6, test_loss=9.96e-6]\u001b[A\n",
      "Epoch 1108:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.82it/s, loss=1.04e-07, v_num=23, train_loss=9.55e-6, test_loss=9.96e-6]\u001b[AAdjusting learning rate of group 0 to 6.2289e-04.\n",
      "Epoch 1108:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.94it/s, loss=9.82e-08, v_num=23, train_loss=9.55e-6, test_loss=9.96e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1108:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.28it/s, loss=9.82e-08, v_num=23, train_loss=9.55e-6, test_loss=9.96e-6]\u001b[A\n",
      "Epoch 1108: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.45it/s, loss=9.82e-08, v_num=23, train_loss=9.72e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 1109:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.44it/s, loss=1.05e-07, v_num=23, train_loss=9.72e-6, test_loss=1.05e-5]\u001b[AAdjusting learning rate of group 0 to 6.2133e-04.\n",
      "Epoch 1109:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.74it/s, loss=1.02e-07, v_num=23, train_loss=9.72e-6, test_loss=1.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1109:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.76it/s, loss=1.02e-07, v_num=23, train_loss=9.72e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 1109: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.44it/s, loss=1.02e-07, v_num=23, train_loss=2.01e-5, test_loss=2.06e-5]\u001b[A\n",
      "Epoch 1110:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.81it/s, loss=1.01e-07, v_num=23, train_loss=2.01e-5, test_loss=2.06e-5]\u001b[AAdjusting learning rate of group 0 to 6.1978e-04.\n",
      "Epoch 1110:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.77it/s, loss=9.59e-08, v_num=23, train_loss=2.01e-5, test_loss=2.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1110:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.27it/s, loss=9.59e-08, v_num=23, train_loss=2.01e-5, test_loss=2.06e-5]\u001b[A\n",
      "Epoch 1110: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.55it/s, loss=9.59e-08, v_num=23, train_loss=8.67e-6, test_loss=9.32e-6]\u001b[A\n",
      "Epoch 1111:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.91it/s, loss=1.11e-07, v_num=23, train_loss=8.67e-6, test_loss=9.32e-6]\u001b[AAdjusting learning rate of group 0 to 6.1823e-04.\n",
      "Epoch 1111:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.00it/s, loss=1.08e-07, v_num=23, train_loss=8.67e-6, test_loss=9.32e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1111:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.03it/s, loss=1.08e-07, v_num=23, train_loss=8.67e-6, test_loss=9.32e-6]\u001b[A\n",
      "Epoch 1111: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.50it/s, loss=1.08e-07, v_num=23, train_loss=1.13e-5, test_loss=1.2e-5]\u001b[A\n",
      "Epoch 1112:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.21it/s, loss=1.05e-07, v_num=23, train_loss=1.13e-5, test_loss=1.2e-5]\u001b[AAdjusting learning rate of group 0 to 6.1668e-04.\n",
      "Epoch 1112:  50%|█████████████████████                     | 79/158 [00:00<00:00, 138.82it/s, loss=1e-07, v_num=23, train_loss=1.13e-5, test_loss=1.2e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1112:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 133.27it/s, loss=1e-07, v_num=23, train_loss=1.13e-5, test_loss=1.2e-5]\u001b[A\n",
      "Epoch 1112: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 169.36it/s, loss=1e-07, v_num=23, train_loss=1.09e-5, test_loss=1.16e-5]\u001b[A\n",
      "Epoch 1113:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.99it/s, loss=1.01e-07, v_num=23, train_loss=1.09e-5, test_loss=1.16e-5]\u001b[AAdjusting learning rate of group 0 to 6.1514e-04.\n",
      "Epoch 1113:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.69it/s, loss=9.71e-08, v_num=23, train_loss=1.09e-5, test_loss=1.16e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1113:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.84it/s, loss=9.71e-08, v_num=23, train_loss=1.09e-5, test_loss=1.16e-5]\u001b[A\n",
      "Epoch 1113: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.69it/s, loss=9.71e-08, v_num=23, train_loss=9.6e-6, test_loss=1.03e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1114:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.49it/s, loss=1.05e-07, v_num=23, train_loss=9.6e-6, test_loss=1.03e-5]\u001b[AAdjusting learning rate of group 0 to 6.1360e-04.\n",
      "Epoch 1114:  50%|█████████████████████                     | 79/158 [00:00<00:00, 138.04it/s, loss=1e-07, v_num=23, train_loss=9.6e-6, test_loss=1.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1114:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 132.39it/s, loss=1e-07, v_num=23, train_loss=9.6e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1114: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 167.77it/s, loss=1e-07, v_num=23, train_loss=1.17e-5, test_loss=1.2e-5]\u001b[A\n",
      "Epoch 1115:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.67it/s, loss=1.05e-07, v_num=23, train_loss=1.17e-5, test_loss=1.2e-5]\u001b[AAdjusting learning rate of group 0 to 6.1207e-04.\n",
      "Epoch 1115:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.69it/s, loss=1.01e-07, v_num=23, train_loss=1.17e-5, test_loss=1.2e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1115:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.75it/s, loss=1.01e-07, v_num=23, train_loss=1.17e-5, test_loss=1.2e-5]\u001b[A\n",
      "Epoch 1115: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.94it/s, loss=1.01e-07, v_num=23, train_loss=1.01e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 1116:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 150.53it/s, loss=9e-08, v_num=23, train_loss=1.01e-5, test_loss=1.09e-5]\u001b[AAdjusting learning rate of group 0 to 6.1054e-04.\n",
      "Epoch 1116:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.02it/s, loss=8.62e-08, v_num=23, train_loss=1.01e-5, test_loss=1.09e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1116:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.35it/s, loss=8.62e-08, v_num=23, train_loss=1.01e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 1116: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.36it/s, loss=8.62e-08, v_num=23, train_loss=8.75e-6, test_loss=9.43e-6]\u001b[A\n",
      "Epoch 1117:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.28it/s, loss=9.72e-08, v_num=23, train_loss=8.75e-6, test_loss=9.43e-6]\u001b[AAdjusting learning rate of group 0 to 6.0901e-04.\n",
      "Epoch 1117:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.49it/s, loss=9.29e-08, v_num=23, train_loss=8.75e-6, test_loss=9.43e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1117:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.43it/s, loss=9.29e-08, v_num=23, train_loss=8.75e-6, test_loss=9.43e-6]\u001b[A\n",
      "Epoch 1117: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.54it/s, loss=9.29e-08, v_num=23, train_loss=1.11e-5, test_loss=1.16e-5]\u001b[A\n",
      "Epoch 1118:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.61it/s, loss=9.34e-08, v_num=23, train_loss=1.11e-5, test_loss=1.16e-5]\u001b[AAdjusting learning rate of group 0 to 6.0749e-04.\n",
      "Epoch 1118:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.60it/s, loss=9.03e-08, v_num=23, train_loss=1.11e-5, test_loss=1.16e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1118:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.51it/s, loss=9.03e-08, v_num=23, train_loss=1.11e-5, test_loss=1.16e-5]\u001b[A\n",
      "Epoch 1118: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.49it/s, loss=9.03e-08, v_num=23, train_loss=1.03e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 1119:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.14it/s, loss=1.26e-07, v_num=23, train_loss=1.03e-5, test_loss=1.1e-5]\u001b[AAdjusting learning rate of group 0 to 6.0597e-04.\n",
      "Epoch 1119:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.46it/s, loss=1.21e-07, v_num=23, train_loss=1.03e-5, test_loss=1.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1119:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.85it/s, loss=1.21e-07, v_num=23, train_loss=1.03e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 1119: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.01it/s, loss=1.21e-07, v_num=23, train_loss=1.47e-5, test_loss=1.53e-5]\u001b[A\n",
      "Epoch 1120:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.98it/s, loss=9.18e-08, v_num=23, train_loss=1.47e-5, test_loss=1.53e-5]\u001b[AAdjusting learning rate of group 0 to 6.0446e-04.\n",
      "Epoch 1120:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.21it/s, loss=8.73e-08, v_num=23, train_loss=1.47e-5, test_loss=1.53e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1120:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.49it/s, loss=8.73e-08, v_num=23, train_loss=1.47e-5, test_loss=1.53e-5]\u001b[A\n",
      "Epoch 1120: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.01it/s, loss=8.73e-08, v_num=23, train_loss=1.32e-5, test_loss=1.37e-5]\u001b[A\n",
      "Epoch 1121:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.23it/s, loss=9.07e-08, v_num=23, train_loss=1.32e-5, test_loss=1.37e-5]\u001b[AAdjusting learning rate of group 0 to 6.0295e-04.\n",
      "Epoch 1121:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.41it/s, loss=8.8e-08, v_num=23, train_loss=1.32e-5, test_loss=1.37e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1121:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.65it/s, loss=8.8e-08, v_num=23, train_loss=1.32e-5, test_loss=1.37e-5]\u001b[A\n",
      "Epoch 1121: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.28it/s, loss=8.8e-08, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\u001b[A\n",
      "Epoch 1122:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.27it/s, loss=8.39e-08, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\u001b[AAdjusting learning rate of group 0 to 6.0144e-04.\n",
      "Epoch 1122:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.25it/s, loss=7.99e-08, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1122:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.39it/s, loss=7.99e-08, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\u001b[A\n",
      "Epoch 1122: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.20it/s, loss=7.99e-08, v_num=23, train_loss=8.16e-6, test_loss=8.8e-6]\u001b[A\n",
      "Epoch 1123:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.82it/s, loss=9.14e-08, v_num=23, train_loss=8.16e-6, test_loss=8.8e-6]\u001b[AAdjusting learning rate of group 0 to 5.9994e-04.\n",
      "Epoch 1123:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.85it/s, loss=8.65e-08, v_num=23, train_loss=8.16e-6, test_loss=8.8e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1123:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.28it/s, loss=8.65e-08, v_num=23, train_loss=8.16e-6, test_loss=8.8e-6]\u001b[A\n",
      "Epoch 1123: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.14it/s, loss=8.65e-08, v_num=23, train_loss=8.99e-6, test_loss=9.58e-6]\u001b[A\n",
      "Epoch 1124:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.11it/s, loss=9.41e-08, v_num=23, train_loss=8.99e-6, test_loss=9.58e-6]\u001b[AAdjusting learning rate of group 0 to 5.9844e-04.\n",
      "Epoch 1124:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.37it/s, loss=9.01e-08, v_num=23, train_loss=8.99e-6, test_loss=9.58e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1124:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.91it/s, loss=9.01e-08, v_num=23, train_loss=8.99e-6, test_loss=9.58e-6]\u001b[A\n",
      "Epoch 1124: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.31it/s, loss=9.01e-08, v_num=23, train_loss=9.6e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1125:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.34it/s, loss=1.31e-07, v_num=23, train_loss=9.6e-6, test_loss=1.02e-5]\u001b[AAdjusting learning rate of group 0 to 5.9694e-04.\n",
      "Epoch 1125:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.28it/s, loss=1.26e-07, v_num=23, train_loss=9.6e-6, test_loss=1.02e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1125:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.67it/s, loss=1.26e-07, v_num=23, train_loss=9.6e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1125: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.48it/s, loss=1.26e-07, v_num=23, train_loss=9.35e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1126:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.05it/s, loss=9.07e-08, v_num=23, train_loss=9.35e-6, test_loss=1.01e-5]\u001b[AAdjusting learning rate of group 0 to 5.9545e-04.\n",
      "Epoch 1126:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.53it/s, loss=8.24e-08, v_num=23, train_loss=9.35e-6, test_loss=1.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1126:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.85it/s, loss=8.24e-08, v_num=23, train_loss=9.35e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1126: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.03it/s, loss=8.24e-08, v_num=23, train_loss=9.21e-6, test_loss=9.89e-6]\u001b[A\n",
      "Epoch 1127:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.65it/s, loss=1.04e-07, v_num=23, train_loss=9.21e-6, test_loss=9.89e-6]\u001b[AAdjusting learning rate of group 0 to 5.9396e-04.\n",
      "Epoch 1127:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.47it/s, loss=9.79e-08, v_num=23, train_loss=9.21e-6, test_loss=9.89e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1127:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.31it/s, loss=9.79e-08, v_num=23, train_loss=9.21e-6, test_loss=9.89e-6]\u001b[A\n",
      "Epoch 1127: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.71it/s, loss=9.79e-08, v_num=23, train_loss=1.09e-5, test_loss=1.15e-5]\u001b[A\n",
      "Epoch 1128:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.99it/s, loss=9.01e-08, v_num=23, train_loss=1.09e-5, test_loss=1.15e-5]\u001b[AAdjusting learning rate of group 0 to 5.9247e-04.\n",
      "Epoch 1128:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.77it/s, loss=8.53e-08, v_num=23, train_loss=1.09e-5, test_loss=1.15e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1128:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.66it/s, loss=8.53e-08, v_num=23, train_loss=1.09e-5, test_loss=1.15e-5]\u001b[A\n",
      "Epoch 1128: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.02it/s, loss=8.53e-08, v_num=23, train_loss=8.43e-6, test_loss=9.18e-6]\u001b[A\n",
      "Epoch 1129:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.08it/s, loss=1.08e-07, v_num=23, train_loss=8.43e-6, test_loss=9.18e-6]\u001b[AAdjusting learning rate of group 0 to 5.9099e-04.\n",
      "Epoch 1129:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.21it/s, loss=1.06e-07, v_num=23, train_loss=8.43e-6, test_loss=9.18e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1129:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.64it/s, loss=1.06e-07, v_num=23, train_loss=8.43e-6, test_loss=9.18e-6]\u001b[A\n",
      "Epoch 1129: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.00it/s, loss=1.06e-07, v_num=23, train_loss=1.07e-5, test_loss=1.16e-5]\u001b[A\n",
      "Epoch 1130:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.91it/s, loss=9.1e-08, v_num=23, train_loss=1.07e-5, test_loss=1.16e-5]\u001b[AAdjusting learning rate of group 0 to 5.8951e-04.\n",
      "Epoch 1130:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.41it/s, loss=8.78e-08, v_num=23, train_loss=1.07e-5, test_loss=1.16e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1130:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.60it/s, loss=8.78e-08, v_num=23, train_loss=1.07e-5, test_loss=1.16e-5]\u001b[A\n",
      "Epoch 1130: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.21it/s, loss=8.78e-08, v_num=23, train_loss=8.51e-6, test_loss=9.18e-6]\u001b[A\n",
      "Epoch 1131:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.91it/s, loss=8.63e-08, v_num=23, train_loss=8.51e-6, test_loss=9.18e-6]\u001b[AAdjusting learning rate of group 0 to 5.8804e-04.\n",
      "Epoch 1131:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.88it/s, loss=8.09e-08, v_num=23, train_loss=8.51e-6, test_loss=9.18e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1131:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.81it/s, loss=8.09e-08, v_num=23, train_loss=8.51e-6, test_loss=9.18e-6]\u001b[A\n",
      "Epoch 1131: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.06it/s, loss=8.09e-08, v_num=23, train_loss=9.93e-6, test_loss=1.07e-5]\u001b[A\n",
      "Epoch 1132:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.32it/s, loss=9.35e-08, v_num=23, train_loss=9.93e-6, test_loss=1.07e-5]\u001b[AAdjusting learning rate of group 0 to 5.8657e-04.\n",
      "Epoch 1132:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.47it/s, loss=8.98e-08, v_num=23, train_loss=9.93e-6, test_loss=1.07e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1132:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.62it/s, loss=8.98e-08, v_num=23, train_loss=9.93e-6, test_loss=1.07e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1132: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.68it/s, loss=8.98e-08, v_num=23, train_loss=8.09e-6, test_loss=8.68e-6]\u001b[A\n",
      "Epoch 1133:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.06it/s, loss=8.95e-08, v_num=23, train_loss=8.09e-6, test_loss=8.68e-6]\u001b[AAdjusting learning rate of group 0 to 5.8510e-04.\n",
      "Epoch 1133:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.67it/s, loss=8.68e-08, v_num=23, train_loss=8.09e-6, test_loss=8.68e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1133:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.84it/s, loss=8.68e-08, v_num=23, train_loss=8.09e-6, test_loss=8.68e-6]\u001b[A\n",
      "Epoch 1133: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.09it/s, loss=8.68e-08, v_num=23, train_loss=1.14e-5, test_loss=1.22e-5]\u001b[A\n",
      "Epoch 1134:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.18it/s, loss=9.73e-08, v_num=23, train_loss=1.14e-5, test_loss=1.22e-5]\u001b[AAdjusting learning rate of group 0 to 5.8364e-04.\n",
      "Epoch 1134:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.24it/s, loss=9.55e-08, v_num=23, train_loss=1.14e-5, test_loss=1.22e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1134:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 135.05it/s, loss=9.55e-08, v_num=23, train_loss=1.14e-5, test_loss=1.22e-5]\u001b[A\n",
      "Epoch 1134: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.76it/s, loss=9.55e-08, v_num=23, train_loss=8.64e-6, test_loss=9.25e-6]\u001b[A\n",
      "Epoch 1135:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.82it/s, loss=1.09e-07, v_num=23, train_loss=8.64e-6, test_loss=9.25e-6]\u001b[AAdjusting learning rate of group 0 to 5.8218e-04.\n",
      "Epoch 1135:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.35it/s, loss=1.06e-07, v_num=23, train_loss=8.64e-6, test_loss=9.25e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1135:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.24it/s, loss=1.06e-07, v_num=23, train_loss=8.64e-6, test_loss=9.25e-6]\u001b[A\n",
      "Epoch 1135: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.59it/s, loss=1.06e-07, v_num=23, train_loss=1.17e-5, test_loss=1.24e-5]\u001b[A\n",
      "Epoch 1136:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.43it/s, loss=9.23e-08, v_num=23, train_loss=1.17e-5, test_loss=1.24e-5]\u001b[AAdjusting learning rate of group 0 to 5.8073e-04.\n",
      "Epoch 1136:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.99it/s, loss=8.44e-08, v_num=23, train_loss=1.17e-5, test_loss=1.24e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1136:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.82it/s, loss=8.44e-08, v_num=23, train_loss=1.17e-5, test_loss=1.24e-5]\u001b[A\n",
      "Epoch 1136: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.83it/s, loss=8.44e-08, v_num=23, train_loss=9.57e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1137:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.73it/s, loss=1.12e-07, v_num=23, train_loss=9.57e-6, test_loss=1.02e-5]\u001b[AAdjusting learning rate of group 0 to 5.7928e-04.\n",
      "Epoch 1137:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.61it/s, loss=1.08e-07, v_num=23, train_loss=9.57e-6, test_loss=1.02e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1137:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.99it/s, loss=1.08e-07, v_num=23, train_loss=9.57e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1137: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.68it/s, loss=1.08e-07, v_num=23, train_loss=1.21e-5, test_loss=1.26e-5]\u001b[A\n",
      "Epoch 1138:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.59it/s, loss=9.63e-08, v_num=23, train_loss=1.21e-5, test_loss=1.26e-5]\u001b[AAdjusting learning rate of group 0 to 5.7783e-04.\n",
      "Epoch 1138:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.57it/s, loss=9.18e-08, v_num=23, train_loss=1.21e-5, test_loss=1.26e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1138:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.98it/s, loss=9.18e-08, v_num=23, train_loss=1.21e-5, test_loss=1.26e-5]\u001b[A\n",
      "Epoch 1138: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.50it/s, loss=9.18e-08, v_num=23, train_loss=9.51e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1139:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.55it/s, loss=1.06e-07, v_num=23, train_loss=9.51e-6, test_loss=1.01e-5]\u001b[AAdjusting learning rate of group 0 to 5.7638e-04.\n",
      "Epoch 1139:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.65it/s, loss=1.01e-07, v_num=23, train_loss=9.51e-6, test_loss=1.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1139:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.40it/s, loss=1.01e-07, v_num=23, train_loss=9.51e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1139: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.37it/s, loss=1.01e-07, v_num=23, train_loss=1.07e-5, test_loss=1.13e-5]\u001b[A\n",
      "Epoch 1140:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.47it/s, loss=1.02e-07, v_num=23, train_loss=1.07e-5, test_loss=1.13e-5]\u001b[AAdjusting learning rate of group 0 to 5.7494e-04.\n",
      "Epoch 1140:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.56it/s, loss=9.81e-08, v_num=23, train_loss=1.07e-5, test_loss=1.13e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1140:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.20it/s, loss=9.81e-08, v_num=23, train_loss=1.07e-5, test_loss=1.13e-5]\u001b[A\n",
      "Epoch 1140: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.82it/s, loss=9.81e-08, v_num=23, train_loss=9.89e-6, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1141:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.57it/s, loss=8.19e-08, v_num=23, train_loss=9.89e-6, test_loss=1.06e-5]\u001b[AAdjusting learning rate of group 0 to 5.7350e-04.\n",
      "Epoch 1141:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.45it/s, loss=7.87e-08, v_num=23, train_loss=9.89e-6, test_loss=1.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1141:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.67it/s, loss=7.87e-08, v_num=23, train_loss=9.89e-6, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1141: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.19it/s, loss=7.87e-08, v_num=23, train_loss=1.03e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 1142:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.60it/s, loss=9.93e-08, v_num=23, train_loss=1.03e-5, test_loss=1.08e-5]\u001b[AAdjusting learning rate of group 0 to 5.7207e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1142:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.59it/s, loss=9.5e-08, v_num=23, train_loss=1.03e-5, test_loss=1.08e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1142:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.39it/s, loss=9.5e-08, v_num=23, train_loss=1.03e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 1142: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.34it/s, loss=9.5e-08, v_num=23, train_loss=8.67e-6, test_loss=9.27e-6]\u001b[A\n",
      "Epoch 1143:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.10it/s, loss=1.02e-07, v_num=23, train_loss=8.67e-6, test_loss=9.27e-6]\u001b[AAdjusting learning rate of group 0 to 5.7064e-04.\n",
      "Epoch 1143:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.54it/s, loss=9.77e-08, v_num=23, train_loss=8.67e-6, test_loss=9.27e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1143:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.68it/s, loss=9.77e-08, v_num=23, train_loss=8.67e-6, test_loss=9.27e-6]\u001b[A\n",
      "Epoch 1143: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.95it/s, loss=9.77e-08, v_num=23, train_loss=1.07e-5, test_loss=1.13e-5]\u001b[A\n",
      "Epoch 1144:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.38it/s, loss=1.43e-07, v_num=23, train_loss=1.07e-5, test_loss=1.13e-5]\u001b[AAdjusting learning rate of group 0 to 5.6921e-04.\n",
      "Epoch 1144:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.13it/s, loss=1.34e-07, v_num=23, train_loss=1.07e-5, test_loss=1.13e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1144:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.71it/s, loss=1.34e-07, v_num=23, train_loss=1.07e-5, test_loss=1.13e-5]\u001b[A\n",
      "Epoch 1144: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.99it/s, loss=1.34e-07, v_num=23, train_loss=1.01e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 1145:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.97it/s, loss=1.01e-07, v_num=23, train_loss=1.01e-5, test_loss=1.09e-5]\u001b[AAdjusting learning rate of group 0 to 5.6779e-04.\n",
      "Epoch 1145:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.81it/s, loss=9.69e-08, v_num=23, train_loss=1.01e-5, test_loss=1.09e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1145:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.21it/s, loss=9.69e-08, v_num=23, train_loss=1.01e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 1145: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.80it/s, loss=9.69e-08, v_num=23, train_loss=9.83e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 1146:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.53it/s, loss=1.01e-07, v_num=23, train_loss=9.83e-6, test_loss=1.05e-5]\u001b[AAdjusting learning rate of group 0 to 5.6637e-04.\n",
      "Epoch 1146:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.09it/s, loss=9.75e-08, v_num=23, train_loss=9.83e-6, test_loss=1.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1146:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.13it/s, loss=9.75e-08, v_num=23, train_loss=9.83e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 1146: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.65it/s, loss=9.75e-08, v_num=23, train_loss=9.92e-6, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1147:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.10it/s, loss=9.75e-08, v_num=23, train_loss=9.92e-6, test_loss=1.06e-5]\u001b[AAdjusting learning rate of group 0 to 5.6496e-04.\n",
      "Epoch 1147:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.00it/s, loss=9.26e-08, v_num=23, train_loss=9.92e-6, test_loss=1.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1147:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.67it/s, loss=9.26e-08, v_num=23, train_loss=9.92e-6, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1147: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.36it/s, loss=9.26e-08, v_num=23, train_loss=8.52e-6, test_loss=9.39e-6]\u001b[A\n",
      "Epoch 1148:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.80it/s, loss=9.93e-08, v_num=23, train_loss=8.52e-6, test_loss=9.39e-6]\u001b[AAdjusting learning rate of group 0 to 5.6354e-04.\n",
      "Epoch 1148:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.04it/s, loss=9.47e-08, v_num=23, train_loss=8.52e-6, test_loss=9.39e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1148:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.23it/s, loss=9.47e-08, v_num=23, train_loss=8.52e-6, test_loss=9.39e-6]\u001b[A\n",
      "Epoch 1148: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.72it/s, loss=9.47e-08, v_num=23, train_loss=9.8e-6, test_loss=1.04e-5]\u001b[A\n",
      "Epoch 1149:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.79it/s, loss=9.4e-08, v_num=23, train_loss=9.8e-6, test_loss=1.04e-5]\u001b[AAdjusting learning rate of group 0 to 5.6213e-04.\n",
      "Epoch 1149:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.94it/s, loss=8.74e-08, v_num=23, train_loss=9.8e-6, test_loss=1.04e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1149:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.73it/s, loss=8.74e-08, v_num=23, train_loss=9.8e-6, test_loss=1.04e-5]\u001b[A\n",
      "Epoch 1149: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.62it/s, loss=8.74e-08, v_num=23, train_loss=8.82e-6, test_loss=9.37e-6]\u001b[A\n",
      "Epoch 1150:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.36it/s, loss=9.52e-08, v_num=23, train_loss=8.82e-6, test_loss=9.37e-6]\u001b[AAdjusting learning rate of group 0 to 5.6073e-04.\n",
      "Epoch 1150:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.59it/s, loss=9.12e-08, v_num=23, train_loss=8.82e-6, test_loss=9.37e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1150:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.66it/s, loss=9.12e-08, v_num=23, train_loss=8.82e-6, test_loss=9.37e-6]\u001b[A\n",
      "Epoch 1150: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.80it/s, loss=9.12e-08, v_num=23, train_loss=1.21e-5, test_loss=1.26e-5]\u001b[A\n",
      "Epoch 1151:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.06it/s, loss=9.69e-08, v_num=23, train_loss=1.21e-5, test_loss=1.26e-5]\u001b[AAdjusting learning rate of group 0 to 5.5933e-04.\n",
      "Epoch 1151:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.95it/s, loss=9.4e-08, v_num=23, train_loss=1.21e-5, test_loss=1.26e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1151:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.34it/s, loss=9.4e-08, v_num=23, train_loss=1.21e-5, test_loss=1.26e-5]\u001b[A\n",
      "Epoch 1151: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.75it/s, loss=9.4e-08, v_num=23, train_loss=1.08e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 1152:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.53it/s, loss=9.72e-08, v_num=23, train_loss=1.08e-5, test_loss=1.14e-5]\u001b[AAdjusting learning rate of group 0 to 5.5793e-04.\n",
      "Epoch 1152:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.42it/s, loss=9.42e-08, v_num=23, train_loss=1.08e-5, test_loss=1.14e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1152:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.97it/s, loss=9.42e-08, v_num=23, train_loss=1.08e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 1152: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.32it/s, loss=9.42e-08, v_num=23, train_loss=9.84e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 1153:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.84it/s, loss=1.04e-07, v_num=23, train_loss=9.84e-6, test_loss=1.05e-5]\u001b[AAdjusting learning rate of group 0 to 5.5653e-04.\n",
      "Epoch 1153:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.98it/s, loss=9.95e-08, v_num=23, train_loss=9.84e-6, test_loss=1.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1153:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.10it/s, loss=9.95e-08, v_num=23, train_loss=9.84e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 1153: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.54it/s, loss=9.95e-08, v_num=23, train_loss=1.05e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 1154:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.02it/s, loss=1.02e-07, v_num=23, train_loss=1.05e-5, test_loss=1.1e-5]\u001b[AAdjusting learning rate of group 0 to 5.5514e-04.\n",
      "Epoch 1154:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.93it/s, loss=9.8e-08, v_num=23, train_loss=1.05e-5, test_loss=1.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1154:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.28it/s, loss=9.8e-08, v_num=23, train_loss=1.05e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 1154: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.36it/s, loss=9.8e-08, v_num=23, train_loss=9.58e-6, test_loss=9.94e-6]\u001b[A\n",
      "Epoch 1155:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.02it/s, loss=8.64e-08, v_num=23, train_loss=9.58e-6, test_loss=9.94e-6]\u001b[AAdjusting learning rate of group 0 to 5.5375e-04.\n",
      "Epoch 1155:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.97it/s, loss=8.25e-08, v_num=23, train_loss=9.58e-6, test_loss=9.94e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1155:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.64it/s, loss=8.25e-08, v_num=23, train_loss=9.58e-6, test_loss=9.94e-6]\u001b[A\n",
      "Epoch 1155: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.82it/s, loss=8.25e-08, v_num=23, train_loss=1.04e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 1156:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.37it/s, loss=8.96e-08, v_num=23, train_loss=1.04e-5, test_loss=1.1e-5]\u001b[AAdjusting learning rate of group 0 to 5.5237e-04.\n",
      "Epoch 1156:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.38it/s, loss=8.72e-08, v_num=23, train_loss=1.04e-5, test_loss=1.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1156:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.75it/s, loss=8.72e-08, v_num=23, train_loss=1.04e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 1156: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.82it/s, loss=8.72e-08, v_num=23, train_loss=1.03e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 1157:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.65it/s, loss=1.12e-07, v_num=23, train_loss=1.03e-5, test_loss=1.09e-5]\u001b[AAdjusting learning rate of group 0 to 5.5099e-04.\n",
      "Epoch 1157:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.36it/s, loss=1.08e-07, v_num=23, train_loss=1.03e-5, test_loss=1.09e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1157:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 128.76it/s, loss=1.08e-07, v_num=23, train_loss=1.03e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 1157: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 163.11it/s, loss=1.08e-07, v_num=23, train_loss=9.32e-6, test_loss=9.82e-6]\u001b[A\n",
      "Epoch 1158:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.61it/s, loss=9.08e-08, v_num=23, train_loss=9.32e-6, test_loss=9.82e-6]\u001b[AAdjusting learning rate of group 0 to 5.4961e-04.\n",
      "Epoch 1158:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.14it/s, loss=8.66e-08, v_num=23, train_loss=9.32e-6, test_loss=9.82e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1158:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.76it/s, loss=8.66e-08, v_num=23, train_loss=9.32e-6, test_loss=9.82e-6]\u001b[A\n",
      "Epoch 1158: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.31it/s, loss=8.66e-08, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\u001b[A\n",
      "Epoch 1159:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 147.43it/s, loss=1e-07, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\u001b[AAdjusting learning rate of group 0 to 5.4824e-04.\n",
      "Epoch 1159:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.63it/s, loss=9.59e-08, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1159:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.08it/s, loss=9.59e-08, v_num=23, train_loss=1.04e-5, test_loss=1.11e-5]\u001b[A\n",
      "Epoch 1159: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.45it/s, loss=9.59e-08, v_num=23, train_loss=1.57e-5, test_loss=1.63e-5]\u001b[A\n",
      "Epoch 1160:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.99it/s, loss=9.68e-08, v_num=23, train_loss=1.57e-5, test_loss=1.63e-5]\u001b[AAdjusting learning rate of group 0 to 5.4687e-04.\n",
      "Epoch 1160:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.74it/s, loss=9.36e-08, v_num=23, train_loss=1.57e-5, test_loss=1.63e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1160:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.66it/s, loss=9.36e-08, v_num=23, train_loss=1.57e-5, test_loss=1.63e-5]\u001b[A\n",
      "Epoch 1160: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.10it/s, loss=9.36e-08, v_num=23, train_loss=8.93e-6, test_loss=9.58e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1161:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 149.14it/s, loss=1e-07, v_num=23, train_loss=8.93e-6, test_loss=9.58e-6]\u001b[AAdjusting learning rate of group 0 to 5.4550e-04.\n",
      "Epoch 1161:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.77it/s, loss=9.35e-08, v_num=23, train_loss=8.93e-6, test_loss=9.58e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1161:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.88it/s, loss=9.35e-08, v_num=23, train_loss=8.93e-6, test_loss=9.58e-6]\u001b[A\n",
      "Epoch 1161: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.13it/s, loss=9.35e-08, v_num=23, train_loss=8.31e-6, test_loss=8.94e-6]\u001b[A\n",
      "Epoch 1162:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.58it/s, loss=9.24e-08, v_num=23, train_loss=8.31e-6, test_loss=8.94e-6]\u001b[AAdjusting learning rate of group 0 to 5.4414e-04.\n",
      "Epoch 1162:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.56it/s, loss=8.92e-08, v_num=23, train_loss=8.31e-6, test_loss=8.94e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1162:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.66it/s, loss=8.92e-08, v_num=23, train_loss=8.31e-6, test_loss=8.94e-6]\u001b[A\n",
      "Epoch 1162: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.91it/s, loss=8.92e-08, v_num=23, train_loss=8.87e-6, test_loss=9.45e-6]\u001b[A\n",
      "Epoch 1163:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.90it/s, loss=8.73e-08, v_num=23, train_loss=8.87e-6, test_loss=9.45e-6]\u001b[AAdjusting learning rate of group 0 to 5.4278e-04.\n",
      "Epoch 1163:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.07it/s, loss=8.33e-08, v_num=23, train_loss=8.87e-6, test_loss=9.45e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1163:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.96it/s, loss=8.33e-08, v_num=23, train_loss=8.87e-6, test_loss=9.45e-6]\u001b[A\n",
      "Epoch 1163: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.70it/s, loss=8.33e-08, v_num=23, train_loss=9.65e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1164:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.13it/s, loss=9.15e-08, v_num=23, train_loss=9.65e-6, test_loss=1.03e-5]\u001b[AAdjusting learning rate of group 0 to 5.4142e-04.\n",
      "Epoch 1164:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.34it/s, loss=8.76e-08, v_num=23, train_loss=9.65e-6, test_loss=1.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1164:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.70it/s, loss=8.76e-08, v_num=23, train_loss=9.65e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1164: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.36it/s, loss=8.76e-08, v_num=23, train_loss=1.12e-5, test_loss=1.18e-5]\u001b[A\n",
      "Epoch 1165:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.85it/s, loss=9.66e-08, v_num=23, train_loss=1.12e-5, test_loss=1.18e-5]\u001b[AAdjusting learning rate of group 0 to 5.4007e-04.\n",
      "Epoch 1165:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.06it/s, loss=9.34e-08, v_num=23, train_loss=1.12e-5, test_loss=1.18e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1165:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.52it/s, loss=9.34e-08, v_num=23, train_loss=1.12e-5, test_loss=1.18e-5]\u001b[A\n",
      "Epoch 1165: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.11it/s, loss=9.34e-08, v_num=23, train_loss=9.04e-6, test_loss=9.57e-6]\u001b[A\n",
      "Epoch 1166:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.38it/s, loss=8.82e-08, v_num=23, train_loss=9.04e-6, test_loss=9.57e-6]\u001b[AAdjusting learning rate of group 0 to 5.3872e-04.\n",
      "Epoch 1166:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.69it/s, loss=8.36e-08, v_num=23, train_loss=9.04e-6, test_loss=9.57e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1166:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.99it/s, loss=8.36e-08, v_num=23, train_loss=9.04e-6, test_loss=9.57e-6]\u001b[A\n",
      "Epoch 1166: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.56it/s, loss=8.36e-08, v_num=23, train_loss=9.69e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1167:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.71it/s, loss=1.04e-07, v_num=23, train_loss=9.69e-6, test_loss=1.03e-5]\u001b[AAdjusting learning rate of group 0 to 5.3737e-04.\n",
      "Epoch 1167:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.44it/s, loss=1.01e-07, v_num=23, train_loss=9.69e-6, test_loss=1.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1167:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.31it/s, loss=1.01e-07, v_num=23, train_loss=9.69e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1167: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.81it/s, loss=1.01e-07, v_num=23, train_loss=1.34e-5, test_loss=1.42e-5]\u001b[A\n",
      "Epoch 1168:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.72it/s, loss=9.64e-08, v_num=23, train_loss=1.34e-5, test_loss=1.42e-5]\u001b[AAdjusting learning rate of group 0 to 5.3603e-04.\n",
      "Epoch 1168:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.65it/s, loss=8.7e-08, v_num=23, train_loss=1.34e-5, test_loss=1.42e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1168:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.82it/s, loss=8.7e-08, v_num=23, train_loss=1.34e-5, test_loss=1.42e-5]\u001b[A\n",
      "Epoch 1168: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.14it/s, loss=8.7e-08, v_num=23, train_loss=8.47e-6, test_loss=9.18e-6]\u001b[A\n",
      "Epoch 1169:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.46it/s, loss=1.05e-07, v_num=23, train_loss=8.47e-6, test_loss=9.18e-6]\u001b[AAdjusting learning rate of group 0 to 5.3469e-04.\n",
      "Epoch 1169:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.71it/s, loss=1.01e-07, v_num=23, train_loss=8.47e-6, test_loss=9.18e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1169:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.55it/s, loss=1.01e-07, v_num=23, train_loss=8.47e-6, test_loss=9.18e-6]\u001b[A\n",
      "Epoch 1169: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.79it/s, loss=1.01e-07, v_num=23, train_loss=1.11e-5, test_loss=1.18e-5]\u001b[A\n",
      "Epoch 1170:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.67it/s, loss=1.1e-07, v_num=23, train_loss=1.11e-5, test_loss=1.18e-5]\u001b[AAdjusting learning rate of group 0 to 5.3335e-04.\n",
      "Epoch 1170:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.19it/s, loss=1.04e-07, v_num=23, train_loss=1.11e-5, test_loss=1.18e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1170:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.70it/s, loss=1.04e-07, v_num=23, train_loss=1.11e-5, test_loss=1.18e-5]\u001b[A\n",
      "Epoch 1170: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.45it/s, loss=1.04e-07, v_num=23, train_loss=8.74e-6, test_loss=9.39e-6]\u001b[A\n",
      "Epoch 1171:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.01it/s, loss=9.32e-08, v_num=23, train_loss=8.74e-6, test_loss=9.39e-6]\u001b[AAdjusting learning rate of group 0 to 5.3202e-04.\n",
      "Epoch 1171:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.01it/s, loss=8.87e-08, v_num=23, train_loss=8.74e-6, test_loss=9.39e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1171:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.21it/s, loss=8.87e-08, v_num=23, train_loss=8.74e-6, test_loss=9.39e-6]\u001b[A\n",
      "Epoch 1171: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.39it/s, loss=8.87e-08, v_num=23, train_loss=1.04e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 1172:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.20it/s, loss=9.08e-08, v_num=23, train_loss=1.04e-5, test_loss=1.08e-5]\u001b[AAdjusting learning rate of group 0 to 5.3069e-04.\n",
      "Epoch 1172:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.48it/s, loss=8.59e-08, v_num=23, train_loss=1.04e-5, test_loss=1.08e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1172:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.40it/s, loss=8.59e-08, v_num=23, train_loss=1.04e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 1172: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.29it/s, loss=8.59e-08, v_num=23, train_loss=9.46e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1173:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 144.37it/s, loss=8.83e-08, v_num=23, train_loss=9.46e-6, test_loss=1.01e-5]\u001b[AAdjusting learning rate of group 0 to 5.2936e-04.\n",
      "Epoch 1173:  50%|███████████████████                   | 79/158 [00:00<00:00, 134.09it/s, loss=8.14e-08, v_num=23, train_loss=9.46e-6, test_loss=1.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1173:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 126.86it/s, loss=8.14e-08, v_num=23, train_loss=9.46e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1173: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 161.54it/s, loss=8.14e-08, v_num=23, train_loss=8.73e-6, test_loss=9.42e-6]\u001b[A\n",
      "Epoch 1174:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.33it/s, loss=8.91e-08, v_num=23, train_loss=8.73e-6, test_loss=9.42e-6]\u001b[AAdjusting learning rate of group 0 to 5.2803e-04.\n",
      "Epoch 1174:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.37it/s, loss=8.48e-08, v_num=23, train_loss=8.73e-6, test_loss=9.42e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1174:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.64it/s, loss=8.48e-08, v_num=23, train_loss=8.73e-6, test_loss=9.42e-6]\u001b[A\n",
      "Epoch 1174: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.09it/s, loss=8.48e-08, v_num=23, train_loss=9.96e-6, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1175:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.23it/s, loss=9.56e-08, v_num=23, train_loss=9.96e-6, test_loss=1.06e-5]\u001b[AAdjusting learning rate of group 0 to 5.2671e-04.\n",
      "Epoch 1175:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.29it/s, loss=9.18e-08, v_num=23, train_loss=9.96e-6, test_loss=1.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1175:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.04it/s, loss=9.18e-08, v_num=23, train_loss=9.96e-6, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1175: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.76it/s, loss=9.18e-08, v_num=23, train_loss=9.85e-6, test_loss=1.04e-5]\u001b[A\n",
      "Epoch 1176:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.64it/s, loss=8.61e-08, v_num=23, train_loss=9.85e-6, test_loss=1.04e-5]\u001b[AAdjusting learning rate of group 0 to 5.2540e-04.\n",
      "Epoch 1176:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.66it/s, loss=8.35e-08, v_num=23, train_loss=9.85e-6, test_loss=1.04e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1176:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.48it/s, loss=8.35e-08, v_num=23, train_loss=9.85e-6, test_loss=1.04e-5]\u001b[A\n",
      "Epoch 1176: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.58it/s, loss=8.35e-08, v_num=23, train_loss=1.1e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 1177:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.87it/s, loss=9.05e-08, v_num=23, train_loss=1.1e-5, test_loss=1.14e-5]\u001b[AAdjusting learning rate of group 0 to 5.2408e-04.\n",
      "Epoch 1177:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.47it/s, loss=8.63e-08, v_num=23, train_loss=1.1e-5, test_loss=1.14e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1177:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.69it/s, loss=8.63e-08, v_num=23, train_loss=1.1e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 1177: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.11it/s, loss=8.63e-08, v_num=23, train_loss=8.49e-6, test_loss=9.14e-6]\u001b[A\n",
      "Epoch 1178:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.11it/s, loss=8.86e-08, v_num=23, train_loss=8.49e-6, test_loss=9.14e-6]\u001b[AAdjusting learning rate of group 0 to 5.2277e-04.\n",
      "Epoch 1178:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.98it/s, loss=8.39e-08, v_num=23, train_loss=8.49e-6, test_loss=9.14e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1178:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.93it/s, loss=8.39e-08, v_num=23, train_loss=8.49e-6, test_loss=9.14e-6]\u001b[A\n",
      "Epoch 1178: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.01it/s, loss=8.39e-08, v_num=23, train_loss=8.69e-6, test_loss=9.37e-6]\u001b[A\n",
      "Epoch 1179:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.89it/s, loss=9.23e-08, v_num=23, train_loss=8.69e-6, test_loss=9.37e-6]\u001b[AAdjusting learning rate of group 0 to 5.2147e-04.\n",
      "Epoch 1179:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.06it/s, loss=8.87e-08, v_num=23, train_loss=8.69e-6, test_loss=9.37e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1179:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.19it/s, loss=8.87e-08, v_num=23, train_loss=8.69e-6, test_loss=9.37e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1179: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.41it/s, loss=8.87e-08, v_num=23, train_loss=9.26e-6, test_loss=9.91e-6]\u001b[A\n",
      "Epoch 1180:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.14it/s, loss=8.56e-08, v_num=23, train_loss=9.26e-6, test_loss=9.91e-6]\u001b[AAdjusting learning rate of group 0 to 5.2016e-04.\n",
      "Epoch 1180:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.70it/s, loss=8.25e-08, v_num=23, train_loss=9.26e-6, test_loss=9.91e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1180:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.07it/s, loss=8.25e-08, v_num=23, train_loss=9.26e-6, test_loss=9.91e-6]\u001b[A\n",
      "Epoch 1180: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.41it/s, loss=8.25e-08, v_num=23, train_loss=8.75e-6, test_loss=9.36e-6]\u001b[A\n",
      "Epoch 1181:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.61it/s, loss=8.26e-08, v_num=23, train_loss=8.75e-6, test_loss=9.36e-6]\u001b[AAdjusting learning rate of group 0 to 5.1886e-04.\n",
      "Epoch 1181:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.68it/s, loss=7.85e-08, v_num=23, train_loss=8.75e-6, test_loss=9.36e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1181:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.68it/s, loss=7.85e-08, v_num=23, train_loss=8.75e-6, test_loss=9.36e-6]\u001b[A\n",
      "Epoch 1181: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.85it/s, loss=7.85e-08, v_num=23, train_loss=8.4e-6, test_loss=8.98e-6]\u001b[A\n",
      "Epoch 1182:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.05it/s, loss=1.14e-07, v_num=23, train_loss=8.4e-6, test_loss=8.98e-6]\u001b[AAdjusting learning rate of group 0 to 5.1757e-04.\n",
      "Epoch 1182:  50%|████████████████████                    | 79/158 [00:00<00:00, 141.49it/s, loss=1.1e-07, v_num=23, train_loss=8.4e-6, test_loss=8.98e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1182:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 134.29it/s, loss=1.1e-07, v_num=23, train_loss=8.4e-6, test_loss=8.98e-6]\u001b[A\n",
      "Epoch 1182: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.55it/s, loss=1.1e-07, v_num=23, train_loss=9.24e-6, test_loss=9.86e-6]\u001b[A\n",
      "Epoch 1183:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.57it/s, loss=8.54e-08, v_num=23, train_loss=9.24e-6, test_loss=9.86e-6]\u001b[AAdjusting learning rate of group 0 to 5.1627e-04.\n",
      "Epoch 1183:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.07it/s, loss=8.16e-08, v_num=23, train_loss=9.24e-6, test_loss=9.86e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1183:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.24it/s, loss=8.16e-08, v_num=23, train_loss=9.24e-6, test_loss=9.86e-6]\u001b[A\n",
      "Epoch 1183: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.53it/s, loss=8.16e-08, v_num=23, train_loss=1.01e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 1184:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.42it/s, loss=1.05e-07, v_num=23, train_loss=1.01e-5, test_loss=1.08e-5]\u001b[AAdjusting learning rate of group 0 to 5.1498e-04.\n",
      "Epoch 1184:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.31it/s, loss=1.02e-07, v_num=23, train_loss=1.01e-5, test_loss=1.08e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1184:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.77it/s, loss=1.02e-07, v_num=23, train_loss=1.01e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 1184: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.55it/s, loss=1.02e-07, v_num=23, train_loss=9.16e-6, test_loss=9.8e-6]\u001b[A\n",
      "Epoch 1185:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 147.92it/s, loss=1e-07, v_num=23, train_loss=9.16e-6, test_loss=9.8e-6]\u001b[AAdjusting learning rate of group 0 to 5.1369e-04.\n",
      "Epoch 1185:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.67it/s, loss=9.68e-08, v_num=23, train_loss=9.16e-6, test_loss=9.8e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1185:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.02it/s, loss=9.68e-08, v_num=23, train_loss=9.16e-6, test_loss=9.8e-6]\u001b[A\n",
      "Epoch 1185: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.53it/s, loss=9.68e-08, v_num=23, train_loss=8.83e-6, test_loss=9.52e-6]\u001b[A\n",
      "Epoch 1186:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.13it/s, loss=1.27e-07, v_num=23, train_loss=8.83e-6, test_loss=9.52e-6]\u001b[AAdjusting learning rate of group 0 to 5.1241e-04.\n",
      "Epoch 1186:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.57it/s, loss=9.99e-08, v_num=23, train_loss=8.83e-6, test_loss=9.52e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1186:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.91it/s, loss=9.99e-08, v_num=23, train_loss=8.83e-6, test_loss=9.52e-6]\u001b[A\n",
      "Epoch 1186: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.08it/s, loss=9.99e-08, v_num=23, train_loss=8.5e-6, test_loss=8.96e-6]\u001b[A\n",
      "Epoch 1187:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.15it/s, loss=9.51e-08, v_num=23, train_loss=8.5e-6, test_loss=8.96e-6]\u001b[AAdjusting learning rate of group 0 to 5.1113e-04.\n",
      "Epoch 1187:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.14it/s, loss=9.03e-08, v_num=23, train_loss=8.5e-6, test_loss=8.96e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1187:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.52it/s, loss=9.03e-08, v_num=23, train_loss=8.5e-6, test_loss=8.96e-6]\u001b[A\n",
      "Epoch 1187: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.97it/s, loss=9.03e-08, v_num=23, train_loss=9.82e-6, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1188:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 145.57it/s, loss=1.04e-07, v_num=23, train_loss=9.82e-6, test_loss=1.06e-5]\u001b[AAdjusting learning rate of group 0 to 5.0985e-04.\n",
      "Epoch 1188:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 134.85it/s, loss=1e-07, v_num=23, train_loss=9.82e-6, test_loss=1.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1188:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 130.75it/s, loss=1e-07, v_num=23, train_loss=9.82e-6, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1188: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 165.79it/s, loss=1e-07, v_num=23, train_loss=1.03e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 1189:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.32it/s, loss=8.19e-08, v_num=23, train_loss=1.03e-5, test_loss=1.09e-5]\u001b[AAdjusting learning rate of group 0 to 5.0858e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1189:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.96it/s, loss=7.82e-08, v_num=23, train_loss=1.03e-5, test_loss=1.09e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1189:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.21it/s, loss=7.82e-08, v_num=23, train_loss=1.03e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 1189: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.18it/s, loss=7.82e-08, v_num=23, train_loss=8.82e-6, test_loss=9.45e-6]\u001b[A\n",
      "Epoch 1190:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.93it/s, loss=8.74e-08, v_num=23, train_loss=8.82e-6, test_loss=9.45e-6]\u001b[AAdjusting learning rate of group 0 to 5.0730e-04.\n",
      "Epoch 1190:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.09it/s, loss=8.36e-08, v_num=23, train_loss=8.82e-6, test_loss=9.45e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1190:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.97it/s, loss=8.36e-08, v_num=23, train_loss=8.82e-6, test_loss=9.45e-6]\u001b[A\n",
      "Epoch 1190: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.96it/s, loss=8.36e-08, v_num=23, train_loss=8.92e-6, test_loss=9.62e-6]\u001b[A\n",
      "Epoch 1191:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.48it/s, loss=1.08e-07, v_num=23, train_loss=8.92e-6, test_loss=9.62e-6]\u001b[AAdjusting learning rate of group 0 to 5.0604e-04.\n",
      "Epoch 1191:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.57it/s, loss=1.03e-07, v_num=23, train_loss=8.92e-6, test_loss=9.62e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1191:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 135.22it/s, loss=1.03e-07, v_num=23, train_loss=8.92e-6, test_loss=9.62e-6]\u001b[A\n",
      "Epoch 1191: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.72it/s, loss=1.03e-07, v_num=23, train_loss=9.87e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1192:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.44it/s, loss=8.67e-08, v_num=23, train_loss=9.87e-6, test_loss=1.03e-5]\u001b[AAdjusting learning rate of group 0 to 5.0477e-04.\n",
      "Epoch 1192:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.35it/s, loss=8.2e-08, v_num=23, train_loss=9.87e-6, test_loss=1.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1192:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.24it/s, loss=8.2e-08, v_num=23, train_loss=9.87e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1192: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.33it/s, loss=8.2e-08, v_num=23, train_loss=9.34e-6, test_loss=9.89e-6]\u001b[A\n",
      "Epoch 1193:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.50it/s, loss=9.75e-08, v_num=23, train_loss=9.34e-6, test_loss=9.89e-6]\u001b[AAdjusting learning rate of group 0 to 5.0351e-04.\n",
      "Epoch 1193:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.39it/s, loss=9.41e-08, v_num=23, train_loss=9.34e-6, test_loss=9.89e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1193:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.47it/s, loss=9.41e-08, v_num=23, train_loss=9.34e-6, test_loss=9.89e-6]\u001b[A\n",
      "Epoch 1193: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.88it/s, loss=9.41e-08, v_num=23, train_loss=1.16e-5, test_loss=1.22e-5]\u001b[A\n",
      "Epoch 1194:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.71it/s, loss=9.45e-08, v_num=23, train_loss=1.16e-5, test_loss=1.22e-5]\u001b[AAdjusting learning rate of group 0 to 5.0225e-04.\n",
      "Epoch 1194:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 138.92it/s, loss=9e-08, v_num=23, train_loss=1.16e-5, test_loss=1.22e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1194:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 131.74it/s, loss=9e-08, v_num=23, train_loss=1.16e-5, test_loss=1.22e-5]\u001b[A\n",
      "Epoch 1194: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 168.14it/s, loss=9e-08, v_num=23, train_loss=1.01e-5, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1195:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.75it/s, loss=9.49e-08, v_num=23, train_loss=1.01e-5, test_loss=1.06e-5]\u001b[AAdjusting learning rate of group 0 to 5.0100e-04.\n",
      "Epoch 1195:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.73it/s, loss=8.91e-08, v_num=23, train_loss=1.01e-5, test_loss=1.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1195:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.95it/s, loss=8.91e-08, v_num=23, train_loss=1.01e-5, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1195: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.51it/s, loss=8.91e-08, v_num=23, train_loss=9.34e-6, test_loss=9.97e-6]\u001b[A\n",
      "Epoch 1196:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.19it/s, loss=7.96e-08, v_num=23, train_loss=9.34e-6, test_loss=9.97e-6]\u001b[AAdjusting learning rate of group 0 to 4.9974e-04.\n",
      "Epoch 1196:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.90it/s, loss=7.71e-08, v_num=23, train_loss=9.34e-6, test_loss=9.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1196:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.56it/s, loss=7.71e-08, v_num=23, train_loss=9.34e-6, test_loss=9.97e-6]\u001b[A\n",
      "Validating:  47%|████████████████████████████████████████████████▏                                                      | 37/79 [00:00<00:00, 173.58it/s]\u001b[A\n",
      "Epoch 1196: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 140.75it/s, loss=7.71e-08, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 1197:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.45it/s, loss=9.37e-08, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\u001b[AAdjusting learning rate of group 0 to 4.9849e-04.\n",
      "Epoch 1197:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.46it/s, loss=8.99e-08, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1197:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.98it/s, loss=8.99e-08, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\u001b[A\n",
      "Validating:  49%|██████████████████████████████████████████████████▊                                                    | 39/79 [00:00<00:00, 180.68it/s]\u001b[A\n",
      "Epoch 1197: 100%|██████████████████████████████████████| 158/158 [00:01<00:00, 141.17it/s, loss=8.99e-08, v_num=23, train_loss=9.2e-6, test_loss=9.92e-6]\u001b[A\n",
      "Epoch 1198:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.70it/s, loss=9.67e-08, v_num=23, train_loss=9.2e-6, test_loss=9.92e-6]\u001b[AAdjusting learning rate of group 0 to 4.9725e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1198:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.27it/s, loss=9.25e-08, v_num=23, train_loss=9.2e-6, test_loss=9.92e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1198:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.62it/s, loss=9.25e-08, v_num=23, train_loss=9.2e-6, test_loss=9.92e-6]\u001b[A\n",
      "Epoch 1198: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 143.22it/s, loss=9.25e-08, v_num=23, train_loss=1.06e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 1199:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.27it/s, loss=9.63e-08, v_num=23, train_loss=1.06e-5, test_loss=1.14e-5]\u001b[AAdjusting learning rate of group 0 to 4.9600e-04.\n",
      "Epoch 1199:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.07it/s, loss=9.24e-08, v_num=23, train_loss=1.06e-5, test_loss=1.14e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.36it/s]\u001b[A\n",
      "Validating:   3%|██▋                                                                                                      | 2/79 [00:00<00:09,  7.97it/s]\u001b[A\n",
      "Validating:   8%|███████▉                                                                                                 | 6/79 [00:00<00:03, 19.39it/s]\u001b[A\n",
      "Validating:  14%|██████████████▍                                                                                         | 11/79 [00:00<00:02, 29.93it/s]\u001b[A\n",
      "Epoch 1199:  67%|█████████████████████████▍            | 106/158 [00:01<00:00, 90.54it/s, loss=9.24e-08, v_num=23, train_loss=1.06e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 1199: 100%|████████████████████████████████████████| 158/158 [00:01<00:00, 120.33it/s, loss=9.24e-08, v_num=23, train_loss=9.38e-6, test_loss=1e-5]\u001b[A\n",
      "Epoch 1200:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 147.29it/s, loss=9.3e-08, v_num=23, train_loss=9.38e-6, test_loss=1e-5]\u001b[AAdjusting learning rate of group 0 to 4.9476e-04.\n",
      "Epoch 1200:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 136.49it/s, loss=8.88e-08, v_num=23, train_loss=9.38e-6, test_loss=1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1200:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 131.83it/s, loss=8.88e-08, v_num=23, train_loss=9.38e-6, test_loss=1e-5]\u001b[A\n",
      "Epoch 1200: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.53it/s, loss=8.88e-08, v_num=23, train_loss=1.08e-5, test_loss=1.15e-5]\u001b[A\n",
      "Epoch 1201:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.73it/s, loss=9e-08, v_num=23, train_loss=1.08e-5, test_loss=1.15e-5]\u001b[AAdjusting learning rate of group 0 to 4.9353e-04.\n",
      "Epoch 1201:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.75it/s, loss=8.64e-08, v_num=23, train_loss=1.08e-5, test_loss=1.15e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1201:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.71it/s, loss=8.64e-08, v_num=23, train_loss=1.08e-5, test_loss=1.15e-5]\u001b[A\n",
      "Epoch 1201: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.91it/s, loss=8.64e-08, v_num=23, train_loss=8.51e-6, test_loss=9.08e-6]\u001b[A\n",
      "Epoch 1202:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 125.58it/s, loss=8.82e-08, v_num=23, train_loss=8.51e-6, test_loss=9.08e-6]\u001b[AAdjusting learning rate of group 0 to 4.9229e-04.\n",
      "Epoch 1202:  50%|███████████████████                   | 79/158 [00:00<00:00, 117.73it/s, loss=8.26e-08, v_num=23, train_loss=8.51e-6, test_loss=9.08e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1202:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 117.21it/s, loss=8.26e-08, v_num=23, train_loss=8.51e-6, test_loss=9.08e-6]\u001b[A\n",
      "Validating:  51%|████████████████████████████████████████████████████▏                                                  | 40/79 [00:00<00:00, 186.91it/s]\u001b[A\n",
      "Epoch 1202: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 130.43it/s, loss=8.26e-08, v_num=23, train_loss=1.14e-5, test_loss=1.22e-5]\u001b[A\n",
      "Epoch 1203:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 118.88it/s, loss=9.28e-08, v_num=23, train_loss=1.14e-5, test_loss=1.22e-5]\u001b[AAdjusting learning rate of group 0 to 4.9106e-04.\n",
      "Epoch 1203:  50%|███████████████████                   | 79/158 [00:00<00:00, 111.63it/s, loss=8.95e-08, v_num=23, train_loss=1.14e-5, test_loss=1.22e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1203:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 113.63it/s, loss=8.95e-08, v_num=23, train_loss=1.14e-5, test_loss=1.22e-5]\u001b[A\n",
      "Validating:  57%|██████████████████████████████████████████████████████████▋                                            | 45/79 [00:00<00:00, 209.26it/s]\u001b[A\n",
      "Epoch 1203: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 127.44it/s, loss=8.95e-08, v_num=23, train_loss=9.87e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 1204:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 119.82it/s, loss=9.66e-08, v_num=23, train_loss=9.87e-6, test_loss=1.05e-5]\u001b[AAdjusting learning rate of group 0 to 4.8983e-04.\n",
      "Epoch 1204:  50%|███████████████████                   | 79/158 [00:00<00:00, 112.82it/s, loss=9.26e-08, v_num=23, train_loss=9.87e-6, test_loss=1.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1204:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 113.33it/s, loss=9.26e-08, v_num=23, train_loss=9.87e-6, test_loss=1.05e-5]\u001b[A\n",
      "Validating:  42%|███████████████████████████████████████████▍                                                            | 33/79 [00:00<00:00, 94.67it/s]\u001b[A\n",
      "Epoch 1204: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 126.38it/s, loss=9.26e-08, v_num=23, train_loss=1.11e-5, test_loss=1.17e-5]\u001b[A\n",
      "Epoch 1205:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 118.79it/s, loss=8.96e-08, v_num=23, train_loss=1.11e-5, test_loss=1.17e-5]\u001b[AAdjusting learning rate of group 0 to 4.8861e-04.\n",
      "Epoch 1205:  50%|███████████████████                   | 79/158 [00:00<00:00, 113.12it/s, loss=8.67e-08, v_num=23, train_loss=1.11e-5, test_loss=1.17e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.26it/s]\u001b[A\n",
      "Validating:   4%|███▉                                                                                                     | 3/79 [00:00<00:06, 12.53it/s]\u001b[A\n",
      "Validating:   8%|███████▉                                                                                                 | 6/79 [00:00<00:03, 18.39it/s]\u001b[A\n",
      "Validating:  14%|██████████████▍                                                                                         | 11/79 [00:00<00:02, 29.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1205:  67%|█████████████████████████▍            | 106/158 [00:01<00:00, 81.47it/s, loss=8.67e-08, v_num=23, train_loss=1.11e-5, test_loss=1.17e-5]\u001b[A\n",
      "Epoch 1205: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 108.49it/s, loss=8.67e-08, v_num=23, train_loss=9.49e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1206:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 113.33it/s, loss=7.89e-08, v_num=23, train_loss=9.49e-6, test_loss=1.02e-5]\u001b[AAdjusting learning rate of group 0 to 4.8739e-04.\n",
      "Epoch 1206:  50%|███████████████████                   | 79/158 [00:00<00:00, 106.46it/s, loss=7.69e-08, v_num=23, train_loss=9.49e-6, test_loss=1.02e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:23,  3.25it/s]\u001b[A\n",
      "Epoch 1206:  67%|█████████████████████████▍            | 106/158 [00:01<00:00, 89.23it/s, loss=7.69e-08, v_num=23, train_loss=9.49e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1206: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 118.59it/s, loss=7.69e-08, v_num=23, train_loss=8.97e-6, test_loss=9.78e-6]\u001b[A\n",
      "Epoch 1207:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.15it/s, loss=9.86e-08, v_num=23, train_loss=8.97e-6, test_loss=9.78e-6]\u001b[AAdjusting learning rate of group 0 to 4.8617e-04.\n",
      "Epoch 1207:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.74it/s, loss=9.47e-08, v_num=23, train_loss=8.97e-6, test_loss=9.78e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1207:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.36it/s, loss=9.47e-08, v_num=23, train_loss=8.97e-6, test_loss=9.78e-6]\u001b[A\n",
      "Epoch 1207: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.56it/s, loss=9.47e-08, v_num=23, train_loss=1.03e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 1208:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.45it/s, loss=1.31e-07, v_num=23, train_loss=1.03e-5, test_loss=1.08e-5]\u001b[AAdjusting learning rate of group 0 to 4.8495e-04.\n",
      "Epoch 1208:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.06it/s, loss=1.26e-07, v_num=23, train_loss=1.03e-5, test_loss=1.08e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1208:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.46it/s, loss=1.26e-07, v_num=23, train_loss=1.03e-5, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 1208: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.67it/s, loss=1.26e-07, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 1209:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.26it/s, loss=8.88e-08, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\u001b[AAdjusting learning rate of group 0 to 4.8374e-04.\n",
      "Epoch 1209:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.29it/s, loss=8.59e-08, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1209:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.70it/s, loss=8.59e-08, v_num=23, train_loss=1.05e-5, test_loss=1.12e-5]\u001b[A\n",
      "Epoch 1209: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.42it/s, loss=8.59e-08, v_num=23, train_loss=9.38e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1210:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.81it/s, loss=8.99e-08, v_num=23, train_loss=9.38e-6, test_loss=1.01e-5]\u001b[AAdjusting learning rate of group 0 to 4.8253e-04.\n",
      "Epoch 1210:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.43it/s, loss=8.7e-08, v_num=23, train_loss=9.38e-6, test_loss=1.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1210:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.22it/s, loss=8.7e-08, v_num=23, train_loss=9.38e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1210: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.40it/s, loss=8.7e-08, v_num=23, train_loss=8.92e-6, test_loss=9.66e-6]\u001b[A\n",
      "Epoch 1211:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.53it/s, loss=9.42e-08, v_num=23, train_loss=8.92e-6, test_loss=9.66e-6]\u001b[AAdjusting learning rate of group 0 to 4.8133e-04.\n",
      "Epoch 1211:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.37it/s, loss=9.14e-08, v_num=23, train_loss=8.92e-6, test_loss=9.66e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1211:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.77it/s, loss=9.14e-08, v_num=23, train_loss=8.92e-6, test_loss=9.66e-6]\u001b[A\n",
      "Epoch 1211: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.34it/s, loss=9.14e-08, v_num=23, train_loss=9.9e-6, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 1212:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.41it/s, loss=8.45e-08, v_num=23, train_loss=9.9e-6, test_loss=1.08e-5]\u001b[AAdjusting learning rate of group 0 to 4.8012e-04.\n",
      "Epoch 1212:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 142.34it/s, loss=8.16e-08, v_num=23, train_loss=9.9e-6, test_loss=1.08e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1212:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.79it/s, loss=8.16e-08, v_num=23, train_loss=9.9e-6, test_loss=1.08e-5]\u001b[A\n",
      "Epoch 1212: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.79it/s, loss=8.16e-08, v_num=23, train_loss=9.29e-6, test_loss=9.99e-6]\u001b[A\n",
      "Epoch 1213:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.53it/s, loss=9.06e-08, v_num=23, train_loss=9.29e-6, test_loss=9.99e-6]\u001b[AAdjusting learning rate of group 0 to 4.7892e-04.\n",
      "Epoch 1213:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.25it/s, loss=8.75e-08, v_num=23, train_loss=9.29e-6, test_loss=9.99e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1213:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.98it/s, loss=8.75e-08, v_num=23, train_loss=9.29e-6, test_loss=9.99e-6]\u001b[A\n",
      "Epoch 1213: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.84it/s, loss=8.75e-08, v_num=23, train_loss=9.77e-6, test_loss=1.04e-5]\u001b[A\n",
      "Epoch 1214:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.32it/s, loss=9.66e-08, v_num=23, train_loss=9.77e-6, test_loss=1.04e-5]\u001b[AAdjusting learning rate of group 0 to 4.7773e-04.\n",
      "Epoch 1214:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.10it/s, loss=9.28e-08, v_num=23, train_loss=9.77e-6, test_loss=1.04e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1214:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.49it/s, loss=9.28e-08, v_num=23, train_loss=9.77e-6, test_loss=1.04e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1214: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.85it/s, loss=9.28e-08, v_num=23, train_loss=9.57e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1215:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.79it/s, loss=9.29e-08, v_num=23, train_loss=9.57e-6, test_loss=1.02e-5]\u001b[AAdjusting learning rate of group 0 to 4.7653e-04.\n",
      "Epoch 1215:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.39it/s, loss=8.86e-08, v_num=23, train_loss=9.57e-6, test_loss=1.02e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1215:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.48it/s, loss=8.86e-08, v_num=23, train_loss=9.57e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1215: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.08it/s, loss=8.86e-08, v_num=23, train_loss=9.62e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1216:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.36it/s, loss=1.03e-07, v_num=23, train_loss=9.62e-6, test_loss=1.02e-5]\u001b[AAdjusting learning rate of group 0 to 4.7534e-04.\n",
      "Epoch 1216:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.17it/s, loss=9.85e-08, v_num=23, train_loss=9.62e-6, test_loss=1.02e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1216:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.42it/s, loss=9.85e-08, v_num=23, train_loss=9.62e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1216: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.59it/s, loss=9.85e-08, v_num=23, train_loss=8.16e-6, test_loss=8.67e-6]\u001b[A\n",
      "Epoch 1217:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.95it/s, loss=8.77e-08, v_num=23, train_loss=8.16e-6, test_loss=8.67e-6]\u001b[AAdjusting learning rate of group 0 to 4.7415e-04.\n",
      "Epoch 1217:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.74it/s, loss=8.36e-08, v_num=23, train_loss=8.16e-6, test_loss=8.67e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1217:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.62it/s, loss=8.36e-08, v_num=23, train_loss=8.16e-6, test_loss=8.67e-6]\u001b[A\n",
      "Epoch 1217: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 169.68it/s, loss=8.36e-08, v_num=23, train_loss=9.38e-6, test_loss=1e-5]\u001b[A\n",
      "Epoch 1218:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.48it/s, loss=8.57e-08, v_num=23, train_loss=9.38e-6, test_loss=1e-5]\u001b[AAdjusting learning rate of group 0 to 4.7297e-04.\n",
      "Epoch 1218:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 137.51it/s, loss=8.11e-08, v_num=23, train_loss=9.38e-6, test_loss=1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1218:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 132.93it/s, loss=8.11e-08, v_num=23, train_loss=9.38e-6, test_loss=1e-5]\u001b[A\n",
      "Epoch 1218: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 170.27it/s, loss=8.11e-08, v_num=23, train_loss=9e-6, test_loss=9.79e-6]\u001b[A\n",
      "Epoch 1219:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.87it/s, loss=9.29e-08, v_num=23, train_loss=9e-6, test_loss=9.79e-6]\u001b[AAdjusting learning rate of group 0 to 4.7178e-04.\n",
      "Epoch 1219:  50%|██████████████████████                      | 79/158 [00:00<00:00, 139.55it/s, loss=9e-08, v_num=23, train_loss=9e-6, test_loss=9.79e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1219:  67%|████████████████████████████▊              | 106/158 [00:00<00:00, 131.94it/s, loss=9e-08, v_num=23, train_loss=9e-6, test_loss=9.79e-6]\u001b[A\n",
      "Epoch 1219: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 169.42it/s, loss=9e-08, v_num=23, train_loss=8.98e-6, test_loss=9.5e-6]\u001b[A\n",
      "Epoch 1220:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.37it/s, loss=9.11e-08, v_num=23, train_loss=8.98e-6, test_loss=9.5e-6]\u001b[AAdjusting learning rate of group 0 to 4.7060e-04.\n",
      "Epoch 1220:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.41it/s, loss=8.67e-08, v_num=23, train_loss=8.98e-6, test_loss=9.5e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1220:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.24it/s, loss=8.67e-08, v_num=23, train_loss=8.98e-6, test_loss=9.5e-6]\u001b[A\n",
      "Epoch 1220: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.75it/s, loss=8.67e-08, v_num=23, train_loss=9.01e-6, test_loss=9.64e-6]\u001b[A\n",
      "Epoch 1221:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.76it/s, loss=8.47e-08, v_num=23, train_loss=9.01e-6, test_loss=9.64e-6]\u001b[AAdjusting learning rate of group 0 to 4.6943e-04.\n",
      "Epoch 1221:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.45it/s, loss=8.13e-08, v_num=23, train_loss=9.01e-6, test_loss=9.64e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1221:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.20it/s, loss=8.13e-08, v_num=23, train_loss=9.01e-6, test_loss=9.64e-6]\u001b[A\n",
      "Epoch 1221: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.58it/s, loss=8.13e-08, v_num=23, train_loss=9.54e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1222:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.12it/s, loss=1.47e-07, v_num=23, train_loss=9.54e-6, test_loss=1.01e-5]\u001b[AAdjusting learning rate of group 0 to 4.6825e-04.\n",
      "Epoch 1222:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.75it/s, loss=1.42e-07, v_num=23, train_loss=9.54e-6, test_loss=1.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1222:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.14it/s, loss=1.42e-07, v_num=23, train_loss=9.54e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1222: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.76it/s, loss=1.42e-07, v_num=23, train_loss=8.76e-6, test_loss=9.54e-6]\u001b[A\n",
      "Epoch 1223:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.52it/s, loss=9.46e-08, v_num=23, train_loss=8.76e-6, test_loss=9.54e-6]\u001b[AAdjusting learning rate of group 0 to 4.6708e-04.\n",
      "Epoch 1223:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.37it/s, loss=9.04e-08, v_num=23, train_loss=8.76e-6, test_loss=9.54e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1223:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.35it/s, loss=9.04e-08, v_num=23, train_loss=8.76e-6, test_loss=9.54e-6]\u001b[A\n",
      "Epoch 1223: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.97it/s, loss=9.04e-08, v_num=23, train_loss=1.09e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 1224:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.20it/s, loss=9.43e-08, v_num=23, train_loss=1.09e-5, test_loss=1.14e-5]\u001b[AAdjusting learning rate of group 0 to 4.6592e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1224:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.08it/s, loss=9.23e-08, v_num=23, train_loss=1.09e-5, test_loss=1.14e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1224:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.81it/s, loss=9.23e-08, v_num=23, train_loss=1.09e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 1224: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.39it/s, loss=9.23e-08, v_num=23, train_loss=7.92e-6, test_loss=8.59e-6]\u001b[A\n",
      "Epoch 1225:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.47it/s, loss=8.84e-08, v_num=23, train_loss=7.92e-6, test_loss=8.59e-6]\u001b[AAdjusting learning rate of group 0 to 4.6475e-04.\n",
      "Epoch 1225:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.47it/s, loss=8.49e-08, v_num=23, train_loss=7.92e-6, test_loss=8.59e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1225:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.16it/s, loss=8.49e-08, v_num=23, train_loss=7.92e-6, test_loss=8.59e-6]\u001b[A\n",
      "Epoch 1225: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.62it/s, loss=8.49e-08, v_num=23, train_loss=8.69e-6, test_loss=9.26e-6]\u001b[A\n",
      "Epoch 1226:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.28it/s, loss=8.48e-08, v_num=23, train_loss=8.69e-6, test_loss=9.26e-6]\u001b[AAdjusting learning rate of group 0 to 4.6359e-04.\n",
      "Epoch 1226:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.39it/s, loss=8.28e-08, v_num=23, train_loss=8.69e-6, test_loss=9.26e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1226:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.98it/s, loss=8.28e-08, v_num=23, train_loss=8.69e-6, test_loss=9.26e-6]\u001b[A\n",
      "Epoch 1226: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.14it/s, loss=8.28e-08, v_num=23, train_loss=9.04e-6, test_loss=9.71e-6]\u001b[A\n",
      "Epoch 1227:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.67it/s, loss=9.95e-08, v_num=23, train_loss=9.04e-6, test_loss=9.71e-6]\u001b[AAdjusting learning rate of group 0 to 4.6243e-04.\n",
      "Epoch 1227:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.47it/s, loss=9.49e-08, v_num=23, train_loss=9.04e-6, test_loss=9.71e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1227:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.44it/s, loss=9.49e-08, v_num=23, train_loss=9.04e-6, test_loss=9.71e-6]\u001b[A\n",
      "Epoch 1227: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 165.80it/s, loss=9.49e-08, v_num=23, train_loss=1e-5, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1228:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 149.37it/s, loss=7.52e-08, v_num=23, train_loss=1e-5, test_loss=1.06e-5]\u001b[AAdjusting learning rate of group 0 to 4.6127e-04.\n",
      "Epoch 1228:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 141.39it/s, loss=7.18e-08, v_num=23, train_loss=1e-5, test_loss=1.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1228:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 132.95it/s, loss=7.18e-08, v_num=23, train_loss=1e-5, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1228: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.67it/s, loss=7.18e-08, v_num=23, train_loss=8.56e-6, test_loss=9.16e-6]\u001b[A\n",
      "Epoch 1229:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.15it/s, loss=8.39e-08, v_num=23, train_loss=8.56e-6, test_loss=9.16e-6]\u001b[AAdjusting learning rate of group 0 to 4.6012e-04.\n",
      "Epoch 1229:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.62it/s, loss=7.84e-08, v_num=23, train_loss=8.56e-6, test_loss=9.16e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1229:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.39it/s, loss=7.84e-08, v_num=23, train_loss=8.56e-6, test_loss=9.16e-6]\u001b[A\n",
      "Epoch 1229: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.28it/s, loss=7.84e-08, v_num=23, train_loss=8.19e-6, test_loss=8.95e-6]\u001b[A\n",
      "Epoch 1230:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.39it/s, loss=9.43e-08, v_num=23, train_loss=8.19e-6, test_loss=8.95e-6]\u001b[AAdjusting learning rate of group 0 to 4.5897e-04.\n",
      "Epoch 1230:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.35it/s, loss=8.96e-08, v_num=23, train_loss=8.19e-6, test_loss=8.95e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1230:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.14it/s, loss=8.96e-08, v_num=23, train_loss=8.19e-6, test_loss=8.95e-6]\u001b[A\n",
      "Epoch 1230: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.88it/s, loss=8.96e-08, v_num=23, train_loss=9.12e-6, test_loss=9.66e-6]\u001b[A\n",
      "Epoch 1231:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.93it/s, loss=9.06e-08, v_num=23, train_loss=9.12e-6, test_loss=9.66e-6]\u001b[AAdjusting learning rate of group 0 to 4.5782e-04.\n",
      "Epoch 1231:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.72it/s, loss=8.68e-08, v_num=23, train_loss=9.12e-6, test_loss=9.66e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1231:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.89it/s, loss=8.68e-08, v_num=23, train_loss=9.12e-6, test_loss=9.66e-6]\u001b[A\n",
      "Epoch 1231: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.03it/s, loss=8.68e-08, v_num=23, train_loss=9.7e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1232:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.24it/s, loss=8.96e-08, v_num=23, train_loss=9.7e-6, test_loss=1.03e-5]\u001b[AAdjusting learning rate of group 0 to 4.5668e-04.\n",
      "Epoch 1232:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.57it/s, loss=8.56e-08, v_num=23, train_loss=9.7e-6, test_loss=1.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1232:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.11it/s, loss=8.56e-08, v_num=23, train_loss=9.7e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1232: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.25it/s, loss=8.56e-08, v_num=23, train_loss=9.17e-6, test_loss=9.72e-6]\u001b[A\n",
      "Epoch 1233:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.52it/s, loss=1.01e-07, v_num=23, train_loss=9.17e-6, test_loss=9.72e-6]\u001b[AAdjusting learning rate of group 0 to 4.5554e-04.\n",
      "Epoch 1233:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.90it/s, loss=9.65e-08, v_num=23, train_loss=9.17e-6, test_loss=9.72e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1233:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.96it/s, loss=9.65e-08, v_num=23, train_loss=9.17e-6, test_loss=9.72e-6]\u001b[A\n",
      "Epoch 1233: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.66it/s, loss=9.65e-08, v_num=23, train_loss=8.72e-6, test_loss=9.32e-6]\u001b[A\n",
      "Epoch 1234:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.44it/s, loss=9.55e-08, v_num=23, train_loss=8.72e-6, test_loss=9.32e-6]\u001b[AAdjusting learning rate of group 0 to 4.5440e-04.\n",
      "Epoch 1234:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.15it/s, loss=9.18e-08, v_num=23, train_loss=8.72e-6, test_loss=9.32e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1234:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.44it/s, loss=9.18e-08, v_num=23, train_loss=8.72e-6, test_loss=9.32e-6]\u001b[A\n",
      "Epoch 1234: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.87it/s, loss=9.18e-08, v_num=23, train_loss=9.77e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1235:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.53it/s, loss=8.65e-08, v_num=23, train_loss=9.77e-6, test_loss=1.02e-5]\u001b[AAdjusting learning rate of group 0 to 4.5326e-04.\n",
      "Epoch 1235:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.23it/s, loss=8.42e-08, v_num=23, train_loss=9.77e-6, test_loss=1.02e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1235:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.55it/s, loss=8.42e-08, v_num=23, train_loss=9.77e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1235: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.79it/s, loss=8.42e-08, v_num=23, train_loss=9.95e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 1236:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.46it/s, loss=8.42e-08, v_num=23, train_loss=9.95e-6, test_loss=1.05e-5]\u001b[AAdjusting learning rate of group 0 to 4.5213e-04.\n",
      "Epoch 1236:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.85it/s, loss=8.13e-08, v_num=23, train_loss=9.95e-6, test_loss=1.05e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1236:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.73it/s, loss=8.13e-08, v_num=23, train_loss=9.95e-6, test_loss=1.05e-5]\u001b[A\n",
      "Epoch 1236: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.59it/s, loss=8.13e-08, v_num=23, train_loss=1.04e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 1237:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.59it/s, loss=9.23e-08, v_num=23, train_loss=1.04e-5, test_loss=1.09e-5]\u001b[AAdjusting learning rate of group 0 to 4.5100e-04.\n",
      "Epoch 1237:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.26it/s, loss=8.94e-08, v_num=23, train_loss=1.04e-5, test_loss=1.09e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1237:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.43it/s, loss=8.94e-08, v_num=23, train_loss=1.04e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 1237: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.17it/s, loss=8.94e-08, v_num=23, train_loss=8.33e-6, test_loss=9.01e-6]\u001b[A\n",
      "Epoch 1238:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.86it/s, loss=8.72e-08, v_num=23, train_loss=8.33e-6, test_loss=9.01e-6]\u001b[AAdjusting learning rate of group 0 to 4.4987e-04.\n",
      "Epoch 1238:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.72it/s, loss=8.36e-08, v_num=23, train_loss=8.33e-6, test_loss=9.01e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1238:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.27it/s, loss=8.36e-08, v_num=23, train_loss=8.33e-6, test_loss=9.01e-6]\u001b[A\n",
      "Epoch 1238: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.16it/s, loss=8.36e-08, v_num=23, train_loss=8.63e-6, test_loss=9.28e-6]\u001b[A\n",
      "Epoch 1239:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.89it/s, loss=8.94e-08, v_num=23, train_loss=8.63e-6, test_loss=9.28e-6]\u001b[AAdjusting learning rate of group 0 to 4.4875e-04.\n",
      "Epoch 1239:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.83it/s, loss=8.48e-08, v_num=23, train_loss=8.63e-6, test_loss=9.28e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1239:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.61it/s, loss=8.48e-08, v_num=23, train_loss=8.63e-6, test_loss=9.28e-6]\u001b[A\n",
      "Epoch 1239: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.76it/s, loss=8.48e-08, v_num=23, train_loss=8.35e-6, test_loss=8.97e-6]\u001b[A\n",
      "Epoch 1240:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.43it/s, loss=1.54e-07, v_num=23, train_loss=8.35e-6, test_loss=8.97e-6]\u001b[AAdjusting learning rate of group 0 to 4.4762e-04.\n",
      "Epoch 1240:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.70it/s, loss=1.47e-07, v_num=23, train_loss=8.35e-6, test_loss=8.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1240:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.20it/s, loss=1.47e-07, v_num=23, train_loss=8.35e-6, test_loss=8.97e-6]\u001b[A\n",
      "Epoch 1240: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.13it/s, loss=1.47e-07, v_num=23, train_loss=1.22e-5, test_loss=1.27e-5]\u001b[A\n",
      "Epoch 1241:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.51it/s, loss=8.71e-08, v_num=23, train_loss=1.22e-5, test_loss=1.27e-5]\u001b[AAdjusting learning rate of group 0 to 4.4651e-04.\n",
      "Epoch 1241:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.77it/s, loss=8.46e-08, v_num=23, train_loss=1.22e-5, test_loss=1.27e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1241:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.93it/s, loss=8.46e-08, v_num=23, train_loss=1.22e-5, test_loss=1.27e-5]\u001b[A\n",
      "Epoch 1241: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.10it/s, loss=8.46e-08, v_num=23, train_loss=1.07e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 1242:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.23it/s, loss=8.97e-08, v_num=23, train_loss=1.07e-5, test_loss=1.14e-5]\u001b[AAdjusting learning rate of group 0 to 4.4539e-04.\n",
      "Epoch 1242:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.83it/s, loss=8.4e-08, v_num=23, train_loss=1.07e-5, test_loss=1.14e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1242:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 128.63it/s, loss=8.4e-08, v_num=23, train_loss=1.07e-5, test_loss=1.14e-5]\u001b[A\n",
      "Epoch 1242: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.01it/s, loss=8.4e-08, v_num=23, train_loss=8.46e-6, test_loss=9.23e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1243:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.35it/s, loss=7.95e-08, v_num=23, train_loss=8.46e-6, test_loss=9.23e-6]\u001b[AAdjusting learning rate of group 0 to 4.4428e-04.\n",
      "Epoch 1243:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.42it/s, loss=7.52e-08, v_num=23, train_loss=8.46e-6, test_loss=9.23e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1243:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.42it/s, loss=7.52e-08, v_num=23, train_loss=8.46e-6, test_loss=9.23e-6]\u001b[A\n",
      "Epoch 1243: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.94it/s, loss=7.52e-08, v_num=23, train_loss=9.49e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1244:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.59it/s, loss=8.81e-08, v_num=23, train_loss=9.49e-6, test_loss=1.02e-5]\u001b[AAdjusting learning rate of group 0 to 4.4317e-04.\n",
      "Epoch 1244:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.57it/s, loss=8.4e-08, v_num=23, train_loss=9.49e-6, test_loss=1.02e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1244:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.39it/s, loss=8.4e-08, v_num=23, train_loss=9.49e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1244: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.53it/s, loss=8.4e-08, v_num=23, train_loss=8.91e-6, test_loss=9.43e-6]\u001b[A\n",
      "Epoch 1245:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.68it/s, loss=9.01e-08, v_num=23, train_loss=8.91e-6, test_loss=9.43e-6]\u001b[AAdjusting learning rate of group 0 to 4.4206e-04.\n",
      "Epoch 1245:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.63it/s, loss=8.65e-08, v_num=23, train_loss=8.91e-6, test_loss=9.43e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1245:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.92it/s, loss=8.65e-08, v_num=23, train_loss=8.91e-6, test_loss=9.43e-6]\u001b[A\n",
      "Epoch 1245: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.05it/s, loss=8.65e-08, v_num=23, train_loss=8.98e-6, test_loss=9.58e-6]\u001b[A\n",
      "Epoch 1246:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.02it/s, loss=7.98e-08, v_num=23, train_loss=8.98e-6, test_loss=9.58e-6]\u001b[AAdjusting learning rate of group 0 to 4.4095e-04.\n",
      "Epoch 1246:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.25it/s, loss=7.56e-08, v_num=23, train_loss=8.98e-6, test_loss=9.58e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1246:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.23it/s, loss=7.56e-08, v_num=23, train_loss=8.98e-6, test_loss=9.58e-6]\u001b[A\n",
      "Epoch 1246: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.86it/s, loss=7.56e-08, v_num=23, train_loss=9.69e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1247:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.48it/s, loss=9.16e-08, v_num=23, train_loss=9.69e-6, test_loss=1.03e-5]\u001b[AAdjusting learning rate of group 0 to 4.3985e-04.\n",
      "Epoch 1247:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.83it/s, loss=8.64e-08, v_num=23, train_loss=9.69e-6, test_loss=1.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1247:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.40it/s, loss=8.64e-08, v_num=23, train_loss=9.69e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1247: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.02it/s, loss=8.64e-08, v_num=23, train_loss=9.59e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1248:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.03it/s, loss=1.05e-07, v_num=23, train_loss=9.59e-6, test_loss=1.02e-5]\u001b[AAdjusting learning rate of group 0 to 4.3875e-04.\n",
      "Epoch 1248:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 137.98it/s, loss=1e-07, v_num=23, train_loss=9.59e-6, test_loss=1.02e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1248:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 133.00it/s, loss=1e-07, v_num=23, train_loss=9.59e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1248: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 168.64it/s, loss=1e-07, v_num=23, train_loss=9.78e-6, test_loss=1.04e-5]\u001b[A\n",
      "Epoch 1249:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.11it/s, loss=9.28e-08, v_num=23, train_loss=9.78e-6, test_loss=1.04e-5]\u001b[AAdjusting learning rate of group 0 to 4.3765e-04.\n",
      "Epoch 1249:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.25it/s, loss=8.84e-08, v_num=23, train_loss=9.78e-6, test_loss=1.04e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1249:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.68it/s, loss=8.84e-08, v_num=23, train_loss=9.78e-6, test_loss=1.04e-5]\u001b[A\n",
      "Epoch 1249: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.17it/s, loss=8.84e-08, v_num=23, train_loss=9.1e-6, test_loss=9.68e-6]\u001b[A\n",
      "Epoch 1250:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.64it/s, loss=9.73e-08, v_num=23, train_loss=9.1e-6, test_loss=9.68e-6]\u001b[AAdjusting learning rate of group 0 to 4.3656e-04.\n",
      "Epoch 1250:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.25it/s, loss=9.39e-08, v_num=23, train_loss=9.1e-6, test_loss=9.68e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1250:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.15it/s, loss=9.39e-08, v_num=23, train_loss=9.1e-6, test_loss=9.68e-6]\u001b[A\n",
      "Epoch 1250: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.47it/s, loss=9.39e-08, v_num=23, train_loss=9.2e-6, test_loss=9.74e-6]\u001b[A\n",
      "Epoch 1251:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.47it/s, loss=8.49e-08, v_num=23, train_loss=9.2e-6, test_loss=9.74e-6]\u001b[AAdjusting learning rate of group 0 to 4.3547e-04.\n",
      "Epoch 1251:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.62it/s, loss=8.05e-08, v_num=23, train_loss=9.2e-6, test_loss=9.74e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1251:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.85it/s, loss=8.05e-08, v_num=23, train_loss=9.2e-6, test_loss=9.74e-6]\u001b[A\n",
      "Epoch 1251: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.95it/s, loss=8.05e-08, v_num=23, train_loss=8.74e-6, test_loss=9.3e-6]\u001b[A\n",
      "Epoch 1252:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.37it/s, loss=8.68e-08, v_num=23, train_loss=8.74e-6, test_loss=9.3e-6]\u001b[AAdjusting learning rate of group 0 to 4.3438e-04.\n",
      "Epoch 1252:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.71it/s, loss=8.33e-08, v_num=23, train_loss=8.74e-6, test_loss=9.3e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1252:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.36it/s, loss=8.33e-08, v_num=23, train_loss=8.74e-6, test_loss=9.3e-6]\u001b[A\n",
      "Epoch 1252: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.18it/s, loss=8.33e-08, v_num=23, train_loss=9.18e-6, test_loss=9.81e-6]\u001b[A\n",
      "Epoch 1253:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.08it/s, loss=9.08e-08, v_num=23, train_loss=9.18e-6, test_loss=9.81e-6]\u001b[AAdjusting learning rate of group 0 to 4.3329e-04.\n",
      "Epoch 1253:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.62it/s, loss=8.75e-08, v_num=23, train_loss=9.18e-6, test_loss=9.81e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1253:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.12it/s, loss=8.75e-08, v_num=23, train_loss=9.18e-6, test_loss=9.81e-6]\u001b[A\n",
      "Epoch 1253: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.05it/s, loss=8.75e-08, v_num=23, train_loss=1.02e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 1254:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.39it/s, loss=8.98e-08, v_num=23, train_loss=1.02e-5, test_loss=1.09e-5]\u001b[AAdjusting learning rate of group 0 to 4.3221e-04.\n",
      "Epoch 1254:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.44it/s, loss=8.71e-08, v_num=23, train_loss=1.02e-5, test_loss=1.09e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1254:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.80it/s, loss=8.71e-08, v_num=23, train_loss=1.02e-5, test_loss=1.09e-5]\u001b[A\n",
      "Epoch 1254: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.76it/s, loss=8.71e-08, v_num=23, train_loss=8.85e-6, test_loss=9.43e-6]\u001b[A\n",
      "Epoch 1255:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.25it/s, loss=9.36e-08, v_num=23, train_loss=8.85e-6, test_loss=9.43e-6]\u001b[AAdjusting learning rate of group 0 to 4.3113e-04.\n",
      "Epoch 1255:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.16it/s, loss=9.11e-08, v_num=23, train_loss=8.85e-6, test_loss=9.43e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1255:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.21it/s, loss=9.11e-08, v_num=23, train_loss=8.85e-6, test_loss=9.43e-6]\u001b[A\n",
      "Epoch 1255: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 167.08it/s, loss=9.11e-08, v_num=23, train_loss=8.28e-6, test_loss=9e-6]\u001b[A\n",
      "Epoch 1256:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 149.23it/s, loss=8.32e-08, v_num=23, train_loss=8.28e-6, test_loss=9e-6]\u001b[AAdjusting learning rate of group 0 to 4.3005e-04.\n",
      "Epoch 1256:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 141.32it/s, loss=7.82e-08, v_num=23, train_loss=8.28e-6, test_loss=9e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1256:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 131.59it/s, loss=7.82e-08, v_num=23, train_loss=8.28e-6, test_loss=9e-6]\u001b[A\n",
      "Epoch 1256: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.10it/s, loss=7.82e-08, v_num=23, train_loss=8.48e-6, test_loss=9.02e-6]\u001b[A\n",
      "Epoch 1257:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.26it/s, loss=9.68e-08, v_num=23, train_loss=8.48e-6, test_loss=9.02e-6]\u001b[AAdjusting learning rate of group 0 to 4.2898e-04.\n",
      "Epoch 1257:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.32it/s, loss=9.44e-08, v_num=23, train_loss=8.48e-6, test_loss=9.02e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1257:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.31it/s, loss=9.44e-08, v_num=23, train_loss=8.48e-6, test_loss=9.02e-6]\u001b[A\n",
      "Epoch 1257: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.42it/s, loss=9.44e-08, v_num=23, train_loss=8.48e-6, test_loss=9.04e-6]\u001b[A\n",
      "Epoch 1258:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.10it/s, loss=8.4e-08, v_num=23, train_loss=8.48e-6, test_loss=9.04e-6]\u001b[AAdjusting learning rate of group 0 to 4.2790e-04.\n",
      "Epoch 1258:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.43it/s, loss=8.05e-08, v_num=23, train_loss=8.48e-6, test_loss=9.04e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1258:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.38it/s, loss=8.05e-08, v_num=23, train_loss=8.48e-6, test_loss=9.04e-6]\u001b[A\n",
      "Epoch 1258: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.98it/s, loss=8.05e-08, v_num=23, train_loss=8.11e-6, test_loss=8.74e-6]\u001b[A\n",
      "Epoch 1259:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.22it/s, loss=9.37e-08, v_num=23, train_loss=8.11e-6, test_loss=8.74e-6]\u001b[AAdjusting learning rate of group 0 to 4.2683e-04.\n",
      "Epoch 1259:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.05it/s, loss=9.04e-08, v_num=23, train_loss=8.11e-6, test_loss=8.74e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1259:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.10it/s, loss=9.04e-08, v_num=23, train_loss=8.11e-6, test_loss=8.74e-6]\u001b[A\n",
      "Epoch 1259: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.66it/s, loss=9.04e-08, v_num=23, train_loss=7.31e-6, test_loss=7.99e-6]\u001b[A\n",
      "Epoch 1260:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.57it/s, loss=9.17e-08, v_num=23, train_loss=7.31e-6, test_loss=7.99e-6]\u001b[AAdjusting learning rate of group 0 to 4.2577e-04.\n",
      "Epoch 1260:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.51it/s, loss=8.77e-08, v_num=23, train_loss=7.31e-6, test_loss=7.99e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1260:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.58it/s, loss=8.77e-08, v_num=23, train_loss=7.31e-6, test_loss=7.99e-6]\u001b[A\n",
      "Epoch 1260: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.98it/s, loss=8.77e-08, v_num=23, train_loss=9.6e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1261:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.44it/s, loss=1.15e-07, v_num=23, train_loss=9.6e-6, test_loss=1.01e-5]\u001b[AAdjusting learning rate of group 0 to 4.2470e-04.\n",
      "Epoch 1261:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.96it/s, loss=1.09e-07, v_num=23, train_loss=9.6e-6, test_loss=1.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1261:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.14it/s, loss=1.09e-07, v_num=23, train_loss=9.6e-6, test_loss=1.01e-5]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1261: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.30it/s, loss=1.09e-07, v_num=23, train_loss=8.57e-6, test_loss=9.4e-6]\u001b[A\n",
      "Epoch 1262:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.15it/s, loss=8.74e-08, v_num=23, train_loss=8.57e-6, test_loss=9.4e-6]\u001b[AAdjusting learning rate of group 0 to 4.2364e-04.\n",
      "Epoch 1262:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.40it/s, loss=8.58e-08, v_num=23, train_loss=8.57e-6, test_loss=9.4e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1262:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.29it/s, loss=8.58e-08, v_num=23, train_loss=8.57e-6, test_loss=9.4e-6]\u001b[A\n",
      "Epoch 1262: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.08it/s, loss=8.58e-08, v_num=23, train_loss=8.41e-6, test_loss=9.07e-6]\u001b[A\n",
      "Epoch 1263:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.05it/s, loss=9.64e-08, v_num=23, train_loss=8.41e-6, test_loss=9.07e-6]\u001b[AAdjusting learning rate of group 0 to 4.2258e-04.\n",
      "Epoch 1263:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.02it/s, loss=9.16e-08, v_num=23, train_loss=8.41e-6, test_loss=9.07e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1263:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.64it/s, loss=9.16e-08, v_num=23, train_loss=8.41e-6, test_loss=9.07e-6]\u001b[A\n",
      "Epoch 1263: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.38it/s, loss=9.16e-08, v_num=23, train_loss=7.18e-6, test_loss=7.9e-6]\u001b[A\n",
      "Epoch 1264:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.48it/s, loss=9.44e-08, v_num=23, train_loss=7.18e-6, test_loss=7.9e-6]\u001b[AAdjusting learning rate of group 0 to 4.2153e-04.\n",
      "Epoch 1264:  50%|█████████████████████                     | 79/158 [00:00<00:00, 136.95it/s, loss=9e-08, v_num=23, train_loss=7.18e-6, test_loss=7.9e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1264:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 131.35it/s, loss=9e-08, v_num=23, train_loss=7.18e-6, test_loss=7.9e-6]\u001b[A\n",
      "Epoch 1264: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 168.96it/s, loss=9e-08, v_num=23, train_loss=8.11e-6, test_loss=8.63e-6]\u001b[A\n",
      "Epoch 1265:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.79it/s, loss=8.61e-08, v_num=23, train_loss=8.11e-6, test_loss=8.63e-6]\u001b[AAdjusting learning rate of group 0 to 4.2047e-04.\n",
      "Epoch 1265:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.38it/s, loss=8.25e-08, v_num=23, train_loss=8.11e-6, test_loss=8.63e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1265:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.77it/s, loss=8.25e-08, v_num=23, train_loss=8.11e-6, test_loss=8.63e-6]\u001b[A\n",
      "Epoch 1265: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.24it/s, loss=8.25e-08, v_num=23, train_loss=7.96e-6, test_loss=8.59e-6]\u001b[A\n",
      "Epoch 1266:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.88it/s, loss=8.74e-08, v_num=23, train_loss=7.96e-6, test_loss=8.59e-6]\u001b[AAdjusting learning rate of group 0 to 4.1942e-04.\n",
      "Epoch 1266:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.91it/s, loss=8.43e-08, v_num=23, train_loss=7.96e-6, test_loss=8.59e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1266:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.49it/s, loss=8.43e-08, v_num=23, train_loss=7.96e-6, test_loss=8.59e-6]\u001b[A\n",
      "Epoch 1266: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.57it/s, loss=8.43e-08, v_num=23, train_loss=8.23e-6, test_loss=8.84e-6]\u001b[A\n",
      "Epoch 1267:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.94it/s, loss=9.31e-08, v_num=23, train_loss=8.23e-6, test_loss=8.84e-6]\u001b[AAdjusting learning rate of group 0 to 4.1837e-04.\n",
      "Epoch 1267:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.72it/s, loss=9.07e-08, v_num=23, train_loss=8.23e-6, test_loss=8.84e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1267:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.71it/s, loss=9.07e-08, v_num=23, train_loss=8.23e-6, test_loss=8.84e-6]\u001b[A\n",
      "Epoch 1267: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.64it/s, loss=9.07e-08, v_num=23, train_loss=8.08e-6, test_loss=8.75e-6]\u001b[A\n",
      "Epoch 1268:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.57it/s, loss=8.5e-08, v_num=23, train_loss=8.08e-6, test_loss=8.75e-6]\u001b[AAdjusting learning rate of group 0 to 4.1733e-04.\n",
      "Epoch 1268:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.17it/s, loss=8.22e-08, v_num=23, train_loss=8.08e-6, test_loss=8.75e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1268:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.37it/s, loss=8.22e-08, v_num=23, train_loss=8.08e-6, test_loss=8.75e-6]\u001b[A\n",
      "Epoch 1268: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.22it/s, loss=8.22e-08, v_num=23, train_loss=1.16e-5, test_loss=1.24e-5]\u001b[A\n",
      "Epoch 1269:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.58it/s, loss=9.04e-08, v_num=23, train_loss=1.16e-5, test_loss=1.24e-5]\u001b[AAdjusting learning rate of group 0 to 4.1628e-04.\n",
      "Epoch 1269:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.08it/s, loss=8.76e-08, v_num=23, train_loss=1.16e-5, test_loss=1.24e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1269:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.56it/s, loss=8.76e-08, v_num=23, train_loss=1.16e-5, test_loss=1.24e-5]\u001b[A\n",
      "Epoch 1269: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.01it/s, loss=8.76e-08, v_num=23, train_loss=8.9e-6, test_loss=9.47e-6]\u001b[A\n",
      "Epoch 1270:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.00it/s, loss=8.02e-08, v_num=23, train_loss=8.9e-6, test_loss=9.47e-6]\u001b[AAdjusting learning rate of group 0 to 4.1524e-04.\n",
      "Epoch 1270:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.02it/s, loss=7.71e-08, v_num=23, train_loss=8.9e-6, test_loss=9.47e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1270:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.07it/s, loss=7.71e-08, v_num=23, train_loss=8.9e-6, test_loss=9.47e-6]\u001b[A\n",
      "Epoch 1270: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.36it/s, loss=7.71e-08, v_num=23, train_loss=8.56e-6, test_loss=9.25e-6]\u001b[A\n",
      "Epoch 1271:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.04it/s, loss=8.68e-08, v_num=23, train_loss=8.56e-6, test_loss=9.25e-6]\u001b[AAdjusting learning rate of group 0 to 4.1420e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1271:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.97it/s, loss=8.22e-08, v_num=23, train_loss=8.56e-6, test_loss=9.25e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1271:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.68it/s, loss=8.22e-08, v_num=23, train_loss=8.56e-6, test_loss=9.25e-6]\u001b[A\n",
      "Epoch 1271: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.45it/s, loss=8.22e-08, v_num=23, train_loss=9.29e-6, test_loss=9.83e-6]\u001b[A\n",
      "Epoch 1272:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.43it/s, loss=8.18e-08, v_num=23, train_loss=9.29e-6, test_loss=9.83e-6]\u001b[AAdjusting learning rate of group 0 to 4.1317e-04.\n",
      "Epoch 1272:  50%|███████████████████                   | 79/158 [00:00<00:00, 142.21it/s, loss=7.77e-08, v_num=23, train_loss=9.29e-6, test_loss=9.83e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1272:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.82it/s, loss=7.77e-08, v_num=23, train_loss=9.29e-6, test_loss=9.83e-6]\u001b[A\n",
      "Epoch 1272: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.97it/s, loss=7.77e-08, v_num=23, train_loss=8.57e-6, test_loss=9.21e-6]\u001b[A\n",
      "Epoch 1273:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.77it/s, loss=1.01e-07, v_num=23, train_loss=8.57e-6, test_loss=9.21e-6]\u001b[AAdjusting learning rate of group 0 to 4.1214e-04.\n",
      "Epoch 1273:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.51it/s, loss=9.69e-08, v_num=23, train_loss=8.57e-6, test_loss=9.21e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1273:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.15it/s, loss=9.69e-08, v_num=23, train_loss=8.57e-6, test_loss=9.21e-6]\u001b[A\n",
      "Epoch 1273: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.21it/s, loss=9.69e-08, v_num=23, train_loss=1.02e-5, test_loss=1.07e-5]\u001b[A\n",
      "Epoch 1274:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.65it/s, loss=8.17e-08, v_num=23, train_loss=1.02e-5, test_loss=1.07e-5]\u001b[AAdjusting learning rate of group 0 to 4.1111e-04.\n",
      "Epoch 1274:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.79it/s, loss=7.85e-08, v_num=23, train_loss=1.02e-5, test_loss=1.07e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1274:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.12it/s, loss=7.85e-08, v_num=23, train_loss=1.02e-5, test_loss=1.07e-5]\u001b[A\n",
      "Epoch 1274: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.40it/s, loss=7.85e-08, v_num=23, train_loss=8.16e-6, test_loss=8.89e-6]\u001b[A\n",
      "Epoch 1275:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.19it/s, loss=8.31e-08, v_num=23, train_loss=8.16e-6, test_loss=8.89e-6]\u001b[AAdjusting learning rate of group 0 to 4.1008e-04.\n",
      "Epoch 1275:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.17it/s, loss=7.97e-08, v_num=23, train_loss=8.16e-6, test_loss=8.89e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1275:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.70it/s, loss=7.97e-08, v_num=23, train_loss=8.16e-6, test_loss=8.89e-6]\u001b[A\n",
      "Epoch 1275: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.06it/s, loss=7.97e-08, v_num=23, train_loss=8.55e-6, test_loss=9.12e-6]\u001b[A\n",
      "Epoch 1276:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.36it/s, loss=9.58e-08, v_num=23, train_loss=8.55e-6, test_loss=9.12e-6]\u001b[AAdjusting learning rate of group 0 to 4.0905e-04.\n",
      "Epoch 1276:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.65it/s, loss=9.19e-08, v_num=23, train_loss=8.55e-6, test_loss=9.12e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1276:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.42it/s, loss=9.19e-08, v_num=23, train_loss=8.55e-6, test_loss=9.12e-6]\u001b[A\n",
      "Epoch 1276: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 163.80it/s, loss=9.19e-08, v_num=23, train_loss=9.64e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1277:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.90it/s, loss=8.84e-08, v_num=23, train_loss=9.64e-6, test_loss=1.03e-5]\u001b[AAdjusting learning rate of group 0 to 4.0803e-04.\n",
      "Epoch 1277:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.09it/s, loss=8.33e-08, v_num=23, train_loss=9.64e-6, test_loss=1.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1277:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.75it/s, loss=8.33e-08, v_num=23, train_loss=9.64e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1277: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.84it/s, loss=8.33e-08, v_num=23, train_loss=7.37e-6, test_loss=8.04e-6]\u001b[A\n",
      "Epoch 1278:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.15it/s, loss=9.93e-08, v_num=23, train_loss=7.37e-6, test_loss=8.04e-6]\u001b[AAdjusting learning rate of group 0 to 4.0701e-04.\n",
      "Epoch 1278:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.93it/s, loss=9.7e-08, v_num=23, train_loss=7.37e-6, test_loss=8.04e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1278:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.67it/s, loss=9.7e-08, v_num=23, train_loss=7.37e-6, test_loss=8.04e-6]\u001b[A\n",
      "Epoch 1278: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.96it/s, loss=9.7e-08, v_num=23, train_loss=8.44e-6, test_loss=9.07e-6]\u001b[A\n",
      "Epoch 1279:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.76it/s, loss=8.72e-08, v_num=23, train_loss=8.44e-6, test_loss=9.07e-6]\u001b[AAdjusting learning rate of group 0 to 4.0599e-04.\n",
      "Epoch 1279:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.68it/s, loss=8.41e-08, v_num=23, train_loss=8.44e-6, test_loss=9.07e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1279:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.12it/s, loss=8.41e-08, v_num=23, train_loss=8.44e-6, test_loss=9.07e-6]\u001b[A\n",
      "Epoch 1279: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.22it/s, loss=8.41e-08, v_num=23, train_loss=9.76e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1280:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.88it/s, loss=9.95e-08, v_num=23, train_loss=9.76e-6, test_loss=1.03e-5]\u001b[AAdjusting learning rate of group 0 to 4.0498e-04.\n",
      "Epoch 1280:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.06it/s, loss=9.6e-08, v_num=23, train_loss=9.76e-6, test_loss=1.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1280:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.21it/s, loss=9.6e-08, v_num=23, train_loss=9.76e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1280: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.29it/s, loss=9.6e-08, v_num=23, train_loss=1.03e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 1281:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 146.83it/s, loss=1.03e-07, v_num=23, train_loss=1.03e-5, test_loss=1.1e-5]\u001b[AAdjusting learning rate of group 0 to 4.0396e-04.\n",
      "Epoch 1281:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.82it/s, loss=9.92e-08, v_num=23, train_loss=1.03e-5, test_loss=1.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1281:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.80it/s, loss=9.92e-08, v_num=23, train_loss=1.03e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 1281: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 169.39it/s, loss=9.92e-08, v_num=23, train_loss=9.46e-6, test_loss=1e-5]\u001b[A\n",
      "Epoch 1282:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 148.64it/s, loss=1.1e-07, v_num=23, train_loss=9.46e-6, test_loss=1e-5]\u001b[AAdjusting learning rate of group 0 to 4.0295e-04.\n",
      "Epoch 1282:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 137.58it/s, loss=1.06e-07, v_num=23, train_loss=9.46e-6, test_loss=1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1282:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 131.32it/s, loss=1.06e-07, v_num=23, train_loss=9.46e-6, test_loss=1e-5]\u001b[A\n",
      "Epoch 1282: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.11it/s, loss=1.06e-07, v_num=23, train_loss=9.08e-6, test_loss=9.75e-6]\u001b[A\n",
      "Epoch 1283:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.27it/s, loss=8.37e-08, v_num=23, train_loss=9.08e-6, test_loss=9.75e-6]\u001b[AAdjusting learning rate of group 0 to 4.0195e-04.\n",
      "Epoch 1283:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.11it/s, loss=8.05e-08, v_num=23, train_loss=9.08e-6, test_loss=9.75e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1283:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.32it/s, loss=8.05e-08, v_num=23, train_loss=9.08e-6, test_loss=9.75e-6]\u001b[A\n",
      "Epoch 1283: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.53it/s, loss=8.05e-08, v_num=23, train_loss=8.71e-6, test_loss=9.55e-6]\u001b[A\n",
      "Epoch 1284:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.79it/s, loss=9.02e-08, v_num=23, train_loss=8.71e-6, test_loss=9.55e-6]\u001b[AAdjusting learning rate of group 0 to 4.0094e-04.\n",
      "Epoch 1284:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.00it/s, loss=8.76e-08, v_num=23, train_loss=8.71e-6, test_loss=9.55e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1284:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.97it/s, loss=8.76e-08, v_num=23, train_loss=8.71e-6, test_loss=9.55e-6]\u001b[A\n",
      "Epoch 1284: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.68it/s, loss=8.76e-08, v_num=23, train_loss=8.52e-6, test_loss=9.29e-6]\u001b[A\n",
      "Epoch 1285:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.04it/s, loss=1.05e-07, v_num=23, train_loss=8.52e-6, test_loss=9.29e-6]\u001b[AAdjusting learning rate of group 0 to 3.9994e-04.\n",
      "Epoch 1285:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.23it/s, loss=9.48e-08, v_num=23, train_loss=8.52e-6, test_loss=9.29e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.34it/s]\u001b[A\n",
      "Epoch 1285: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.11it/s, loss=9.48e-08, v_num=23, train_loss=9.36e-6, test_loss=9.87e-6]\u001b[A\n",
      "Epoch 1286:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.93it/s, loss=7.81e-08, v_num=23, train_loss=9.36e-6, test_loss=9.87e-6]\u001b[AAdjusting learning rate of group 0 to 3.9894e-04.\n",
      "Epoch 1286:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.23it/s, loss=7.5e-08, v_num=23, train_loss=9.36e-6, test_loss=9.87e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1286:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.59it/s, loss=7.5e-08, v_num=23, train_loss=9.36e-6, test_loss=9.87e-6]\u001b[A\n",
      "Epoch 1286: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.49it/s, loss=7.5e-08, v_num=23, train_loss=8.19e-6, test_loss=8.78e-6]\u001b[A\n",
      "Epoch 1287:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.64it/s, loss=8.07e-08, v_num=23, train_loss=8.19e-6, test_loss=8.78e-6]\u001b[AAdjusting learning rate of group 0 to 3.9794e-04.\n",
      "Epoch 1287:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.27it/s, loss=7.69e-08, v_num=23, train_loss=8.19e-6, test_loss=8.78e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1287:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.73it/s, loss=7.69e-08, v_num=23, train_loss=8.19e-6, test_loss=8.78e-6]\u001b[A\n",
      "Epoch 1287: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.19it/s, loss=7.69e-08, v_num=23, train_loss=7.35e-6, test_loss=7.98e-6]\u001b[A\n",
      "Epoch 1288:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.64it/s, loss=1.06e-07, v_num=23, train_loss=7.35e-6, test_loss=7.98e-6]\u001b[AAdjusting learning rate of group 0 to 3.9695e-04.\n",
      "Epoch 1288:  50%|███████████████████                   | 79/158 [00:00<00:00, 134.77it/s, loss=1.03e-07, v_num=23, train_loss=7.35e-6, test_loss=7.98e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1288:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.74it/s, loss=1.03e-07, v_num=23, train_loss=7.35e-6, test_loss=7.98e-6]\u001b[A\n",
      "Epoch 1288: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.09it/s, loss=1.03e-07, v_num=23, train_loss=7.86e-6, test_loss=8.55e-6]\u001b[A\n",
      "Epoch 1289:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.18it/s, loss=8.55e-08, v_num=23, train_loss=7.86e-6, test_loss=8.55e-6]\u001b[AAdjusting learning rate of group 0 to 3.9596e-04.\n",
      "Epoch 1289:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.41it/s, loss=8.03e-08, v_num=23, train_loss=7.86e-6, test_loss=8.55e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.22it/s]\u001b[A\n",
      "Epoch 1289: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 162.85it/s, loss=8.03e-08, v_num=23, train_loss=7.76e-6, test_loss=8.35e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1290:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.23it/s, loss=8.72e-08, v_num=23, train_loss=7.76e-6, test_loss=8.35e-6]\u001b[AAdjusting learning rate of group 0 to 3.9497e-04.\n",
      "Epoch 1290:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.29it/s, loss=8.36e-08, v_num=23, train_loss=7.76e-6, test_loss=8.35e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1290:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.74it/s, loss=8.36e-08, v_num=23, train_loss=7.76e-6, test_loss=8.35e-6]\u001b[A\n",
      "Epoch 1290: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.90it/s, loss=8.36e-08, v_num=23, train_loss=7.62e-6, test_loss=8.37e-6]\u001b[A\n",
      "Epoch 1291:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.67it/s, loss=9.36e-08, v_num=23, train_loss=7.62e-6, test_loss=8.37e-6]\u001b[AAdjusting learning rate of group 0 to 3.9398e-04.\n",
      "Epoch 1291:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.69it/s, loss=9.03e-08, v_num=23, train_loss=7.62e-6, test_loss=8.37e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1291:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.33it/s, loss=9.03e-08, v_num=23, train_loss=7.62e-6, test_loss=8.37e-6]\u001b[A\n",
      "Epoch 1291: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.51it/s, loss=9.03e-08, v_num=23, train_loss=9.66e-6, test_loss=1.04e-5]\u001b[A\n",
      "Epoch 1292:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.13it/s, loss=9.54e-08, v_num=23, train_loss=9.66e-6, test_loss=1.04e-5]\u001b[AAdjusting learning rate of group 0 to 3.9299e-04.\n",
      "Epoch 1292:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.34it/s, loss=9.18e-08, v_num=23, train_loss=9.66e-6, test_loss=1.04e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1292:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.15it/s, loss=9.18e-08, v_num=23, train_loss=9.66e-6, test_loss=1.04e-5]\u001b[A\n",
      "Epoch 1292: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.69it/s, loss=9.18e-08, v_num=23, train_loss=8.1e-6, test_loss=8.76e-6]\u001b[A\n",
      "Epoch 1293:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 150.01it/s, loss=9.6e-08, v_num=23, train_loss=8.1e-6, test_loss=8.76e-6]\u001b[AAdjusting learning rate of group 0 to 3.9201e-04.\n",
      "Epoch 1293:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.34it/s, loss=9.13e-08, v_num=23, train_loss=8.1e-6, test_loss=8.76e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1293:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.65it/s, loss=9.13e-08, v_num=23, train_loss=8.1e-6, test_loss=8.76e-6]\u001b[A\n",
      "Epoch 1293: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.11it/s, loss=9.13e-08, v_num=23, train_loss=8.81e-6, test_loss=9.4e-6]\u001b[A\n",
      "Epoch 1294:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.25it/s, loss=9.63e-08, v_num=23, train_loss=8.81e-6, test_loss=9.4e-6]\u001b[AAdjusting learning rate of group 0 to 3.9103e-04.\n",
      "Epoch 1294:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.18it/s, loss=9.1e-08, v_num=23, train_loss=8.81e-6, test_loss=9.4e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1294:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.85it/s, loss=9.1e-08, v_num=23, train_loss=8.81e-6, test_loss=9.4e-6]\u001b[A\n",
      "Epoch 1294: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.66it/s, loss=9.1e-08, v_num=23, train_loss=8.17e-6, test_loss=8.98e-6]\u001b[A\n",
      "Epoch 1295:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.40it/s, loss=9.67e-08, v_num=23, train_loss=8.17e-6, test_loss=8.98e-6]\u001b[AAdjusting learning rate of group 0 to 3.9005e-04.\n",
      "Epoch 1295:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.28it/s, loss=9.35e-08, v_num=23, train_loss=8.17e-6, test_loss=8.98e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1295:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.41it/s, loss=9.35e-08, v_num=23, train_loss=8.17e-6, test_loss=8.98e-6]\u001b[A\n",
      "Epoch 1295: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.58it/s, loss=9.35e-08, v_num=23, train_loss=9.2e-6, test_loss=9.87e-6]\u001b[A\n",
      "Epoch 1296:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.51it/s, loss=9.34e-08, v_num=23, train_loss=9.2e-6, test_loss=9.87e-6]\u001b[AAdjusting learning rate of group 0 to 3.8908e-04.\n",
      "Epoch 1296:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.49it/s, loss=9.07e-08, v_num=23, train_loss=9.2e-6, test_loss=9.87e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1296:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.35it/s, loss=9.07e-08, v_num=23, train_loss=9.2e-6, test_loss=9.87e-6]\u001b[A\n",
      "Epoch 1296: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.18it/s, loss=9.07e-08, v_num=23, train_loss=8.24e-6, test_loss=8.83e-6]\u001b[A\n",
      "Epoch 1297:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.62it/s, loss=8.43e-08, v_num=23, train_loss=8.24e-6, test_loss=8.83e-6]\u001b[AAdjusting learning rate of group 0 to 3.8811e-04.\n",
      "Epoch 1297:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.52it/s, loss=8.03e-08, v_num=23, train_loss=8.24e-6, test_loss=8.83e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1297:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.90it/s, loss=8.03e-08, v_num=23, train_loss=8.24e-6, test_loss=8.83e-6]\u001b[A\n",
      "Epoch 1297: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.03it/s, loss=8.03e-08, v_num=23, train_loss=8.13e-6, test_loss=8.78e-6]\u001b[A\n",
      "Epoch 1298:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.20it/s, loss=7.99e-08, v_num=23, train_loss=8.13e-6, test_loss=8.78e-6]\u001b[AAdjusting learning rate of group 0 to 3.8714e-04.\n",
      "Epoch 1298:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.77it/s, loss=7.55e-08, v_num=23, train_loss=8.13e-6, test_loss=8.78e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1298:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.04it/s, loss=7.55e-08, v_num=23, train_loss=8.13e-6, test_loss=8.78e-6]\u001b[A\n",
      "Epoch 1298: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.54it/s, loss=7.55e-08, v_num=23, train_loss=8.67e-6, test_loss=9.32e-6]\u001b[A\n",
      "Epoch 1299:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.00it/s, loss=9.27e-08, v_num=23, train_loss=8.67e-6, test_loss=9.32e-6]\u001b[AAdjusting learning rate of group 0 to 3.8617e-04.\n",
      "Epoch 1299:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 138.39it/s, loss=9e-08, v_num=23, train_loss=8.67e-6, test_loss=9.32e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1299:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 131.01it/s, loss=9e-08, v_num=23, train_loss=8.67e-6, test_loss=9.32e-6]\u001b[A\n",
      "Epoch 1299: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 167.80it/s, loss=9e-08, v_num=23, train_loss=1.02e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 1300:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.39it/s, loss=8.19e-08, v_num=23, train_loss=1.02e-5, test_loss=1.1e-5]\u001b[AAdjusting learning rate of group 0 to 3.8520e-04.\n",
      "Epoch 1300:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.37it/s, loss=7.98e-08, v_num=23, train_loss=1.02e-5, test_loss=1.1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1300:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.73it/s, loss=7.98e-08, v_num=23, train_loss=1.02e-5, test_loss=1.1e-5]\u001b[A\n",
      "Epoch 1300: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.92it/s, loss=7.98e-08, v_num=23, train_loss=8.95e-6, test_loss=9.66e-6]\u001b[A\n",
      "Epoch 1301:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.56it/s, loss=9.16e-08, v_num=23, train_loss=8.95e-6, test_loss=9.66e-6]\u001b[AAdjusting learning rate of group 0 to 3.8424e-04.\n",
      "Epoch 1301:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.83it/s, loss=8.76e-08, v_num=23, train_loss=8.95e-6, test_loss=9.66e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1301:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.22it/s, loss=8.76e-08, v_num=23, train_loss=8.95e-6, test_loss=9.66e-6]\u001b[A\n",
      "Epoch 1301: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.15it/s, loss=8.76e-08, v_num=23, train_loss=8.24e-6, test_loss=8.96e-6]\u001b[A\n",
      "Epoch 1302:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.58it/s, loss=8.36e-08, v_num=23, train_loss=8.24e-6, test_loss=8.96e-6]\u001b[AAdjusting learning rate of group 0 to 3.8328e-04.\n",
      "Epoch 1302:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.12it/s, loss=7.99e-08, v_num=23, train_loss=8.24e-6, test_loss=8.96e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1302:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.25it/s, loss=7.99e-08, v_num=23, train_loss=8.24e-6, test_loss=8.96e-6]\u001b[A\n",
      "Epoch 1302: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.53it/s, loss=7.99e-08, v_num=23, train_loss=8.14e-6, test_loss=8.85e-6]\u001b[A\n",
      "Epoch 1303:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.85it/s, loss=1.01e-07, v_num=23, train_loss=8.14e-6, test_loss=8.85e-6]\u001b[AAdjusting learning rate of group 0 to 3.8232e-04.\n",
      "Epoch 1303:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.89it/s, loss=9.49e-08, v_num=23, train_loss=8.14e-6, test_loss=8.85e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1303:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.36it/s, loss=9.49e-08, v_num=23, train_loss=8.14e-6, test_loss=8.85e-6]\u001b[A\n",
      "Epoch 1303: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.42it/s, loss=9.49e-08, v_num=23, train_loss=9.01e-6, test_loss=9.74e-6]\u001b[A\n",
      "Epoch 1304:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.53it/s, loss=8.7e-08, v_num=23, train_loss=9.01e-6, test_loss=9.74e-6]\u001b[AAdjusting learning rate of group 0 to 3.8136e-04.\n",
      "Epoch 1304:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.78it/s, loss=8.28e-08, v_num=23, train_loss=9.01e-6, test_loss=9.74e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1304:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.17it/s, loss=8.28e-08, v_num=23, train_loss=9.01e-6, test_loss=9.74e-6]\u001b[A\n",
      "Epoch 1304: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.09it/s, loss=8.28e-08, v_num=23, train_loss=9.01e-6, test_loss=9.64e-6]\u001b[A\n",
      "Epoch 1305:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.75it/s, loss=8.94e-08, v_num=23, train_loss=9.01e-6, test_loss=9.64e-6]\u001b[AAdjusting learning rate of group 0 to 3.8041e-04.\n",
      "Epoch 1305:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.75it/s, loss=8.44e-08, v_num=23, train_loss=9.01e-6, test_loss=9.64e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1305:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.68it/s, loss=8.44e-08, v_num=23, train_loss=9.01e-6, test_loss=9.64e-6]\u001b[A\n",
      "Epoch 1305: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.14it/s, loss=8.44e-08, v_num=23, train_loss=8.73e-6, test_loss=9.42e-6]\u001b[A\n",
      "Epoch 1306:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.75it/s, loss=1.57e-07, v_num=23, train_loss=8.73e-6, test_loss=9.42e-6]\u001b[AAdjusting learning rate of group 0 to 3.7946e-04.\n",
      "Epoch 1306:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.60it/s, loss=1.54e-07, v_num=23, train_loss=8.73e-6, test_loss=9.42e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1306:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.18it/s, loss=1.54e-07, v_num=23, train_loss=8.73e-6, test_loss=9.42e-6]\u001b[A\n",
      "Epoch 1306: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.46it/s, loss=1.54e-07, v_num=23, train_loss=1.13e-5, test_loss=1.22e-5]\u001b[A\n",
      "Epoch 1307:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.52it/s, loss=1.4e-07, v_num=23, train_loss=1.13e-5, test_loss=1.22e-5]\u001b[AAdjusting learning rate of group 0 to 3.7851e-04.\n",
      "Epoch 1307:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.95it/s, loss=1.37e-07, v_num=23, train_loss=1.13e-5, test_loss=1.22e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1307:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.79it/s, loss=1.37e-07, v_num=23, train_loss=1.13e-5, test_loss=1.22e-5]\u001b[A\n",
      "Epoch 1307: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.14it/s, loss=1.37e-07, v_num=23, train_loss=9.07e-6, test_loss=9.57e-6]\u001b[A\n",
      "Epoch 1308:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.68it/s, loss=7.69e-08, v_num=23, train_loss=9.07e-6, test_loss=9.57e-6]\u001b[AAdjusting learning rate of group 0 to 3.7757e-04.\n",
      "Epoch 1308:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.88it/s, loss=7.31e-08, v_num=23, train_loss=9.07e-6, test_loss=9.57e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1308:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.62it/s, loss=7.31e-08, v_num=23, train_loss=9.07e-6, test_loss=9.57e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1308: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.42it/s, loss=7.31e-08, v_num=23, train_loss=8.07e-6, test_loss=8.84e-6]\u001b[A\n",
      "Epoch 1309:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.05it/s, loss=8.62e-08, v_num=23, train_loss=8.07e-6, test_loss=8.84e-6]\u001b[AAdjusting learning rate of group 0 to 3.7662e-04.\n",
      "Epoch 1309:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.98it/s, loss=8.33e-08, v_num=23, train_loss=8.07e-6, test_loss=8.84e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1309:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.42it/s, loss=8.33e-08, v_num=23, train_loss=8.07e-6, test_loss=8.84e-6]\u001b[A\n",
      "Epoch 1309: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.17it/s, loss=8.33e-08, v_num=23, train_loss=7.79e-6, test_loss=8.47e-6]\u001b[A\n",
      "Epoch 1310:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.16it/s, loss=8.62e-08, v_num=23, train_loss=7.79e-6, test_loss=8.47e-6]\u001b[AAdjusting learning rate of group 0 to 3.7568e-04.\n",
      "Epoch 1310:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.19it/s, loss=8.35e-08, v_num=23, train_loss=7.79e-6, test_loss=8.47e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1310:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.92it/s, loss=8.35e-08, v_num=23, train_loss=7.79e-6, test_loss=8.47e-6]\u001b[A\n",
      "Epoch 1310: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.63it/s, loss=8.35e-08, v_num=23, train_loss=9.1e-6, test_loss=9.84e-6]\u001b[A\n",
      "Epoch 1311:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.66it/s, loss=1.65e-07, v_num=23, train_loss=9.1e-6, test_loss=9.84e-6]\u001b[AAdjusting learning rate of group 0 to 3.7474e-04.\n",
      "Epoch 1311:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.63it/s, loss=1.57e-07, v_num=23, train_loss=9.1e-6, test_loss=9.84e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1311:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.21it/s, loss=1.57e-07, v_num=23, train_loss=9.1e-6, test_loss=9.84e-6]\u001b[A\n",
      "Epoch 1311: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.97it/s, loss=1.57e-07, v_num=23, train_loss=7.99e-6, test_loss=8.69e-6]\u001b[A\n",
      "Epoch 1312:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.61it/s, loss=8.18e-08, v_num=23, train_loss=7.99e-6, test_loss=8.69e-6]\u001b[AAdjusting learning rate of group 0 to 3.7380e-04.\n",
      "Epoch 1312:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.82it/s, loss=7.8e-08, v_num=23, train_loss=7.99e-6, test_loss=8.69e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1312:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.21it/s, loss=7.8e-08, v_num=23, train_loss=7.99e-6, test_loss=8.69e-6]\u001b[A\n",
      "Epoch 1312: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.39it/s, loss=7.8e-08, v_num=23, train_loss=8.13e-6, test_loss=8.8e-6]\u001b[A\n",
      "Epoch 1313:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.93it/s, loss=9.24e-08, v_num=23, train_loss=8.13e-6, test_loss=8.8e-6]\u001b[AAdjusting learning rate of group 0 to 3.7287e-04.\n",
      "Epoch 1313:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.61it/s, loss=8.92e-08, v_num=23, train_loss=8.13e-6, test_loss=8.8e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1313:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.95it/s, loss=8.92e-08, v_num=23, train_loss=8.13e-6, test_loss=8.8e-6]\u001b[A\n",
      "Epoch 1313: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.26it/s, loss=8.92e-08, v_num=23, train_loss=8.7e-6, test_loss=9.39e-6]\u001b[A\n",
      "Epoch 1314:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.29it/s, loss=8.18e-08, v_num=23, train_loss=8.7e-6, test_loss=9.39e-6]\u001b[AAdjusting learning rate of group 0 to 3.7194e-04.\n",
      "Epoch 1314:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.97it/s, loss=7.85e-08, v_num=23, train_loss=8.7e-6, test_loss=9.39e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1314:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.67it/s, loss=7.85e-08, v_num=23, train_loss=8.7e-6, test_loss=9.39e-6]\u001b[A\n",
      "Epoch 1314: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.08it/s, loss=7.85e-08, v_num=23, train_loss=7.97e-6, test_loss=8.69e-6]\u001b[A\n",
      "Epoch 1315:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.62it/s, loss=7.13e-08, v_num=23, train_loss=7.97e-6, test_loss=8.69e-6]\u001b[AAdjusting learning rate of group 0 to 3.7101e-04.\n",
      "Epoch 1315:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.20it/s, loss=6.74e-08, v_num=23, train_loss=7.97e-6, test_loss=8.69e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1315:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.85it/s, loss=6.74e-08, v_num=23, train_loss=7.97e-6, test_loss=8.69e-6]\u001b[A\n",
      "Epoch 1315: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.39it/s, loss=6.74e-08, v_num=23, train_loss=8.38e-6, test_loss=9.06e-6]\u001b[A\n",
      "Epoch 1316:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.53it/s, loss=8.63e-08, v_num=23, train_loss=8.38e-6, test_loss=9.06e-6]\u001b[AAdjusting learning rate of group 0 to 3.7008e-04.\n",
      "Epoch 1316:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.63it/s, loss=8.02e-08, v_num=23, train_loss=8.38e-6, test_loss=9.06e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1316:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.03it/s, loss=8.02e-08, v_num=23, train_loss=8.38e-6, test_loss=9.06e-6]\u001b[A\n",
      "Epoch 1316: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.95it/s, loss=8.02e-08, v_num=23, train_loss=8.46e-6, test_loss=9.13e-6]\u001b[A\n",
      "Epoch 1317:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.62it/s, loss=8.43e-08, v_num=23, train_loss=8.46e-6, test_loss=9.13e-6]\u001b[AAdjusting learning rate of group 0 to 3.6915e-04.\n",
      "Epoch 1317:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.88it/s, loss=7.25e-08, v_num=23, train_loss=8.46e-6, test_loss=9.13e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1317:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.51it/s, loss=7.25e-08, v_num=23, train_loss=8.46e-6, test_loss=9.13e-6]\u001b[A\n",
      "Epoch 1317: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.36it/s, loss=7.25e-08, v_num=23, train_loss=7.89e-6, test_loss=8.53e-6]\u001b[A\n",
      "Epoch 1318:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.40it/s, loss=7.86e-08, v_num=23, train_loss=7.89e-6, test_loss=8.53e-6]\u001b[AAdjusting learning rate of group 0 to 3.6823e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1318:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.75it/s, loss=7.49e-08, v_num=23, train_loss=7.89e-6, test_loss=8.53e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1318:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.68it/s, loss=7.49e-08, v_num=23, train_loss=7.89e-6, test_loss=8.53e-6]\u001b[A\n",
      "Epoch 1318: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.38it/s, loss=7.49e-08, v_num=23, train_loss=8.23e-6, test_loss=8.92e-6]\u001b[A\n",
      "Epoch 1319:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.15it/s, loss=8.49e-08, v_num=23, train_loss=8.23e-6, test_loss=8.92e-6]\u001b[AAdjusting learning rate of group 0 to 3.6731e-04.\n",
      "Epoch 1319:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.22it/s, loss=8.05e-08, v_num=23, train_loss=8.23e-6, test_loss=8.92e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1319:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.74it/s, loss=8.05e-08, v_num=23, train_loss=8.23e-6, test_loss=8.92e-6]\u001b[A\n",
      "Epoch 1319: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.49it/s, loss=8.05e-08, v_num=23, train_loss=9.98e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1320:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.26it/s, loss=9.99e-08, v_num=23, train_loss=9.98e-6, test_loss=1.03e-5]\u001b[AAdjusting learning rate of group 0 to 3.6639e-04.\n",
      "Epoch 1320:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.24it/s, loss=9.61e-08, v_num=23, train_loss=9.98e-6, test_loss=1.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1320:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.11it/s, loss=9.61e-08, v_num=23, train_loss=9.98e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1320: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.57it/s, loss=9.61e-08, v_num=23, train_loss=8.75e-6, test_loss=9.33e-6]\u001b[A\n",
      "Epoch 1321:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.07it/s, loss=9.68e-08, v_num=23, train_loss=8.75e-6, test_loss=9.33e-6]\u001b[AAdjusting learning rate of group 0 to 3.6548e-04.\n",
      "Epoch 1321:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.98it/s, loss=8.97e-08, v_num=23, train_loss=8.75e-6, test_loss=9.33e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1321:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.44it/s, loss=8.97e-08, v_num=23, train_loss=8.75e-6, test_loss=9.33e-6]\u001b[A\n",
      "Epoch 1321: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.62it/s, loss=8.97e-08, v_num=23, train_loss=7.85e-6, test_loss=8.52e-6]\u001b[A\n",
      "Epoch 1322:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.92it/s, loss=8.92e-08, v_num=23, train_loss=7.85e-6, test_loss=8.52e-6]\u001b[AAdjusting learning rate of group 0 to 3.6456e-04.\n",
      "Epoch 1322:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.72it/s, loss=8.62e-08, v_num=23, train_loss=7.85e-6, test_loss=8.52e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1322:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.01it/s, loss=8.62e-08, v_num=23, train_loss=7.85e-6, test_loss=8.52e-6]\u001b[A\n",
      "Epoch 1322: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.52it/s, loss=8.62e-08, v_num=23, train_loss=8.37e-6, test_loss=9.12e-6]\u001b[A\n",
      "Epoch 1323:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.70it/s, loss=8.95e-08, v_num=23, train_loss=8.37e-6, test_loss=9.12e-6]\u001b[AAdjusting learning rate of group 0 to 3.6365e-04.\n",
      "Epoch 1323:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.81it/s, loss=8.55e-08, v_num=23, train_loss=8.37e-6, test_loss=9.12e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1323:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.43it/s, loss=8.55e-08, v_num=23, train_loss=8.37e-6, test_loss=9.12e-6]\u001b[A\n",
      "Epoch 1323: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 168.23it/s, loss=8.55e-08, v_num=23, train_loss=8e-6, test_loss=8.66e-6]\u001b[A\n",
      "Epoch 1324:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 149.80it/s, loss=9.54e-08, v_num=23, train_loss=8e-6, test_loss=8.66e-6]\u001b[AAdjusting learning rate of group 0 to 3.6274e-04.\n",
      "Epoch 1324:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 139.50it/s, loss=8.51e-08, v_num=23, train_loss=8e-6, test_loss=8.66e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1324:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 132.98it/s, loss=8.51e-08, v_num=23, train_loss=8e-6, test_loss=8.66e-6]\u001b[A\n",
      "Epoch 1324: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.15it/s, loss=8.51e-08, v_num=23, train_loss=9.23e-6, test_loss=9.93e-6]\u001b[A\n",
      "Epoch 1325:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.31it/s, loss=7.84e-08, v_num=23, train_loss=9.23e-6, test_loss=9.93e-6]\u001b[AAdjusting learning rate of group 0 to 3.6184e-04.\n",
      "Epoch 1325:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.60it/s, loss=7.53e-08, v_num=23, train_loss=9.23e-6, test_loss=9.93e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1325:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.07it/s, loss=7.53e-08, v_num=23, train_loss=9.23e-6, test_loss=9.93e-6]\u001b[A\n",
      "Epoch 1325: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.21it/s, loss=7.53e-08, v_num=23, train_loss=7.75e-6, test_loss=8.42e-6]\u001b[A\n",
      "Epoch 1326:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.08it/s, loss=8.53e-08, v_num=23, train_loss=7.75e-6, test_loss=8.42e-6]\u001b[AAdjusting learning rate of group 0 to 3.6093e-04.\n",
      "Epoch 1326:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.66it/s, loss=7.96e-08, v_num=23, train_loss=7.75e-6, test_loss=8.42e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1326:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.53it/s, loss=7.96e-08, v_num=23, train_loss=7.75e-6, test_loss=8.42e-6]\u001b[A\n",
      "Epoch 1326: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.77it/s, loss=7.96e-08, v_num=23, train_loss=9.23e-6, test_loss=9.86e-6]\u001b[A\n",
      "Epoch 1327:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.11it/s, loss=1.02e-07, v_num=23, train_loss=9.23e-6, test_loss=9.86e-6]\u001b[AAdjusting learning rate of group 0 to 3.6003e-04.\n",
      "Epoch 1327:  50%|███████████████████                   | 79/158 [00:00<00:00, 142.05it/s, loss=9.73e-08, v_num=23, train_loss=9.23e-6, test_loss=9.86e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1327:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.04it/s, loss=9.73e-08, v_num=23, train_loss=9.23e-6, test_loss=9.86e-6]\u001b[A\n",
      "Epoch 1327: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.82it/s, loss=9.73e-08, v_num=23, train_loss=8.76e-6, test_loss=9.4e-6]\u001b[A\n",
      "Epoch 1328:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.35it/s, loss=8.2e-08, v_num=23, train_loss=8.76e-6, test_loss=9.4e-6]\u001b[AAdjusting learning rate of group 0 to 3.5913e-04.\n",
      "Epoch 1328:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.29it/s, loss=7.88e-08, v_num=23, train_loss=8.76e-6, test_loss=9.4e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1328:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.94it/s, loss=7.88e-08, v_num=23, train_loss=8.76e-6, test_loss=9.4e-6]\u001b[A\n",
      "Epoch 1328: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.55it/s, loss=7.88e-08, v_num=23, train_loss=8.3e-6, test_loss=8.89e-6]\u001b[A\n",
      "Epoch 1329:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.82it/s, loss=7.58e-08, v_num=23, train_loss=8.3e-6, test_loss=8.89e-6]\u001b[AAdjusting learning rate of group 0 to 3.5823e-04.\n",
      "Epoch 1329:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.01it/s, loss=7.28e-08, v_num=23, train_loss=8.3e-6, test_loss=8.89e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1329:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.52it/s, loss=7.28e-08, v_num=23, train_loss=8.3e-6, test_loss=8.89e-6]\u001b[A\n",
      "Epoch 1329: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.19it/s, loss=7.28e-08, v_num=23, train_loss=8.71e-6, test_loss=9.32e-6]\u001b[A\n",
      "Epoch 1330:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.19it/s, loss=8.28e-08, v_num=23, train_loss=8.71e-6, test_loss=9.32e-6]\u001b[AAdjusting learning rate of group 0 to 3.5734e-04.\n",
      "Epoch 1330:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.12it/s, loss=7.83e-08, v_num=23, train_loss=8.71e-6, test_loss=9.32e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1330:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.81it/s, loss=7.83e-08, v_num=23, train_loss=8.71e-6, test_loss=9.32e-6]\u001b[A\n",
      "Epoch 1330: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.59it/s, loss=7.83e-08, v_num=23, train_loss=9.14e-6, test_loss=9.73e-6]\u001b[A\n",
      "Epoch 1331:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.86it/s, loss=9.26e-08, v_num=23, train_loss=9.14e-6, test_loss=9.73e-6]\u001b[AAdjusting learning rate of group 0 to 3.5644e-04.\n",
      "Epoch 1331:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.98it/s, loss=8.9e-08, v_num=23, train_loss=9.14e-6, test_loss=9.73e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1331:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 127.41it/s, loss=8.9e-08, v_num=23, train_loss=9.14e-6, test_loss=9.73e-6]\u001b[A\n",
      "Epoch 1331: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 162.48it/s, loss=8.9e-08, v_num=23, train_loss=8.46e-6, test_loss=9.16e-6]\u001b[A\n",
      "Epoch 1332:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.54it/s, loss=7.8e-08, v_num=23, train_loss=8.46e-6, test_loss=9.16e-6]\u001b[AAdjusting learning rate of group 0 to 3.5555e-04.\n",
      "Epoch 1332:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.05it/s, loss=7.44e-08, v_num=23, train_loss=8.46e-6, test_loss=9.16e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1332:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.18it/s, loss=7.44e-08, v_num=23, train_loss=8.46e-6, test_loss=9.16e-6]\u001b[A\n",
      "Epoch 1332: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.73it/s, loss=7.44e-08, v_num=23, train_loss=7.34e-6, test_loss=7.95e-6]\u001b[A\n",
      "Epoch 1333:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.53it/s, loss=7.88e-08, v_num=23, train_loss=7.34e-6, test_loss=7.95e-6]\u001b[AAdjusting learning rate of group 0 to 3.5466e-04.\n",
      "Epoch 1333:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.03it/s, loss=7.55e-08, v_num=23, train_loss=7.34e-6, test_loss=7.95e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1333:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 128.32it/s, loss=7.55e-08, v_num=23, train_loss=7.34e-6, test_loss=7.95e-6]\u001b[A\n",
      "Epoch 1333: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.16it/s, loss=7.55e-08, v_num=23, train_loss=8.01e-6, test_loss=8.72e-6]\u001b[A\n",
      "Epoch 1334:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.32it/s, loss=7.39e-08, v_num=23, train_loss=8.01e-6, test_loss=8.72e-6]\u001b[AAdjusting learning rate of group 0 to 3.5378e-04.\n",
      "Epoch 1334:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.36it/s, loss=7.05e-08, v_num=23, train_loss=8.01e-6, test_loss=8.72e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1334:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.68it/s, loss=7.05e-08, v_num=23, train_loss=8.01e-6, test_loss=8.72e-6]\u001b[A\n",
      "Epoch 1334: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.80it/s, loss=7.05e-08, v_num=23, train_loss=8.21e-6, test_loss=8.76e-6]\u001b[A\n",
      "Epoch 1335:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.69it/s, loss=8.21e-08, v_num=23, train_loss=8.21e-6, test_loss=8.76e-6]\u001b[AAdjusting learning rate of group 0 to 3.5289e-04.\n",
      "Epoch 1335:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.89it/s, loss=7.81e-08, v_num=23, train_loss=8.21e-6, test_loss=8.76e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1335:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.94it/s, loss=7.81e-08, v_num=23, train_loss=8.21e-6, test_loss=8.76e-6]\u001b[A\n",
      "Epoch 1335: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.76it/s, loss=7.81e-08, v_num=23, train_loss=7.98e-6, test_loss=8.59e-6]\u001b[A\n",
      "Epoch 1336:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.49it/s, loss=1.07e-07, v_num=23, train_loss=7.98e-6, test_loss=8.59e-6]\u001b[AAdjusting learning rate of group 0 to 3.5201e-04.\n",
      "Epoch 1336:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.60it/s, loss=1.03e-07, v_num=23, train_loss=7.98e-6, test_loss=8.59e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1336:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 128.73it/s, loss=1.03e-07, v_num=23, train_loss=7.98e-6, test_loss=8.59e-6]\u001b[A\n",
      "Epoch 1336: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.90it/s, loss=1.03e-07, v_num=23, train_loss=7.88e-6, test_loss=8.59e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1337:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.92it/s, loss=8.66e-08, v_num=23, train_loss=7.88e-6, test_loss=8.59e-6]\u001b[AAdjusting learning rate of group 0 to 3.5113e-04.\n",
      "Epoch 1337:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.13it/s, loss=8.22e-08, v_num=23, train_loss=7.88e-6, test_loss=8.59e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1337:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.34it/s, loss=8.22e-08, v_num=23, train_loss=7.88e-6, test_loss=8.59e-6]\u001b[A\n",
      "Epoch 1337: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.17it/s, loss=8.22e-08, v_num=23, train_loss=7.18e-6, test_loss=7.82e-6]\u001b[A\n",
      "Epoch 1338:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.64it/s, loss=8.34e-08, v_num=23, train_loss=7.18e-6, test_loss=7.82e-6]\u001b[AAdjusting learning rate of group 0 to 3.5025e-04.\n",
      "Epoch 1338:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.50it/s, loss=8.04e-08, v_num=23, train_loss=7.18e-6, test_loss=7.82e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1338:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.47it/s, loss=8.04e-08, v_num=23, train_loss=7.18e-6, test_loss=7.82e-6]\u001b[A\n",
      "Epoch 1338: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.86it/s, loss=8.04e-08, v_num=23, train_loss=7.41e-6, test_loss=8.03e-6]\u001b[A\n",
      "Epoch 1339:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.16it/s, loss=9.2e-08, v_num=23, train_loss=7.41e-6, test_loss=8.03e-6]\u001b[AAdjusting learning rate of group 0 to 3.4938e-04.\n",
      "Epoch 1339:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.18it/s, loss=8.91e-08, v_num=23, train_loss=7.41e-6, test_loss=8.03e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1339:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.37it/s, loss=8.91e-08, v_num=23, train_loss=7.41e-6, test_loss=8.03e-6]\u001b[A\n",
      "Epoch 1339: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.54it/s, loss=8.91e-08, v_num=23, train_loss=9.75e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1340:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.61it/s, loss=1.24e-07, v_num=23, train_loss=9.75e-6, test_loss=1.03e-5]\u001b[AAdjusting learning rate of group 0 to 3.4850e-04.\n",
      "Epoch 1340:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.76it/s, loss=1.21e-07, v_num=23, train_loss=9.75e-6, test_loss=1.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1340:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.86it/s, loss=1.21e-07, v_num=23, train_loss=9.75e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1340: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.79it/s, loss=1.21e-07, v_num=23, train_loss=7.7e-6, test_loss=8.34e-6]\u001b[A\n",
      "Epoch 1341:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.54it/s, loss=7.61e-08, v_num=23, train_loss=7.7e-6, test_loss=8.34e-6]\u001b[AAdjusting learning rate of group 0 to 3.4763e-04.\n",
      "Epoch 1341:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.50it/s, loss=7.36e-08, v_num=23, train_loss=7.7e-6, test_loss=8.34e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1341:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.73it/s, loss=7.36e-08, v_num=23, train_loss=7.7e-6, test_loss=8.34e-6]\u001b[A\n",
      "Epoch 1341: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.88it/s, loss=7.36e-08, v_num=23, train_loss=7.8e-6, test_loss=8.45e-6]\u001b[A\n",
      "Epoch 1342:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.15it/s, loss=8.99e-08, v_num=23, train_loss=7.8e-6, test_loss=8.45e-6]\u001b[AAdjusting learning rate of group 0 to 3.4676e-04.\n",
      "Epoch 1342:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.10it/s, loss=8.69e-08, v_num=23, train_loss=7.8e-6, test_loss=8.45e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1342:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.58it/s, loss=8.69e-08, v_num=23, train_loss=7.8e-6, test_loss=8.45e-6]\u001b[A\n",
      "Epoch 1342: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.06it/s, loss=8.69e-08, v_num=23, train_loss=9.21e-6, test_loss=9.73e-6]\u001b[A\n",
      "Epoch 1343:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.29it/s, loss=1.01e-07, v_num=23, train_loss=9.21e-6, test_loss=9.73e-6]\u001b[AAdjusting learning rate of group 0 to 3.4589e-04.\n",
      "Epoch 1343:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.49it/s, loss=9.7e-08, v_num=23, train_loss=9.21e-6, test_loss=9.73e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1343:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.45it/s, loss=9.7e-08, v_num=23, train_loss=9.21e-6, test_loss=9.73e-6]\u001b[A\n",
      "Epoch 1343: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.90it/s, loss=9.7e-08, v_num=23, train_loss=8.08e-6, test_loss=8.84e-6]\u001b[A\n",
      "Epoch 1344:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.56it/s, loss=1.64e-07, v_num=23, train_loss=8.08e-6, test_loss=8.84e-6]\u001b[AAdjusting learning rate of group 0 to 3.4503e-04.\n",
      "Epoch 1344:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.69it/s, loss=1.61e-07, v_num=23, train_loss=8.08e-6, test_loss=8.84e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1344:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.81it/s, loss=1.61e-07, v_num=23, train_loss=8.08e-6, test_loss=8.84e-6]\u001b[A\n",
      "Epoch 1344: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.29it/s, loss=1.61e-07, v_num=23, train_loss=8.4e-6, test_loss=9.12e-6]\u001b[A\n",
      "Epoch 1345:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.74it/s, loss=9.17e-08, v_num=23, train_loss=8.4e-6, test_loss=9.12e-6]\u001b[AAdjusting learning rate of group 0 to 3.4417e-04.\n",
      "Epoch 1345:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.88it/s, loss=8.76e-08, v_num=23, train_loss=8.4e-6, test_loss=9.12e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1345:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.39it/s, loss=8.76e-08, v_num=23, train_loss=8.4e-6, test_loss=9.12e-6]\u001b[A\n",
      "Epoch 1345: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.87it/s, loss=8.76e-08, v_num=23, train_loss=8.94e-6, test_loss=9.49e-6]\u001b[A\n",
      "Epoch 1346:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.73it/s, loss=8.68e-08, v_num=23, train_loss=8.94e-6, test_loss=9.49e-6]\u001b[AAdjusting learning rate of group 0 to 3.4331e-04.\n",
      "Epoch 1346:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.71it/s, loss=8.33e-08, v_num=23, train_loss=8.94e-6, test_loss=9.49e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1346:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.26it/s, loss=8.33e-08, v_num=23, train_loss=8.94e-6, test_loss=9.49e-6]\u001b[A\n",
      "Epoch 1346: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.86it/s, loss=8.33e-08, v_num=23, train_loss=8.42e-6, test_loss=9.04e-6]\u001b[A\n",
      "Epoch 1347:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.43it/s, loss=8.45e-08, v_num=23, train_loss=8.42e-6, test_loss=9.04e-6]\u001b[AAdjusting learning rate of group 0 to 3.4245e-04.\n",
      "Epoch 1347:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.85it/s, loss=8.14e-08, v_num=23, train_loss=8.42e-6, test_loss=9.04e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1347:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.98it/s, loss=8.14e-08, v_num=23, train_loss=8.42e-6, test_loss=9.04e-6]\u001b[A\n",
      "Epoch 1347: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.28it/s, loss=8.14e-08, v_num=23, train_loss=8.87e-6, test_loss=9.44e-6]\u001b[A\n",
      "Epoch 1348:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.94it/s, loss=7.38e-08, v_num=23, train_loss=8.87e-6, test_loss=9.44e-6]\u001b[AAdjusting learning rate of group 0 to 3.4159e-04.\n",
      "Epoch 1348:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.92it/s, loss=7.06e-08, v_num=23, train_loss=8.87e-6, test_loss=9.44e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1348:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.25it/s, loss=7.06e-08, v_num=23, train_loss=8.87e-6, test_loss=9.44e-6]\u001b[A\n",
      "Epoch 1348: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.14it/s, loss=7.06e-08, v_num=23, train_loss=8.48e-6, test_loss=9.06e-6]\u001b[A\n",
      "Epoch 1349:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.61it/s, loss=8.21e-08, v_num=23, train_loss=8.48e-6, test_loss=9.06e-6]\u001b[AAdjusting learning rate of group 0 to 3.4074e-04.\n",
      "Epoch 1349:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.86it/s, loss=7.78e-08, v_num=23, train_loss=8.48e-6, test_loss=9.06e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1349:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.82it/s, loss=7.78e-08, v_num=23, train_loss=8.48e-6, test_loss=9.06e-6]\u001b[A\n",
      "Epoch 1349: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.59it/s, loss=7.78e-08, v_num=23, train_loss=8.06e-6, test_loss=8.69e-6]\u001b[A\n",
      "Epoch 1350:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.22it/s, loss=7.99e-08, v_num=23, train_loss=8.06e-6, test_loss=8.69e-6]\u001b[AAdjusting learning rate of group 0 to 3.3989e-04.\n",
      "Epoch 1350:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.48it/s, loss=7.53e-08, v_num=23, train_loss=8.06e-6, test_loss=8.69e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1350:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.67it/s, loss=7.53e-08, v_num=23, train_loss=8.06e-6, test_loss=8.69e-6]\u001b[A\n",
      "Epoch 1350: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.44it/s, loss=7.53e-08, v_num=23, train_loss=7.69e-6, test_loss=8.35e-6]\u001b[A\n",
      "Epoch 1351:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.67it/s, loss=9.7e-08, v_num=23, train_loss=7.69e-6, test_loss=8.35e-6]\u001b[AAdjusting learning rate of group 0 to 3.3904e-04.\n",
      "Epoch 1351:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.22it/s, loss=9.43e-08, v_num=23, train_loss=7.69e-6, test_loss=8.35e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1351:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.67it/s, loss=9.43e-08, v_num=23, train_loss=7.69e-6, test_loss=8.35e-6]\u001b[A\n",
      "Epoch 1351: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.19it/s, loss=9.43e-08, v_num=23, train_loss=8.64e-6, test_loss=9.22e-6]\u001b[A\n",
      "Epoch 1352:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.43it/s, loss=8.47e-08, v_num=23, train_loss=8.64e-6, test_loss=9.22e-6]\u001b[AAdjusting learning rate of group 0 to 3.3819e-04.\n",
      "Epoch 1352:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.42it/s, loss=8.25e-08, v_num=23, train_loss=8.64e-6, test_loss=9.22e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1352:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.72it/s, loss=8.25e-08, v_num=23, train_loss=8.64e-6, test_loss=9.22e-6]\u001b[A\n",
      "Epoch 1352: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.47it/s, loss=8.25e-08, v_num=23, train_loss=8.09e-6, test_loss=8.67e-6]\u001b[A\n",
      "Epoch 1353:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.86it/s, loss=7.91e-08, v_num=23, train_loss=8.09e-6, test_loss=8.67e-6]\u001b[AAdjusting learning rate of group 0 to 3.3734e-04.\n",
      "Epoch 1353:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.79it/s, loss=7.57e-08, v_num=23, train_loss=8.09e-6, test_loss=8.67e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1353:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.54it/s, loss=7.57e-08, v_num=23, train_loss=8.09e-6, test_loss=8.67e-6]\u001b[A\n",
      "Epoch 1353: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.81it/s, loss=7.57e-08, v_num=23, train_loss=8.14e-6, test_loss=8.8e-6]\u001b[A\n",
      "Epoch 1354:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.12it/s, loss=8.45e-08, v_num=23, train_loss=8.14e-6, test_loss=8.8e-6]\u001b[AAdjusting learning rate of group 0 to 3.3650e-04.\n",
      "Epoch 1354:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.70it/s, loss=7.94e-08, v_num=23, train_loss=8.14e-6, test_loss=8.8e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1354:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.50it/s, loss=7.94e-08, v_num=23, train_loss=8.14e-6, test_loss=8.8e-6]\u001b[A\n",
      "Epoch 1354: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.03it/s, loss=7.94e-08, v_num=23, train_loss=8.39e-6, test_loss=9.11e-6]\u001b[A\n",
      "Epoch 1355:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.27it/s, loss=8.61e-08, v_num=23, train_loss=8.39e-6, test_loss=9.11e-6]\u001b[AAdjusting learning rate of group 0 to 3.3566e-04.\n",
      "Epoch 1355:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.51it/s, loss=8.33e-08, v_num=23, train_loss=8.39e-6, test_loss=9.11e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1355:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.75it/s, loss=8.33e-08, v_num=23, train_loss=8.39e-6, test_loss=9.11e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1355: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.27it/s, loss=8.33e-08, v_num=23, train_loss=8.46e-6, test_loss=9.1e-6]\u001b[A\n",
      "Epoch 1356:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.55it/s, loss=1.02e-07, v_num=23, train_loss=8.46e-6, test_loss=9.1e-6]\u001b[AAdjusting learning rate of group 0 to 3.3482e-04.\n",
      "Epoch 1356:  50%|█████████████████████                     | 79/158 [00:00<00:00, 140.88it/s, loss=1e-07, v_num=23, train_loss=8.46e-6, test_loss=9.1e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1356:  67%|███████████████████████████▌             | 106/158 [00:00<00:00, 135.01it/s, loss=1e-07, v_num=23, train_loss=8.46e-6, test_loss=9.1e-6]\u001b[A\n",
      "Epoch 1356: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 172.30it/s, loss=1e-07, v_num=23, train_loss=9.48e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1357:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.81it/s, loss=8.04e-08, v_num=23, train_loss=9.48e-6, test_loss=1.03e-5]\u001b[AAdjusting learning rate of group 0 to 3.3398e-04.\n",
      "Epoch 1357:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.47it/s, loss=7.66e-08, v_num=23, train_loss=9.48e-6, test_loss=1.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1357:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.37it/s, loss=7.66e-08, v_num=23, train_loss=9.48e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1357: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.15it/s, loss=7.66e-08, v_num=23, train_loss=7.55e-6, test_loss=8.25e-6]\u001b[A\n",
      "Epoch 1358:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.82it/s, loss=8.38e-08, v_num=23, train_loss=7.55e-6, test_loss=8.25e-6]\u001b[AAdjusting learning rate of group 0 to 3.3315e-04.\n",
      "Epoch 1358:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.65it/s, loss=7.95e-08, v_num=23, train_loss=7.55e-6, test_loss=8.25e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1358:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.87it/s, loss=7.95e-08, v_num=23, train_loss=7.55e-6, test_loss=8.25e-6]\u001b[A\n",
      "Epoch 1358: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.69it/s, loss=7.95e-08, v_num=23, train_loss=7.62e-6, test_loss=8.25e-6]\u001b[A\n",
      "Epoch 1359:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.59it/s, loss=8.24e-08, v_num=23, train_loss=7.62e-6, test_loss=8.25e-6]\u001b[AAdjusting learning rate of group 0 to 3.3231e-04.\n",
      "Epoch 1359:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.50it/s, loss=7.95e-08, v_num=23, train_loss=7.62e-6, test_loss=8.25e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1359:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.59it/s, loss=7.95e-08, v_num=23, train_loss=7.62e-6, test_loss=8.25e-6]\u001b[A\n",
      "Epoch 1359: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.89it/s, loss=7.95e-08, v_num=23, train_loss=8.65e-6, test_loss=9.41e-6]\u001b[A\n",
      "Epoch 1360:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.79it/s, loss=8.64e-08, v_num=23, train_loss=8.65e-6, test_loss=9.41e-6]\u001b[AAdjusting learning rate of group 0 to 3.3148e-04.\n",
      "Epoch 1360:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.16it/s, loss=8.39e-08, v_num=23, train_loss=8.65e-6, test_loss=9.41e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1360:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.89it/s, loss=8.39e-08, v_num=23, train_loss=8.65e-6, test_loss=9.41e-6]\u001b[A\n",
      "Epoch 1360: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.78it/s, loss=8.39e-08, v_num=23, train_loss=9.49e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1361:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.93it/s, loss=8.18e-08, v_num=23, train_loss=9.49e-6, test_loss=1.01e-5]\u001b[AAdjusting learning rate of group 0 to 3.3066e-04.\n",
      "Epoch 1361:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.65it/s, loss=7.79e-08, v_num=23, train_loss=9.49e-6, test_loss=1.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1361:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.50it/s, loss=7.79e-08, v_num=23, train_loss=9.49e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1361: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 166.45it/s, loss=7.79e-08, v_num=23, train_loss=9.25e-6, test_loss=1e-5]\u001b[A\n",
      "Epoch 1362:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.71it/s, loss=7.64e-08, v_num=23, train_loss=9.25e-6, test_loss=1e-5]\u001b[AAdjusting learning rate of group 0 to 3.2983e-04.\n",
      "Epoch 1362:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 140.92it/s, loss=7.21e-08, v_num=23, train_loss=9.25e-6, test_loss=1e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1362:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 134.70it/s, loss=7.21e-08, v_num=23, train_loss=9.25e-6, test_loss=1e-5]\u001b[A\n",
      "Epoch 1362: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.61it/s, loss=7.21e-08, v_num=23, train_loss=7.52e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1363:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.74it/s, loss=1.35e-07, v_num=23, train_loss=7.52e-6, test_loss=8.17e-6]\u001b[AAdjusting learning rate of group 0 to 3.2900e-04.\n",
      "Epoch 1363:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.59it/s, loss=1.3e-07, v_num=23, train_loss=7.52e-6, test_loss=8.17e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1363:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.05it/s, loss=1.3e-07, v_num=23, train_loss=7.52e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1363: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.71it/s, loss=1.3e-07, v_num=23, train_loss=8.45e-6, test_loss=9.11e-6]\u001b[A\n",
      "Epoch 1364:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.82it/s, loss=1.07e-07, v_num=23, train_loss=8.45e-6, test_loss=9.11e-6]\u001b[AAdjusting learning rate of group 0 to 3.2818e-04.\n",
      "Epoch 1364:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.98it/s, loss=1.03e-07, v_num=23, train_loss=8.45e-6, test_loss=9.11e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1364:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.30it/s, loss=1.03e-07, v_num=23, train_loss=8.45e-6, test_loss=9.11e-6]\u001b[A\n",
      "Epoch 1364: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.86it/s, loss=1.03e-07, v_num=23, train_loss=8.1e-6, test_loss=8.77e-6]\u001b[A\n",
      "Epoch 1365:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.53it/s, loss=8.33e-08, v_num=23, train_loss=8.1e-6, test_loss=8.77e-6]\u001b[AAdjusting learning rate of group 0 to 3.2736e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1365:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.47it/s, loss=7.99e-08, v_num=23, train_loss=8.1e-6, test_loss=8.77e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1365:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.49it/s, loss=7.99e-08, v_num=23, train_loss=8.1e-6, test_loss=8.77e-6]\u001b[A\n",
      "Epoch 1365: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.36it/s, loss=7.99e-08, v_num=23, train_loss=8.41e-6, test_loss=9.13e-6]\u001b[A\n",
      "Epoch 1366:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.19it/s, loss=8.79e-08, v_num=23, train_loss=8.41e-6, test_loss=9.13e-6]\u001b[AAdjusting learning rate of group 0 to 3.2654e-04.\n",
      "Epoch 1366:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.85it/s, loss=8.5e-08, v_num=23, train_loss=8.41e-6, test_loss=9.13e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1366:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.98it/s, loss=8.5e-08, v_num=23, train_loss=8.41e-6, test_loss=9.13e-6]\u001b[A\n",
      "Epoch 1366: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.61it/s, loss=8.5e-08, v_num=23, train_loss=8.25e-6, test_loss=8.9e-6]\u001b[A\n",
      "Epoch 1367:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.81it/s, loss=9.23e-08, v_num=23, train_loss=8.25e-6, test_loss=8.9e-6]\u001b[AAdjusting learning rate of group 0 to 3.2573e-04.\n",
      "Epoch 1367:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.31it/s, loss=8.98e-08, v_num=23, train_loss=8.25e-6, test_loss=8.9e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1367:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.81it/s, loss=8.98e-08, v_num=23, train_loss=8.25e-6, test_loss=8.9e-6]\u001b[A\n",
      "Epoch 1367: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.71it/s, loss=8.98e-08, v_num=23, train_loss=8.11e-6, test_loss=8.62e-6]\u001b[A\n",
      "Epoch 1368:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.83it/s, loss=1.04e-07, v_num=23, train_loss=8.11e-6, test_loss=8.62e-6]\u001b[AAdjusting learning rate of group 0 to 3.2491e-04.\n",
      "Epoch 1368:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.94it/s, loss=9.97e-08, v_num=23, train_loss=8.11e-6, test_loss=8.62e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1368:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.64it/s, loss=9.97e-08, v_num=23, train_loss=8.11e-6, test_loss=8.62e-6]\u001b[A\n",
      "Epoch 1368: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.25it/s, loss=9.97e-08, v_num=23, train_loss=8.6e-6, test_loss=9.24e-6]\u001b[A\n",
      "Epoch 1369:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.18it/s, loss=7.63e-08, v_num=23, train_loss=8.6e-6, test_loss=9.24e-6]\u001b[AAdjusting learning rate of group 0 to 3.2410e-04.\n",
      "Epoch 1369:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.39it/s, loss=7.35e-08, v_num=23, train_loss=8.6e-6, test_loss=9.24e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1369:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.72it/s, loss=7.35e-08, v_num=23, train_loss=8.6e-6, test_loss=9.24e-6]\u001b[A\n",
      "Epoch 1369: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.73it/s, loss=7.35e-08, v_num=23, train_loss=7.36e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1370:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.99it/s, loss=8.69e-08, v_num=23, train_loss=7.36e-6, test_loss=7.93e-6]\u001b[AAdjusting learning rate of group 0 to 3.2329e-04.\n",
      "Epoch 1370:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.07it/s, loss=8.26e-08, v_num=23, train_loss=7.36e-6, test_loss=7.93e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1370:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.96it/s, loss=8.26e-08, v_num=23, train_loss=7.36e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1370: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.24it/s, loss=8.26e-08, v_num=23, train_loss=8.25e-6, test_loss=8.82e-6]\u001b[A\n",
      "Epoch 1371:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.34it/s, loss=9.03e-08, v_num=23, train_loss=8.25e-6, test_loss=8.82e-6]\u001b[AAdjusting learning rate of group 0 to 3.2248e-04.\n",
      "Epoch 1371:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.10it/s, loss=8.76e-08, v_num=23, train_loss=8.25e-6, test_loss=8.82e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1371:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.47it/s, loss=8.76e-08, v_num=23, train_loss=8.25e-6, test_loss=8.82e-6]\u001b[A\n",
      "Epoch 1371: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.71it/s, loss=8.76e-08, v_num=23, train_loss=9.62e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1372:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.74it/s, loss=8.4e-08, v_num=23, train_loss=9.62e-6, test_loss=1.02e-5]\u001b[AAdjusting learning rate of group 0 to 3.2168e-04.\n",
      "Epoch 1372:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.50it/s, loss=8.11e-08, v_num=23, train_loss=9.62e-6, test_loss=1.02e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1372:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.91it/s, loss=8.11e-08, v_num=23, train_loss=9.62e-6, test_loss=1.02e-5]\u001b[A\n",
      "Epoch 1372: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.62it/s, loss=8.11e-08, v_num=23, train_loss=7.64e-6, test_loss=8.16e-6]\u001b[A\n",
      "Epoch 1373:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.79it/s, loss=8.15e-08, v_num=23, train_loss=7.64e-6, test_loss=8.16e-6]\u001b[AAdjusting learning rate of group 0 to 3.2087e-04.\n",
      "Epoch 1373:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.75it/s, loss=7.84e-08, v_num=23, train_loss=7.64e-6, test_loss=8.16e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1373:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 135.14it/s, loss=7.84e-08, v_num=23, train_loss=7.64e-6, test_loss=8.16e-6]\u001b[A\n",
      "Epoch 1373: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.68it/s, loss=7.84e-08, v_num=23, train_loss=7.49e-6, test_loss=8.18e-6]\u001b[A\n",
      "Epoch 1374:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.60it/s, loss=8.29e-08, v_num=23, train_loss=7.49e-6, test_loss=8.18e-6]\u001b[AAdjusting learning rate of group 0 to 3.2007e-04.\n",
      "Epoch 1374:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.15it/s, loss=7.86e-08, v_num=23, train_loss=7.49e-6, test_loss=8.18e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1374:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.26it/s, loss=7.86e-08, v_num=23, train_loss=7.49e-6, test_loss=8.18e-6]\u001b[A\n",
      "Epoch 1374: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.03it/s, loss=7.86e-08, v_num=23, train_loss=6.81e-6, test_loss=7.4e-6]\u001b[A\n",
      "Epoch 1375:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.87it/s, loss=7.49e-08, v_num=23, train_loss=6.81e-6, test_loss=7.4e-6]\u001b[AAdjusting learning rate of group 0 to 3.1927e-04.\n",
      "Epoch 1375:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.70it/s, loss=7.16e-08, v_num=23, train_loss=6.81e-6, test_loss=7.4e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1375:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.17it/s, loss=7.16e-08, v_num=23, train_loss=6.81e-6, test_loss=7.4e-6]\u001b[A\n",
      "Epoch 1375: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.74it/s, loss=7.16e-08, v_num=23, train_loss=7.69e-6, test_loss=8.39e-6]\u001b[A\n",
      "Epoch 1376:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.76it/s, loss=8.29e-08, v_num=23, train_loss=7.69e-6, test_loss=8.39e-6]\u001b[AAdjusting learning rate of group 0 to 3.1847e-04.\n",
      "Epoch 1376:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.08it/s, loss=7.88e-08, v_num=23, train_loss=7.69e-6, test_loss=8.39e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1376:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.41it/s, loss=7.88e-08, v_num=23, train_loss=7.69e-6, test_loss=8.39e-6]\u001b[A\n",
      "Epoch 1376: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.32it/s, loss=7.88e-08, v_num=23, train_loss=8.21e-6, test_loss=8.76e-6]\u001b[A\n",
      "Epoch 1377:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.17it/s, loss=7e-08, v_num=23, train_loss=8.21e-6, test_loss=8.76e-6]\u001b[AAdjusting learning rate of group 0 to 3.1767e-04.\n",
      "Epoch 1377:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.45it/s, loss=7.7e-08, v_num=23, train_loss=8.21e-6, test_loss=8.76e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1377:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.59it/s, loss=7.7e-08, v_num=23, train_loss=8.21e-6, test_loss=8.76e-6]\u001b[A\n",
      "Epoch 1377: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.01it/s, loss=7.7e-08, v_num=23, train_loss=8.31e-6, test_loss=8.87e-6]\u001b[A\n",
      "Epoch 1378:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.80it/s, loss=9.43e-08, v_num=23, train_loss=8.31e-6, test_loss=8.87e-6]\u001b[AAdjusting learning rate of group 0 to 3.1688e-04.\n",
      "Epoch 1378:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.65it/s, loss=9.01e-08, v_num=23, train_loss=8.31e-6, test_loss=8.87e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1378:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.65it/s, loss=9.01e-08, v_num=23, train_loss=8.31e-6, test_loss=8.87e-6]\u001b[A\n",
      "Epoch 1378: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.55it/s, loss=9.01e-08, v_num=23, train_loss=8.69e-6, test_loss=9.21e-6]\u001b[A\n",
      "Epoch 1379:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.73it/s, loss=9.13e-08, v_num=23, train_loss=8.69e-6, test_loss=9.21e-6]\u001b[AAdjusting learning rate of group 0 to 3.1609e-04.\n",
      "Epoch 1379:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.02it/s, loss=8.71e-08, v_num=23, train_loss=8.69e-6, test_loss=9.21e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1379:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.39it/s, loss=8.71e-08, v_num=23, train_loss=8.69e-6, test_loss=9.21e-6]\u001b[A\n",
      "Epoch 1379: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.52it/s, loss=8.71e-08, v_num=23, train_loss=9.21e-6, test_loss=9.88e-6]\u001b[A\n",
      "Epoch 1380:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.67it/s, loss=1.38e-07, v_num=23, train_loss=9.21e-6, test_loss=9.88e-6]\u001b[AAdjusting learning rate of group 0 to 3.1530e-04.\n",
      "Epoch 1380:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.73it/s, loss=1.32e-07, v_num=23, train_loss=9.21e-6, test_loss=9.88e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1380:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.85it/s, loss=1.32e-07, v_num=23, train_loss=9.21e-6, test_loss=9.88e-6]\u001b[A\n",
      "Epoch 1380: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.27it/s, loss=1.32e-07, v_num=23, train_loss=8.17e-6, test_loss=8.83e-6]\u001b[A\n",
      "Epoch 1381:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.29it/s, loss=7.27e-08, v_num=23, train_loss=8.17e-6, test_loss=8.83e-6]\u001b[AAdjusting learning rate of group 0 to 3.1451e-04.\n",
      "Epoch 1381:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.66it/s, loss=6.91e-08, v_num=23, train_loss=8.17e-6, test_loss=8.83e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1381:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.99it/s, loss=6.91e-08, v_num=23, train_loss=8.17e-6, test_loss=8.83e-6]\u001b[A\n",
      "Epoch 1381: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.06it/s, loss=6.91e-08, v_num=23, train_loss=8.02e-6, test_loss=8.59e-6]\u001b[A\n",
      "Epoch 1382:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.53it/s, loss=8.78e-08, v_num=23, train_loss=8.02e-6, test_loss=8.59e-6]\u001b[AAdjusting learning rate of group 0 to 3.1372e-04.\n",
      "Epoch 1382:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.02it/s, loss=8.46e-08, v_num=23, train_loss=8.02e-6, test_loss=8.59e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1382:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.17it/s, loss=8.46e-08, v_num=23, train_loss=8.02e-6, test_loss=8.59e-6]\u001b[A\n",
      "Epoch 1382: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.57it/s, loss=8.46e-08, v_num=23, train_loss=8.17e-6, test_loss=8.74e-6]\u001b[A\n",
      "Epoch 1383:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.96it/s, loss=7.46e-08, v_num=23, train_loss=8.17e-6, test_loss=8.74e-6]\u001b[AAdjusting learning rate of group 0 to 3.1294e-04.\n",
      "Epoch 1383:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.82it/s, loss=7.17e-08, v_num=23, train_loss=8.17e-6, test_loss=8.74e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1383:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.65it/s, loss=7.17e-08, v_num=23, train_loss=8.17e-6, test_loss=8.74e-6]\u001b[A\n",
      "Epoch 1383: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.55it/s, loss=7.17e-08, v_num=23, train_loss=7.77e-6, test_loss=8.44e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1384:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.65it/s, loss=8.11e-08, v_num=23, train_loss=7.77e-6, test_loss=8.44e-6]\u001b[AAdjusting learning rate of group 0 to 3.1216e-04.\n",
      "Epoch 1384:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.72it/s, loss=7.67e-08, v_num=23, train_loss=7.77e-6, test_loss=8.44e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1384:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.29it/s, loss=7.67e-08, v_num=23, train_loss=7.77e-6, test_loss=8.44e-6]\u001b[A\n",
      "Epoch 1384: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.30it/s, loss=7.67e-08, v_num=23, train_loss=8.33e-6, test_loss=9.03e-6]\u001b[A\n",
      "Epoch 1385:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.24it/s, loss=2.66e-07, v_num=23, train_loss=8.33e-6, test_loss=9.03e-6]\u001b[AAdjusting learning rate of group 0 to 3.1138e-04.\n",
      "Epoch 1385:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.35it/s, loss=2.64e-07, v_num=23, train_loss=8.33e-6, test_loss=9.03e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1385:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.73it/s, loss=2.64e-07, v_num=23, train_loss=8.33e-6, test_loss=9.03e-6]\u001b[A\n",
      "Epoch 1385: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.71it/s, loss=2.64e-07, v_num=23, train_loss=2.24e-5, test_loss=2.41e-5]\u001b[A\n",
      "Epoch 1386:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.50it/s, loss=8.82e-08, v_num=23, train_loss=2.24e-5, test_loss=2.41e-5]\u001b[AAdjusting learning rate of group 0 to 3.1060e-04.\n",
      "Epoch 1386:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.06it/s, loss=8.58e-08, v_num=23, train_loss=2.24e-5, test_loss=2.41e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1386:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.32it/s, loss=8.58e-08, v_num=23, train_loss=2.24e-5, test_loss=2.41e-5]\u001b[A\n",
      "Epoch 1386: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.30it/s, loss=8.58e-08, v_num=23, train_loss=8.12e-6, test_loss=8.8e-6]\u001b[A\n",
      "Epoch 1387:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 148.24it/s, loss=1e-07, v_num=23, train_loss=8.12e-6, test_loss=8.8e-6]\u001b[AAdjusting learning rate of group 0 to 3.0982e-04.\n",
      "Epoch 1387:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.11it/s, loss=9.73e-08, v_num=23, train_loss=8.12e-6, test_loss=8.8e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1387:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.26it/s, loss=9.73e-08, v_num=23, train_loss=8.12e-6, test_loss=8.8e-6]\u001b[A\n",
      "Epoch 1387: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.58it/s, loss=9.73e-08, v_num=23, train_loss=9.05e-6, test_loss=9.8e-6]\u001b[A\n",
      "Epoch 1388:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.63it/s, loss=9.44e-08, v_num=23, train_loss=9.05e-6, test_loss=9.8e-6]\u001b[AAdjusting learning rate of group 0 to 3.0905e-04.\n",
      "Epoch 1388:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.77it/s, loss=9.15e-08, v_num=23, train_loss=9.05e-6, test_loss=9.8e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1388:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 128.52it/s, loss=9.15e-08, v_num=23, train_loss=9.05e-6, test_loss=9.8e-6]\u001b[A\n",
      "Epoch 1388: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 165.03it/s, loss=9.15e-08, v_num=23, train_loss=8e-6, test_loss=8.79e-6]\u001b[A\n",
      "Epoch 1389:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 149.12it/s, loss=9.72e-08, v_num=23, train_loss=8e-6, test_loss=8.79e-6]\u001b[AAdjusting learning rate of group 0 to 3.0827e-04.\n",
      "Epoch 1389:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 141.28it/s, loss=9.17e-08, v_num=23, train_loss=8e-6, test_loss=8.79e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1389:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 135.22it/s, loss=9.17e-08, v_num=23, train_loss=8e-6, test_loss=8.79e-6]\u001b[A\n",
      "Epoch 1389: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.58it/s, loss=9.17e-08, v_num=23, train_loss=7.51e-6, test_loss=8.21e-6]\u001b[A\n",
      "Epoch 1390:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.02it/s, loss=8.16e-08, v_num=23, train_loss=7.51e-6, test_loss=8.21e-6]\u001b[AAdjusting learning rate of group 0 to 3.0750e-04.\n",
      "Epoch 1390:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.84it/s, loss=7.81e-08, v_num=23, train_loss=7.51e-6, test_loss=8.21e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1390:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.51it/s, loss=7.81e-08, v_num=23, train_loss=7.51e-6, test_loss=8.21e-6]\u001b[A\n",
      "Epoch 1390: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.64it/s, loss=7.81e-08, v_num=23, train_loss=7.73e-6, test_loss=8.42e-6]\u001b[A\n",
      "Epoch 1391:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.94it/s, loss=7.89e-08, v_num=23, train_loss=7.73e-6, test_loss=8.42e-6]\u001b[AAdjusting learning rate of group 0 to 3.0673e-04.\n",
      "Epoch 1391:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.80it/s, loss=7.6e-08, v_num=23, train_loss=7.73e-6, test_loss=8.42e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1391:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.17it/s, loss=7.6e-08, v_num=23, train_loss=7.73e-6, test_loss=8.42e-6]\u001b[A\n",
      "Epoch 1391: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.58it/s, loss=7.6e-08, v_num=23, train_loss=8.37e-6, test_loss=9.03e-6]\u001b[A\n",
      "Epoch 1392:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.93it/s, loss=8.06e-08, v_num=23, train_loss=8.37e-6, test_loss=9.03e-6]\u001b[AAdjusting learning rate of group 0 to 3.0597e-04.\n",
      "Epoch 1392:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.10it/s, loss=7.8e-08, v_num=23, train_loss=8.37e-6, test_loss=9.03e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1392:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.30it/s, loss=7.8e-08, v_num=23, train_loss=8.37e-6, test_loss=9.03e-6]\u001b[A\n",
      "Epoch 1392: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.85it/s, loss=7.8e-08, v_num=23, train_loss=7.27e-6, test_loss=7.99e-6]\u001b[A\n",
      "Epoch 1393:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.65it/s, loss=8.53e-08, v_num=23, train_loss=7.27e-6, test_loss=7.99e-6]\u001b[AAdjusting learning rate of group 0 to 3.0520e-04.\n",
      "Epoch 1393:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.44it/s, loss=8.23e-08, v_num=23, train_loss=7.27e-6, test_loss=7.99e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1393:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.29it/s, loss=8.23e-08, v_num=23, train_loss=7.27e-6, test_loss=7.99e-6]\u001b[A\n",
      "Epoch 1393: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.60it/s, loss=8.23e-08, v_num=23, train_loss=8.22e-6, test_loss=8.91e-6]\u001b[A\n",
      "Epoch 1394:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.11it/s, loss=8.63e-08, v_num=23, train_loss=8.22e-6, test_loss=8.91e-6]\u001b[AAdjusting learning rate of group 0 to 3.0444e-04.\n",
      "Epoch 1394:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.87it/s, loss=8.39e-08, v_num=23, train_loss=8.22e-6, test_loss=8.91e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1394:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.16it/s, loss=8.39e-08, v_num=23, train_loss=8.22e-6, test_loss=8.91e-6]\u001b[A\n",
      "Epoch 1394: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.57it/s, loss=8.39e-08, v_num=23, train_loss=8.5e-6, test_loss=9.24e-6]\u001b[A\n",
      "Epoch 1395:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.12it/s, loss=8.49e-08, v_num=23, train_loss=8.5e-6, test_loss=9.24e-6]\u001b[AAdjusting learning rate of group 0 to 3.0368e-04.\n",
      "Epoch 1395:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.17it/s, loss=8.18e-08, v_num=23, train_loss=8.5e-6, test_loss=9.24e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1395:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.83it/s, loss=8.18e-08, v_num=23, train_loss=8.5e-6, test_loss=9.24e-6]\u001b[A\n",
      "Epoch 1395: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.56it/s, loss=8.18e-08, v_num=23, train_loss=7.46e-6, test_loss=8.11e-6]\u001b[A\n",
      "Epoch 1396:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.37it/s, loss=8.71e-08, v_num=23, train_loss=7.46e-6, test_loss=8.11e-6]\u001b[AAdjusting learning rate of group 0 to 3.0292e-04.\n",
      "Epoch 1396:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.95it/s, loss=8.25e-08, v_num=23, train_loss=7.46e-6, test_loss=8.11e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1396:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 135.12it/s, loss=8.25e-08, v_num=23, train_loss=7.46e-6, test_loss=8.11e-6]\u001b[A\n",
      "Epoch 1396: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.35it/s, loss=8.25e-08, v_num=23, train_loss=7.73e-6, test_loss=8.51e-6]\u001b[A\n",
      "Epoch 1397:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.65it/s, loss=9.47e-08, v_num=23, train_loss=7.73e-6, test_loss=8.51e-6]\u001b[AAdjusting learning rate of group 0 to 3.0216e-04.\n",
      "Epoch 1397:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.85it/s, loss=9.1e-08, v_num=23, train_loss=7.73e-6, test_loss=8.51e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1397:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.87it/s, loss=9.1e-08, v_num=23, train_loss=7.73e-6, test_loss=8.51e-6]\u001b[A\n",
      "Epoch 1397: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.45it/s, loss=9.1e-08, v_num=23, train_loss=7.43e-6, test_loss=8.19e-6]\u001b[A\n",
      "Epoch 1398:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.36it/s, loss=9.03e-08, v_num=23, train_loss=7.43e-6, test_loss=8.19e-6]\u001b[AAdjusting learning rate of group 0 to 3.0141e-04.\n",
      "Epoch 1398:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.26it/s, loss=8.8e-08, v_num=23, train_loss=7.43e-6, test_loss=8.19e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1398:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.55it/s, loss=8.8e-08, v_num=23, train_loss=7.43e-6, test_loss=8.19e-6]\u001b[A\n",
      "Epoch 1398: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.81it/s, loss=8.8e-08, v_num=23, train_loss=8.03e-6, test_loss=8.77e-6]\u001b[A\n",
      "Epoch 1399:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.06it/s, loss=7.26e-08, v_num=23, train_loss=8.03e-6, test_loss=8.77e-6]\u001b[AAdjusting learning rate of group 0 to 3.0065e-04.\n",
      "Epoch 1399:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.35it/s, loss=6.98e-08, v_num=23, train_loss=8.03e-6, test_loss=8.77e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1399:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.05it/s, loss=6.98e-08, v_num=23, train_loss=8.03e-6, test_loss=8.77e-6]\u001b[A\n",
      "Epoch 1399: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.65it/s, loss=6.98e-08, v_num=23, train_loss=8.04e-6, test_loss=8.68e-6]\u001b[A\n",
      "Epoch 1400:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.83it/s, loss=9.28e-08, v_num=23, train_loss=8.04e-6, test_loss=8.68e-6]\u001b[AAdjusting learning rate of group 0 to 2.9990e-04.\n",
      "Epoch 1400:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.80it/s, loss=9.04e-08, v_num=23, train_loss=8.04e-6, test_loss=8.68e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1400:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.37it/s, loss=9.04e-08, v_num=23, train_loss=8.04e-6, test_loss=8.68e-6]\u001b[A\n",
      "Epoch 1400: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.92it/s, loss=9.04e-08, v_num=23, train_loss=7.65e-6, test_loss=8.32e-6]\u001b[A\n",
      "Epoch 1401:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.80it/s, loss=8.88e-08, v_num=23, train_loss=7.65e-6, test_loss=8.32e-6]\u001b[AAdjusting learning rate of group 0 to 2.9915e-04.\n",
      "Epoch 1401:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.18it/s, loss=8.62e-08, v_num=23, train_loss=7.65e-6, test_loss=8.32e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1401:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.14it/s, loss=8.62e-08, v_num=23, train_loss=7.65e-6, test_loss=8.32e-6]\u001b[A\n",
      "Epoch 1401: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.94it/s, loss=8.62e-08, v_num=23, train_loss=7.36e-6, test_loss=7.99e-6]\u001b[A\n",
      "Epoch 1402:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 145.65it/s, loss=7.87e-08, v_num=23, train_loss=7.36e-6, test_loss=7.99e-6]\u001b[AAdjusting learning rate of group 0 to 2.9840e-04.\n",
      "Epoch 1402:  50%|███████████████████                   | 79/158 [00:00<00:00, 135.24it/s, loss=7.55e-08, v_num=23, train_loss=7.36e-6, test_loss=7.99e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1402:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.04it/s, loss=7.55e-08, v_num=23, train_loss=7.36e-6, test_loss=7.99e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1402: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.14it/s, loss=7.55e-08, v_num=23, train_loss=7.71e-6, test_loss=8.4e-6]\u001b[A\n",
      "Epoch 1403:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.10it/s, loss=6.92e-08, v_num=23, train_loss=7.71e-6, test_loss=8.4e-6]\u001b[AAdjusting learning rate of group 0 to 2.9766e-04.\n",
      "Epoch 1403:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.99it/s, loss=6.59e-08, v_num=23, train_loss=7.71e-6, test_loss=8.4e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1403:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.50it/s, loss=6.59e-08, v_num=23, train_loss=7.71e-6, test_loss=8.4e-6]\u001b[A\n",
      "Epoch 1403: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.24it/s, loss=6.59e-08, v_num=23, train_loss=7.97e-6, test_loss=8.51e-6]\u001b[A\n",
      "Epoch 1404:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.21it/s, loss=8.08e-08, v_num=23, train_loss=7.97e-6, test_loss=8.51e-6]\u001b[AAdjusting learning rate of group 0 to 2.9691e-04.\n",
      "Epoch 1404:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.80it/s, loss=7.7e-08, v_num=23, train_loss=7.97e-6, test_loss=8.51e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1404:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.07it/s, loss=7.7e-08, v_num=23, train_loss=7.97e-6, test_loss=8.51e-6]\u001b[A\n",
      "Epoch 1404: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.22it/s, loss=7.7e-08, v_num=23, train_loss=8.88e-6, test_loss=9.64e-6]\u001b[A\n",
      "Epoch 1405:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.52it/s, loss=1.42e-07, v_num=23, train_loss=8.88e-6, test_loss=9.64e-6]\u001b[AAdjusting learning rate of group 0 to 2.9617e-04.\n",
      "Epoch 1405:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.50it/s, loss=1.4e-07, v_num=23, train_loss=8.88e-6, test_loss=9.64e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1405:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.37it/s, loss=1.4e-07, v_num=23, train_loss=8.88e-6, test_loss=9.64e-6]\u001b[A\n",
      "Epoch 1405: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.96it/s, loss=1.4e-07, v_num=23, train_loss=8.03e-6, test_loss=8.86e-6]\u001b[A\n",
      "Epoch 1406:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.24it/s, loss=7.54e-08, v_num=23, train_loss=8.03e-6, test_loss=8.86e-6]\u001b[AAdjusting learning rate of group 0 to 2.9543e-04.\n",
      "Epoch 1406:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 138.11it/s, loss=7e-08, v_num=23, train_loss=8.03e-6, test_loss=8.86e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1406:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 132.33it/s, loss=7e-08, v_num=23, train_loss=8.03e-6, test_loss=8.86e-6]\u001b[A\n",
      "Epoch 1406: 100%|█████████████████████████████████████████| 158/158 [00:00<00:00, 167.35it/s, loss=7e-08, v_num=23, train_loss=7.86e-6, test_loss=8.5e-6]\u001b[A\n",
      "Epoch 1407:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.52it/s, loss=7.27e-08, v_num=23, train_loss=7.86e-6, test_loss=8.5e-6]\u001b[AAdjusting learning rate of group 0 to 2.9469e-04.\n",
      "Epoch 1407:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.46it/s, loss=7.01e-08, v_num=23, train_loss=7.86e-6, test_loss=8.5e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1407:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.50it/s, loss=7.01e-08, v_num=23, train_loss=7.86e-6, test_loss=8.5e-6]\u001b[A\n",
      "Epoch 1407: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.86it/s, loss=7.01e-08, v_num=23, train_loss=8.06e-6, test_loss=8.7e-6]\u001b[A\n",
      "Epoch 1408:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.30it/s, loss=8.16e-08, v_num=23, train_loss=8.06e-6, test_loss=8.7e-6]\u001b[AAdjusting learning rate of group 0 to 2.9396e-04.\n",
      "Epoch 1408:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.91it/s, loss=7.61e-08, v_num=23, train_loss=8.06e-6, test_loss=8.7e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1408:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.70it/s, loss=7.61e-08, v_num=23, train_loss=8.06e-6, test_loss=8.7e-6]\u001b[A\n",
      "Epoch 1408: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.80it/s, loss=7.61e-08, v_num=23, train_loss=7.55e-6, test_loss=8.24e-6]\u001b[A\n",
      "Epoch 1409:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.45it/s, loss=7.65e-08, v_num=23, train_loss=7.55e-6, test_loss=8.24e-6]\u001b[AAdjusting learning rate of group 0 to 2.9322e-04.\n",
      "Epoch 1409:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.66it/s, loss=7.41e-08, v_num=23, train_loss=7.55e-6, test_loss=8.24e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1409:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.35it/s, loss=7.41e-08, v_num=23, train_loss=7.55e-6, test_loss=8.24e-6]\u001b[A\n",
      "Epoch 1409: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.22it/s, loss=7.41e-08, v_num=23, train_loss=8.38e-6, test_loss=9.04e-6]\u001b[A\n",
      "Epoch 1410:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.41it/s, loss=7.48e-08, v_num=23, train_loss=8.38e-6, test_loss=9.04e-6]\u001b[AAdjusting learning rate of group 0 to 2.9249e-04.\n",
      "Epoch 1410:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.90it/s, loss=7.12e-08, v_num=23, train_loss=8.38e-6, test_loss=9.04e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1410:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.82it/s, loss=7.12e-08, v_num=23, train_loss=8.38e-6, test_loss=9.04e-6]\u001b[A\n",
      "Epoch 1410: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.17it/s, loss=7.12e-08, v_num=23, train_loss=9.59e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1411:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.38it/s, loss=9.41e-08, v_num=23, train_loss=9.59e-6, test_loss=1.03e-5]\u001b[AAdjusting learning rate of group 0 to 2.9176e-04.\n",
      "Epoch 1411:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.60it/s, loss=8.89e-08, v_num=23, train_loss=9.59e-6, test_loss=1.03e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1411:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.94it/s, loss=8.89e-08, v_num=23, train_loss=9.59e-6, test_loss=1.03e-5]\u001b[A\n",
      "Epoch 1411: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.62it/s, loss=8.89e-08, v_num=23, train_loss=8.88e-6, test_loss=9.7e-6]\u001b[A\n",
      "Epoch 1412:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 147.90it/s, loss=8e-08, v_num=23, train_loss=8.88e-6, test_loss=9.7e-6]\u001b[AAdjusting learning rate of group 0 to 2.9103e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1412:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.73it/s, loss=7.71e-08, v_num=23, train_loss=8.88e-6, test_loss=9.7e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1412:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.19it/s, loss=7.71e-08, v_num=23, train_loss=8.88e-6, test_loss=9.7e-6]\u001b[A\n",
      "Epoch 1412: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 165.47it/s, loss=7.71e-08, v_num=23, train_loss=1e-5, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1413:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 147.90it/s, loss=7.21e-08, v_num=23, train_loss=1e-5, test_loss=1.06e-5]\u001b[AAdjusting learning rate of group 0 to 2.9030e-04.\n",
      "Epoch 1413:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 137.36it/s, loss=6.86e-08, v_num=23, train_loss=1e-5, test_loss=1.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1413:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 131.28it/s, loss=6.86e-08, v_num=23, train_loss=1e-5, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1413: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.45it/s, loss=6.86e-08, v_num=23, train_loss=9.17e-6, test_loss=9.8e-6]\u001b[A\n",
      "Epoch 1414:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.92it/s, loss=8.07e-08, v_num=23, train_loss=9.17e-6, test_loss=9.8e-6]\u001b[AAdjusting learning rate of group 0 to 2.8957e-04.\n",
      "Epoch 1414:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.56it/s, loss=7.75e-08, v_num=23, train_loss=9.17e-6, test_loss=9.8e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1414:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.28it/s, loss=7.75e-08, v_num=23, train_loss=9.17e-6, test_loss=9.8e-6]\u001b[A\n",
      "Epoch 1414: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.16it/s, loss=7.75e-08, v_num=23, train_loss=9.22e-6, test_loss=9.87e-6]\u001b[A\n",
      "Epoch 1415:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.07it/s, loss=8.2e-08, v_num=23, train_loss=9.22e-6, test_loss=9.87e-6]\u001b[AAdjusting learning rate of group 0 to 2.8885e-04.\n",
      "Epoch 1415:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.94it/s, loss=7.91e-08, v_num=23, train_loss=9.22e-6, test_loss=9.87e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1415:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.24it/s, loss=7.91e-08, v_num=23, train_loss=9.22e-6, test_loss=9.87e-6]\u001b[A\n",
      "Epoch 1415: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.59it/s, loss=7.91e-08, v_num=23, train_loss=8.62e-6, test_loss=9.27e-6]\u001b[A\n",
      "Epoch 1416:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.03it/s, loss=9.24e-08, v_num=23, train_loss=8.62e-6, test_loss=9.27e-6]\u001b[AAdjusting learning rate of group 0 to 2.8813e-04.\n",
      "Epoch 1416:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.23it/s, loss=8.84e-08, v_num=23, train_loss=8.62e-6, test_loss=9.27e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1416:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.07it/s, loss=8.84e-08, v_num=23, train_loss=8.62e-6, test_loss=9.27e-6]\u001b[A\n",
      "Epoch 1416: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.11it/s, loss=8.84e-08, v_num=23, train_loss=7.73e-6, test_loss=8.6e-6]\u001b[A\n",
      "Epoch 1417:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.21it/s, loss=8.67e-08, v_num=23, train_loss=7.73e-6, test_loss=8.6e-6]\u001b[AAdjusting learning rate of group 0 to 2.8741e-04.\n",
      "Epoch 1417:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.72it/s, loss=8.33e-08, v_num=23, train_loss=7.73e-6, test_loss=8.6e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1417:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.27it/s, loss=8.33e-08, v_num=23, train_loss=7.73e-6, test_loss=8.6e-6]\u001b[A\n",
      "Epoch 1417: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.71it/s, loss=8.33e-08, v_num=23, train_loss=7.3e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1418:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.87it/s, loss=7.06e-08, v_num=23, train_loss=7.3e-6, test_loss=7.97e-6]\u001b[AAdjusting learning rate of group 0 to 2.8669e-04.\n",
      "Epoch 1418:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.98it/s, loss=6.77e-08, v_num=23, train_loss=7.3e-6, test_loss=7.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1418:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.33it/s, loss=6.77e-08, v_num=23, train_loss=7.3e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1418: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.13it/s, loss=6.77e-08, v_num=23, train_loss=7.48e-6, test_loss=8.14e-6]\u001b[A\n",
      "Epoch 1419:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.26it/s, loss=9.08e-08, v_num=23, train_loss=7.48e-6, test_loss=8.14e-6]\u001b[AAdjusting learning rate of group 0 to 2.8597e-04.\n",
      "Epoch 1419:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.47it/s, loss=8.73e-08, v_num=23, train_loss=7.48e-6, test_loss=8.14e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1419:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.75it/s, loss=8.73e-08, v_num=23, train_loss=7.48e-6, test_loss=8.14e-6]\u001b[A\n",
      "Epoch 1419: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.24it/s, loss=8.73e-08, v_num=23, train_loss=8.3e-6, test_loss=8.85e-6]\u001b[A\n",
      "Epoch 1420:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.53it/s, loss=7.56e-08, v_num=23, train_loss=8.3e-6, test_loss=8.85e-6]\u001b[AAdjusting learning rate of group 0 to 2.8526e-04.\n",
      "Epoch 1420:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.74it/s, loss=7.1e-08, v_num=23, train_loss=8.3e-6, test_loss=8.85e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1420:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.39it/s, loss=7.1e-08, v_num=23, train_loss=8.3e-6, test_loss=8.85e-6]\u001b[A\n",
      "Epoch 1420: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.59it/s, loss=7.1e-08, v_num=23, train_loss=9.36e-6, test_loss=9.97e-6]\u001b[A\n",
      "Epoch 1421:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.80it/s, loss=8.08e-08, v_num=23, train_loss=9.36e-6, test_loss=9.97e-6]\u001b[AAdjusting learning rate of group 0 to 2.8454e-04.\n",
      "Epoch 1421:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.58it/s, loss=7.76e-08, v_num=23, train_loss=9.36e-6, test_loss=9.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1421:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.12it/s, loss=7.76e-08, v_num=23, train_loss=9.36e-6, test_loss=9.97e-6]\u001b[A\n",
      "Epoch 1421: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.28it/s, loss=7.76e-08, v_num=23, train_loss=8.28e-6, test_loss=8.94e-6]\u001b[A\n",
      "Epoch 1422:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.54it/s, loss=8.03e-08, v_num=23, train_loss=8.28e-6, test_loss=8.94e-6]\u001b[AAdjusting learning rate of group 0 to 2.8383e-04.\n",
      "Epoch 1422:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.59it/s, loss=7.79e-08, v_num=23, train_loss=8.28e-6, test_loss=8.94e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1422:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.75it/s, loss=7.79e-08, v_num=23, train_loss=8.28e-6, test_loss=8.94e-6]\u001b[A\n",
      "Epoch 1422: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.78it/s, loss=7.79e-08, v_num=23, train_loss=9.15e-6, test_loss=9.74e-6]\u001b[A\n",
      "Epoch 1423:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.80it/s, loss=8.32e-08, v_num=23, train_loss=9.15e-6, test_loss=9.74e-6]\u001b[AAdjusting learning rate of group 0 to 2.8312e-04.\n",
      "Epoch 1423:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.60it/s, loss=7.9e-08, v_num=23, train_loss=9.15e-6, test_loss=9.74e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1423:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.03it/s, loss=7.9e-08, v_num=23, train_loss=9.15e-6, test_loss=9.74e-6]\u001b[A\n",
      "Epoch 1423: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.74it/s, loss=7.9e-08, v_num=23, train_loss=8.45e-6, test_loss=9.1e-6]\u001b[A\n",
      "Epoch 1424:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 146.97it/s, loss=8.48e-08, v_num=23, train_loss=8.45e-6, test_loss=9.1e-6]\u001b[AAdjusting learning rate of group 0 to 2.8242e-04.\n",
      "Epoch 1424:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.18it/s, loss=8.22e-08, v_num=23, train_loss=8.45e-6, test_loss=9.1e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1424:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.85it/s, loss=8.22e-08, v_num=23, train_loss=8.45e-6, test_loss=9.1e-6]\u001b[A\n",
      "Epoch 1424: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.43it/s, loss=8.22e-08, v_num=23, train_loss=8.03e-6, test_loss=8.66e-6]\u001b[A\n",
      "Epoch 1425:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.51it/s, loss=7.31e-08, v_num=23, train_loss=8.03e-6, test_loss=8.66e-6]\u001b[AAdjusting learning rate of group 0 to 2.8171e-04.\n",
      "Epoch 1425:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.42it/s, loss=7.02e-08, v_num=23, train_loss=8.03e-6, test_loss=8.66e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1425:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.67it/s, loss=7.02e-08, v_num=23, train_loss=8.03e-6, test_loss=8.66e-6]\u001b[A\n",
      "Epoch 1425: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.50it/s, loss=7.02e-08, v_num=23, train_loss=8.06e-6, test_loss=8.7e-6]\u001b[A\n",
      "Epoch 1426:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.00it/s, loss=8.16e-08, v_num=23, train_loss=8.06e-6, test_loss=8.7e-6]\u001b[AAdjusting learning rate of group 0 to 2.8101e-04.\n",
      "Epoch 1426:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.72it/s, loss=7.8e-08, v_num=23, train_loss=8.06e-6, test_loss=8.7e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1426:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.59it/s, loss=7.8e-08, v_num=23, train_loss=8.06e-6, test_loss=8.7e-6]\u001b[A\n",
      "Epoch 1426: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.32it/s, loss=7.8e-08, v_num=23, train_loss=8.37e-6, test_loss=9.08e-6]\u001b[A\n",
      "Epoch 1427:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.73it/s, loss=8.14e-08, v_num=23, train_loss=8.37e-6, test_loss=9.08e-6]\u001b[AAdjusting learning rate of group 0 to 2.8030e-04.\n",
      "Epoch 1427:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.88it/s, loss=7.91e-08, v_num=23, train_loss=8.37e-6, test_loss=9.08e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1427:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.90it/s, loss=7.91e-08, v_num=23, train_loss=8.37e-6, test_loss=9.08e-6]\u001b[A\n",
      "Epoch 1427: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.97it/s, loss=7.91e-08, v_num=23, train_loss=9.4e-6, test_loss=9.99e-6]\u001b[A\n",
      "Epoch 1428:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.77it/s, loss=8.29e-08, v_num=23, train_loss=9.4e-6, test_loss=9.99e-6]\u001b[AAdjusting learning rate of group 0 to 2.7960e-04.\n",
      "Epoch 1428:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.96it/s, loss=7.74e-08, v_num=23, train_loss=9.4e-6, test_loss=9.99e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1428:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.52it/s, loss=7.74e-08, v_num=23, train_loss=9.4e-6, test_loss=9.99e-6]\u001b[A\n",
      "Epoch 1428: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.42it/s, loss=7.74e-08, v_num=23, train_loss=8.52e-6, test_loss=9.25e-6]\u001b[A\n",
      "Epoch 1429:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.08it/s, loss=7.78e-08, v_num=23, train_loss=8.52e-6, test_loss=9.25e-6]\u001b[AAdjusting learning rate of group 0 to 2.7890e-04.\n",
      "Epoch 1429:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.77it/s, loss=7.59e-08, v_num=23, train_loss=8.52e-6, test_loss=9.25e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1429:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.32it/s, loss=7.59e-08, v_num=23, train_loss=8.52e-6, test_loss=9.25e-6]\u001b[A\n",
      "Epoch 1429: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.38it/s, loss=7.59e-08, v_num=23, train_loss=8.22e-6, test_loss=8.84e-6]\u001b[A\n",
      "Epoch 1430:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.93it/s, loss=8.69e-08, v_num=23, train_loss=8.22e-6, test_loss=8.84e-6]\u001b[AAdjusting learning rate of group 0 to 2.7821e-04.\n",
      "Epoch 1430:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.82it/s, loss=8.46e-08, v_num=23, train_loss=8.22e-6, test_loss=8.84e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1430:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.89it/s, loss=8.46e-08, v_num=23, train_loss=8.22e-6, test_loss=8.84e-6]\u001b[A\n",
      "Epoch 1430: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.13it/s, loss=8.46e-08, v_num=23, train_loss=7.76e-6, test_loss=8.39e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1431:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.06it/s, loss=8.75e-08, v_num=23, train_loss=7.76e-6, test_loss=8.39e-6]\u001b[AAdjusting learning rate of group 0 to 2.7751e-04.\n",
      "Epoch 1431:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.94it/s, loss=8.03e-08, v_num=23, train_loss=7.76e-6, test_loss=8.39e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1431:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.26it/s, loss=8.03e-08, v_num=23, train_loss=7.76e-6, test_loss=8.39e-6]\u001b[A\n",
      "Epoch 1431: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.26it/s, loss=8.03e-08, v_num=23, train_loss=8.91e-6, test_loss=9.44e-6]\u001b[A\n",
      "Epoch 1432:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.85it/s, loss=7.02e-08, v_num=23, train_loss=8.91e-6, test_loss=9.44e-6]\u001b[AAdjusting learning rate of group 0 to 2.7682e-04.\n",
      "Epoch 1432:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.97it/s, loss=6.71e-08, v_num=23, train_loss=8.91e-6, test_loss=9.44e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1432:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.62it/s, loss=6.71e-08, v_num=23, train_loss=8.91e-6, test_loss=9.44e-6]\u001b[A\n",
      "Epoch 1432: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.40it/s, loss=6.71e-08, v_num=23, train_loss=7.61e-6, test_loss=8.36e-6]\u001b[A\n",
      "Epoch 1433:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.38it/s, loss=7.85e-08, v_num=23, train_loss=7.61e-6, test_loss=8.36e-6]\u001b[AAdjusting learning rate of group 0 to 2.7612e-04.\n",
      "Epoch 1433:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.01it/s, loss=7.39e-08, v_num=23, train_loss=7.61e-6, test_loss=8.36e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1433:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.15it/s, loss=7.39e-08, v_num=23, train_loss=7.61e-6, test_loss=8.36e-6]\u001b[A\n",
      "Epoch 1433: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.35it/s, loss=7.39e-08, v_num=23, train_loss=7.82e-6, test_loss=8.46e-6]\u001b[A\n",
      "Epoch 1434:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.73it/s, loss=7.83e-08, v_num=23, train_loss=7.82e-6, test_loss=8.46e-6]\u001b[AAdjusting learning rate of group 0 to 2.7543e-04.\n",
      "Epoch 1434:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.34it/s, loss=7.4e-08, v_num=23, train_loss=7.82e-6, test_loss=8.46e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1434:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.88it/s, loss=7.4e-08, v_num=23, train_loss=7.82e-6, test_loss=8.46e-6]\u001b[A\n",
      "Epoch 1434: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.16it/s, loss=7.4e-08, v_num=23, train_loss=8.27e-6, test_loss=8.86e-6]\u001b[A\n",
      "Epoch 1435:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.23it/s, loss=8.32e-08, v_num=23, train_loss=8.27e-6, test_loss=8.86e-6]\u001b[AAdjusting learning rate of group 0 to 2.7475e-04.\n",
      "Epoch 1435:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.35it/s, loss=8.1e-08, v_num=23, train_loss=8.27e-6, test_loss=8.86e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1435:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.34it/s, loss=8.1e-08, v_num=23, train_loss=8.27e-6, test_loss=8.86e-6]\u001b[A\n",
      "Epoch 1435: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.10it/s, loss=8.1e-08, v_num=23, train_loss=8.19e-6, test_loss=8.81e-6]\u001b[A\n",
      "Epoch 1436:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.05it/s, loss=7.65e-08, v_num=23, train_loss=8.19e-6, test_loss=8.81e-6]\u001b[AAdjusting learning rate of group 0 to 2.7406e-04.\n",
      "Epoch 1436:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.19it/s, loss=7.32e-08, v_num=23, train_loss=8.19e-6, test_loss=8.81e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1436:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.89it/s, loss=7.32e-08, v_num=23, train_loss=8.19e-6, test_loss=8.81e-6]\u001b[A\n",
      "Epoch 1436: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.31it/s, loss=7.32e-08, v_num=23, train_loss=8.12e-6, test_loss=8.79e-6]\u001b[A\n",
      "Epoch 1437:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.42it/s, loss=7.53e-08, v_num=23, train_loss=8.12e-6, test_loss=8.79e-6]\u001b[AAdjusting learning rate of group 0 to 2.7337e-04.\n",
      "Epoch 1437:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.26it/s, loss=7.25e-08, v_num=23, train_loss=8.12e-6, test_loss=8.79e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1437:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.10it/s, loss=7.25e-08, v_num=23, train_loss=8.12e-6, test_loss=8.79e-6]\u001b[A\n",
      "Epoch 1437: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.21it/s, loss=7.25e-08, v_num=23, train_loss=7.8e-6, test_loss=8.46e-6]\u001b[A\n",
      "Epoch 1438:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.60it/s, loss=8.67e-08, v_num=23, train_loss=7.8e-6, test_loss=8.46e-6]\u001b[AAdjusting learning rate of group 0 to 2.7269e-04.\n",
      "Epoch 1438:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.56it/s, loss=8.46e-08, v_num=23, train_loss=7.8e-6, test_loss=8.46e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1438:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.54it/s, loss=8.46e-08, v_num=23, train_loss=7.8e-6, test_loss=8.46e-6]\u001b[A\n",
      "Epoch 1438: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.10it/s, loss=8.46e-08, v_num=23, train_loss=9.5e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1439:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.56it/s, loss=1.06e-07, v_num=23, train_loss=9.5e-6, test_loss=1.01e-5]\u001b[AAdjusting learning rate of group 0 to 2.7201e-04.\n",
      "Epoch 1439:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.52it/s, loss=1.02e-07, v_num=23, train_loss=9.5e-6, test_loss=1.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1439:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.75it/s, loss=1.02e-07, v_num=23, train_loss=9.5e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1439: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.12it/s, loss=1.02e-07, v_num=23, train_loss=7.63e-6, test_loss=8.42e-6]\u001b[A\n",
      "Epoch 1440:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.59it/s, loss=7.23e-08, v_num=23, train_loss=7.63e-6, test_loss=8.42e-6]\u001b[AAdjusting learning rate of group 0 to 2.7133e-04.\n",
      "Epoch 1440:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.64it/s, loss=6.91e-08, v_num=23, train_loss=7.63e-6, test_loss=8.42e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1440:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.39it/s, loss=6.91e-08, v_num=23, train_loss=7.63e-6, test_loss=8.42e-6]\u001b[A\n",
      "Epoch 1440: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.20it/s, loss=6.91e-08, v_num=23, train_loss=8.06e-6, test_loss=8.79e-6]\u001b[A\n",
      "Epoch 1441:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.09it/s, loss=8.34e-08, v_num=23, train_loss=8.06e-6, test_loss=8.79e-6]\u001b[AAdjusting learning rate of group 0 to 2.7065e-04.\n",
      "Epoch 1441:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.19it/s, loss=8.1e-08, v_num=23, train_loss=8.06e-6, test_loss=8.79e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1441:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.94it/s, loss=8.1e-08, v_num=23, train_loss=8.06e-6, test_loss=8.79e-6]\u001b[A\n",
      "Epoch 1441: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.64it/s, loss=8.1e-08, v_num=23, train_loss=8.1e-6, test_loss=8.83e-6]\u001b[A\n",
      "Epoch 1442:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.58it/s, loss=6.95e-08, v_num=23, train_loss=8.1e-6, test_loss=8.83e-6]\u001b[AAdjusting learning rate of group 0 to 2.6997e-04.\n",
      "Epoch 1442:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.95it/s, loss=6.7e-08, v_num=23, train_loss=8.1e-6, test_loss=8.83e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1442:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.79it/s, loss=6.7e-08, v_num=23, train_loss=8.1e-6, test_loss=8.83e-6]\u001b[A\n",
      "Epoch 1442: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.05it/s, loss=6.7e-08, v_num=23, train_loss=7.63e-6, test_loss=8.3e-6]\u001b[A\n",
      "Epoch 1443:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.35it/s, loss=7.96e-08, v_num=23, train_loss=7.63e-6, test_loss=8.3e-6]\u001b[AAdjusting learning rate of group 0 to 2.6930e-04.\n",
      "Epoch 1443:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.14it/s, loss=7.7e-08, v_num=23, train_loss=7.63e-6, test_loss=8.3e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1443:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.66it/s, loss=7.7e-08, v_num=23, train_loss=7.63e-6, test_loss=8.3e-6]\u001b[A\n",
      "Epoch 1443: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.63it/s, loss=7.7e-08, v_num=23, train_loss=8.59e-6, test_loss=9.24e-6]\u001b[A\n",
      "Epoch 1444:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.08it/s, loss=8.24e-08, v_num=23, train_loss=8.59e-6, test_loss=9.24e-6]\u001b[AAdjusting learning rate of group 0 to 2.6863e-04.\n",
      "Epoch 1444:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.98it/s, loss=7.87e-08, v_num=23, train_loss=8.59e-6, test_loss=9.24e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1444:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.08it/s, loss=7.87e-08, v_num=23, train_loss=8.59e-6, test_loss=9.24e-6]\u001b[A\n",
      "Epoch 1444: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.99it/s, loss=7.87e-08, v_num=23, train_loss=7.95e-6, test_loss=8.62e-6]\u001b[A\n",
      "Epoch 1445:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.03it/s, loss=6.78e-08, v_num=23, train_loss=7.95e-6, test_loss=8.62e-6]\u001b[AAdjusting learning rate of group 0 to 2.6795e-04.\n",
      "Epoch 1445:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.44it/s, loss=6.5e-08, v_num=23, train_loss=7.95e-6, test_loss=8.62e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1445:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.16it/s, loss=6.5e-08, v_num=23, train_loss=7.95e-6, test_loss=8.62e-6]\u001b[A\n",
      "Epoch 1445: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.44it/s, loss=6.5e-08, v_num=23, train_loss=8.67e-6, test_loss=9.31e-6]\u001b[A\n",
      "Epoch 1446:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.43it/s, loss=7.38e-08, v_num=23, train_loss=8.67e-6, test_loss=9.31e-6]\u001b[AAdjusting learning rate of group 0 to 2.6728e-04.\n",
      "Epoch 1446:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.42it/s, loss=7.13e-08, v_num=23, train_loss=8.67e-6, test_loss=9.31e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1446:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.05it/s, loss=7.13e-08, v_num=23, train_loss=8.67e-6, test_loss=9.31e-6]\u001b[A\n",
      "Epoch 1446: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.73it/s, loss=7.13e-08, v_num=23, train_loss=7.91e-6, test_loss=8.55e-6]\u001b[A\n",
      "Epoch 1447:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.88it/s, loss=7.48e-08, v_num=23, train_loss=7.91e-6, test_loss=8.55e-6]\u001b[AAdjusting learning rate of group 0 to 2.6662e-04.\n",
      "Epoch 1447:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.99it/s, loss=7.08e-08, v_num=23, train_loss=7.91e-6, test_loss=8.55e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1447:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.68it/s, loss=7.08e-08, v_num=23, train_loss=7.91e-6, test_loss=8.55e-6]\u001b[A\n",
      "Epoch 1447: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.78it/s, loss=7.08e-08, v_num=23, train_loss=8.1e-6, test_loss=8.75e-6]\u001b[A\n",
      "Epoch 1448:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.52it/s, loss=8.5e-08, v_num=23, train_loss=8.1e-6, test_loss=8.75e-6]\u001b[AAdjusting learning rate of group 0 to 2.6595e-04.\n",
      "Epoch 1448:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.25it/s, loss=7.87e-08, v_num=23, train_loss=8.1e-6, test_loss=8.75e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1448:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.09it/s, loss=7.87e-08, v_num=23, train_loss=8.1e-6, test_loss=8.75e-6]\u001b[A\n",
      "Epoch 1448: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.89it/s, loss=7.87e-08, v_num=23, train_loss=7.91e-6, test_loss=8.53e-6]\u001b[A\n",
      "Epoch 1449:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.80it/s, loss=8.12e-08, v_num=23, train_loss=7.91e-6, test_loss=8.53e-6]\u001b[AAdjusting learning rate of group 0 to 2.6528e-04.\n",
      "Epoch 1449:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.69it/s, loss=7.89e-08, v_num=23, train_loss=7.91e-6, test_loss=8.53e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1449:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.11it/s, loss=7.89e-08, v_num=23, train_loss=7.91e-6, test_loss=8.53e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1449: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.19it/s, loss=7.89e-08, v_num=23, train_loss=7.31e-6, test_loss=7.96e-6]\u001b[A\n",
      "Epoch 1450:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.95it/s, loss=8.42e-08, v_num=23, train_loss=7.31e-6, test_loss=7.96e-6]\u001b[AAdjusting learning rate of group 0 to 2.6462e-04.\n",
      "Epoch 1450:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.84it/s, loss=8.13e-08, v_num=23, train_loss=7.31e-6, test_loss=7.96e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1450:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.53it/s, loss=8.13e-08, v_num=23, train_loss=7.31e-6, test_loss=7.96e-6]\u001b[A\n",
      "Epoch 1450: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.20it/s, loss=8.13e-08, v_num=23, train_loss=7.31e-6, test_loss=8.07e-6]\u001b[A\n",
      "Epoch 1451:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.06it/s, loss=8.22e-08, v_num=23, train_loss=7.31e-6, test_loss=8.07e-6]\u001b[AAdjusting learning rate of group 0 to 2.6396e-04.\n",
      "Epoch 1451:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.38it/s, loss=7.94e-08, v_num=23, train_loss=7.31e-6, test_loss=8.07e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1451:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.30it/s, loss=7.94e-08, v_num=23, train_loss=7.31e-6, test_loss=8.07e-6]\u001b[A\n",
      "Epoch 1451: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.90it/s, loss=7.94e-08, v_num=23, train_loss=8.61e-6, test_loss=9.16e-6]\u001b[A\n",
      "Epoch 1452:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 144.59it/s, loss=7.03e-08, v_num=23, train_loss=8.61e-6, test_loss=9.16e-6]\u001b[AAdjusting learning rate of group 0 to 2.6330e-04.\n",
      "Epoch 1452:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.21it/s, loss=6.81e-08, v_num=23, train_loss=8.61e-6, test_loss=9.16e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1452:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.59it/s, loss=6.81e-08, v_num=23, train_loss=8.61e-6, test_loss=9.16e-6]\u001b[A\n",
      "Epoch 1452: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.79it/s, loss=6.81e-08, v_num=23, train_loss=7.57e-6, test_loss=8.15e-6]\u001b[A\n",
      "Epoch 1453:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.60it/s, loss=6.8e-08, v_num=23, train_loss=7.57e-6, test_loss=8.15e-6]\u001b[AAdjusting learning rate of group 0 to 2.6264e-04.\n",
      "Epoch 1453:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.32it/s, loss=6.54e-08, v_num=23, train_loss=7.57e-6, test_loss=8.15e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1453:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.15it/s, loss=6.54e-08, v_num=23, train_loss=7.57e-6, test_loss=8.15e-6]\u001b[A\n",
      "Epoch 1453: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.35it/s, loss=6.54e-08, v_num=23, train_loss=8.35e-6, test_loss=8.97e-6]\u001b[A\n",
      "Epoch 1454:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.77it/s, loss=6.86e-08, v_num=23, train_loss=8.35e-6, test_loss=8.97e-6]\u001b[AAdjusting learning rate of group 0 to 2.6198e-04.\n",
      "Epoch 1454:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.49it/s, loss=6.57e-08, v_num=23, train_loss=8.35e-6, test_loss=8.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1454:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.42it/s, loss=6.57e-08, v_num=23, train_loss=8.35e-6, test_loss=8.97e-6]\u001b[A\n",
      "Epoch 1454: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.97it/s, loss=6.57e-08, v_num=23, train_loss=7.55e-6, test_loss=8.15e-6]\u001b[A\n",
      "Epoch 1455:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.88it/s, loss=7.82e-08, v_num=23, train_loss=7.55e-6, test_loss=8.15e-6]\u001b[AAdjusting learning rate of group 0 to 2.6133e-04.\n",
      "Epoch 1455:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.67it/s, loss=7.51e-08, v_num=23, train_loss=7.55e-6, test_loss=8.15e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1455:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.32it/s, loss=7.51e-08, v_num=23, train_loss=7.55e-6, test_loss=8.15e-6]\u001b[A\n",
      "Epoch 1455: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.03it/s, loss=7.51e-08, v_num=23, train_loss=8.34e-6, test_loss=9.03e-6]\u001b[A\n",
      "Epoch 1456:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.43it/s, loss=1.56e-07, v_num=23, train_loss=8.34e-6, test_loss=9.03e-6]\u001b[AAdjusting learning rate of group 0 to 2.6068e-04.\n",
      "Epoch 1456:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.61it/s, loss=1.54e-07, v_num=23, train_loss=8.34e-6, test_loss=9.03e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1456:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.62it/s, loss=1.54e-07, v_num=23, train_loss=8.34e-6, test_loss=9.03e-6]\u001b[A\n",
      "Epoch 1456: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.29it/s, loss=1.54e-07, v_num=23, train_loss=8.52e-6, test_loss=9.07e-6]\u001b[A\n",
      "Epoch 1457:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.42it/s, loss=9.01e-08, v_num=23, train_loss=8.52e-6, test_loss=9.07e-6]\u001b[AAdjusting learning rate of group 0 to 2.6002e-04.\n",
      "Epoch 1457:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.19it/s, loss=8.83e-08, v_num=23, train_loss=8.52e-6, test_loss=9.07e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1457:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.96it/s, loss=8.83e-08, v_num=23, train_loss=8.52e-6, test_loss=9.07e-6]\u001b[A\n",
      "Epoch 1457: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.81it/s, loss=8.83e-08, v_num=23, train_loss=8.85e-6, test_loss=9.5e-6]\u001b[A\n",
      "Epoch 1458:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.67it/s, loss=8.63e-08, v_num=23, train_loss=8.85e-6, test_loss=9.5e-6]\u001b[AAdjusting learning rate of group 0 to 2.5937e-04.\n",
      "Epoch 1458:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.55it/s, loss=8.29e-08, v_num=23, train_loss=8.85e-6, test_loss=9.5e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1458:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.34it/s, loss=8.29e-08, v_num=23, train_loss=8.85e-6, test_loss=9.5e-6]\u001b[A\n",
      "Epoch 1458: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.54it/s, loss=8.29e-08, v_num=23, train_loss=7.57e-6, test_loss=8.36e-6]\u001b[A\n",
      "Epoch 1459:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.99it/s, loss=7.61e-08, v_num=23, train_loss=7.57e-6, test_loss=8.36e-6]\u001b[AAdjusting learning rate of group 0 to 2.5873e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1459:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.05it/s, loss=7.28e-08, v_num=23, train_loss=7.57e-6, test_loss=8.36e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1459:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.62it/s, loss=7.28e-08, v_num=23, train_loss=7.57e-6, test_loss=8.36e-6]\u001b[A\n",
      "Epoch 1459: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.68it/s, loss=7.28e-08, v_num=23, train_loss=8.47e-6, test_loss=9.04e-6]\u001b[A\n",
      "Epoch 1460:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.05it/s, loss=1.66e-07, v_num=23, train_loss=8.47e-6, test_loss=9.04e-6]\u001b[AAdjusting learning rate of group 0 to 2.5808e-04.\n",
      "Epoch 1460:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.87it/s, loss=8.46e-08, v_num=23, train_loss=8.47e-6, test_loss=9.04e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1460:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.93it/s, loss=8.46e-08, v_num=23, train_loss=8.47e-6, test_loss=9.04e-6]\u001b[A\n",
      "Epoch 1460: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.53it/s, loss=8.46e-08, v_num=23, train_loss=9.02e-6, test_loss=9.81e-6]\u001b[A\n",
      "Epoch 1461:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.71it/s, loss=7.57e-08, v_num=23, train_loss=9.02e-6, test_loss=9.81e-6]\u001b[AAdjusting learning rate of group 0 to 2.5743e-04.\n",
      "Epoch 1461:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.46it/s, loss=7.18e-08, v_num=23, train_loss=9.02e-6, test_loss=9.81e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1461:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.69it/s, loss=7.18e-08, v_num=23, train_loss=9.02e-6, test_loss=9.81e-6]\u001b[A\n",
      "Epoch 1461: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.15it/s, loss=7.18e-08, v_num=23, train_loss=7.58e-6, test_loss=8.28e-6]\u001b[A\n",
      "Epoch 1462:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.29it/s, loss=7.58e-08, v_num=23, train_loss=7.58e-6, test_loss=8.28e-6]\u001b[AAdjusting learning rate of group 0 to 2.5679e-04.\n",
      "Epoch 1462:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.77it/s, loss=7.2e-08, v_num=23, train_loss=7.58e-6, test_loss=8.28e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1462:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.44it/s, loss=7.2e-08, v_num=23, train_loss=7.58e-6, test_loss=8.28e-6]\u001b[A\n",
      "Epoch 1462: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.44it/s, loss=7.2e-08, v_num=23, train_loss=7.43e-6, test_loss=8.08e-6]\u001b[A\n",
      "Epoch 1463:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.10it/s, loss=8.36e-08, v_num=23, train_loss=7.43e-6, test_loss=8.08e-6]\u001b[AAdjusting learning rate of group 0 to 2.5615e-04.\n",
      "Epoch 1463:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.97it/s, loss=7.61e-08, v_num=23, train_loss=7.43e-6, test_loss=8.08e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1463:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.10it/s, loss=7.61e-08, v_num=23, train_loss=7.43e-6, test_loss=8.08e-6]\u001b[A\n",
      "Epoch 1463: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.42it/s, loss=7.61e-08, v_num=23, train_loss=8.42e-6, test_loss=9.08e-6]\u001b[A\n",
      "Epoch 1464:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.03it/s, loss=8.01e-08, v_num=23, train_loss=8.42e-6, test_loss=9.08e-6]\u001b[AAdjusting learning rate of group 0 to 2.5551e-04.\n",
      "Epoch 1464:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.23it/s, loss=7.36e-08, v_num=23, train_loss=8.42e-6, test_loss=9.08e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1464:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.99it/s, loss=7.36e-08, v_num=23, train_loss=8.42e-6, test_loss=9.08e-6]\u001b[A\n",
      "Epoch 1464: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.27it/s, loss=7.36e-08, v_num=23, train_loss=7.55e-6, test_loss=8.29e-6]\u001b[A\n",
      "Epoch 1465:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.51it/s, loss=7.77e-08, v_num=23, train_loss=7.55e-6, test_loss=8.29e-6]\u001b[AAdjusting learning rate of group 0 to 2.5487e-04.\n",
      "Epoch 1465:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.63it/s, loss=7.49e-08, v_num=23, train_loss=7.55e-6, test_loss=8.29e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1465:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.48it/s, loss=7.49e-08, v_num=23, train_loss=7.55e-6, test_loss=8.29e-6]\u001b[A\n",
      "Epoch 1465: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.00it/s, loss=7.49e-08, v_num=23, train_loss=7.53e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1466:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.70it/s, loss=8.24e-08, v_num=23, train_loss=7.53e-6, test_loss=8.17e-6]\u001b[AAdjusting learning rate of group 0 to 2.5423e-04.\n",
      "Epoch 1466:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.36it/s, loss=7.94e-08, v_num=23, train_loss=7.53e-6, test_loss=8.17e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1466:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.80it/s, loss=7.94e-08, v_num=23, train_loss=7.53e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1466: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.77it/s, loss=7.94e-08, v_num=23, train_loss=8.33e-6, test_loss=8.98e-6]\u001b[A\n",
      "Epoch 1467:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.58it/s, loss=7.83e-08, v_num=23, train_loss=8.33e-6, test_loss=8.98e-6]\u001b[AAdjusting learning rate of group 0 to 2.5360e-04.\n",
      "Epoch 1467:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.50it/s, loss=7.49e-08, v_num=23, train_loss=8.33e-6, test_loss=8.98e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1467:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.89it/s, loss=7.49e-08, v_num=23, train_loss=8.33e-6, test_loss=8.98e-6]\u001b[A\n",
      "Epoch 1467: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.64it/s, loss=7.49e-08, v_num=23, train_loss=9.92e-6, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1468:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.85it/s, loss=8.46e-08, v_num=23, train_loss=9.92e-6, test_loss=1.06e-5]\u001b[AAdjusting learning rate of group 0 to 2.5296e-04.\n",
      "Epoch 1468:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.67it/s, loss=7.58e-08, v_num=23, train_loss=9.92e-6, test_loss=1.06e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1468:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.22it/s, loss=7.58e-08, v_num=23, train_loss=9.92e-6, test_loss=1.06e-5]\u001b[A\n",
      "Epoch 1468: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 165.99it/s, loss=7.58e-08, v_num=23, train_loss=8e-6, test_loss=8.62e-6]\u001b[A\n",
      "Epoch 1469:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 148.61it/s, loss=8.7e-08, v_num=23, train_loss=8e-6, test_loss=8.62e-6]\u001b[AAdjusting learning rate of group 0 to 2.5233e-04.\n",
      "Epoch 1469:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 140.72it/s, loss=8.29e-08, v_num=23, train_loss=8e-6, test_loss=8.62e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1469:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 132.43it/s, loss=8.29e-08, v_num=23, train_loss=8e-6, test_loss=8.62e-6]\u001b[A\n",
      "Epoch 1469: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.03it/s, loss=8.29e-08, v_num=23, train_loss=8.64e-6, test_loss=9.3e-6]\u001b[A\n",
      "Epoch 1470:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.70it/s, loss=7.33e-08, v_num=23, train_loss=8.64e-6, test_loss=9.3e-6]\u001b[AAdjusting learning rate of group 0 to 2.5170e-04.\n",
      "Epoch 1470:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.39it/s, loss=7.03e-08, v_num=23, train_loss=8.64e-6, test_loss=9.3e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1470:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.63it/s, loss=7.03e-08, v_num=23, train_loss=8.64e-6, test_loss=9.3e-6]\u001b[A\n",
      "Epoch 1470: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.01it/s, loss=7.03e-08, v_num=23, train_loss=7.77e-6, test_loss=8.48e-6]\u001b[A\n",
      "Epoch 1471:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.37it/s, loss=8.17e-08, v_num=23, train_loss=7.77e-6, test_loss=8.48e-6]\u001b[AAdjusting learning rate of group 0 to 2.5107e-04.\n",
      "Epoch 1471:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.01it/s, loss=7.58e-08, v_num=23, train_loss=7.77e-6, test_loss=8.48e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1471:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.18it/s, loss=7.58e-08, v_num=23, train_loss=7.77e-6, test_loss=8.48e-6]\u001b[A\n",
      "Epoch 1471: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 163.97it/s, loss=7.58e-08, v_num=23, train_loss=8.47e-6, test_loss=9.12e-6]\u001b[A\n",
      "Epoch 1472:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.21it/s, loss=7.76e-08, v_num=23, train_loss=8.47e-6, test_loss=9.12e-6]\u001b[AAdjusting learning rate of group 0 to 2.5044e-04.\n",
      "Epoch 1472:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.56it/s, loss=7.55e-08, v_num=23, train_loss=8.47e-6, test_loss=9.12e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1472:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.82it/s, loss=7.55e-08, v_num=23, train_loss=8.47e-6, test_loss=9.12e-6]\u001b[A\n",
      "Epoch 1472: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.00it/s, loss=7.55e-08, v_num=23, train_loss=7.96e-6, test_loss=8.58e-6]\u001b[A\n",
      "Epoch 1473:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.30it/s, loss=8.26e-08, v_num=23, train_loss=7.96e-6, test_loss=8.58e-6]\u001b[AAdjusting learning rate of group 0 to 2.4982e-04.\n",
      "Epoch 1473:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.56it/s, loss=7.93e-08, v_num=23, train_loss=7.96e-6, test_loss=8.58e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1473:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.56it/s, loss=7.93e-08, v_num=23, train_loss=7.96e-6, test_loss=8.58e-6]\u001b[A\n",
      "Epoch 1473: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.79it/s, loss=7.93e-08, v_num=23, train_loss=8.7e-6, test_loss=9.28e-6]\u001b[A\n",
      "Epoch 1474:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.12it/s, loss=7.92e-08, v_num=23, train_loss=8.7e-6, test_loss=9.28e-6]\u001b[AAdjusting learning rate of group 0 to 2.4919e-04.\n",
      "Epoch 1474:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.97it/s, loss=7.51e-08, v_num=23, train_loss=8.7e-6, test_loss=9.28e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1474:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.70it/s, loss=7.51e-08, v_num=23, train_loss=8.7e-6, test_loss=9.28e-6]\u001b[A\n",
      "Epoch 1474: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.65it/s, loss=7.51e-08, v_num=23, train_loss=8.95e-6, test_loss=9.49e-6]\u001b[A\n",
      "Epoch 1475:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.32it/s, loss=9.1e-08, v_num=23, train_loss=8.95e-6, test_loss=9.49e-6]\u001b[AAdjusting learning rate of group 0 to 2.4857e-04.\n",
      "Epoch 1475:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.59it/s, loss=8.78e-08, v_num=23, train_loss=8.95e-6, test_loss=9.49e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1475:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.93it/s, loss=8.78e-08, v_num=23, train_loss=8.95e-6, test_loss=9.49e-6]\u001b[A\n",
      "Epoch 1475: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.60it/s, loss=8.78e-08, v_num=23, train_loss=8.06e-6, test_loss=8.66e-6]\u001b[A\n",
      "Epoch 1476:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.85it/s, loss=9.48e-08, v_num=23, train_loss=8.06e-6, test_loss=8.66e-6]\u001b[AAdjusting learning rate of group 0 to 2.4795e-04.\n",
      "Epoch 1476:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.66it/s, loss=6.98e-08, v_num=23, train_loss=8.06e-6, test_loss=8.66e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1476:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.33it/s, loss=6.98e-08, v_num=23, train_loss=8.06e-6, test_loss=8.66e-6]\u001b[A\n",
      "Epoch 1476: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.60it/s, loss=6.98e-08, v_num=23, train_loss=7.76e-6, test_loss=8.42e-6]\u001b[A\n",
      "Epoch 1477:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.14it/s, loss=8.31e-08, v_num=23, train_loss=7.76e-6, test_loss=8.42e-6]\u001b[AAdjusting learning rate of group 0 to 2.4733e-04.\n",
      "Epoch 1477:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.47it/s, loss=7.99e-08, v_num=23, train_loss=7.76e-6, test_loss=8.42e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1477:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.46it/s, loss=7.99e-08, v_num=23, train_loss=7.76e-6, test_loss=8.42e-6]\u001b[A\n",
      "Epoch 1477: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.92it/s, loss=7.99e-08, v_num=23, train_loss=8.64e-6, test_loss=9.28e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1478:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.72it/s, loss=7.6e-08, v_num=23, train_loss=8.64e-6, test_loss=9.28e-6]\u001b[AAdjusting learning rate of group 0 to 2.4671e-04.\n",
      "Epoch 1478:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.00it/s, loss=7.11e-08, v_num=23, train_loss=8.64e-6, test_loss=9.28e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1478:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.64it/s, loss=7.11e-08, v_num=23, train_loss=8.64e-6, test_loss=9.28e-6]\u001b[A\n",
      "Epoch 1478: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.45it/s, loss=7.11e-08, v_num=23, train_loss=7.89e-6, test_loss=8.58e-6]\u001b[A\n",
      "Epoch 1479:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.77it/s, loss=7.28e-08, v_num=23, train_loss=7.89e-6, test_loss=8.58e-6]\u001b[AAdjusting learning rate of group 0 to 2.4609e-04.\n",
      "Epoch 1479:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.39it/s, loss=7.02e-08, v_num=23, train_loss=7.89e-6, test_loss=8.58e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1479:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.21it/s, loss=7.02e-08, v_num=23, train_loss=7.89e-6, test_loss=8.58e-6]\u001b[A\n",
      "Epoch 1479: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.28it/s, loss=7.02e-08, v_num=23, train_loss=8.69e-6, test_loss=9.29e-6]\u001b[A\n",
      "Epoch 1480:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.08it/s, loss=8.52e-08, v_num=23, train_loss=8.69e-6, test_loss=9.29e-6]\u001b[AAdjusting learning rate of group 0 to 2.4548e-04.\n",
      "Epoch 1480:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.24it/s, loss=8.08e-08, v_num=23, train_loss=8.69e-6, test_loss=9.29e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1480:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.07it/s, loss=8.08e-08, v_num=23, train_loss=8.69e-6, test_loss=9.29e-6]\u001b[A\n",
      "Epoch 1480: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.70it/s, loss=8.08e-08, v_num=23, train_loss=7.97e-6, test_loss=8.7e-6]\u001b[A\n",
      "Epoch 1481:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.29it/s, loss=7.78e-08, v_num=23, train_loss=7.97e-6, test_loss=8.7e-6]\u001b[AAdjusting learning rate of group 0 to 2.4486e-04.\n",
      "Epoch 1481:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.30it/s, loss=7.29e-08, v_num=23, train_loss=7.97e-6, test_loss=8.7e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1481:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.58it/s, loss=7.29e-08, v_num=23, train_loss=7.97e-6, test_loss=8.7e-6]\u001b[A\n",
      "Epoch 1481: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.20it/s, loss=7.29e-08, v_num=23, train_loss=7.86e-6, test_loss=8.63e-6]\u001b[A\n",
      "Epoch 1482:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.22it/s, loss=7.54e-08, v_num=23, train_loss=7.86e-6, test_loss=8.63e-6]\u001b[AAdjusting learning rate of group 0 to 2.4425e-04.\n",
      "Epoch 1482:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.07it/s, loss=7.13e-08, v_num=23, train_loss=7.86e-6, test_loss=8.63e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1482:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.84it/s, loss=7.13e-08, v_num=23, train_loss=7.86e-6, test_loss=8.63e-6]\u001b[A\n",
      "Epoch 1482: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.96it/s, loss=7.13e-08, v_num=23, train_loss=7.47e-6, test_loss=8.1e-6]\u001b[A\n",
      "Epoch 1483:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.00it/s, loss=8.19e-08, v_num=23, train_loss=7.47e-6, test_loss=8.1e-6]\u001b[AAdjusting learning rate of group 0 to 2.4364e-04.\n",
      "Epoch 1483:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.88it/s, loss=7.9e-08, v_num=23, train_loss=7.47e-6, test_loss=8.1e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1483:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.02it/s, loss=7.9e-08, v_num=23, train_loss=7.47e-6, test_loss=8.1e-6]\u001b[A\n",
      "Epoch 1483: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.32it/s, loss=7.9e-08, v_num=23, train_loss=8.41e-6, test_loss=8.97e-6]\u001b[A\n",
      "Epoch 1484:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.79it/s, loss=7.95e-08, v_num=23, train_loss=8.41e-6, test_loss=8.97e-6]\u001b[AAdjusting learning rate of group 0 to 2.4303e-04.\n",
      "Epoch 1484:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.82it/s, loss=7.65e-08, v_num=23, train_loss=8.41e-6, test_loss=8.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1484:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.68it/s, loss=7.65e-08, v_num=23, train_loss=8.41e-6, test_loss=8.97e-6]\u001b[A\n",
      "Epoch 1484: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.69it/s, loss=7.65e-08, v_num=23, train_loss=8.7e-6, test_loss=9.3e-6]\u001b[A\n",
      "Epoch 1485:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.57it/s, loss=9.34e-08, v_num=23, train_loss=8.7e-6, test_loss=9.3e-6]\u001b[AAdjusting learning rate of group 0 to 2.4242e-04.\n",
      "Epoch 1485:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.03it/s, loss=9.11e-08, v_num=23, train_loss=8.7e-6, test_loss=9.3e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1485:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.19it/s, loss=9.11e-08, v_num=23, train_loss=8.7e-6, test_loss=9.3e-6]\u001b[A\n",
      "Epoch 1485: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.74it/s, loss=9.11e-08, v_num=23, train_loss=9.19e-6, test_loss=9.95e-6]\u001b[A\n",
      "Epoch 1486:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.31it/s, loss=8.51e-08, v_num=23, train_loss=9.19e-6, test_loss=9.95e-6]\u001b[AAdjusting learning rate of group 0 to 2.4182e-04.\n",
      "Epoch 1486:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.04it/s, loss=7.52e-08, v_num=23, train_loss=9.19e-6, test_loss=9.95e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1486:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.65it/s, loss=7.52e-08, v_num=23, train_loss=9.19e-6, test_loss=9.95e-6]\u001b[A\n",
      "Epoch 1486: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.42it/s, loss=7.52e-08, v_num=23, train_loss=8.36e-6, test_loss=8.97e-6]\u001b[A\n",
      "Epoch 1487:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.15it/s, loss=8.08e-08, v_num=23, train_loss=8.36e-6, test_loss=8.97e-6]\u001b[AAdjusting learning rate of group 0 to 2.4121e-04.\n",
      "Epoch 1487:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.96it/s, loss=7.64e-08, v_num=23, train_loss=8.36e-6, test_loss=8.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1487:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.90it/s, loss=7.64e-08, v_num=23, train_loss=8.36e-6, test_loss=8.97e-6]\u001b[A\n",
      "Epoch 1487: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.32it/s, loss=7.64e-08, v_num=23, train_loss=7.89e-6, test_loss=8.5e-6]\u001b[A\n",
      "Epoch 1488:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.95it/s, loss=1.08e-07, v_num=23, train_loss=7.89e-6, test_loss=8.5e-6]\u001b[AAdjusting learning rate of group 0 to 2.4061e-04.\n",
      "Epoch 1488:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.05it/s, loss=1.05e-07, v_num=23, train_loss=7.89e-6, test_loss=8.5e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1488:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.22it/s, loss=1.05e-07, v_num=23, train_loss=7.89e-6, test_loss=8.5e-6]\u001b[A\n",
      "Epoch 1488: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.96it/s, loss=1.05e-07, v_num=23, train_loss=9.34e-6, test_loss=9.73e-6]\u001b[A\n",
      "Epoch 1489:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.53it/s, loss=7.79e-08, v_num=23, train_loss=9.34e-6, test_loss=9.73e-6]\u001b[AAdjusting learning rate of group 0 to 2.4001e-04.\n",
      "Epoch 1489:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.73it/s, loss=7.53e-08, v_num=23, train_loss=9.34e-6, test_loss=9.73e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1489:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.18it/s, loss=7.53e-08, v_num=23, train_loss=9.34e-6, test_loss=9.73e-6]\u001b[A\n",
      "Epoch 1489: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.34it/s, loss=7.53e-08, v_num=23, train_loss=9.07e-6, test_loss=9.64e-6]\u001b[A\n",
      "Epoch 1490:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.28it/s, loss=7.24e-08, v_num=23, train_loss=9.07e-6, test_loss=9.64e-6]\u001b[AAdjusting learning rate of group 0 to 2.3941e-04.\n",
      "Epoch 1490:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.36it/s, loss=6.95e-08, v_num=23, train_loss=9.07e-6, test_loss=9.64e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1490:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.88it/s, loss=6.95e-08, v_num=23, train_loss=9.07e-6, test_loss=9.64e-6]\u001b[A\n",
      "Epoch 1490: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.72it/s, loss=6.95e-08, v_num=23, train_loss=8.58e-6, test_loss=9.13e-6]\u001b[A\n",
      "Epoch 1491:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.75it/s, loss=7.51e-08, v_num=23, train_loss=8.58e-6, test_loss=9.13e-6]\u001b[AAdjusting learning rate of group 0 to 2.3881e-04.\n",
      "Epoch 1491:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.67it/s, loss=7.14e-08, v_num=23, train_loss=8.58e-6, test_loss=9.13e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1491:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.21it/s, loss=7.14e-08, v_num=23, train_loss=8.58e-6, test_loss=9.13e-6]\u001b[A\n",
      "Epoch 1491: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.78it/s, loss=7.14e-08, v_num=23, train_loss=8.3e-6, test_loss=9.06e-6]\u001b[A\n",
      "Epoch 1492:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.37it/s, loss=7.45e-08, v_num=23, train_loss=8.3e-6, test_loss=9.06e-6]\u001b[AAdjusting learning rate of group 0 to 2.3821e-04.\n",
      "Epoch 1492:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.09it/s, loss=7.19e-08, v_num=23, train_loss=8.3e-6, test_loss=9.06e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1492:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.71it/s, loss=7.19e-08, v_num=23, train_loss=8.3e-6, test_loss=9.06e-6]\u001b[A\n",
      "Epoch 1492: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.69it/s, loss=7.19e-08, v_num=23, train_loss=7.82e-6, test_loss=8.49e-6]\u001b[A\n",
      "Epoch 1493:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.81it/s, loss=7.79e-08, v_num=23, train_loss=7.82e-6, test_loss=8.49e-6]\u001b[AAdjusting learning rate of group 0 to 2.3762e-04.\n",
      "Epoch 1493:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.43it/s, loss=7.46e-08, v_num=23, train_loss=7.82e-6, test_loss=8.49e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1493:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.95it/s, loss=7.46e-08, v_num=23, train_loss=7.82e-6, test_loss=8.49e-6]\u001b[A\n",
      "Epoch 1493: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.70it/s, loss=7.46e-08, v_num=23, train_loss=7.96e-6, test_loss=8.64e-6]\u001b[A\n",
      "Epoch 1494:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.67it/s, loss=7.84e-08, v_num=23, train_loss=7.96e-6, test_loss=8.64e-6]\u001b[AAdjusting learning rate of group 0 to 2.3702e-04.\n",
      "Epoch 1494:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.40it/s, loss=7.41e-08, v_num=23, train_loss=7.96e-6, test_loss=8.64e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1494:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.43it/s, loss=7.41e-08, v_num=23, train_loss=7.96e-6, test_loss=8.64e-6]\u001b[A\n",
      "Epoch 1494: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.03it/s, loss=7.41e-08, v_num=23, train_loss=7.97e-6, test_loss=8.56e-6]\u001b[A\n",
      "Epoch 1495:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.51it/s, loss=7.54e-08, v_num=23, train_loss=7.97e-6, test_loss=8.56e-6]\u001b[AAdjusting learning rate of group 0 to 2.3643e-04.\n",
      "Epoch 1495:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.34it/s, loss=7.19e-08, v_num=23, train_loss=7.97e-6, test_loss=8.56e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1495:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 135.68it/s, loss=7.19e-08, v_num=23, train_loss=7.97e-6, test_loss=8.56e-6]\u001b[A\n",
      "Epoch 1495: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.69it/s, loss=7.19e-08, v_num=23, train_loss=7.75e-6, test_loss=8.43e-6]\u001b[A\n",
      "Epoch 1496:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.82it/s, loss=7.79e-08, v_num=23, train_loss=7.75e-6, test_loss=8.43e-6]\u001b[AAdjusting learning rate of group 0 to 2.3584e-04.\n",
      "Epoch 1496:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.77it/s, loss=7.45e-08, v_num=23, train_loss=7.75e-6, test_loss=8.43e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1496:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.67it/s, loss=7.45e-08, v_num=23, train_loss=7.75e-6, test_loss=8.43e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1496: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.09it/s, loss=7.45e-08, v_num=23, train_loss=7.24e-6, test_loss=7.88e-6]\u001b[A\n",
      "Epoch 1497:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.00it/s, loss=7.79e-08, v_num=23, train_loss=7.24e-6, test_loss=7.88e-6]\u001b[AAdjusting learning rate of group 0 to 2.3525e-04.\n",
      "Epoch 1497:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.51it/s, loss=7.49e-08, v_num=23, train_loss=7.24e-6, test_loss=7.88e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1497:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.08it/s, loss=7.49e-08, v_num=23, train_loss=7.24e-6, test_loss=7.88e-6]\u001b[A\n",
      "Epoch 1497: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.72it/s, loss=7.49e-08, v_num=23, train_loss=7.76e-6, test_loss=8.31e-6]\u001b[A\n",
      "Epoch 1498:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.12it/s, loss=8.86e-08, v_num=23, train_loss=7.76e-6, test_loss=8.31e-6]\u001b[AAdjusting learning rate of group 0 to 2.3466e-04.\n",
      "Epoch 1498:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.28it/s, loss=8.61e-08, v_num=23, train_loss=7.76e-6, test_loss=8.31e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1498:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.49it/s, loss=8.61e-08, v_num=23, train_loss=7.76e-6, test_loss=8.31e-6]\u001b[A\n",
      "Epoch 1498: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.12it/s, loss=8.61e-08, v_num=23, train_loss=7.66e-6, test_loss=8.38e-6]\u001b[A\n",
      "Epoch 1499:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.73it/s, loss=9.73e-08, v_num=23, train_loss=7.66e-6, test_loss=8.38e-6]\u001b[AAdjusting learning rate of group 0 to 2.3408e-04.\n",
      "Epoch 1499:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.84it/s, loss=9.47e-08, v_num=23, train_loss=7.66e-6, test_loss=8.38e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1499:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.10it/s, loss=9.47e-08, v_num=23, train_loss=7.66e-6, test_loss=8.38e-6]\u001b[A\n",
      "Epoch 1499: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.66it/s, loss=9.47e-08, v_num=23, train_loss=8.95e-6, test_loss=9.53e-6]\u001b[A\n",
      "Epoch 1500:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.01it/s, loss=1.05e-07, v_num=23, train_loss=8.95e-6, test_loss=9.53e-6]\u001b[AAdjusting learning rate of group 0 to 2.3349e-04.\n",
      "Epoch 1500:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.13it/s, loss=1.03e-07, v_num=23, train_loss=8.95e-6, test_loss=9.53e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1500:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.93it/s, loss=1.03e-07, v_num=23, train_loss=8.95e-6, test_loss=9.53e-6]\u001b[A\n",
      "Epoch 1500: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.19it/s, loss=1.03e-07, v_num=23, train_loss=7.81e-6, test_loss=8.48e-6]\u001b[A\n",
      "Epoch 1501:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.22it/s, loss=8e-08, v_num=23, train_loss=7.81e-6, test_loss=8.48e-6]\u001b[AAdjusting learning rate of group 0 to 2.3291e-04.\n",
      "Epoch 1501:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.95it/s, loss=7.78e-08, v_num=23, train_loss=7.81e-6, test_loss=8.48e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1501:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.82it/s, loss=7.78e-08, v_num=23, train_loss=7.81e-6, test_loss=8.48e-6]\u001b[A\n",
      "Epoch 1501: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.33it/s, loss=7.78e-08, v_num=23, train_loss=8.57e-6, test_loss=9.16e-6]\u001b[A\n",
      "Epoch 1502:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.12it/s, loss=7.72e-08, v_num=23, train_loss=8.57e-6, test_loss=9.16e-6]\u001b[AAdjusting learning rate of group 0 to 2.3232e-04.\n",
      "Epoch 1502:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.12it/s, loss=7.23e-08, v_num=23, train_loss=8.57e-6, test_loss=9.16e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1502:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.47it/s, loss=7.23e-08, v_num=23, train_loss=8.57e-6, test_loss=9.16e-6]\u001b[A\n",
      "Epoch 1502: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.52it/s, loss=7.23e-08, v_num=23, train_loss=7.23e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1503:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.82it/s, loss=7.79e-08, v_num=23, train_loss=7.23e-6, test_loss=7.97e-6]\u001b[AAdjusting learning rate of group 0 to 2.3174e-04.\n",
      "Epoch 1503:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.21it/s, loss=7.5e-08, v_num=23, train_loss=7.23e-6, test_loss=7.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1503:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.49it/s, loss=7.5e-08, v_num=23, train_loss=7.23e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1503: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.53it/s, loss=7.5e-08, v_num=23, train_loss=7.66e-6, test_loss=8.4e-6]\u001b[A\n",
      "Epoch 1504:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.56it/s, loss=7.18e-08, v_num=23, train_loss=7.66e-6, test_loss=8.4e-6]\u001b[AAdjusting learning rate of group 0 to 2.3116e-04.\n",
      "Epoch 1504:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.38it/s, loss=6.87e-08, v_num=23, train_loss=7.66e-6, test_loss=8.4e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1504:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.67it/s, loss=6.87e-08, v_num=23, train_loss=7.66e-6, test_loss=8.4e-6]\u001b[A\n",
      "Epoch 1504: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.33it/s, loss=6.87e-08, v_num=23, train_loss=7.42e-6, test_loss=8.11e-6]\u001b[A\n",
      "Epoch 1505:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.52it/s, loss=8.01e-08, v_num=23, train_loss=7.42e-6, test_loss=8.11e-6]\u001b[AAdjusting learning rate of group 0 to 2.3059e-04.\n",
      "Epoch 1505:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.87it/s, loss=7.79e-08, v_num=23, train_loss=7.42e-6, test_loss=8.11e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1505:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.00it/s, loss=7.79e-08, v_num=23, train_loss=7.42e-6, test_loss=8.11e-6]\u001b[A\n",
      "Epoch 1505: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.24it/s, loss=7.79e-08, v_num=23, train_loss=7.29e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1506:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.09it/s, loss=7.49e-08, v_num=23, train_loss=7.29e-6, test_loss=7.97e-6]\u001b[AAdjusting learning rate of group 0 to 2.3001e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1506:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.77it/s, loss=7.26e-08, v_num=23, train_loss=7.29e-6, test_loss=7.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1506:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.50it/s, loss=7.26e-08, v_num=23, train_loss=7.29e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1506: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.10it/s, loss=7.26e-08, v_num=23, train_loss=7.62e-6, test_loss=8.24e-6]\u001b[A\n",
      "Epoch 1507:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.80it/s, loss=7.6e-08, v_num=23, train_loss=7.62e-6, test_loss=8.24e-6]\u001b[AAdjusting learning rate of group 0 to 2.2944e-04.\n",
      "Epoch 1507:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.00it/s, loss=7.25e-08, v_num=23, train_loss=7.62e-6, test_loss=8.24e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1507:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.57it/s, loss=7.25e-08, v_num=23, train_loss=7.62e-6, test_loss=8.24e-6]\u001b[A\n",
      "Epoch 1507: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.06it/s, loss=7.25e-08, v_num=23, train_loss=7.92e-6, test_loss=8.53e-6]\u001b[A\n",
      "Epoch 1508:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.57it/s, loss=7.17e-08, v_num=23, train_loss=7.92e-6, test_loss=8.53e-6]\u001b[AAdjusting learning rate of group 0 to 2.2886e-04.\n",
      "Epoch 1508:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.44it/s, loss=6.86e-08, v_num=23, train_loss=7.92e-6, test_loss=8.53e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1508:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.39it/s, loss=6.86e-08, v_num=23, train_loss=7.92e-6, test_loss=8.53e-6]\u001b[A\n",
      "Epoch 1508: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.30it/s, loss=6.86e-08, v_num=23, train_loss=7.89e-6, test_loss=8.55e-6]\u001b[A\n",
      "Epoch 1509:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.46it/s, loss=7.48e-08, v_num=23, train_loss=7.89e-6, test_loss=8.55e-6]\u001b[AAdjusting learning rate of group 0 to 2.2829e-04.\n",
      "Epoch 1509:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.93it/s, loss=6.83e-08, v_num=23, train_loss=7.89e-6, test_loss=8.55e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1509:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.84it/s, loss=6.83e-08, v_num=23, train_loss=7.89e-6, test_loss=8.55e-6]\u001b[A\n",
      "Epoch 1509: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.54it/s, loss=6.83e-08, v_num=23, train_loss=7.09e-6, test_loss=7.72e-6]\u001b[A\n",
      "Epoch 1510:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.97it/s, loss=8.51e-08, v_num=23, train_loss=7.09e-6, test_loss=7.72e-6]\u001b[AAdjusting learning rate of group 0 to 2.2772e-04.\n",
      "Epoch 1510:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.50it/s, loss=7.96e-08, v_num=23, train_loss=7.09e-6, test_loss=7.72e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1510:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.16it/s, loss=7.96e-08, v_num=23, train_loss=7.09e-6, test_loss=7.72e-6]\u001b[A\n",
      "Epoch 1510: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.22it/s, loss=7.96e-08, v_num=23, train_loss=7.77e-6, test_loss=8.41e-6]\u001b[A\n",
      "Epoch 1511:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.09it/s, loss=7.63e-08, v_num=23, train_loss=7.77e-6, test_loss=8.41e-6]\u001b[AAdjusting learning rate of group 0 to 2.2715e-04.\n",
      "Epoch 1511:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.88it/s, loss=7.28e-08, v_num=23, train_loss=7.77e-6, test_loss=8.41e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1511:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.77it/s, loss=7.28e-08, v_num=23, train_loss=7.77e-6, test_loss=8.41e-6]\u001b[A\n",
      "Epoch 1511: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.17it/s, loss=7.28e-08, v_num=23, train_loss=7.65e-6, test_loss=8.26e-6]\u001b[A\n",
      "Epoch 1512:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.02it/s, loss=8.22e-08, v_num=23, train_loss=7.65e-6, test_loss=8.26e-6]\u001b[AAdjusting learning rate of group 0 to 2.2658e-04.\n",
      "Epoch 1512:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.78it/s, loss=7.81e-08, v_num=23, train_loss=7.65e-6, test_loss=8.26e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1512:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.78it/s, loss=7.81e-08, v_num=23, train_loss=7.65e-6, test_loss=8.26e-6]\u001b[A\n",
      "Epoch 1512: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.52it/s, loss=7.81e-08, v_num=23, train_loss=8.89e-6, test_loss=9.5e-6]\u001b[A\n",
      "Epoch 1513:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.89it/s, loss=7.1e-08, v_num=23, train_loss=8.89e-6, test_loss=9.5e-6]\u001b[AAdjusting learning rate of group 0 to 2.2601e-04.\n",
      "Epoch 1513:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.76it/s, loss=6.75e-08, v_num=23, train_loss=8.89e-6, test_loss=9.5e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1513:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.03it/s, loss=6.75e-08, v_num=23, train_loss=8.89e-6, test_loss=9.5e-6]\u001b[A\n",
      "Epoch 1513: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.96it/s, loss=6.75e-08, v_num=23, train_loss=7.67e-6, test_loss=8.31e-6]\u001b[A\n",
      "Epoch 1514:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.02it/s, loss=8.56e-08, v_num=23, train_loss=7.67e-6, test_loss=8.31e-6]\u001b[AAdjusting learning rate of group 0 to 2.2545e-04.\n",
      "Epoch 1514:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.68it/s, loss=8.25e-08, v_num=23, train_loss=7.67e-6, test_loss=8.31e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1514:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 135.51it/s, loss=8.25e-08, v_num=23, train_loss=7.67e-6, test_loss=8.31e-6]\u001b[A\n",
      "Epoch 1514: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.40it/s, loss=8.25e-08, v_num=23, train_loss=9.12e-6, test_loss=9.74e-6]\u001b[A\n",
      "Epoch 1515:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.90it/s, loss=8.43e-08, v_num=23, train_loss=9.12e-6, test_loss=9.74e-6]\u001b[AAdjusting learning rate of group 0 to 2.2489e-04.\n",
      "Epoch 1515:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.18it/s, loss=8.19e-08, v_num=23, train_loss=9.12e-6, test_loss=9.74e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1515:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.47it/s, loss=8.19e-08, v_num=23, train_loss=9.12e-6, test_loss=9.74e-6]\u001b[A\n",
      "Epoch 1515: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.68it/s, loss=8.19e-08, v_num=23, train_loss=7.91e-6, test_loss=8.63e-6]\u001b[A\n",
      "Epoch 1516:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.21it/s, loss=8.96e-08, v_num=23, train_loss=7.91e-6, test_loss=8.63e-6]\u001b[AAdjusting learning rate of group 0 to 2.2432e-04.\n",
      "Epoch 1516:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.88it/s, loss=8.65e-08, v_num=23, train_loss=7.91e-6, test_loss=8.63e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1516:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.18it/s, loss=8.65e-08, v_num=23, train_loss=7.91e-6, test_loss=8.63e-6]\u001b[A\n",
      "Epoch 1516: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.91it/s, loss=8.65e-08, v_num=23, train_loss=7.88e-6, test_loss=8.56e-6]\u001b[A\n",
      "Epoch 1517:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.58it/s, loss=8.26e-08, v_num=23, train_loss=7.88e-6, test_loss=8.56e-6]\u001b[AAdjusting learning rate of group 0 to 2.2376e-04.\n",
      "Epoch 1517:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.33it/s, loss=8.02e-08, v_num=23, train_loss=7.88e-6, test_loss=8.56e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1517:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.05it/s, loss=8.02e-08, v_num=23, train_loss=7.88e-6, test_loss=8.56e-6]\u001b[A\n",
      "Epoch 1517: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.64it/s, loss=8.02e-08, v_num=23, train_loss=7.94e-6, test_loss=8.58e-6]\u001b[A\n",
      "Epoch 1518:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.20it/s, loss=8.14e-08, v_num=23, train_loss=7.94e-6, test_loss=8.58e-6]\u001b[AAdjusting learning rate of group 0 to 2.2320e-04.\n",
      "Epoch 1518:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.09it/s, loss=7.86e-08, v_num=23, train_loss=7.94e-6, test_loss=8.58e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1518:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.62it/s, loss=7.86e-08, v_num=23, train_loss=7.94e-6, test_loss=8.58e-6]\u001b[A\n",
      "Epoch 1518: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.26it/s, loss=7.86e-08, v_num=23, train_loss=8.4e-6, test_loss=9.05e-6]\u001b[A\n",
      "Epoch 1519:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.80it/s, loss=8.44e-08, v_num=23, train_loss=8.4e-6, test_loss=9.05e-6]\u001b[AAdjusting learning rate of group 0 to 2.2265e-04.\n",
      "Epoch 1519:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.67it/s, loss=7.66e-08, v_num=23, train_loss=8.4e-6, test_loss=9.05e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1519:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.36it/s, loss=7.66e-08, v_num=23, train_loss=8.4e-6, test_loss=9.05e-6]\u001b[A\n",
      "Epoch 1519: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 172.71it/s, loss=7.66e-08, v_num=23, train_loss=7.65e-6, test_loss=8.38e-6]\u001b[A\n",
      "Epoch 1520:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.97it/s, loss=7.66e-08, v_num=23, train_loss=7.65e-6, test_loss=8.38e-6]\u001b[AAdjusting learning rate of group 0 to 2.2209e-04.\n",
      "Epoch 1520:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.01it/s, loss=7.35e-08, v_num=23, train_loss=7.65e-6, test_loss=8.38e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1520:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.75it/s, loss=7.35e-08, v_num=23, train_loss=7.65e-6, test_loss=8.38e-6]\u001b[A\n",
      "Epoch 1520: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.10it/s, loss=7.35e-08, v_num=23, train_loss=7.4e-6, test_loss=8.13e-6]\u001b[A\n",
      "Epoch 1521:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.34it/s, loss=9.64e-08, v_num=23, train_loss=7.4e-6, test_loss=8.13e-6]\u001b[AAdjusting learning rate of group 0 to 2.2153e-04.\n",
      "Epoch 1521:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.62it/s, loss=9.27e-08, v_num=23, train_loss=7.4e-6, test_loss=8.13e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1521:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.10it/s, loss=9.27e-08, v_num=23, train_loss=7.4e-6, test_loss=8.13e-6]\u001b[A\n",
      "Epoch 1521: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 173.00it/s, loss=9.27e-08, v_num=23, train_loss=7.68e-6, test_loss=8.32e-6]\u001b[A\n",
      "Epoch 1522:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.74it/s, loss=7.21e-08, v_num=23, train_loss=7.68e-6, test_loss=8.32e-6]\u001b[AAdjusting learning rate of group 0 to 2.2098e-04.\n",
      "Epoch 1522:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.76it/s, loss=6.9e-08, v_num=23, train_loss=7.68e-6, test_loss=8.32e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1522:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.67it/s, loss=6.9e-08, v_num=23, train_loss=7.68e-6, test_loss=8.32e-6]\u001b[A\n",
      "Epoch 1522: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.81it/s, loss=6.9e-08, v_num=23, train_loss=7.72e-6, test_loss=8.41e-6]\u001b[A\n",
      "Epoch 1523:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.28it/s, loss=8.18e-08, v_num=23, train_loss=7.72e-6, test_loss=8.41e-6]\u001b[AAdjusting learning rate of group 0 to 2.2043e-04.\n",
      "Epoch 1523:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.76it/s, loss=7.74e-08, v_num=23, train_loss=7.72e-6, test_loss=8.41e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1523:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.54it/s, loss=7.74e-08, v_num=23, train_loss=7.72e-6, test_loss=8.41e-6]\u001b[A\n",
      "Epoch 1523: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.05it/s, loss=7.74e-08, v_num=23, train_loss=7.47e-6, test_loss=8.09e-6]\u001b[A\n",
      "Epoch 1524:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.98it/s, loss=7.47e-08, v_num=23, train_loss=7.47e-6, test_loss=8.09e-6]\u001b[AAdjusting learning rate of group 0 to 2.1988e-04.\n",
      "Epoch 1524:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.05it/s, loss=7.06e-08, v_num=23, train_loss=7.47e-6, test_loss=8.09e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1524:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.92it/s, loss=7.06e-08, v_num=23, train_loss=7.47e-6, test_loss=8.09e-6]\u001b[A\n",
      "Epoch 1524: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 170.77it/s, loss=7.06e-08, v_num=23, train_loss=7.7e-6, test_loss=8.4e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1525:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.20it/s, loss=8.75e-08, v_num=23, train_loss=7.7e-6, test_loss=8.4e-6]\u001b[AAdjusting learning rate of group 0 to 2.1933e-04.\n",
      "Epoch 1525:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.90it/s, loss=8.46e-08, v_num=23, train_loss=7.7e-6, test_loss=8.4e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1525:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.68it/s, loss=8.46e-08, v_num=23, train_loss=7.7e-6, test_loss=8.4e-6]\u001b[A\n",
      "Epoch 1525: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.20it/s, loss=8.46e-08, v_num=23, train_loss=8.44e-6, test_loss=9.16e-6]\u001b[A\n",
      "Epoch 1526:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.20it/s, loss=7.77e-08, v_num=23, train_loss=8.44e-6, test_loss=9.16e-6]\u001b[AAdjusting learning rate of group 0 to 2.1878e-04.\n",
      "Epoch 1526:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.72it/s, loss=7.39e-08, v_num=23, train_loss=8.44e-6, test_loss=9.16e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1526:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.25it/s, loss=7.39e-08, v_num=23, train_loss=8.44e-6, test_loss=9.16e-6]\u001b[A\n",
      "Epoch 1526: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.81it/s, loss=7.39e-08, v_num=23, train_loss=8.24e-6, test_loss=9.01e-6]\u001b[A\n",
      "Epoch 1527:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.58it/s, loss=7.36e-08, v_num=23, train_loss=8.24e-6, test_loss=9.01e-6]\u001b[AAdjusting learning rate of group 0 to 2.1823e-04.\n",
      "Epoch 1527:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.51it/s, loss=6.96e-08, v_num=23, train_loss=8.24e-6, test_loss=9.01e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1527:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.13it/s, loss=6.96e-08, v_num=23, train_loss=8.24e-6, test_loss=9.01e-6]\u001b[A\n",
      "Epoch 1527: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.38it/s, loss=6.96e-08, v_num=23, train_loss=7.97e-6, test_loss=8.6e-6]\u001b[A\n",
      "Epoch 1528:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.32it/s, loss=1.42e-07, v_num=23, train_loss=7.97e-6, test_loss=8.6e-6]\u001b[AAdjusting learning rate of group 0 to 2.1769e-04.\n",
      "Epoch 1528:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.45it/s, loss=1.38e-07, v_num=23, train_loss=7.97e-6, test_loss=8.6e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1528:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.62it/s, loss=1.38e-07, v_num=23, train_loss=7.97e-6, test_loss=8.6e-6]\u001b[A\n",
      "Epoch 1528: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.54it/s, loss=1.38e-07, v_num=23, train_loss=7.86e-6, test_loss=8.52e-6]\u001b[A\n",
      "Epoch 1529:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.30it/s, loss=8.03e-08, v_num=23, train_loss=7.86e-6, test_loss=8.52e-6]\u001b[AAdjusting learning rate of group 0 to 2.1714e-04.\n",
      "Epoch 1529:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.58it/s, loss=7.68e-08, v_num=23, train_loss=7.86e-6, test_loss=8.52e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1529:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.48it/s, loss=7.68e-08, v_num=23, train_loss=7.86e-6, test_loss=8.52e-6]\u001b[A\n",
      "Epoch 1529: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.57it/s, loss=7.68e-08, v_num=23, train_loss=8.6e-6, test_loss=9.31e-6]\u001b[A\n",
      "Epoch 1530:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.10it/s, loss=7.48e-08, v_num=23, train_loss=8.6e-6, test_loss=9.31e-6]\u001b[AAdjusting learning rate of group 0 to 2.1660e-04.\n",
      "Epoch 1530:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.96it/s, loss=7.13e-08, v_num=23, train_loss=8.6e-6, test_loss=9.31e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1530:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 128.64it/s, loss=7.13e-08, v_num=23, train_loss=8.6e-6, test_loss=9.31e-6]\u001b[A\n",
      "Epoch 1530: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 163.79it/s, loss=7.13e-08, v_num=23, train_loss=7.88e-6, test_loss=8.47e-6]\u001b[A\n",
      "Epoch 1531:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.81it/s, loss=8.14e-08, v_num=23, train_loss=7.88e-6, test_loss=8.47e-6]\u001b[AAdjusting learning rate of group 0 to 2.1606e-04.\n",
      "Epoch 1531:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.72it/s, loss=7.86e-08, v_num=23, train_loss=7.88e-6, test_loss=8.47e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1531:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.12it/s, loss=7.86e-08, v_num=23, train_loss=7.88e-6, test_loss=8.47e-6]\u001b[A\n",
      "Epoch 1531: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.58it/s, loss=7.86e-08, v_num=23, train_loss=8.64e-6, test_loss=9.29e-6]\u001b[A\n",
      "Epoch 1532:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.87it/s, loss=6.82e-08, v_num=23, train_loss=8.64e-6, test_loss=9.29e-6]\u001b[AAdjusting learning rate of group 0 to 2.1552e-04.\n",
      "Epoch 1532:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.81it/s, loss=6.52e-08, v_num=23, train_loss=8.64e-6, test_loss=9.29e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1532:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.24it/s, loss=6.52e-08, v_num=23, train_loss=8.64e-6, test_loss=9.29e-6]\u001b[A\n",
      "Epoch 1532: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.67it/s, loss=6.52e-08, v_num=23, train_loss=7.93e-6, test_loss=8.58e-6]\u001b[A\n",
      "Epoch 1533:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.19it/s, loss=7.47e-08, v_num=23, train_loss=7.93e-6, test_loss=8.58e-6]\u001b[AAdjusting learning rate of group 0 to 2.1498e-04.\n",
      "Epoch 1533:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.70it/s, loss=7.07e-08, v_num=23, train_loss=7.93e-6, test_loss=8.58e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1533:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.36it/s, loss=7.07e-08, v_num=23, train_loss=7.93e-6, test_loss=8.58e-6]\u001b[A\n",
      "Epoch 1533: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 163.98it/s, loss=7.07e-08, v_num=23, train_loss=8.18e-6, test_loss=8.87e-6]\u001b[A\n",
      "Epoch 1534:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.09it/s, loss=9.57e-08, v_num=23, train_loss=8.18e-6, test_loss=8.87e-6]\u001b[AAdjusting learning rate of group 0 to 2.1444e-04.\n",
      "Epoch 1534:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.78it/s, loss=9.14e-08, v_num=23, train_loss=8.18e-6, test_loss=8.87e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1534:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.90it/s, loss=9.14e-08, v_num=23, train_loss=8.18e-6, test_loss=8.87e-6]\u001b[A\n",
      "Epoch 1534: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.84it/s, loss=9.14e-08, v_num=23, train_loss=7.93e-6, test_loss=8.59e-6]\u001b[A\n",
      "Epoch 1535:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.23it/s, loss=7.57e-08, v_num=23, train_loss=7.93e-6, test_loss=8.59e-6]\u001b[AAdjusting learning rate of group 0 to 2.1391e-04.\n",
      "Epoch 1535:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.76it/s, loss=7.42e-08, v_num=23, train_loss=7.93e-6, test_loss=8.59e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1535:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.31it/s, loss=7.42e-08, v_num=23, train_loss=7.93e-6, test_loss=8.59e-6]\u001b[A\n",
      "Epoch 1535: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.96it/s, loss=7.42e-08, v_num=23, train_loss=7.68e-6, test_loss=8.36e-6]\u001b[A\n",
      "Epoch 1536:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.25it/s, loss=7.06e-08, v_num=23, train_loss=7.68e-6, test_loss=8.36e-6]\u001b[AAdjusting learning rate of group 0 to 2.1337e-04.\n",
      "Epoch 1536:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.42it/s, loss=6.83e-08, v_num=23, train_loss=7.68e-6, test_loss=8.36e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1536:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.51it/s, loss=6.83e-08, v_num=23, train_loss=7.68e-6, test_loss=8.36e-6]\u001b[A\n",
      "Epoch 1536: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.45it/s, loss=6.83e-08, v_num=23, train_loss=8.05e-6, test_loss=8.68e-6]\u001b[A\n",
      "Epoch 1537:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.82it/s, loss=7.61e-08, v_num=23, train_loss=8.05e-6, test_loss=8.68e-6]\u001b[AAdjusting learning rate of group 0 to 2.1284e-04.\n",
      "Epoch 1537:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.22it/s, loss=7.25e-08, v_num=23, train_loss=8.05e-6, test_loss=8.68e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1537:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.69it/s, loss=7.25e-08, v_num=23, train_loss=8.05e-6, test_loss=8.68e-6]\u001b[A\n",
      "Epoch 1537: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.06it/s, loss=7.25e-08, v_num=23, train_loss=7.53e-6, test_loss=8.1e-6]\u001b[A\n",
      "Epoch 1538:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.59it/s, loss=7.08e-08, v_num=23, train_loss=7.53e-6, test_loss=8.1e-6]\u001b[AAdjusting learning rate of group 0 to 2.1230e-04.\n",
      "Epoch 1538:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.74it/s, loss=7.62e-08, v_num=23, train_loss=7.53e-6, test_loss=8.1e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1538:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.65it/s, loss=7.62e-08, v_num=23, train_loss=7.53e-6, test_loss=8.1e-6]\u001b[A\n",
      "Epoch 1538: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.54it/s, loss=7.62e-08, v_num=23, train_loss=7.75e-6, test_loss=8.43e-6]\u001b[A\n",
      "Epoch 1539:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.59it/s, loss=7.01e-08, v_num=23, train_loss=7.75e-6, test_loss=8.43e-6]\u001b[AAdjusting learning rate of group 0 to 2.1177e-04.\n",
      "Epoch 1539:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.57it/s, loss=6.67e-08, v_num=23, train_loss=7.75e-6, test_loss=8.43e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1539:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.87it/s, loss=6.67e-08, v_num=23, train_loss=7.75e-6, test_loss=8.43e-6]\u001b[A\n",
      "Epoch 1539: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 170.57it/s, loss=6.67e-08, v_num=23, train_loss=8e-6, test_loss=8.65e-6]\u001b[A\n",
      "Epoch 1540:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 149.54it/s, loss=7.57e-08, v_num=23, train_loss=8e-6, test_loss=8.65e-6]\u001b[AAdjusting learning rate of group 0 to 2.1124e-04.\n",
      "Epoch 1540:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 138.67it/s, loss=7.36e-08, v_num=23, train_loss=8e-6, test_loss=8.65e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1540:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 132.52it/s, loss=7.36e-08, v_num=23, train_loss=8e-6, test_loss=8.65e-6]\u001b[A\n",
      "Epoch 1540: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.77it/s, loss=7.36e-08, v_num=23, train_loss=7.86e-6, test_loss=8.51e-6]\u001b[A\n",
      "Epoch 1541:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.58it/s, loss=8.52e-08, v_num=23, train_loss=7.86e-6, test_loss=8.51e-6]\u001b[AAdjusting learning rate of group 0 to 2.1072e-04.\n",
      "Epoch 1541:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.57it/s, loss=8.25e-08, v_num=23, train_loss=7.86e-6, test_loss=8.51e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1541:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.99it/s, loss=8.25e-08, v_num=23, train_loss=7.86e-6, test_loss=8.51e-6]\u001b[A\n",
      "Epoch 1541: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.17it/s, loss=8.25e-08, v_num=23, train_loss=8.5e-6, test_loss=9.2e-6]\u001b[A\n",
      "Epoch 1542:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.73it/s, loss=8.31e-08, v_num=23, train_loss=8.5e-6, test_loss=9.2e-6]\u001b[AAdjusting learning rate of group 0 to 2.1019e-04.\n",
      "Epoch 1542:  50%|████████████████████                    | 79/158 [00:00<00:00, 137.10it/s, loss=7.92e-08, v_num=23, train_loss=8.5e-6, test_loss=9.2e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1542:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.51it/s, loss=7.92e-08, v_num=23, train_loss=8.5e-6, test_loss=9.2e-6]\u001b[A\n",
      "Epoch 1542: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.27it/s, loss=7.92e-08, v_num=23, train_loss=7.99e-6, test_loss=8.7e-6]\u001b[A\n",
      "Epoch 1543:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.74it/s, loss=8.31e-08, v_num=23, train_loss=7.99e-6, test_loss=8.7e-6]\u001b[AAdjusting learning rate of group 0 to 2.0966e-04.\n",
      "Epoch 1543:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.63it/s, loss=7.59e-08, v_num=23, train_loss=7.99e-6, test_loss=8.7e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1543:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.46it/s, loss=7.59e-08, v_num=23, train_loss=7.99e-6, test_loss=8.7e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1543: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.42it/s, loss=7.59e-08, v_num=23, train_loss=7.52e-6, test_loss=8.12e-6]\u001b[A\n",
      "Epoch 1544:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.16it/s, loss=8.43e-08, v_num=23, train_loss=7.52e-6, test_loss=8.12e-6]\u001b[AAdjusting learning rate of group 0 to 2.0914e-04.\n",
      "Epoch 1544:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.06it/s, loss=7.85e-08, v_num=23, train_loss=7.52e-6, test_loss=8.12e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1544:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.41it/s, loss=7.85e-08, v_num=23, train_loss=7.52e-6, test_loss=8.12e-6]\u001b[A\n",
      "Epoch 1544: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.59it/s, loss=7.85e-08, v_num=23, train_loss=7.56e-6, test_loss=8.21e-6]\u001b[A\n",
      "Epoch 1545:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.36it/s, loss=6.93e-08, v_num=23, train_loss=7.56e-6, test_loss=8.21e-6]\u001b[AAdjusting learning rate of group 0 to 2.0862e-04.\n",
      "Epoch 1545:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.13it/s, loss=6.64e-08, v_num=23, train_loss=7.56e-6, test_loss=8.21e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1545:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.29it/s, loss=6.64e-08, v_num=23, train_loss=7.56e-6, test_loss=8.21e-6]\u001b[A\n",
      "Epoch 1545: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.91it/s, loss=6.64e-08, v_num=23, train_loss=8.61e-6, test_loss=9.25e-6]\u001b[A\n",
      "Epoch 1546:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.16it/s, loss=6.99e-08, v_num=23, train_loss=8.61e-6, test_loss=9.25e-6]\u001b[AAdjusting learning rate of group 0 to 2.0810e-04.\n",
      "Epoch 1546:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.22it/s, loss=6.79e-08, v_num=23, train_loss=8.61e-6, test_loss=9.25e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1546:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.29it/s, loss=6.79e-08, v_num=23, train_loss=8.61e-6, test_loss=9.25e-6]\u001b[A\n",
      "Epoch 1546: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.27it/s, loss=6.79e-08, v_num=23, train_loss=7.73e-6, test_loss=8.36e-6]\u001b[A\n",
      "Epoch 1547:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.81it/s, loss=7.52e-08, v_num=23, train_loss=7.73e-6, test_loss=8.36e-6]\u001b[AAdjusting learning rate of group 0 to 2.0758e-04.\n",
      "Epoch 1547:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.80it/s, loss=7.31e-08, v_num=23, train_loss=7.73e-6, test_loss=8.36e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1547:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.56it/s, loss=7.31e-08, v_num=23, train_loss=7.73e-6, test_loss=8.36e-6]\u001b[A\n",
      "Epoch 1547: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.33it/s, loss=7.31e-08, v_num=23, train_loss=7.57e-6, test_loss=8.23e-6]\u001b[A\n",
      "Epoch 1548:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.24it/s, loss=7.34e-08, v_num=23, train_loss=7.57e-6, test_loss=8.23e-6]\u001b[AAdjusting learning rate of group 0 to 2.0706e-04.\n",
      "Epoch 1548:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.55it/s, loss=6.91e-08, v_num=23, train_loss=7.57e-6, test_loss=8.23e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1548:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.17it/s, loss=6.91e-08, v_num=23, train_loss=7.57e-6, test_loss=8.23e-6]\u001b[A\n",
      "Epoch 1548: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.50it/s, loss=6.91e-08, v_num=23, train_loss=8.19e-6, test_loss=8.71e-6]\u001b[A\n",
      "Epoch 1549:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.14it/s, loss=8.26e-08, v_num=23, train_loss=8.19e-6, test_loss=8.71e-6]\u001b[AAdjusting learning rate of group 0 to 2.0654e-04.\n",
      "Epoch 1549:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.01it/s, loss=7.88e-08, v_num=23, train_loss=8.19e-6, test_loss=8.71e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1549:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.20it/s, loss=7.88e-08, v_num=23, train_loss=8.19e-6, test_loss=8.71e-6]\u001b[A\n",
      "Epoch 1549: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.24it/s, loss=7.88e-08, v_num=23, train_loss=7.83e-6, test_loss=8.49e-6]\u001b[A\n",
      "Epoch 1550:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.07it/s, loss=7.6e-08, v_num=23, train_loss=7.83e-6, test_loss=8.49e-6]\u001b[AAdjusting learning rate of group 0 to 2.0602e-04.\n",
      "Epoch 1550:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.15it/s, loss=7.33e-08, v_num=23, train_loss=7.83e-6, test_loss=8.49e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1550:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.14it/s, loss=7.33e-08, v_num=23, train_loss=7.83e-6, test_loss=8.49e-6]\u001b[A\n",
      "Epoch 1550: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.17it/s, loss=7.33e-08, v_num=23, train_loss=8.27e-6, test_loss=8.85e-6]\u001b[A\n",
      "Epoch 1551:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.26it/s, loss=7.38e-08, v_num=23, train_loss=8.27e-6, test_loss=8.85e-6]\u001b[AAdjusting learning rate of group 0 to 2.0551e-04.\n",
      "Epoch 1551:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.26it/s, loss=7.07e-08, v_num=23, train_loss=8.27e-6, test_loss=8.85e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1551:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.10it/s, loss=7.07e-08, v_num=23, train_loss=8.27e-6, test_loss=8.85e-6]\u001b[A\n",
      "Epoch 1551: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.29it/s, loss=7.07e-08, v_num=23, train_loss=7.9e-6, test_loss=8.49e-6]\u001b[A\n",
      "Epoch 1552:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.52it/s, loss=7.97e-08, v_num=23, train_loss=7.9e-6, test_loss=8.49e-6]\u001b[AAdjusting learning rate of group 0 to 2.0499e-04.\n",
      "Epoch 1552:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.03it/s, loss=7.65e-08, v_num=23, train_loss=7.9e-6, test_loss=8.49e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1552:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.19it/s, loss=7.65e-08, v_num=23, train_loss=7.9e-6, test_loss=8.49e-6]\u001b[A\n",
      "Epoch 1552: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.79it/s, loss=7.65e-08, v_num=23, train_loss=7.61e-6, test_loss=8.32e-6]\u001b[A\n",
      "Epoch 1553:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.59it/s, loss=7.86e-08, v_num=23, train_loss=7.61e-6, test_loss=8.32e-6]\u001b[AAdjusting learning rate of group 0 to 2.0448e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1553:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.56it/s, loss=7.45e-08, v_num=23, train_loss=7.61e-6, test_loss=8.32e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1553:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.89it/s, loss=7.45e-08, v_num=23, train_loss=7.61e-6, test_loss=8.32e-6]\u001b[A\n",
      "Epoch 1553: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.14it/s, loss=7.45e-08, v_num=23, train_loss=7.99e-6, test_loss=8.55e-6]\u001b[A\n",
      "Epoch 1554:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.52it/s, loss=7.89e-08, v_num=23, train_loss=7.99e-6, test_loss=8.55e-6]\u001b[AAdjusting learning rate of group 0 to 2.0397e-04.\n",
      "Epoch 1554:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.85it/s, loss=7.58e-08, v_num=23, train_loss=7.99e-6, test_loss=8.55e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1554:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.01it/s, loss=7.58e-08, v_num=23, train_loss=7.99e-6, test_loss=8.55e-6]\u001b[A\n",
      "Epoch 1554: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.98it/s, loss=7.58e-08, v_num=23, train_loss=8.06e-6, test_loss=8.81e-6]\u001b[A\n",
      "Epoch 1555:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.62it/s, loss=9.32e-08, v_num=23, train_loss=8.06e-6, test_loss=8.81e-6]\u001b[AAdjusting learning rate of group 0 to 2.0346e-04.\n",
      "Epoch 1555:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.98it/s, loss=8.95e-08, v_num=23, train_loss=8.06e-6, test_loss=8.81e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1555:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.89it/s, loss=8.95e-08, v_num=23, train_loss=8.06e-6, test_loss=8.81e-6]\u001b[A\n",
      "Epoch 1555: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.82it/s, loss=8.95e-08, v_num=23, train_loss=7.58e-6, test_loss=8.24e-6]\u001b[A\n",
      "Epoch 1556:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.11it/s, loss=7.56e-08, v_num=23, train_loss=7.58e-6, test_loss=8.24e-6]\u001b[AAdjusting learning rate of group 0 to 2.0295e-04.\n",
      "Epoch 1556:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.29it/s, loss=7.32e-08, v_num=23, train_loss=7.58e-6, test_loss=8.24e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1556:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.39it/s, loss=7.32e-08, v_num=23, train_loss=7.58e-6, test_loss=8.24e-6]\u001b[A\n",
      "Epoch 1556: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.68it/s, loss=7.32e-08, v_num=23, train_loss=8.05e-6, test_loss=8.64e-6]\u001b[A\n",
      "Epoch 1557:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.28it/s, loss=8.23e-08, v_num=23, train_loss=8.05e-6, test_loss=8.64e-6]\u001b[AAdjusting learning rate of group 0 to 2.0244e-04.\n",
      "Epoch 1557:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.68it/s, loss=7.86e-08, v_num=23, train_loss=8.05e-6, test_loss=8.64e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1557:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 127.88it/s, loss=7.86e-08, v_num=23, train_loss=8.05e-6, test_loss=8.64e-6]\u001b[A\n",
      "Epoch 1557: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 163.15it/s, loss=7.86e-08, v_num=23, train_loss=7.96e-6, test_loss=8.66e-6]\u001b[A\n",
      "Epoch 1558:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.20it/s, loss=7.87e-08, v_num=23, train_loss=7.96e-6, test_loss=8.66e-6]\u001b[AAdjusting learning rate of group 0 to 2.0194e-04.\n",
      "Epoch 1558:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.56it/s, loss=7.53e-08, v_num=23, train_loss=7.96e-6, test_loss=8.66e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1558:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.02it/s, loss=7.53e-08, v_num=23, train_loss=7.96e-6, test_loss=8.66e-6]\u001b[A\n",
      "Epoch 1558: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.79it/s, loss=7.53e-08, v_num=23, train_loss=8.17e-6, test_loss=8.8e-6]\u001b[A\n",
      "Epoch 1559:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.69it/s, loss=7.01e-08, v_num=23, train_loss=8.17e-6, test_loss=8.8e-6]\u001b[AAdjusting learning rate of group 0 to 2.0143e-04.\n",
      "Epoch 1559:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.83it/s, loss=6.69e-08, v_num=23, train_loss=8.17e-6, test_loss=8.8e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1559:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.77it/s, loss=6.69e-08, v_num=23, train_loss=8.17e-6, test_loss=8.8e-6]\u001b[A\n",
      "Epoch 1559: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.97it/s, loss=6.69e-08, v_num=23, train_loss=7.81e-6, test_loss=8.49e-6]\u001b[A\n",
      "Epoch 1560:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.35it/s, loss=9.16e-08, v_num=23, train_loss=7.81e-6, test_loss=8.49e-6]\u001b[AAdjusting learning rate of group 0 to 2.0093e-04.\n",
      "Epoch 1560:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.39it/s, loss=8.86e-08, v_num=23, train_loss=7.81e-6, test_loss=8.49e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1560:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.71it/s, loss=8.86e-08, v_num=23, train_loss=7.81e-6, test_loss=8.49e-6]\u001b[A\n",
      "Epoch 1560: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.59it/s, loss=8.86e-08, v_num=23, train_loss=7.2e-6, test_loss=7.9e-6]\u001b[A\n",
      "Epoch 1561:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.60it/s, loss=7.64e-08, v_num=23, train_loss=7.2e-6, test_loss=7.9e-6]\u001b[AAdjusting learning rate of group 0 to 2.0043e-04.\n",
      "Epoch 1561:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.37it/s, loss=7.27e-08, v_num=23, train_loss=7.2e-6, test_loss=7.9e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1561:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.61it/s, loss=7.27e-08, v_num=23, train_loss=7.2e-6, test_loss=7.9e-6]\u001b[A\n",
      "Epoch 1561: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.78it/s, loss=7.27e-08, v_num=23, train_loss=7.61e-6, test_loss=8.26e-6]\u001b[A\n",
      "Epoch 1562:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.83it/s, loss=7.62e-08, v_num=23, train_loss=7.61e-6, test_loss=8.26e-6]\u001b[AAdjusting learning rate of group 0 to 1.9993e-04.\n",
      "Epoch 1562:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.87it/s, loss=7.36e-08, v_num=23, train_loss=7.61e-6, test_loss=8.26e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1562:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.47it/s, loss=7.36e-08, v_num=23, train_loss=7.61e-6, test_loss=8.26e-6]\u001b[A\n",
      "Epoch 1562: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.21it/s, loss=7.36e-08, v_num=23, train_loss=7.97e-6, test_loss=8.69e-6]\u001b[A\n",
      "Epoch 1563:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.91it/s, loss=7.02e-08, v_num=23, train_loss=7.97e-6, test_loss=8.69e-6]\u001b[AAdjusting learning rate of group 0 to 1.9943e-04.\n",
      "Epoch 1563:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.50it/s, loss=6.74e-08, v_num=23, train_loss=7.97e-6, test_loss=8.69e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1563:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.71it/s, loss=6.74e-08, v_num=23, train_loss=7.97e-6, test_loss=8.69e-6]\u001b[A\n",
      "Epoch 1563: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.01it/s, loss=6.74e-08, v_num=23, train_loss=7.56e-6, test_loss=8.27e-6]\u001b[A\n",
      "Epoch 1564:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.22it/s, loss=7.13e-08, v_num=23, train_loss=7.56e-6, test_loss=8.27e-6]\u001b[AAdjusting learning rate of group 0 to 1.9893e-04.\n",
      "Epoch 1564:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.82it/s, loss=6.74e-08, v_num=23, train_loss=7.56e-6, test_loss=8.27e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1564:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.01it/s, loss=6.74e-08, v_num=23, train_loss=7.56e-6, test_loss=8.27e-6]\u001b[A\n",
      "Epoch 1564: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.94it/s, loss=6.74e-08, v_num=23, train_loss=7.63e-6, test_loss=8.26e-6]\u001b[A\n",
      "Epoch 1565:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.19it/s, loss=7.58e-08, v_num=23, train_loss=7.63e-6, test_loss=8.26e-6]\u001b[AAdjusting learning rate of group 0 to 1.9843e-04.\n",
      "Epoch 1565:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.32it/s, loss=7.15e-08, v_num=23, train_loss=7.63e-6, test_loss=8.26e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1565:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.12it/s, loss=7.15e-08, v_num=23, train_loss=7.63e-6, test_loss=8.26e-6]\u001b[A\n",
      "Epoch 1565: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.61it/s, loss=7.15e-08, v_num=23, train_loss=7.19e-6, test_loss=7.81e-6]\u001b[A\n",
      "Epoch 1566:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.04it/s, loss=7.92e-08, v_num=23, train_loss=7.19e-6, test_loss=7.81e-6]\u001b[AAdjusting learning rate of group 0 to 1.9793e-04.\n",
      "Epoch 1566:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.70it/s, loss=7.57e-08, v_num=23, train_loss=7.19e-6, test_loss=7.81e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1566:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.77it/s, loss=7.57e-08, v_num=23, train_loss=7.19e-6, test_loss=7.81e-6]\u001b[A\n",
      "Epoch 1566: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.07it/s, loss=7.57e-08, v_num=23, train_loss=7.66e-6, test_loss=8.25e-6]\u001b[A\n",
      "Epoch 1567:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.73it/s, loss=7.95e-08, v_num=23, train_loss=7.66e-6, test_loss=8.25e-6]\u001b[AAdjusting learning rate of group 0 to 1.9744e-04.\n",
      "Epoch 1567:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.92it/s, loss=7.59e-08, v_num=23, train_loss=7.66e-6, test_loss=8.25e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1567:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.83it/s, loss=7.59e-08, v_num=23, train_loss=7.66e-6, test_loss=8.25e-6]\u001b[A\n",
      "Epoch 1567: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.32it/s, loss=7.59e-08, v_num=23, train_loss=8.01e-6, test_loss=8.56e-6]\u001b[A\n",
      "Epoch 1568:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.49it/s, loss=8.59e-08, v_num=23, train_loss=8.01e-6, test_loss=8.56e-6]\u001b[AAdjusting learning rate of group 0 to 1.9695e-04.\n",
      "Epoch 1568:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.70it/s, loss=8.27e-08, v_num=23, train_loss=8.01e-6, test_loss=8.56e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1568:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.58it/s, loss=8.27e-08, v_num=23, train_loss=8.01e-6, test_loss=8.56e-6]\u001b[A\n",
      "Epoch 1568: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.96it/s, loss=8.27e-08, v_num=23, train_loss=7.89e-6, test_loss=8.53e-6]\u001b[A\n",
      "Epoch 1569:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.47it/s, loss=7.55e-08, v_num=23, train_loss=7.89e-6, test_loss=8.53e-6]\u001b[AAdjusting learning rate of group 0 to 1.9645e-04.\n",
      "Epoch 1569:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.48it/s, loss=7.28e-08, v_num=23, train_loss=7.89e-6, test_loss=8.53e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1569:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.58it/s, loss=7.28e-08, v_num=23, train_loss=7.89e-6, test_loss=8.53e-6]\u001b[A\n",
      "Epoch 1569: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.82it/s, loss=7.28e-08, v_num=23, train_loss=7.66e-6, test_loss=8.4e-6]\u001b[A\n",
      "Epoch 1570:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.21it/s, loss=8.92e-08, v_num=23, train_loss=7.66e-6, test_loss=8.4e-6]\u001b[AAdjusting learning rate of group 0 to 1.9596e-04.\n",
      "Epoch 1570:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.16it/s, loss=8.65e-08, v_num=23, train_loss=7.66e-6, test_loss=8.4e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1570:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.83it/s, loss=8.65e-08, v_num=23, train_loss=7.66e-6, test_loss=8.4e-6]\u001b[A\n",
      "Epoch 1570: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.69it/s, loss=8.65e-08, v_num=23, train_loss=7.38e-6, test_loss=7.94e-6]\u001b[A\n",
      "Epoch 1571:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.44it/s, loss=7.82e-08, v_num=23, train_loss=7.38e-6, test_loss=7.94e-6]\u001b[AAdjusting learning rate of group 0 to 1.9547e-04.\n",
      "Epoch 1571:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.06it/s, loss=7.1e-08, v_num=23, train_loss=7.38e-6, test_loss=7.94e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1571:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.00it/s, loss=7.1e-08, v_num=23, train_loss=7.38e-6, test_loss=7.94e-6]\u001b[A\n",
      "Epoch 1571: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.55it/s, loss=7.1e-08, v_num=23, train_loss=7.6e-6, test_loss=8.28e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1572:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.81it/s, loss=7.22e-08, v_num=23, train_loss=7.6e-6, test_loss=8.28e-6]\u001b[AAdjusting learning rate of group 0 to 1.9498e-04.\n",
      "Epoch 1572:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.41it/s, loss=7.04e-08, v_num=23, train_loss=7.6e-6, test_loss=8.28e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1572:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.89it/s, loss=7.04e-08, v_num=23, train_loss=7.6e-6, test_loss=8.28e-6]\u001b[A\n",
      "Epoch 1572: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.91it/s, loss=7.04e-08, v_num=23, train_loss=7.54e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1573:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.83it/s, loss=8.05e-08, v_num=23, train_loss=7.54e-6, test_loss=8.17e-6]\u001b[AAdjusting learning rate of group 0 to 1.9450e-04.\n",
      "Epoch 1573:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.69it/s, loss=7.74e-08, v_num=23, train_loss=7.54e-6, test_loss=8.17e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1573:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.48it/s, loss=7.74e-08, v_num=23, train_loss=7.54e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1573: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.70it/s, loss=7.74e-08, v_num=23, train_loss=8.34e-6, test_loss=8.96e-6]\u001b[A\n",
      "Epoch 1574:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 125.54it/s, loss=8.07e-08, v_num=23, train_loss=8.34e-6, test_loss=8.96e-6]\u001b[AAdjusting learning rate of group 0 to 1.9401e-04.\n",
      "Epoch 1574:  50%|███████████████████                   | 79/158 [00:00<00:00, 118.36it/s, loss=7.69e-08, v_num=23, train_loss=8.34e-6, test_loss=8.96e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1574:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 117.57it/s, loss=7.69e-08, v_num=23, train_loss=8.34e-6, test_loss=8.96e-6]\u001b[A\n",
      "Validating:  52%|█████████████████████████████████████████████████████▍                                                 | 41/79 [00:00<00:00, 190.79it/s]\u001b[A\n",
      "Epoch 1574: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 130.68it/s, loss=7.69e-08, v_num=23, train_loss=8.12e-6, test_loss=8.81e-6]\u001b[A\n",
      "Epoch 1575:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 119.47it/s, loss=7.19e-08, v_num=23, train_loss=8.12e-6, test_loss=8.81e-6]\u001b[AAdjusting learning rate of group 0 to 1.9353e-04.\n",
      "Epoch 1575:  50%|███████████████████                   | 79/158 [00:00<00:00, 113.67it/s, loss=6.88e-08, v_num=23, train_loss=8.12e-6, test_loss=8.81e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1575:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 113.85it/s, loss=6.88e-08, v_num=23, train_loss=8.12e-6, test_loss=8.81e-6]\u001b[A\n",
      "Validating:  53%|██████████████████████████████████████████████████████▊                                                | 42/79 [00:00<00:00, 194.59it/s]\u001b[A\n",
      "Epoch 1575: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 127.79it/s, loss=6.88e-08, v_num=23, train_loss=7.59e-6, test_loss=8.21e-6]\u001b[A\n",
      "Epoch 1576:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 119.19it/s, loss=7.63e-08, v_num=23, train_loss=7.59e-6, test_loss=8.21e-6]\u001b[AAdjusting learning rate of group 0 to 1.9304e-04.\n",
      "Epoch 1576:  50%|███████████████████                   | 79/158 [00:00<00:00, 111.70it/s, loss=7.05e-08, v_num=23, train_loss=7.59e-6, test_loss=8.21e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1576:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 113.79it/s, loss=7.05e-08, v_num=23, train_loss=7.59e-6, test_loss=8.21e-6]\u001b[A\n",
      "Epoch 1576: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 127.64it/s, loss=7.05e-08, v_num=23, train_loss=8.06e-6, test_loss=8.61e-6]\u001b[A\n",
      "Epoch 1577:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 119.80it/s, loss=7.25e-08, v_num=23, train_loss=8.06e-6, test_loss=8.61e-6]\u001b[AAdjusting learning rate of group 0 to 1.9256e-04.\n",
      "Epoch 1577:  50%|███████████████████                   | 79/158 [00:00<00:00, 112.33it/s, loss=6.92e-08, v_num=23, train_loss=8.06e-6, test_loss=8.61e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.22it/s]\u001b[A\n",
      "Validating:   5%|█████▎                                                                                                   | 4/79 [00:00<00:04, 16.40it/s]\u001b[A\n",
      "Validating:   8%|███████▉                                                                                                 | 6/79 [00:00<00:05, 13.16it/s]\u001b[A\n",
      "Validating:  14%|██████████████▍                                                                                         | 11/79 [00:00<00:02, 23.85it/s]\u001b[A\n",
      "Epoch 1577:  67%|█████████████████████████▍            | 106/158 [00:01<00:00, 76.19it/s, loss=6.92e-08, v_num=23, train_loss=8.06e-6, test_loss=8.61e-6]\u001b[A\n",
      "Epoch 1577: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 102.83it/s, loss=6.92e-08, v_num=23, train_loss=7.59e-6, test_loss=8.21e-6]\u001b[A\n",
      "Epoch 1578:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.46it/s, loss=8e-08, v_num=23, train_loss=7.59e-6, test_loss=8.21e-6]\u001b[AAdjusting learning rate of group 0 to 1.9208e-04.\n",
      "Epoch 1578:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.44it/s, loss=7.52e-08, v_num=23, train_loss=7.59e-6, test_loss=8.21e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:25,  3.12it/s]\u001b[A\n",
      "Epoch 1578:  67%|████████████████████████▊            | 106/158 [00:01<00:00, 102.01it/s, loss=7.52e-08, v_num=23, train_loss=7.59e-6, test_loss=8.21e-6]\u001b[A\n",
      "Epoch 1578: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 132.91it/s, loss=7.52e-08, v_num=23, train_loss=7.86e-6, test_loss=8.54e-6]\u001b[A\n",
      "Epoch 1579:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.44it/s, loss=7.66e-08, v_num=23, train_loss=7.86e-6, test_loss=8.54e-6]\u001b[AAdjusting learning rate of group 0 to 1.9160e-04.\n",
      "Epoch 1579:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.28it/s, loss=7.3e-08, v_num=23, train_loss=7.86e-6, test_loss=8.54e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1579:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.66it/s, loss=7.3e-08, v_num=23, train_loss=7.86e-6, test_loss=8.54e-6]\u001b[A\n",
      "Epoch 1579: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.84it/s, loss=7.3e-08, v_num=23, train_loss=7.11e-6, test_loss=7.79e-6]\u001b[A\n",
      "Epoch 1580:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.26it/s, loss=9.15e-08, v_num=23, train_loss=7.11e-6, test_loss=7.79e-6]\u001b[AAdjusting learning rate of group 0 to 1.9112e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1580:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.98it/s, loss=8.85e-08, v_num=23, train_loss=7.11e-6, test_loss=7.79e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1580:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.22it/s, loss=8.85e-08, v_num=23, train_loss=7.11e-6, test_loss=7.79e-6]\u001b[A\n",
      "Epoch 1580: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.32it/s, loss=8.85e-08, v_num=23, train_loss=7.61e-6, test_loss=8.16e-6]\u001b[A\n",
      "Epoch 1581:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.41it/s, loss=7.45e-08, v_num=23, train_loss=7.61e-6, test_loss=8.16e-6]\u001b[AAdjusting learning rate of group 0 to 1.9064e-04.\n",
      "Epoch 1581:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.11it/s, loss=7.26e-08, v_num=23, train_loss=7.61e-6, test_loss=8.16e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1581:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.95it/s, loss=7.26e-08, v_num=23, train_loss=7.61e-6, test_loss=8.16e-6]\u001b[A\n",
      "Epoch 1581: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.81it/s, loss=7.26e-08, v_num=23, train_loss=7.91e-6, test_loss=8.53e-6]\u001b[A\n",
      "Epoch 1582:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.52it/s, loss=7.44e-08, v_num=23, train_loss=7.91e-6, test_loss=8.53e-6]\u001b[AAdjusting learning rate of group 0 to 1.9016e-04.\n",
      "Epoch 1582:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.74it/s, loss=7.03e-08, v_num=23, train_loss=7.91e-6, test_loss=8.53e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1582:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 135.55it/s, loss=7.03e-08, v_num=23, train_loss=7.91e-6, test_loss=8.53e-6]\u001b[A\n",
      "Epoch 1582: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.17it/s, loss=7.03e-08, v_num=23, train_loss=8.2e-6, test_loss=8.81e-6]\u001b[A\n",
      "Epoch 1583:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.20it/s, loss=7.24e-08, v_num=23, train_loss=8.2e-6, test_loss=8.81e-6]\u001b[AAdjusting learning rate of group 0 to 1.8969e-04.\n",
      "Epoch 1583:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.91it/s, loss=6.93e-08, v_num=23, train_loss=8.2e-6, test_loss=8.81e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1583:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.88it/s, loss=6.93e-08, v_num=23, train_loss=8.2e-6, test_loss=8.81e-6]\u001b[A\n",
      "Epoch 1583: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.30it/s, loss=6.93e-08, v_num=23, train_loss=8.17e-6, test_loss=8.81e-6]\u001b[A\n",
      "Epoch 1584:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 146.95it/s, loss=7.5e-08, v_num=23, train_loss=8.17e-6, test_loss=8.81e-6]\u001b[AAdjusting learning rate of group 0 to 1.8921e-04.\n",
      "Epoch 1584:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.38it/s, loss=7.15e-08, v_num=23, train_loss=8.17e-6, test_loss=8.81e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1584:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.22it/s, loss=7.15e-08, v_num=23, train_loss=8.17e-6, test_loss=8.81e-6]\u001b[A\n",
      "Epoch 1584: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.42it/s, loss=7.15e-08, v_num=23, train_loss=8.16e-6, test_loss=8.82e-6]\u001b[A\n",
      "Epoch 1585:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.97it/s, loss=8.68e-08, v_num=23, train_loss=8.16e-6, test_loss=8.82e-6]\u001b[AAdjusting learning rate of group 0 to 1.8874e-04.\n",
      "Epoch 1585:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.26it/s, loss=8.35e-08, v_num=23, train_loss=8.16e-6, test_loss=8.82e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1585:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.00it/s, loss=8.35e-08, v_num=23, train_loss=8.16e-6, test_loss=8.82e-6]\u001b[A\n",
      "Epoch 1585: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.49it/s, loss=8.35e-08, v_num=23, train_loss=8.05e-6, test_loss=8.71e-6]\u001b[A\n",
      "Epoch 1586:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.27it/s, loss=9e-08, v_num=23, train_loss=8.05e-6, test_loss=8.71e-6]\u001b[AAdjusting learning rate of group 0 to 1.8827e-04.\n",
      "Epoch 1586:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.37it/s, loss=8.76e-08, v_num=23, train_loss=8.05e-6, test_loss=8.71e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1586:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.55it/s, loss=8.76e-08, v_num=23, train_loss=8.05e-6, test_loss=8.71e-6]\u001b[A\n",
      "Epoch 1586: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.82it/s, loss=8.76e-08, v_num=23, train_loss=9.44e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1587:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.01it/s, loss=7.65e-08, v_num=23, train_loss=9.44e-6, test_loss=1.01e-5]\u001b[AAdjusting learning rate of group 0 to 1.8780e-04.\n",
      "Epoch 1587:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.81it/s, loss=7.46e-08, v_num=23, train_loss=9.44e-6, test_loss=1.01e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1587:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.62it/s, loss=7.46e-08, v_num=23, train_loss=9.44e-6, test_loss=1.01e-5]\u001b[A\n",
      "Epoch 1587: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.18it/s, loss=7.46e-08, v_num=23, train_loss=7.73e-6, test_loss=8.42e-6]\u001b[A\n",
      "Epoch 1588:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.12it/s, loss=8.7e-08, v_num=23, train_loss=7.73e-6, test_loss=8.42e-6]\u001b[AAdjusting learning rate of group 0 to 1.8733e-04.\n",
      "Epoch 1588:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.30it/s, loss=8.39e-08, v_num=23, train_loss=7.73e-6, test_loss=8.42e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1588:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.10it/s, loss=8.39e-08, v_num=23, train_loss=7.73e-6, test_loss=8.42e-6]\u001b[A\n",
      "Epoch 1588: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.20it/s, loss=8.39e-08, v_num=23, train_loss=7.33e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1589:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.65it/s, loss=7.17e-08, v_num=23, train_loss=7.33e-6, test_loss=7.97e-6]\u001b[AAdjusting learning rate of group 0 to 1.8686e-04.\n",
      "Epoch 1589:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.58it/s, loss=6.87e-08, v_num=23, train_loss=7.33e-6, test_loss=7.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1589:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.53it/s, loss=6.87e-08, v_num=23, train_loss=7.33e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1589: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.95it/s, loss=6.87e-08, v_num=23, train_loss=7.72e-6, test_loss=8.42e-6]\u001b[A\n",
      "Epoch 1590:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.39it/s, loss=6.49e-08, v_num=23, train_loss=7.72e-6, test_loss=8.42e-6]\u001b[AAdjusting learning rate of group 0 to 1.8639e-04.\n",
      "Epoch 1590:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.29it/s, loss=6.31e-08, v_num=23, train_loss=7.72e-6, test_loss=8.42e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1590:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.68it/s, loss=6.31e-08, v_num=23, train_loss=7.72e-6, test_loss=8.42e-6]\u001b[A\n",
      "Epoch 1590: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.50it/s, loss=6.31e-08, v_num=23, train_loss=7.69e-6, test_loss=8.32e-6]\u001b[A\n",
      "Epoch 1591:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.70it/s, loss=8.68e-08, v_num=23, train_loss=7.69e-6, test_loss=8.32e-6]\u001b[AAdjusting learning rate of group 0 to 1.8593e-04.\n",
      "Epoch 1591:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.51it/s, loss=8.33e-08, v_num=23, train_loss=7.69e-6, test_loss=8.32e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1591:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.51it/s, loss=8.33e-08, v_num=23, train_loss=7.69e-6, test_loss=8.32e-6]\u001b[A\n",
      "Epoch 1591: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.16it/s, loss=8.33e-08, v_num=23, train_loss=8.23e-6, test_loss=8.88e-6]\u001b[A\n",
      "Epoch 1592:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.62it/s, loss=7.17e-08, v_num=23, train_loss=8.23e-6, test_loss=8.88e-6]\u001b[AAdjusting learning rate of group 0 to 1.8546e-04.\n",
      "Epoch 1592:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.24it/s, loss=6.96e-08, v_num=23, train_loss=8.23e-6, test_loss=8.88e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1592:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.48it/s, loss=6.96e-08, v_num=23, train_loss=8.23e-6, test_loss=8.88e-6]\u001b[A\n",
      "Epoch 1592: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.43it/s, loss=6.96e-08, v_num=23, train_loss=7.45e-6, test_loss=8.08e-6]\u001b[A\n",
      "Epoch 1593:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.59it/s, loss=6.85e-08, v_num=23, train_loss=7.45e-6, test_loss=8.08e-6]\u001b[AAdjusting learning rate of group 0 to 1.8500e-04.\n",
      "Epoch 1593:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.41it/s, loss=6.41e-08, v_num=23, train_loss=7.45e-6, test_loss=8.08e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1593:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.64it/s, loss=6.41e-08, v_num=23, train_loss=7.45e-6, test_loss=8.08e-6]\u001b[A\n",
      "Epoch 1593: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.22it/s, loss=6.41e-08, v_num=23, train_loss=7.09e-6, test_loss=7.68e-6]\u001b[A\n",
      "Epoch 1594:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.27it/s, loss=6.97e-08, v_num=23, train_loss=7.09e-6, test_loss=7.68e-6]\u001b[AAdjusting learning rate of group 0 to 1.8454e-04.\n",
      "Epoch 1594:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.35it/s, loss=6.64e-08, v_num=23, train_loss=7.09e-6, test_loss=7.68e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1594:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.99it/s, loss=6.64e-08, v_num=23, train_loss=7.09e-6, test_loss=7.68e-6]\u001b[A\n",
      "Epoch 1594: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.52it/s, loss=6.64e-08, v_num=23, train_loss=7.5e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1595:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.63it/s, loss=7.49e-08, v_num=23, train_loss=7.5e-6, test_loss=8.17e-6]\u001b[AAdjusting learning rate of group 0 to 1.8408e-04.\n",
      "Epoch 1595:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.43it/s, loss=7.21e-08, v_num=23, train_loss=7.5e-6, test_loss=8.17e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1595:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.22it/s, loss=7.21e-08, v_num=23, train_loss=7.5e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1595: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.61it/s, loss=7.21e-08, v_num=23, train_loss=7.21e-6, test_loss=7.79e-6]\u001b[A\n",
      "Epoch 1596:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.49it/s, loss=7.33e-08, v_num=23, train_loss=7.21e-6, test_loss=7.79e-6]\u001b[AAdjusting learning rate of group 0 to 1.8362e-04.\n",
      "Epoch 1596:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.39it/s, loss=7.11e-08, v_num=23, train_loss=7.21e-6, test_loss=7.79e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1596:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.67it/s, loss=7.11e-08, v_num=23, train_loss=7.21e-6, test_loss=7.79e-6]\u001b[A\n",
      "Epoch 1596: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.16it/s, loss=7.11e-08, v_num=23, train_loss=8.26e-6, test_loss=8.84e-6]\u001b[A\n",
      "Epoch 1597:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.73it/s, loss=8.62e-08, v_num=23, train_loss=8.26e-6, test_loss=8.84e-6]\u001b[AAdjusting learning rate of group 0 to 1.8316e-04.\n",
      "Epoch 1597:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.42it/s, loss=8.37e-08, v_num=23, train_loss=8.26e-6, test_loss=8.84e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1597:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.91it/s, loss=8.37e-08, v_num=23, train_loss=8.26e-6, test_loss=8.84e-6]\u001b[A\n",
      "Epoch 1597: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.66it/s, loss=8.37e-08, v_num=23, train_loss=8.75e-6, test_loss=9.45e-6]\u001b[A\n",
      "Epoch 1598:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.27it/s, loss=7.69e-08, v_num=23, train_loss=8.75e-6, test_loss=9.45e-6]\u001b[AAdjusting learning rate of group 0 to 1.8270e-04.\n",
      "Epoch 1598:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.18it/s, loss=7.52e-08, v_num=23, train_loss=8.75e-6, test_loss=9.45e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1598:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.57it/s, loss=7.52e-08, v_num=23, train_loss=8.75e-6, test_loss=9.45e-6]\u001b[A\n",
      "Epoch 1598: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.55it/s, loss=7.52e-08, v_num=23, train_loss=7.71e-6, test_loss=8.42e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1599:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.58it/s, loss=7.13e-08, v_num=23, train_loss=7.71e-6, test_loss=8.42e-6]\u001b[AAdjusting learning rate of group 0 to 1.8224e-04.\n",
      "Epoch 1599:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.88it/s, loss=6.85e-08, v_num=23, train_loss=7.71e-6, test_loss=8.42e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1599:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 127.94it/s, loss=6.85e-08, v_num=23, train_loss=7.71e-6, test_loss=8.42e-6]\u001b[A\n",
      "Epoch 1599: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 163.18it/s, loss=6.85e-08, v_num=23, train_loss=7.59e-6, test_loss=8.23e-6]\u001b[A\n",
      "Epoch 1600:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.98it/s, loss=8.22e-08, v_num=23, train_loss=7.59e-6, test_loss=8.23e-6]\u001b[AAdjusting learning rate of group 0 to 1.8179e-04.\n",
      "Epoch 1600:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.88it/s, loss=7.89e-08, v_num=23, train_loss=7.59e-6, test_loss=8.23e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1600:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.25it/s, loss=7.89e-08, v_num=23, train_loss=7.59e-6, test_loss=8.23e-6]\u001b[A\n",
      "Epoch 1600: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.44it/s, loss=7.89e-08, v_num=23, train_loss=8.92e-6, test_loss=9.45e-6]\u001b[A\n",
      "Epoch 1601:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.22it/s, loss=7.12e-08, v_num=23, train_loss=8.92e-6, test_loss=9.45e-6]\u001b[AAdjusting learning rate of group 0 to 1.8133e-04.\n",
      "Epoch 1601:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.24it/s, loss=6.74e-08, v_num=23, train_loss=8.92e-6, test_loss=9.45e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1601:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.43it/s, loss=6.74e-08, v_num=23, train_loss=8.92e-6, test_loss=9.45e-6]\u001b[A\n",
      "Epoch 1601: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.55it/s, loss=6.74e-08, v_num=23, train_loss=7.27e-6, test_loss=7.94e-6]\u001b[A\n",
      "Epoch 1602:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.65it/s, loss=7.33e-08, v_num=23, train_loss=7.27e-6, test_loss=7.94e-6]\u001b[AAdjusting learning rate of group 0 to 1.8088e-04.\n",
      "Epoch 1602:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.50it/s, loss=7.06e-08, v_num=23, train_loss=7.27e-6, test_loss=7.94e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1602:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.34it/s, loss=7.06e-08, v_num=23, train_loss=7.27e-6, test_loss=7.94e-6]\u001b[A\n",
      "Epoch 1602: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.87it/s, loss=7.06e-08, v_num=23, train_loss=7.68e-6, test_loss=8.31e-6]\u001b[A\n",
      "Epoch 1603:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.64it/s, loss=6.94e-08, v_num=23, train_loss=7.68e-6, test_loss=8.31e-6]\u001b[AAdjusting learning rate of group 0 to 1.8043e-04.\n",
      "Epoch 1603:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.01it/s, loss=6.42e-08, v_num=23, train_loss=7.68e-6, test_loss=8.31e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1603:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 128.54it/s, loss=6.42e-08, v_num=23, train_loss=7.68e-6, test_loss=8.31e-6]\u001b[A\n",
      "Epoch 1603: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 163.47it/s, loss=6.42e-08, v_num=23, train_loss=7.01e-6, test_loss=7.73e-6]\u001b[A\n",
      "Epoch 1604:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.48it/s, loss=7.04e-08, v_num=23, train_loss=7.01e-6, test_loss=7.73e-6]\u001b[AAdjusting learning rate of group 0 to 1.7997e-04.\n",
      "Epoch 1604:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.98it/s, loss=6.64e-08, v_num=23, train_loss=7.01e-6, test_loss=7.73e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1604:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.32it/s, loss=6.64e-08, v_num=23, train_loss=7.01e-6, test_loss=7.73e-6]\u001b[A\n",
      "Epoch 1604: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.51it/s, loss=6.64e-08, v_num=23, train_loss=7.7e-6, test_loss=8.31e-6]\u001b[A\n",
      "Epoch 1605:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.81it/s, loss=1.06e-07, v_num=23, train_loss=7.7e-6, test_loss=8.31e-6]\u001b[AAdjusting learning rate of group 0 to 1.7952e-04.\n",
      "Epoch 1605:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.35it/s, loss=1.01e-07, v_num=23, train_loss=7.7e-6, test_loss=8.31e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1605:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.42it/s, loss=1.01e-07, v_num=23, train_loss=7.7e-6, test_loss=8.31e-6]\u001b[A\n",
      "Epoch 1605: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.55it/s, loss=1.01e-07, v_num=23, train_loss=7.32e-6, test_loss=7.91e-6]\u001b[A\n",
      "Epoch 1606:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.86it/s, loss=7.3e-08, v_num=23, train_loss=7.32e-6, test_loss=7.91e-6]\u001b[AAdjusting learning rate of group 0 to 1.7908e-04.\n",
      "Epoch 1606:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.02it/s, loss=6.96e-08, v_num=23, train_loss=7.32e-6, test_loss=7.91e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1606:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.53it/s, loss=6.96e-08, v_num=23, train_loss=7.32e-6, test_loss=7.91e-6]\u001b[A\n",
      "Epoch 1606: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.61it/s, loss=6.96e-08, v_num=23, train_loss=8.24e-6, test_loss=8.92e-6]\u001b[A\n",
      "Epoch 1607:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.74it/s, loss=8.95e-08, v_num=23, train_loss=8.24e-6, test_loss=8.92e-6]\u001b[AAdjusting learning rate of group 0 to 1.7863e-04.\n",
      "Epoch 1607:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.95it/s, loss=8.53e-08, v_num=23, train_loss=8.24e-6, test_loss=8.92e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1607:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.21it/s, loss=8.53e-08, v_num=23, train_loss=8.24e-6, test_loss=8.92e-6]\u001b[A\n",
      "Epoch 1607: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.08it/s, loss=8.53e-08, v_num=23, train_loss=7.16e-6, test_loss=7.87e-6]\u001b[A\n",
      "Epoch 1608:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.75it/s, loss=7.18e-08, v_num=23, train_loss=7.16e-6, test_loss=7.87e-6]\u001b[AAdjusting learning rate of group 0 to 1.7818e-04.\n",
      "Epoch 1608:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.04it/s, loss=6.8e-08, v_num=23, train_loss=7.16e-6, test_loss=7.87e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1608:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.89it/s, loss=6.8e-08, v_num=23, train_loss=7.16e-6, test_loss=7.87e-6]\u001b[A\n",
      "Epoch 1608: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.08it/s, loss=6.8e-08, v_num=23, train_loss=7.45e-6, test_loss=8.09e-6]\u001b[A\n",
      "Epoch 1609:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.40it/s, loss=7.92e-08, v_num=23, train_loss=7.45e-6, test_loss=8.09e-6]\u001b[AAdjusting learning rate of group 0 to 1.7774e-04.\n",
      "Epoch 1609:  50%|███████████████████                   | 79/158 [00:00<00:00, 142.38it/s, loss=7.75e-08, v_num=23, train_loss=7.45e-6, test_loss=8.09e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1609:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.83it/s, loss=7.75e-08, v_num=23, train_loss=7.45e-6, test_loss=8.09e-6]\u001b[A\n",
      "Epoch 1609: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 172.50it/s, loss=7.75e-08, v_num=23, train_loss=7.06e-6, test_loss=7.69e-6]\u001b[A\n",
      "Epoch 1610:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.50it/s, loss=7.28e-08, v_num=23, train_loss=7.06e-6, test_loss=7.69e-6]\u001b[AAdjusting learning rate of group 0 to 1.7729e-04.\n",
      "Epoch 1610:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.41it/s, loss=7.02e-08, v_num=23, train_loss=7.06e-6, test_loss=7.69e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1610:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.51it/s, loss=7.02e-08, v_num=23, train_loss=7.06e-6, test_loss=7.69e-6]\u001b[A\n",
      "Epoch 1610: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.01it/s, loss=7.02e-08, v_num=23, train_loss=7.77e-6, test_loss=8.38e-6]\u001b[A\n",
      "Epoch 1611:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.98it/s, loss=1.32e-07, v_num=23, train_loss=7.77e-6, test_loss=8.38e-6]\u001b[AAdjusting learning rate of group 0 to 1.7685e-04.\n",
      "Epoch 1611:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.24it/s, loss=1.28e-07, v_num=23, train_loss=7.77e-6, test_loss=8.38e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1611:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.24it/s, loss=1.28e-07, v_num=23, train_loss=7.77e-6, test_loss=8.38e-6]\u001b[A\n",
      "Epoch 1611: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.31it/s, loss=1.28e-07, v_num=23, train_loss=7.43e-6, test_loss=8.11e-6]\u001b[A\n",
      "Epoch 1612:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.69it/s, loss=6.75e-08, v_num=23, train_loss=7.43e-6, test_loss=8.11e-6]\u001b[AAdjusting learning rate of group 0 to 1.7641e-04.\n",
      "Epoch 1612:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.37it/s, loss=6.43e-08, v_num=23, train_loss=7.43e-6, test_loss=8.11e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1612:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.50it/s, loss=6.43e-08, v_num=23, train_loss=7.43e-6, test_loss=8.11e-6]\u001b[A\n",
      "Epoch 1612: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.05it/s, loss=6.43e-08, v_num=23, train_loss=7.05e-6, test_loss=7.73e-6]\u001b[A\n",
      "Epoch 1613:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.13it/s, loss=7.37e-08, v_num=23, train_loss=7.05e-6, test_loss=7.73e-6]\u001b[AAdjusting learning rate of group 0 to 1.7597e-04.\n",
      "Epoch 1613:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.34it/s, loss=7.18e-08, v_num=23, train_loss=7.05e-6, test_loss=7.73e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1613:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.20it/s, loss=7.18e-08, v_num=23, train_loss=7.05e-6, test_loss=7.73e-6]\u001b[A\n",
      "Epoch 1613: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.83it/s, loss=7.18e-08, v_num=23, train_loss=7.47e-6, test_loss=8.15e-6]\u001b[A\n",
      "Epoch 1614:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.53it/s, loss=7.43e-08, v_num=23, train_loss=7.47e-6, test_loss=8.15e-6]\u001b[AAdjusting learning rate of group 0 to 1.7553e-04.\n",
      "Epoch 1614:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.27it/s, loss=7.13e-08, v_num=23, train_loss=7.47e-6, test_loss=8.15e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1614:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.71it/s, loss=7.13e-08, v_num=23, train_loss=7.47e-6, test_loss=8.15e-6]\u001b[A\n",
      "Epoch 1614: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.21it/s, loss=7.13e-08, v_num=23, train_loss=7.32e-6, test_loss=7.96e-6]\u001b[A\n",
      "Epoch 1615:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.65it/s, loss=8.04e-08, v_num=23, train_loss=7.32e-6, test_loss=7.96e-6]\u001b[AAdjusting learning rate of group 0 to 1.7509e-04.\n",
      "Epoch 1615:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.42it/s, loss=7.78e-08, v_num=23, train_loss=7.32e-6, test_loss=7.96e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1615:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.68it/s, loss=7.78e-08, v_num=23, train_loss=7.32e-6, test_loss=7.96e-6]\u001b[A\n",
      "Epoch 1615: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.97it/s, loss=7.78e-08, v_num=23, train_loss=7.81e-6, test_loss=8.44e-6]\u001b[A\n",
      "Epoch 1616:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.96it/s, loss=7.31e-08, v_num=23, train_loss=7.81e-6, test_loss=8.44e-6]\u001b[AAdjusting learning rate of group 0 to 1.7465e-04.\n",
      "Epoch 1616:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.56it/s, loss=6.68e-08, v_num=23, train_loss=7.81e-6, test_loss=8.44e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1616:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.60it/s, loss=6.68e-08, v_num=23, train_loss=7.81e-6, test_loss=8.44e-6]\u001b[A\n",
      "Epoch 1616: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.60it/s, loss=6.68e-08, v_num=23, train_loss=7.49e-6, test_loss=8.16e-6]\u001b[A\n",
      "Epoch 1617:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.84it/s, loss=7.61e-08, v_num=23, train_loss=7.49e-6, test_loss=8.16e-6]\u001b[AAdjusting learning rate of group 0 to 1.7421e-04.\n",
      "Epoch 1617:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.08it/s, loss=7.14e-08, v_num=23, train_loss=7.49e-6, test_loss=8.16e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1617:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.39it/s, loss=7.14e-08, v_num=23, train_loss=7.49e-6, test_loss=8.16e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1617: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.24it/s, loss=7.14e-08, v_num=23, train_loss=7.73e-6, test_loss=8.4e-6]\u001b[A\n",
      "Epoch 1618:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.80it/s, loss=7.43e-08, v_num=23, train_loss=7.73e-6, test_loss=8.4e-6]\u001b[AAdjusting learning rate of group 0 to 1.7378e-04.\n",
      "Epoch 1618:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.60it/s, loss=6.94e-08, v_num=23, train_loss=7.73e-6, test_loss=8.4e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1618:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.20it/s, loss=6.94e-08, v_num=23, train_loss=7.73e-6, test_loss=8.4e-6]\u001b[A\n",
      "Epoch 1618: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.12it/s, loss=6.94e-08, v_num=23, train_loss=7.91e-6, test_loss=8.56e-6]\u001b[A\n",
      "Epoch 1619:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.04it/s, loss=7.57e-08, v_num=23, train_loss=7.91e-6, test_loss=8.56e-6]\u001b[AAdjusting learning rate of group 0 to 1.7334e-04.\n",
      "Epoch 1619:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.75it/s, loss=7.11e-08, v_num=23, train_loss=7.91e-6, test_loss=8.56e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1619:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.85it/s, loss=7.11e-08, v_num=23, train_loss=7.91e-6, test_loss=8.56e-6]\u001b[A\n",
      "Epoch 1619: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.55it/s, loss=7.11e-08, v_num=23, train_loss=7.45e-6, test_loss=8.09e-6]\u001b[A\n",
      "Epoch 1620:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.83it/s, loss=7.22e-08, v_num=23, train_loss=7.45e-6, test_loss=8.09e-6]\u001b[AAdjusting learning rate of group 0 to 1.7291e-04.\n",
      "Epoch 1620:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.74it/s, loss=6.9e-08, v_num=23, train_loss=7.45e-6, test_loss=8.09e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1620:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.37it/s, loss=6.9e-08, v_num=23, train_loss=7.45e-6, test_loss=8.09e-6]\u001b[A\n",
      "Epoch 1620: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.61it/s, loss=6.9e-08, v_num=23, train_loss=7.75e-6, test_loss=8.47e-6]\u001b[A\n",
      "Epoch 1621:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.23it/s, loss=7.16e-08, v_num=23, train_loss=7.75e-6, test_loss=8.47e-6]\u001b[AAdjusting learning rate of group 0 to 1.7248e-04.\n",
      "Epoch 1621:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.52it/s, loss=6.9e-08, v_num=23, train_loss=7.75e-6, test_loss=8.47e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1621:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.84it/s, loss=6.9e-08, v_num=23, train_loss=7.75e-6, test_loss=8.47e-6]\u001b[A\n",
      "Epoch 1621: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 168.36it/s, loss=6.9e-08, v_num=23, train_loss=7.31e-6, test_loss=7.9e-6]\u001b[A\n",
      "Epoch 1622:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.70it/s, loss=6.92e-08, v_num=23, train_loss=7.31e-6, test_loss=7.9e-6]\u001b[AAdjusting learning rate of group 0 to 1.7205e-04.\n",
      "Epoch 1622:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.39it/s, loss=6.59e-08, v_num=23, train_loss=7.31e-6, test_loss=7.9e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1622:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.37it/s, loss=6.59e-08, v_num=23, train_loss=7.31e-6, test_loss=7.9e-6]\u001b[A\n",
      "Epoch 1622: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.66it/s, loss=6.59e-08, v_num=23, train_loss=7.22e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1623:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.75it/s, loss=8.35e-08, v_num=23, train_loss=7.22e-6, test_loss=7.93e-6]\u001b[AAdjusting learning rate of group 0 to 1.7162e-04.\n",
      "Epoch 1623:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.50it/s, loss=8.03e-08, v_num=23, train_loss=7.22e-6, test_loss=7.93e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1623:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.45it/s, loss=8.03e-08, v_num=23, train_loss=7.22e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1623: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.97it/s, loss=8.03e-08, v_num=23, train_loss=8.1e-6, test_loss=8.71e-6]\u001b[A\n",
      "Epoch 1624:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.67it/s, loss=6.54e-08, v_num=23, train_loss=8.1e-6, test_loss=8.71e-6]\u001b[AAdjusting learning rate of group 0 to 1.7119e-04.\n",
      "Epoch 1624:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.11it/s, loss=6.26e-08, v_num=23, train_loss=8.1e-6, test_loss=8.71e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1624:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.03it/s, loss=6.26e-08, v_num=23, train_loss=8.1e-6, test_loss=8.71e-6]\u001b[A\n",
      "Epoch 1624: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.23it/s, loss=6.26e-08, v_num=23, train_loss=7.51e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1625:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.82it/s, loss=7.61e-08, v_num=23, train_loss=7.51e-6, test_loss=8.17e-6]\u001b[AAdjusting learning rate of group 0 to 1.7076e-04.\n",
      "Epoch 1625:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.66it/s, loss=7.34e-08, v_num=23, train_loss=7.51e-6, test_loss=8.17e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1625:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.93it/s, loss=7.34e-08, v_num=23, train_loss=7.51e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1625: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.85it/s, loss=7.34e-08, v_num=23, train_loss=7.21e-6, test_loss=7.86e-6]\u001b[A\n",
      "Epoch 1626:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.21it/s, loss=7.68e-08, v_num=23, train_loss=7.21e-6, test_loss=7.86e-6]\u001b[AAdjusting learning rate of group 0 to 1.7033e-04.\n",
      "Epoch 1626:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.89it/s, loss=7.35e-08, v_num=23, train_loss=7.21e-6, test_loss=7.86e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1626:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.56it/s, loss=7.35e-08, v_num=23, train_loss=7.21e-6, test_loss=7.86e-6]\u001b[A\n",
      "Epoch 1626: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.44it/s, loss=7.35e-08, v_num=23, train_loss=7.81e-6, test_loss=8.43e-6]\u001b[A\n",
      "Epoch 1627:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.92it/s, loss=7.5e-08, v_num=23, train_loss=7.81e-6, test_loss=8.43e-6]\u001b[AAdjusting learning rate of group 0 to 1.6991e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1627:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.43it/s, loss=7.02e-08, v_num=23, train_loss=7.81e-6, test_loss=8.43e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1627:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.34it/s, loss=7.02e-08, v_num=23, train_loss=7.81e-6, test_loss=8.43e-6]\u001b[A\n",
      "Epoch 1627: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.97it/s, loss=7.02e-08, v_num=23, train_loss=7.22e-6, test_loss=7.94e-6]\u001b[A\n",
      "Epoch 1628:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.28it/s, loss=7.74e-08, v_num=23, train_loss=7.22e-6, test_loss=7.94e-6]\u001b[AAdjusting learning rate of group 0 to 1.6948e-04.\n",
      "Epoch 1628:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.13it/s, loss=7.51e-08, v_num=23, train_loss=7.22e-6, test_loss=7.94e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1628:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.19it/s, loss=7.51e-08, v_num=23, train_loss=7.22e-6, test_loss=7.94e-6]\u001b[A\n",
      "Epoch 1628: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.76it/s, loss=7.51e-08, v_num=23, train_loss=7.75e-6, test_loss=8.4e-6]\u001b[A\n",
      "Epoch 1629:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 149.50it/s, loss=7e-08, v_num=23, train_loss=7.75e-6, test_loss=8.4e-6]\u001b[AAdjusting learning rate of group 0 to 1.6906e-04.\n",
      "Epoch 1629:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.38it/s, loss=6.54e-08, v_num=23, train_loss=7.75e-6, test_loss=8.4e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1629:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.64it/s, loss=6.54e-08, v_num=23, train_loss=7.75e-6, test_loss=8.4e-6]\u001b[A\n",
      "Epoch 1629: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.14it/s, loss=6.54e-08, v_num=23, train_loss=8.31e-6, test_loss=8.95e-6]\u001b[A\n",
      "Epoch 1630:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.73it/s, loss=7.86e-08, v_num=23, train_loss=8.31e-6, test_loss=8.95e-6]\u001b[AAdjusting learning rate of group 0 to 1.6863e-04.\n",
      "Epoch 1630:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.36it/s, loss=7.65e-08, v_num=23, train_loss=8.31e-6, test_loss=8.95e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1630:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.20it/s, loss=7.65e-08, v_num=23, train_loss=8.31e-6, test_loss=8.95e-6]\u001b[A\n",
      "Epoch 1630: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.68it/s, loss=7.65e-08, v_num=23, train_loss=8.53e-6, test_loss=9.19e-6]\u001b[A\n",
      "Epoch 1631:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.34it/s, loss=6.88e-08, v_num=23, train_loss=8.53e-6, test_loss=9.19e-6]\u001b[AAdjusting learning rate of group 0 to 1.6821e-04.\n",
      "Epoch 1631:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.27it/s, loss=6.69e-08, v_num=23, train_loss=8.53e-6, test_loss=9.19e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1631:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.81it/s, loss=6.69e-08, v_num=23, train_loss=8.53e-6, test_loss=9.19e-6]\u001b[A\n",
      "Epoch 1631: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.58it/s, loss=6.69e-08, v_num=23, train_loss=7.23e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1632:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.17it/s, loss=7.41e-08, v_num=23, train_loss=7.23e-6, test_loss=7.93e-6]\u001b[AAdjusting learning rate of group 0 to 1.6779e-04.\n",
      "Epoch 1632:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.00it/s, loss=7.13e-08, v_num=23, train_loss=7.23e-6, test_loss=7.93e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1632:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.45it/s, loss=7.13e-08, v_num=23, train_loss=7.23e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1632: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.06it/s, loss=7.13e-08, v_num=23, train_loss=7.49e-6, test_loss=8.15e-6]\u001b[A\n",
      "Epoch 1633:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.56it/s, loss=7.51e-08, v_num=23, train_loss=7.49e-6, test_loss=8.15e-6]\u001b[AAdjusting learning rate of group 0 to 1.6737e-04.\n",
      "Epoch 1633:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.74it/s, loss=7.3e-08, v_num=23, train_loss=7.49e-6, test_loss=8.15e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1633:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.11it/s, loss=7.3e-08, v_num=23, train_loss=7.49e-6, test_loss=8.15e-6]\u001b[A\n",
      "Epoch 1633: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.58it/s, loss=7.3e-08, v_num=23, train_loss=7.61e-6, test_loss=8.28e-6]\u001b[A\n",
      "Epoch 1634:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.92it/s, loss=8.02e-08, v_num=23, train_loss=7.61e-6, test_loss=8.28e-6]\u001b[AAdjusting learning rate of group 0 to 1.6695e-04.\n",
      "Epoch 1634:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.32it/s, loss=7.73e-08, v_num=23, train_loss=7.61e-6, test_loss=8.28e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1634:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.17it/s, loss=7.73e-08, v_num=23, train_loss=7.61e-6, test_loss=8.28e-6]\u001b[A\n",
      "Epoch 1634: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.89it/s, loss=7.73e-08, v_num=23, train_loss=7.11e-6, test_loss=7.8e-6]\u001b[A\n",
      "Epoch 1635:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.36it/s, loss=7.71e-08, v_num=23, train_loss=7.11e-6, test_loss=7.8e-6]\u001b[AAdjusting learning rate of group 0 to 1.6654e-04.\n",
      "Epoch 1635:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.26it/s, loss=7.46e-08, v_num=23, train_loss=7.11e-6, test_loss=7.8e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1635:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.56it/s, loss=7.46e-08, v_num=23, train_loss=7.11e-6, test_loss=7.8e-6]\u001b[A\n",
      "Epoch 1635: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.47it/s, loss=7.46e-08, v_num=23, train_loss=8.1e-6, test_loss=8.69e-6]\u001b[A\n",
      "Epoch 1636:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 146.35it/s, loss=6.54e-08, v_num=23, train_loss=8.1e-6, test_loss=8.69e-6]\u001b[AAdjusting learning rate of group 0 to 1.6612e-04.\n",
      "Epoch 1636:  50%|████████████████████                    | 79/158 [00:00<00:00, 136.64it/s, loss=6.3e-08, v_num=23, train_loss=8.1e-6, test_loss=8.69e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1636:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.74it/s, loss=6.3e-08, v_num=23, train_loss=8.1e-6, test_loss=8.69e-6]\u001b[A\n",
      "Epoch 1636: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.55it/s, loss=6.3e-08, v_num=23, train_loss=7.18e-6, test_loss=7.82e-6]\u001b[A\n",
      "Epoch 1637:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.40it/s, loss=8.76e-08, v_num=23, train_loss=7.18e-6, test_loss=7.82e-6]\u001b[AAdjusting learning rate of group 0 to 1.6571e-04.\n",
      "Epoch 1637:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.12it/s, loss=8.61e-08, v_num=23, train_loss=7.18e-6, test_loss=7.82e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1637:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.63it/s, loss=8.61e-08, v_num=23, train_loss=7.18e-6, test_loss=7.82e-6]\u001b[A\n",
      "Epoch 1637: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.29it/s, loss=8.61e-08, v_num=23, train_loss=7.01e-6, test_loss=7.7e-6]\u001b[A\n",
      "Epoch 1638:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.78it/s, loss=1.43e-07, v_num=23, train_loss=7.01e-6, test_loss=7.7e-6]\u001b[AAdjusting learning rate of group 0 to 1.6529e-04.\n",
      "Epoch 1638:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.00it/s, loss=1.41e-07, v_num=23, train_loss=7.01e-6, test_loss=7.7e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1638:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.00it/s, loss=1.41e-07, v_num=23, train_loss=7.01e-6, test_loss=7.7e-6]\u001b[A\n",
      "Epoch 1638: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.98it/s, loss=1.41e-07, v_num=23, train_loss=7.55e-6, test_loss=8.13e-6]\u001b[A\n",
      "Epoch 1639:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.01it/s, loss=1.29e-07, v_num=23, train_loss=7.55e-6, test_loss=8.13e-6]\u001b[AAdjusting learning rate of group 0 to 1.6488e-04.\n",
      "Epoch 1639:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.11it/s, loss=1.25e-07, v_num=23, train_loss=7.55e-6, test_loss=8.13e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1639:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.07it/s, loss=1.25e-07, v_num=23, train_loss=7.55e-6, test_loss=8.13e-6]\u001b[A\n",
      "Epoch 1639: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.00it/s, loss=1.25e-07, v_num=23, train_loss=8.82e-6, test_loss=9.6e-6]\u001b[A\n",
      "Epoch 1640:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.60it/s, loss=7.08e-08, v_num=23, train_loss=8.82e-6, test_loss=9.6e-6]\u001b[AAdjusting learning rate of group 0 to 1.6447e-04.\n",
      "Epoch 1640:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.38it/s, loss=6.89e-08, v_num=23, train_loss=8.82e-6, test_loss=9.6e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1640:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.23it/s, loss=6.89e-08, v_num=23, train_loss=8.82e-6, test_loss=9.6e-6]\u001b[A\n",
      "Epoch 1640: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.23it/s, loss=6.89e-08, v_num=23, train_loss=7.52e-6, test_loss=8.21e-6]\u001b[A\n",
      "Epoch 1641:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.00it/s, loss=7.34e-08, v_num=23, train_loss=7.52e-6, test_loss=8.21e-6]\u001b[AAdjusting learning rate of group 0 to 1.6405e-04.\n",
      "Epoch 1641:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.59it/s, loss=7.06e-08, v_num=23, train_loss=7.52e-6, test_loss=8.21e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1641:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.45it/s, loss=7.06e-08, v_num=23, train_loss=7.52e-6, test_loss=8.21e-6]\u001b[A\n",
      "Epoch 1641: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.50it/s, loss=7.06e-08, v_num=23, train_loss=7.9e-6, test_loss=8.57e-6]\u001b[A\n",
      "Epoch 1642:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.21it/s, loss=7.13e-08, v_num=23, train_loss=7.9e-6, test_loss=8.57e-6]\u001b[AAdjusting learning rate of group 0 to 1.6364e-04.\n",
      "Epoch 1642:  50%|████████████████████                    | 79/158 [00:00<00:00, 139.46it/s, loss=6.9e-08, v_num=23, train_loss=7.9e-6, test_loss=8.57e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1642:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 133.26it/s, loss=6.9e-08, v_num=23, train_loss=7.9e-6, test_loss=8.57e-6]\u001b[A\n",
      "Epoch 1642: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.94it/s, loss=6.9e-08, v_num=23, train_loss=7.51e-6, test_loss=8.11e-6]\u001b[A\n",
      "Epoch 1643:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.71it/s, loss=8.91e-08, v_num=23, train_loss=7.51e-6, test_loss=8.11e-6]\u001b[AAdjusting learning rate of group 0 to 1.6324e-04.\n",
      "Epoch 1643:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.79it/s, loss=8.5e-08, v_num=23, train_loss=7.51e-6, test_loss=8.11e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1643:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.43it/s, loss=8.5e-08, v_num=23, train_loss=7.51e-6, test_loss=8.11e-6]\u001b[A\n",
      "Epoch 1643: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.07it/s, loss=8.5e-08, v_num=23, train_loss=7.49e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1644:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.02it/s, loss=8.04e-08, v_num=23, train_loss=7.49e-6, test_loss=8.17e-6]\u001b[AAdjusting learning rate of group 0 to 1.6283e-04.\n",
      "Epoch 1644:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.57it/s, loss=7.72e-08, v_num=23, train_loss=7.49e-6, test_loss=8.17e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1644:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.68it/s, loss=7.72e-08, v_num=23, train_loss=7.49e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1644: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.74it/s, loss=7.72e-08, v_num=23, train_loss=7.42e-6, test_loss=8.1e-6]\u001b[A\n",
      "Epoch 1645:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.44it/s, loss=6.82e-08, v_num=23, train_loss=7.42e-6, test_loss=8.1e-6]\u001b[AAdjusting learning rate of group 0 to 1.6242e-04.\n",
      "Epoch 1645:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.69it/s, loss=6.51e-08, v_num=23, train_loss=7.42e-6, test_loss=8.1e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1645:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.02it/s, loss=6.51e-08, v_num=23, train_loss=7.42e-6, test_loss=8.1e-6]\u001b[A\n",
      "Epoch 1645: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.76it/s, loss=6.51e-08, v_num=23, train_loss=7.37e-6, test_loss=8.04e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1646:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.26it/s, loss=8.87e-08, v_num=23, train_loss=7.37e-6, test_loss=8.04e-6]\u001b[AAdjusting learning rate of group 0 to 1.6201e-04.\n",
      "Epoch 1646:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.32it/s, loss=8.68e-08, v_num=23, train_loss=7.37e-6, test_loss=8.04e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1646:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.54it/s, loss=8.68e-08, v_num=23, train_loss=7.37e-6, test_loss=8.04e-6]\u001b[A\n",
      "Epoch 1646: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.67it/s, loss=8.68e-08, v_num=23, train_loss=7.74e-6, test_loss=8.45e-6]\u001b[A\n",
      "Epoch 1647:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.69it/s, loss=6.98e-08, v_num=23, train_loss=7.74e-6, test_loss=8.45e-6]\u001b[AAdjusting learning rate of group 0 to 1.6161e-04.\n",
      "Epoch 1647:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.30it/s, loss=6.71e-08, v_num=23, train_loss=7.74e-6, test_loss=8.45e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1647:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.16it/s, loss=6.71e-08, v_num=23, train_loss=7.74e-6, test_loss=8.45e-6]\u001b[A\n",
      "Epoch 1647: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.02it/s, loss=6.71e-08, v_num=23, train_loss=7.66e-6, test_loss=8.32e-6]\u001b[A\n",
      "Epoch 1648:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.78it/s, loss=7.54e-08, v_num=23, train_loss=7.66e-6, test_loss=8.32e-6]\u001b[AAdjusting learning rate of group 0 to 1.6121e-04.\n",
      "Epoch 1648:  50%|███████████████████                   | 79/158 [00:00<00:00, 135.61it/s, loss=7.02e-08, v_num=23, train_loss=7.66e-6, test_loss=8.32e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1648:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.59it/s, loss=7.02e-08, v_num=23, train_loss=7.66e-6, test_loss=8.32e-6]\u001b[A\n",
      "Epoch 1648: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.58it/s, loss=7.02e-08, v_num=23, train_loss=7.19e-6, test_loss=7.84e-6]\u001b[A\n",
      "Epoch 1649:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.81it/s, loss=7.77e-08, v_num=23, train_loss=7.19e-6, test_loss=7.84e-6]\u001b[AAdjusting learning rate of group 0 to 1.6080e-04.\n",
      "Epoch 1649:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.13it/s, loss=7.49e-08, v_num=23, train_loss=7.19e-6, test_loss=7.84e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1649:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.96it/s, loss=7.49e-08, v_num=23, train_loss=7.19e-6, test_loss=7.84e-6]\u001b[A\n",
      "Epoch 1649: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.90it/s, loss=7.49e-08, v_num=23, train_loss=8.2e-6, test_loss=8.71e-6]\u001b[A\n",
      "Epoch 1650:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 146.50it/s, loss=8.28e-08, v_num=23, train_loss=8.2e-6, test_loss=8.71e-6]\u001b[AAdjusting learning rate of group 0 to 1.6040e-04.\n",
      "Epoch 1650:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.37it/s, loss=8.03e-08, v_num=23, train_loss=8.2e-6, test_loss=8.71e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1650:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.59it/s, loss=8.03e-08, v_num=23, train_loss=8.2e-6, test_loss=8.71e-6]\u001b[A\n",
      "Epoch 1650: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.41it/s, loss=8.03e-08, v_num=23, train_loss=8.03e-6, test_loss=8.61e-6]\u001b[A\n",
      "Epoch 1651:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.65it/s, loss=7.29e-08, v_num=23, train_loss=8.03e-6, test_loss=8.61e-6]\u001b[AAdjusting learning rate of group 0 to 1.6000e-04.\n",
      "Epoch 1651:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.40it/s, loss=6.79e-08, v_num=23, train_loss=8.03e-6, test_loss=8.61e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1651:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.14it/s, loss=6.79e-08, v_num=23, train_loss=8.03e-6, test_loss=8.61e-6]\u001b[A\n",
      "Epoch 1651: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.37it/s, loss=6.79e-08, v_num=23, train_loss=7.69e-6, test_loss=8.29e-6]\u001b[A\n",
      "Epoch 1652:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.98it/s, loss=7.14e-08, v_num=23, train_loss=7.69e-6, test_loss=8.29e-6]\u001b[AAdjusting learning rate of group 0 to 1.5960e-04.\n",
      "Epoch 1652:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.58it/s, loss=6.6e-08, v_num=23, train_loss=7.69e-6, test_loss=8.29e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1652:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 135.09it/s, loss=6.6e-08, v_num=23, train_loss=7.69e-6, test_loss=8.29e-6]\u001b[A\n",
      "Epoch 1652: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 172.15it/s, loss=6.6e-08, v_num=23, train_loss=8.42e-6, test_loss=8.96e-6]\u001b[A\n",
      "Epoch 1653:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.57it/s, loss=1.1e-07, v_num=23, train_loss=8.42e-6, test_loss=8.96e-6]\u001b[AAdjusting learning rate of group 0 to 1.5920e-04.\n",
      "Epoch 1653:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.43it/s, loss=7.41e-08, v_num=23, train_loss=8.42e-6, test_loss=8.96e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1653:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.26it/s, loss=7.41e-08, v_num=23, train_loss=8.42e-6, test_loss=8.96e-6]\u001b[A\n",
      "Epoch 1653: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.91it/s, loss=7.41e-08, v_num=23, train_loss=7.47e-6, test_loss=8.07e-6]\u001b[A\n",
      "Epoch 1654:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.04it/s, loss=7.34e-08, v_num=23, train_loss=7.47e-6, test_loss=8.07e-6]\u001b[AAdjusting learning rate of group 0 to 1.5880e-04.\n",
      "Epoch 1654:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.96it/s, loss=7.1e-08, v_num=23, train_loss=7.47e-6, test_loss=8.07e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1654:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.90it/s, loss=7.1e-08, v_num=23, train_loss=7.47e-6, test_loss=8.07e-6]\u001b[A\n",
      "Epoch 1654: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.50it/s, loss=7.1e-08, v_num=23, train_loss=7.52e-6, test_loss=8.12e-6]\u001b[A\n",
      "Epoch 1655:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.47it/s, loss=6.97e-08, v_num=23, train_loss=7.52e-6, test_loss=8.12e-6]\u001b[AAdjusting learning rate of group 0 to 1.5841e-04.\n",
      "Epoch 1655:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.68it/s, loss=6.72e-08, v_num=23, train_loss=7.52e-6, test_loss=8.12e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1655:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.72it/s, loss=6.72e-08, v_num=23, train_loss=7.52e-6, test_loss=8.12e-6]\u001b[A\n",
      "Epoch 1655: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.56it/s, loss=6.72e-08, v_num=23, train_loss=7.5e-6, test_loss=8.09e-6]\u001b[A\n",
      "Epoch 1656:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.50it/s, loss=6.84e-08, v_num=23, train_loss=7.5e-6, test_loss=8.09e-6]\u001b[AAdjusting learning rate of group 0 to 1.5801e-04.\n",
      "Epoch 1656:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.04it/s, loss=6.56e-08, v_num=23, train_loss=7.5e-6, test_loss=8.09e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1656:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.58it/s, loss=6.56e-08, v_num=23, train_loss=7.5e-6, test_loss=8.09e-6]\u001b[A\n",
      "Epoch 1656: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.73it/s, loss=6.56e-08, v_num=23, train_loss=7.58e-6, test_loss=8.18e-6]\u001b[A\n",
      "Epoch 1657:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.53it/s, loss=9.47e-08, v_num=23, train_loss=7.58e-6, test_loss=8.18e-6]\u001b[AAdjusting learning rate of group 0 to 1.5761e-04.\n",
      "Epoch 1657:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.13it/s, loss=9.05e-08, v_num=23, train_loss=7.58e-6, test_loss=8.18e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1657:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.69it/s, loss=9.05e-08, v_num=23, train_loss=7.58e-6, test_loss=8.18e-6]\u001b[A\n",
      "Epoch 1657: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.80it/s, loss=9.05e-08, v_num=23, train_loss=7.06e-6, test_loss=7.73e-6]\u001b[A\n",
      "Epoch 1658:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.93it/s, loss=7.32e-08, v_num=23, train_loss=7.06e-6, test_loss=7.73e-6]\u001b[AAdjusting learning rate of group 0 to 1.5722e-04.\n",
      "Epoch 1658:  50%|███████████████████                   | 79/158 [00:00<00:00, 135.82it/s, loss=7.06e-08, v_num=23, train_loss=7.06e-6, test_loss=7.73e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1658:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 128.21it/s, loss=7.06e-08, v_num=23, train_loss=7.06e-6, test_loss=7.73e-6]\u001b[A\n",
      "Epoch 1658: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 163.24it/s, loss=7.06e-08, v_num=23, train_loss=8.07e-6, test_loss=8.67e-6]\u001b[A\n",
      "Epoch 1659:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.13it/s, loss=8.19e-08, v_num=23, train_loss=8.07e-6, test_loss=8.67e-6]\u001b[AAdjusting learning rate of group 0 to 1.5683e-04.\n",
      "Epoch 1659:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.23it/s, loss=7.88e-08, v_num=23, train_loss=8.07e-6, test_loss=8.67e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1659:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.36it/s, loss=7.88e-08, v_num=23, train_loss=8.07e-6, test_loss=8.67e-6]\u001b[A\n",
      "Epoch 1659: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 163.79it/s, loss=7.88e-08, v_num=23, train_loss=8.21e-6, test_loss=8.91e-6]\u001b[A\n",
      "Epoch 1660:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.50it/s, loss=7.62e-08, v_num=23, train_loss=8.21e-6, test_loss=8.91e-6]\u001b[AAdjusting learning rate of group 0 to 1.5644e-04.\n",
      "Epoch 1660:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.44it/s, loss=7.29e-08, v_num=23, train_loss=8.21e-6, test_loss=8.91e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1660:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.77it/s, loss=7.29e-08, v_num=23, train_loss=8.21e-6, test_loss=8.91e-6]\u001b[A\n",
      "Epoch 1660: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.88it/s, loss=7.29e-08, v_num=23, train_loss=7.69e-6, test_loss=8.33e-6]\u001b[A\n",
      "Epoch 1661:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.99it/s, loss=8.24e-08, v_num=23, train_loss=7.69e-6, test_loss=8.33e-6]\u001b[AAdjusting learning rate of group 0 to 1.5604e-04.\n",
      "Epoch 1661:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.83it/s, loss=7.97e-08, v_num=23, train_loss=7.69e-6, test_loss=8.33e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1661:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 127.78it/s, loss=7.97e-08, v_num=23, train_loss=7.69e-6, test_loss=8.33e-6]\u001b[A\n",
      "Epoch 1661: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 163.56it/s, loss=7.97e-08, v_num=23, train_loss=7.57e-6, test_loss=8.26e-6]\u001b[A\n",
      "Epoch 1662:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.48it/s, loss=7.33e-08, v_num=23, train_loss=7.57e-6, test_loss=8.26e-6]\u001b[AAdjusting learning rate of group 0 to 1.5565e-04.\n",
      "Epoch 1662:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.21it/s, loss=7.13e-08, v_num=23, train_loss=7.57e-6, test_loss=8.26e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1662:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.76it/s, loss=7.13e-08, v_num=23, train_loss=7.57e-6, test_loss=8.26e-6]\u001b[A\n",
      "Epoch 1662: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.70it/s, loss=7.13e-08, v_num=23, train_loss=7.57e-6, test_loss=8.26e-6]\u001b[A\n",
      "Epoch 1663:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.79it/s, loss=7.81e-08, v_num=23, train_loss=7.57e-6, test_loss=8.26e-6]\u001b[AAdjusting learning rate of group 0 to 1.5526e-04.\n",
      "Epoch 1663:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.00it/s, loss=7.52e-08, v_num=23, train_loss=7.57e-6, test_loss=8.26e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1663:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.42it/s, loss=7.52e-08, v_num=23, train_loss=7.57e-6, test_loss=8.26e-6]\u001b[A\n",
      "Epoch 1663: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.26it/s, loss=7.52e-08, v_num=23, train_loss=7.39e-6, test_loss=8.06e-6]\u001b[A\n",
      "Epoch 1664:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 145.86it/s, loss=7.05e-08, v_num=23, train_loss=7.39e-6, test_loss=8.06e-6]\u001b[AAdjusting learning rate of group 0 to 1.5488e-04.\n",
      "Epoch 1664:  50%|███████████████████                   | 79/158 [00:00<00:00, 135.60it/s, loss=6.72e-08, v_num=23, train_loss=7.39e-6, test_loss=8.06e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1664:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.75it/s, loss=6.72e-08, v_num=23, train_loss=7.39e-6, test_loss=8.06e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1664: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.67it/s, loss=6.72e-08, v_num=23, train_loss=7.42e-6, test_loss=8.05e-6]\u001b[A\n",
      "Epoch 1665:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.13it/s, loss=7.4e-08, v_num=23, train_loss=7.42e-6, test_loss=8.05e-6]\u001b[AAdjusting learning rate of group 0 to 1.5449e-04.\n",
      "Epoch 1665:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.45it/s, loss=7.07e-08, v_num=23, train_loss=7.42e-6, test_loss=8.05e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1665:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.33it/s, loss=7.07e-08, v_num=23, train_loss=7.42e-6, test_loss=8.05e-6]\u001b[A\n",
      "Epoch 1665: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.41it/s, loss=7.07e-08, v_num=23, train_loss=7.51e-6, test_loss=8.25e-6]\u001b[A\n",
      "Epoch 1666:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.92it/s, loss=7.78e-08, v_num=23, train_loss=7.51e-6, test_loss=8.25e-6]\u001b[AAdjusting learning rate of group 0 to 1.5410e-04.\n",
      "Epoch 1666:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.47it/s, loss=7.38e-08, v_num=23, train_loss=7.51e-6, test_loss=8.25e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1666:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.43it/s, loss=7.38e-08, v_num=23, train_loss=7.51e-6, test_loss=8.25e-6]\u001b[A\n",
      "Epoch 1666: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.82it/s, loss=7.38e-08, v_num=23, train_loss=7.58e-6, test_loss=8.2e-6]\u001b[A\n",
      "Epoch 1667:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.62it/s, loss=7.23e-08, v_num=23, train_loss=7.58e-6, test_loss=8.2e-6]\u001b[AAdjusting learning rate of group 0 to 1.5372e-04.\n",
      "Epoch 1667:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.09it/s, loss=6.81e-08, v_num=23, train_loss=7.58e-6, test_loss=8.2e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1667:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.87it/s, loss=6.81e-08, v_num=23, train_loss=7.58e-6, test_loss=8.2e-6]\u001b[A\n",
      "Epoch 1667: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.01it/s, loss=6.81e-08, v_num=23, train_loss=7.76e-6, test_loss=8.45e-6]\u001b[A\n",
      "Epoch 1668:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.51it/s, loss=6.82e-08, v_num=23, train_loss=7.76e-6, test_loss=8.45e-6]\u001b[AAdjusting learning rate of group 0 to 1.5333e-04.\n",
      "Epoch 1668:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.44it/s, loss=6.49e-08, v_num=23, train_loss=7.76e-6, test_loss=8.45e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1668:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.25it/s, loss=6.49e-08, v_num=23, train_loss=7.76e-6, test_loss=8.45e-6]\u001b[A\n",
      "Epoch 1668: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.37it/s, loss=6.49e-08, v_num=23, train_loss=7.31e-6, test_loss=7.98e-6]\u001b[A\n",
      "Epoch 1669:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.37it/s, loss=7.11e-08, v_num=23, train_loss=7.31e-6, test_loss=7.98e-6]\u001b[AAdjusting learning rate of group 0 to 1.5295e-04.\n",
      "Epoch 1669:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.32it/s, loss=6.88e-08, v_num=23, train_loss=7.31e-6, test_loss=7.98e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1669:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.42it/s, loss=6.88e-08, v_num=23, train_loss=7.31e-6, test_loss=7.98e-6]\u001b[A\n",
      "Epoch 1669: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.14it/s, loss=6.88e-08, v_num=23, train_loss=7.33e-6, test_loss=7.96e-6]\u001b[A\n",
      "Epoch 1670:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.79it/s, loss=7.24e-08, v_num=23, train_loss=7.33e-6, test_loss=7.96e-6]\u001b[AAdjusting learning rate of group 0 to 1.5257e-04.\n",
      "Epoch 1670:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.05it/s, loss=6.92e-08, v_num=23, train_loss=7.33e-6, test_loss=7.96e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1670:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.83it/s, loss=6.92e-08, v_num=23, train_loss=7.33e-6, test_loss=7.96e-6]\u001b[A\n",
      "Epoch 1670: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.44it/s, loss=6.92e-08, v_num=23, train_loss=7.74e-6, test_loss=8.36e-6]\u001b[A\n",
      "Epoch 1671:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.05it/s, loss=7.44e-08, v_num=23, train_loss=7.74e-6, test_loss=8.36e-6]\u001b[AAdjusting learning rate of group 0 to 1.5219e-04.\n",
      "Epoch 1671:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.42it/s, loss=7.2e-08, v_num=23, train_loss=7.74e-6, test_loss=8.36e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1671:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.75it/s, loss=7.2e-08, v_num=23, train_loss=7.74e-6, test_loss=8.36e-6]\u001b[A\n",
      "Epoch 1671: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.90it/s, loss=7.2e-08, v_num=23, train_loss=7.55e-6, test_loss=8.22e-6]\u001b[A\n",
      "Epoch 1672:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.49it/s, loss=6.99e-08, v_num=23, train_loss=7.55e-6, test_loss=8.22e-6]\u001b[AAdjusting learning rate of group 0 to 1.5181e-04.\n",
      "Epoch 1672:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.48it/s, loss=6.78e-08, v_num=23, train_loss=7.55e-6, test_loss=8.22e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1672:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.72it/s, loss=6.78e-08, v_num=23, train_loss=7.55e-6, test_loss=8.22e-6]\u001b[A\n",
      "Epoch 1672: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.03it/s, loss=6.78e-08, v_num=23, train_loss=7.47e-6, test_loss=8.12e-6]\u001b[A\n",
      "Epoch 1673:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.59it/s, loss=7.34e-08, v_num=23, train_loss=7.47e-6, test_loss=8.12e-6]\u001b[AAdjusting learning rate of group 0 to 1.5143e-04.\n",
      "Epoch 1673:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.77it/s, loss=7.08e-08, v_num=23, train_loss=7.47e-6, test_loss=8.12e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1673:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.99it/s, loss=7.08e-08, v_num=23, train_loss=7.47e-6, test_loss=8.12e-6]\u001b[A\n",
      "Epoch 1673: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 167.90it/s, loss=7.08e-08, v_num=23, train_loss=7.3e-6, test_loss=7.9e-6]\u001b[A\n",
      "Epoch 1674:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.58it/s, loss=6.88e-08, v_num=23, train_loss=7.3e-6, test_loss=7.9e-6]\u001b[AAdjusting learning rate of group 0 to 1.5105e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1674:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.72it/s, loss=6.54e-08, v_num=23, train_loss=7.3e-6, test_loss=7.9e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1674:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.03it/s, loss=6.54e-08, v_num=23, train_loss=7.3e-6, test_loss=7.9e-6]\u001b[A\n",
      "Epoch 1674: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.26it/s, loss=6.54e-08, v_num=23, train_loss=7.29e-6, test_loss=7.88e-6]\u001b[A\n",
      "Epoch 1675:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.88it/s, loss=7.51e-08, v_num=23, train_loss=7.29e-6, test_loss=7.88e-6]\u001b[AAdjusting learning rate of group 0 to 1.5067e-04.\n",
      "Epoch 1675:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.26it/s, loss=7.2e-08, v_num=23, train_loss=7.29e-6, test_loss=7.88e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1675:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.55it/s, loss=7.2e-08, v_num=23, train_loss=7.29e-6, test_loss=7.88e-6]\u001b[A\n",
      "Epoch 1675: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.88it/s, loss=7.2e-08, v_num=23, train_loss=7.75e-6, test_loss=8.34e-6]\u001b[A\n",
      "Epoch 1676:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.12it/s, loss=6.73e-08, v_num=23, train_loss=7.75e-6, test_loss=8.34e-6]\u001b[AAdjusting learning rate of group 0 to 1.5029e-04.\n",
      "Epoch 1676:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.02it/s, loss=6.33e-08, v_num=23, train_loss=7.75e-6, test_loss=8.34e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1676:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.27it/s, loss=6.33e-08, v_num=23, train_loss=7.75e-6, test_loss=8.34e-6]\u001b[A\n",
      "Epoch 1676: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.79it/s, loss=6.33e-08, v_num=23, train_loss=7.8e-6, test_loss=8.44e-6]\u001b[A\n",
      "Epoch 1677:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.86it/s, loss=6.77e-08, v_num=23, train_loss=7.8e-6, test_loss=8.44e-6]\u001b[AAdjusting learning rate of group 0 to 1.4992e-04.\n",
      "Epoch 1677:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.90it/s, loss=6.39e-08, v_num=23, train_loss=7.8e-6, test_loss=8.44e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1677:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.90it/s, loss=6.39e-08, v_num=23, train_loss=7.8e-6, test_loss=8.44e-6]\u001b[A\n",
      "Epoch 1677: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.16it/s, loss=6.39e-08, v_num=23, train_loss=7.75e-6, test_loss=8.31e-6]\u001b[A\n",
      "Epoch 1678:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.77it/s, loss=6.5e-08, v_num=23, train_loss=7.75e-6, test_loss=8.31e-6]\u001b[AAdjusting learning rate of group 0 to 1.4954e-04.\n",
      "Epoch 1678:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.23it/s, loss=6.12e-08, v_num=23, train_loss=7.75e-6, test_loss=8.31e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1678:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 128.36it/s, loss=6.12e-08, v_num=23, train_loss=7.75e-6, test_loss=8.31e-6]\u001b[A\n",
      "Epoch 1678: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 163.82it/s, loss=6.12e-08, v_num=23, train_loss=7.58e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1679:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.15it/s, loss=9.37e-08, v_num=23, train_loss=7.58e-6, test_loss=8.17e-6]\u001b[AAdjusting learning rate of group 0 to 1.4917e-04.\n",
      "Epoch 1679:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.40it/s, loss=9.1e-08, v_num=23, train_loss=7.58e-6, test_loss=8.17e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1679:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.21it/s, loss=9.1e-08, v_num=23, train_loss=7.58e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1679: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.59it/s, loss=9.1e-08, v_num=23, train_loss=7.37e-6, test_loss=8.04e-6]\u001b[A\n",
      "Epoch 1680:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.29it/s, loss=8.24e-08, v_num=23, train_loss=7.37e-6, test_loss=8.04e-6]\u001b[AAdjusting learning rate of group 0 to 1.4880e-04.\n",
      "Epoch 1680:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.78it/s, loss=7.91e-08, v_num=23, train_loss=7.37e-6, test_loss=8.04e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1680:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.83it/s, loss=7.91e-08, v_num=23, train_loss=7.37e-6, test_loss=8.04e-6]\u001b[A\n",
      "Epoch 1680: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.65it/s, loss=7.91e-08, v_num=23, train_loss=7.43e-6, test_loss=8.08e-6]\u001b[A\n",
      "Epoch 1681:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.60it/s, loss=7.08e-08, v_num=23, train_loss=7.43e-6, test_loss=8.08e-6]\u001b[AAdjusting learning rate of group 0 to 1.4842e-04.\n",
      "Epoch 1681:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.88it/s, loss=6.83e-08, v_num=23, train_loss=7.43e-6, test_loss=8.08e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1681:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.21it/s, loss=6.83e-08, v_num=23, train_loss=7.43e-6, test_loss=8.08e-6]\u001b[A\n",
      "Epoch 1681: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.26it/s, loss=6.83e-08, v_num=23, train_loss=7.62e-6, test_loss=8.28e-6]\u001b[A\n",
      "Epoch 1682:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.43it/s, loss=7.45e-08, v_num=23, train_loss=7.62e-6, test_loss=8.28e-6]\u001b[AAdjusting learning rate of group 0 to 1.4805e-04.\n",
      "Epoch 1682:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.79it/s, loss=7.12e-08, v_num=23, train_loss=7.62e-6, test_loss=8.28e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1682:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.23it/s, loss=7.12e-08, v_num=23, train_loss=7.62e-6, test_loss=8.28e-6]\u001b[A\n",
      "Epoch 1682: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.07it/s, loss=7.12e-08, v_num=23, train_loss=7.93e-6, test_loss=8.53e-6]\u001b[A\n",
      "Epoch 1683:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.81it/s, loss=7.61e-08, v_num=23, train_loss=7.93e-6, test_loss=8.53e-6]\u001b[AAdjusting learning rate of group 0 to 1.4768e-04.\n",
      "Epoch 1683:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.90it/s, loss=7.39e-08, v_num=23, train_loss=7.93e-6, test_loss=8.53e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1683:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.62it/s, loss=7.39e-08, v_num=23, train_loss=7.93e-6, test_loss=8.53e-6]\u001b[A\n",
      "Epoch 1683: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.55it/s, loss=7.39e-08, v_num=23, train_loss=7.5e-6, test_loss=8.11e-6]\u001b[A\n",
      "Epoch 1684:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.58it/s, loss=6.84e-08, v_num=23, train_loss=7.5e-6, test_loss=8.11e-6]\u001b[AAdjusting learning rate of group 0 to 1.4731e-04.\n",
      "Epoch 1684:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.66it/s, loss=6.59e-08, v_num=23, train_loss=7.5e-6, test_loss=8.11e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1684:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.25it/s, loss=6.59e-08, v_num=23, train_loss=7.5e-6, test_loss=8.11e-6]\u001b[A\n",
      "Epoch 1684: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.40it/s, loss=6.59e-08, v_num=23, train_loss=7.3e-6, test_loss=7.94e-6]\u001b[A\n",
      "Epoch 1685:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.32it/s, loss=6.71e-08, v_num=23, train_loss=7.3e-6, test_loss=7.94e-6]\u001b[AAdjusting learning rate of group 0 to 1.4695e-04.\n",
      "Epoch 1685:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.30it/s, loss=6.35e-08, v_num=23, train_loss=7.3e-6, test_loss=7.94e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1685:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.80it/s, loss=6.35e-08, v_num=23, train_loss=7.3e-6, test_loss=7.94e-6]\u001b[A\n",
      "Epoch 1685: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.38it/s, loss=6.35e-08, v_num=23, train_loss=7.34e-6, test_loss=7.98e-6]\u001b[A\n",
      "Epoch 1686:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.90it/s, loss=7.96e-08, v_num=23, train_loss=7.34e-6, test_loss=7.98e-6]\u001b[AAdjusting learning rate of group 0 to 1.4658e-04.\n",
      "Epoch 1686:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.19it/s, loss=7.76e-08, v_num=23, train_loss=7.34e-6, test_loss=7.98e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1686:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.45it/s, loss=7.76e-08, v_num=23, train_loss=7.34e-6, test_loss=7.98e-6]\u001b[A\n",
      "Epoch 1686: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.55it/s, loss=7.76e-08, v_num=23, train_loss=7.44e-6, test_loss=8.12e-6]\u001b[A\n",
      "Epoch 1687:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.77it/s, loss=7.14e-08, v_num=23, train_loss=7.44e-6, test_loss=8.12e-6]\u001b[AAdjusting learning rate of group 0 to 1.4621e-04.\n",
      "Epoch 1687:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.05it/s, loss=6.75e-08, v_num=23, train_loss=7.44e-6, test_loss=8.12e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1687:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.98it/s, loss=6.75e-08, v_num=23, train_loss=7.44e-6, test_loss=8.12e-6]\u001b[A\n",
      "Epoch 1687: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.05it/s, loss=6.75e-08, v_num=23, train_loss=7.07e-6, test_loss=7.64e-6]\u001b[A\n",
      "Epoch 1688:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.84it/s, loss=7.48e-08, v_num=23, train_loss=7.07e-6, test_loss=7.64e-6]\u001b[AAdjusting learning rate of group 0 to 1.4585e-04.\n",
      "Epoch 1688:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.68it/s, loss=6.75e-08, v_num=23, train_loss=7.07e-6, test_loss=7.64e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1688:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.86it/s, loss=6.75e-08, v_num=23, train_loss=7.07e-6, test_loss=7.64e-6]\u001b[A\n",
      "Epoch 1688: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.98it/s, loss=6.75e-08, v_num=23, train_loss=6.94e-6, test_loss=7.64e-6]\u001b[A\n",
      "Epoch 1689:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.62it/s, loss=7.38e-08, v_num=23, train_loss=6.94e-6, test_loss=7.64e-6]\u001b[AAdjusting learning rate of group 0 to 1.4548e-04.\n",
      "Epoch 1689:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.29it/s, loss=7.01e-08, v_num=23, train_loss=6.94e-6, test_loss=7.64e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1689:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.07it/s, loss=7.01e-08, v_num=23, train_loss=6.94e-6, test_loss=7.64e-6]\u001b[A\n",
      "Epoch 1689: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.60it/s, loss=7.01e-08, v_num=23, train_loss=7.38e-6, test_loss=8.06e-6]\u001b[A\n",
      "Epoch 1690:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.41it/s, loss=8.07e-08, v_num=23, train_loss=7.38e-6, test_loss=8.06e-6]\u001b[AAdjusting learning rate of group 0 to 1.4512e-04.\n",
      "Epoch 1690:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.40it/s, loss=7.63e-08, v_num=23, train_loss=7.38e-6, test_loss=8.06e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1690:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.17it/s, loss=7.63e-08, v_num=23, train_loss=7.38e-6, test_loss=8.06e-6]\u001b[A\n",
      "Epoch 1690: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.20it/s, loss=7.63e-08, v_num=23, train_loss=7.86e-6, test_loss=8.5e-6]\u001b[A\n",
      "Epoch 1691:  49%|████████████████████▋                     | 78/158 [00:00<00:00, 148.45it/s, loss=8e-08, v_num=23, train_loss=7.86e-6, test_loss=8.5e-6]\u001b[AAdjusting learning rate of group 0 to 1.4476e-04.\n",
      "Epoch 1691:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.44it/s, loss=7.74e-08, v_num=23, train_loss=7.86e-6, test_loss=8.5e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1691:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.18it/s, loss=7.74e-08, v_num=23, train_loss=7.86e-6, test_loss=8.5e-6]\u001b[A\n",
      "Epoch 1691: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.00it/s, loss=7.74e-08, v_num=23, train_loss=7.12e-6, test_loss=7.73e-6]\u001b[A\n",
      "Epoch 1692:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.43it/s, loss=7.24e-08, v_num=23, train_loss=7.12e-6, test_loss=7.73e-6]\u001b[AAdjusting learning rate of group 0 to 1.4439e-04.\n",
      "Epoch 1692:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.03it/s, loss=6.95e-08, v_num=23, train_loss=7.12e-6, test_loss=7.73e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1692:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.04it/s, loss=6.95e-08, v_num=23, train_loss=7.12e-6, test_loss=7.73e-6]\u001b[A\n",
      "Epoch 1692: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.40it/s, loss=6.95e-08, v_num=23, train_loss=7.67e-6, test_loss=8.32e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1693:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.03it/s, loss=6.84e-08, v_num=23, train_loss=7.67e-6, test_loss=8.32e-6]\u001b[AAdjusting learning rate of group 0 to 1.4403e-04.\n",
      "Epoch 1693:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.77it/s, loss=6.37e-08, v_num=23, train_loss=7.67e-6, test_loss=8.32e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1693:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.73it/s, loss=6.37e-08, v_num=23, train_loss=7.67e-6, test_loss=8.32e-6]\u001b[A\n",
      "Epoch 1693: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.83it/s, loss=6.37e-08, v_num=23, train_loss=7.4e-6, test_loss=8.04e-6]\u001b[A\n",
      "Epoch 1694:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.73it/s, loss=6.33e-08, v_num=23, train_loss=7.4e-6, test_loss=8.04e-6]\u001b[AAdjusting learning rate of group 0 to 1.4367e-04.\n",
      "Epoch 1694:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.62it/s, loss=6.08e-08, v_num=23, train_loss=7.4e-6, test_loss=8.04e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1694:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.21it/s, loss=6.08e-08, v_num=23, train_loss=7.4e-6, test_loss=8.04e-6]\u001b[A\n",
      "Epoch 1694: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.06it/s, loss=6.08e-08, v_num=23, train_loss=7.08e-6, test_loss=7.74e-6]\u001b[A\n",
      "Epoch 1695:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.87it/s, loss=6.74e-08, v_num=23, train_loss=7.08e-6, test_loss=7.74e-6]\u001b[AAdjusting learning rate of group 0 to 1.4331e-04.\n",
      "Epoch 1695:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.16it/s, loss=6.47e-08, v_num=23, train_loss=7.08e-6, test_loss=7.74e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1695:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.98it/s, loss=6.47e-08, v_num=23, train_loss=7.08e-6, test_loss=7.74e-6]\u001b[A\n",
      "Epoch 1695: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.55it/s, loss=6.47e-08, v_num=23, train_loss=7.13e-6, test_loss=7.84e-6]\u001b[A\n",
      "Epoch 1696:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.82it/s, loss=7.12e-08, v_num=23, train_loss=7.13e-6, test_loss=7.84e-6]\u001b[AAdjusting learning rate of group 0 to 1.4295e-04.\n",
      "Epoch 1696:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.11it/s, loss=6.62e-08, v_num=23, train_loss=7.13e-6, test_loss=7.84e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1696:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.09it/s, loss=6.62e-08, v_num=23, train_loss=7.13e-6, test_loss=7.84e-6]\u001b[A\n",
      "Epoch 1696: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.26it/s, loss=6.62e-08, v_num=23, train_loss=6.98e-6, test_loss=7.66e-6]\u001b[A\n",
      "Epoch 1697:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.02it/s, loss=6.36e-08, v_num=23, train_loss=6.98e-6, test_loss=7.66e-6]\u001b[AAdjusting learning rate of group 0 to 1.4260e-04.\n",
      "Epoch 1697:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.23it/s, loss=6.11e-08, v_num=23, train_loss=6.98e-6, test_loss=7.66e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1697:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.28it/s, loss=6.11e-08, v_num=23, train_loss=6.98e-6, test_loss=7.66e-6]\u001b[A\n",
      "Epoch 1697: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.85it/s, loss=6.11e-08, v_num=23, train_loss=7.43e-6, test_loss=8.07e-6]\u001b[A\n",
      "Epoch 1698:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.57it/s, loss=6.85e-08, v_num=23, train_loss=7.43e-6, test_loss=8.07e-6]\u001b[AAdjusting learning rate of group 0 to 1.4224e-04.\n",
      "Epoch 1698:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.03it/s, loss=6.49e-08, v_num=23, train_loss=7.43e-6, test_loss=8.07e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1698:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.16it/s, loss=6.49e-08, v_num=23, train_loss=7.43e-6, test_loss=8.07e-6]\u001b[A\n",
      "Epoch 1698: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.33it/s, loss=6.49e-08, v_num=23, train_loss=7.63e-6, test_loss=8.24e-6]\u001b[A\n",
      "Epoch 1699:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.65it/s, loss=6.28e-08, v_num=23, train_loss=7.63e-6, test_loss=8.24e-6]\u001b[AAdjusting learning rate of group 0 to 1.4189e-04.\n",
      "Epoch 1699:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.23it/s, loss=6.1e-08, v_num=23, train_loss=7.63e-6, test_loss=8.24e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1699:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.98it/s, loss=6.1e-08, v_num=23, train_loss=7.63e-6, test_loss=8.24e-6]\u001b[A\n",
      "Epoch 1699: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.56it/s, loss=6.1e-08, v_num=23, train_loss=7.62e-6, test_loss=8.19e-6]\u001b[A\n",
      "Epoch 1700:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.58it/s, loss=7.01e-08, v_num=23, train_loss=7.62e-6, test_loss=8.19e-6]\u001b[AAdjusting learning rate of group 0 to 1.4153e-04.\n",
      "Epoch 1700:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.52it/s, loss=6.67e-08, v_num=23, train_loss=7.62e-6, test_loss=8.19e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1700:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 135.19it/s, loss=6.67e-08, v_num=23, train_loss=7.62e-6, test_loss=8.19e-6]\u001b[A\n",
      "Epoch 1700: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.77it/s, loss=6.67e-08, v_num=23, train_loss=7.37e-6, test_loss=8.04e-6]\u001b[A\n",
      "Epoch 1701:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.04it/s, loss=6.9e-08, v_num=23, train_loss=7.37e-6, test_loss=8.04e-6]\u001b[AAdjusting learning rate of group 0 to 1.4118e-04.\n",
      "Epoch 1701:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.33it/s, loss=6.64e-08, v_num=23, train_loss=7.37e-6, test_loss=8.04e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1701:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.19it/s, loss=6.64e-08, v_num=23, train_loss=7.37e-6, test_loss=8.04e-6]\u001b[A\n",
      "Epoch 1701: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.15it/s, loss=6.64e-08, v_num=23, train_loss=7.61e-6, test_loss=8.25e-6]\u001b[A\n",
      "Epoch 1702:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.47it/s, loss=6.78e-08, v_num=23, train_loss=7.61e-6, test_loss=8.25e-6]\u001b[AAdjusting learning rate of group 0 to 1.4082e-04.\n",
      "Epoch 1702:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.34it/s, loss=6.4e-08, v_num=23, train_loss=7.61e-6, test_loss=8.25e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1702:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.77it/s, loss=6.4e-08, v_num=23, train_loss=7.61e-6, test_loss=8.25e-6]\u001b[A\n",
      "Epoch 1702: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.25it/s, loss=6.4e-08, v_num=23, train_loss=7.74e-6, test_loss=8.38e-6]\u001b[A\n",
      "Epoch 1703:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.78it/s, loss=7.09e-08, v_num=23, train_loss=7.74e-6, test_loss=8.38e-6]\u001b[AAdjusting learning rate of group 0 to 1.4047e-04.\n",
      "Epoch 1703:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.42it/s, loss=6.85e-08, v_num=23, train_loss=7.74e-6, test_loss=8.38e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1703:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.82it/s, loss=6.85e-08, v_num=23, train_loss=7.74e-6, test_loss=8.38e-6]\u001b[A\n",
      "Epoch 1703: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.88it/s, loss=6.85e-08, v_num=23, train_loss=7.67e-6, test_loss=8.28e-6]\u001b[A\n",
      "Epoch 1704:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.18it/s, loss=7.18e-08, v_num=23, train_loss=7.67e-6, test_loss=8.28e-6]\u001b[AAdjusting learning rate of group 0 to 1.4012e-04.\n",
      "Epoch 1704:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.70it/s, loss=6.95e-08, v_num=23, train_loss=7.67e-6, test_loss=8.28e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1704:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.33it/s, loss=6.95e-08, v_num=23, train_loss=7.67e-6, test_loss=8.28e-6]\u001b[A\n",
      "Epoch 1704: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.65it/s, loss=6.95e-08, v_num=23, train_loss=7.25e-6, test_loss=7.87e-6]\u001b[A\n",
      "Epoch 1705:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.01it/s, loss=7.36e-08, v_num=23, train_loss=7.25e-6, test_loss=7.87e-6]\u001b[AAdjusting learning rate of group 0 to 1.3977e-04.\n",
      "Epoch 1705:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.84it/s, loss=7.15e-08, v_num=23, train_loss=7.25e-6, test_loss=7.87e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1705:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.74it/s, loss=7.15e-08, v_num=23, train_loss=7.25e-6, test_loss=7.87e-6]\u001b[A\n",
      "Epoch 1705: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.28it/s, loss=7.15e-08, v_num=23, train_loss=7.26e-6, test_loss=7.86e-6]\u001b[A\n",
      "Epoch 1706:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.90it/s, loss=7.65e-08, v_num=23, train_loss=7.26e-6, test_loss=7.86e-6]\u001b[AAdjusting learning rate of group 0 to 1.3942e-04.\n",
      "Epoch 1706:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.10it/s, loss=7.33e-08, v_num=23, train_loss=7.26e-6, test_loss=7.86e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1706:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.12it/s, loss=7.33e-08, v_num=23, train_loss=7.26e-6, test_loss=7.86e-6]\u001b[A\n",
      "Epoch 1706: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.64it/s, loss=7.33e-08, v_num=23, train_loss=8.03e-6, test_loss=8.67e-6]\u001b[A\n",
      "Epoch 1707:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.96it/s, loss=7.73e-08, v_num=23, train_loss=8.03e-6, test_loss=8.67e-6]\u001b[AAdjusting learning rate of group 0 to 1.3907e-04.\n",
      "Epoch 1707:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.71it/s, loss=7.11e-08, v_num=23, train_loss=8.03e-6, test_loss=8.67e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1707:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.38it/s, loss=7.11e-08, v_num=23, train_loss=8.03e-6, test_loss=8.67e-6]\u001b[A\n",
      "Epoch 1707: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.86it/s, loss=7.11e-08, v_num=23, train_loss=7.28e-6, test_loss=7.92e-6]\u001b[A\n",
      "Epoch 1708:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.75it/s, loss=7.11e-08, v_num=23, train_loss=7.28e-6, test_loss=7.92e-6]\u001b[AAdjusting learning rate of group 0 to 1.3872e-04.\n",
      "Epoch 1708:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.05it/s, loss=6.84e-08, v_num=23, train_loss=7.28e-6, test_loss=7.92e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1708:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.68it/s, loss=6.84e-08, v_num=23, train_loss=7.28e-6, test_loss=7.92e-6]\u001b[A\n",
      "Epoch 1708: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.08it/s, loss=6.84e-08, v_num=23, train_loss=6.87e-6, test_loss=7.58e-6]\u001b[A\n",
      "Epoch 1709:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.66it/s, loss=7.39e-08, v_num=23, train_loss=6.87e-6, test_loss=7.58e-6]\u001b[AAdjusting learning rate of group 0 to 1.3838e-04.\n",
      "Epoch 1709:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.98it/s, loss=7.05e-08, v_num=23, train_loss=6.87e-6, test_loss=7.58e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1709:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.72it/s, loss=7.05e-08, v_num=23, train_loss=6.87e-6, test_loss=7.58e-6]\u001b[A\n",
      "Epoch 1709: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.12it/s, loss=7.05e-08, v_num=23, train_loss=7.52e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1710:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.49it/s, loss=1.13e-07, v_num=23, train_loss=7.52e-6, test_loss=8.17e-6]\u001b[AAdjusting learning rate of group 0 to 1.3803e-04.\n",
      "Epoch 1710:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.58it/s, loss=1.12e-07, v_num=23, train_loss=7.52e-6, test_loss=8.17e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1710:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.43it/s, loss=1.12e-07, v_num=23, train_loss=7.52e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1710: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.26it/s, loss=1.12e-07, v_num=23, train_loss=7.56e-6, test_loss=8.35e-6]\u001b[A\n",
      "Epoch 1711:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.10it/s, loss=6.54e-08, v_num=23, train_loss=7.56e-6, test_loss=8.35e-6]\u001b[AAdjusting learning rate of group 0 to 1.3769e-04.\n",
      "Epoch 1711:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.72it/s, loss=6.18e-08, v_num=23, train_loss=7.56e-6, test_loss=8.35e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1711:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.80it/s, loss=6.18e-08, v_num=23, train_loss=7.56e-6, test_loss=8.35e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1711: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.73it/s, loss=6.18e-08, v_num=23, train_loss=7.65e-6, test_loss=8.29e-6]\u001b[A\n",
      "Epoch 1712:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.66it/s, loss=6.67e-08, v_num=23, train_loss=7.65e-6, test_loss=8.29e-6]\u001b[AAdjusting learning rate of group 0 to 1.3734e-04.\n",
      "Epoch 1712:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.14it/s, loss=6.39e-08, v_num=23, train_loss=7.65e-6, test_loss=8.29e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1712:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.41it/s, loss=6.39e-08, v_num=23, train_loss=7.65e-6, test_loss=8.29e-6]\u001b[A\n",
      "Epoch 1712: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.65it/s, loss=6.39e-08, v_num=23, train_loss=6.69e-6, test_loss=7.3e-6]\u001b[A\n",
      "Epoch 1713:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.18it/s, loss=7.24e-08, v_num=23, train_loss=6.69e-6, test_loss=7.3e-6]\u001b[AAdjusting learning rate of group 0 to 1.3700e-04.\n",
      "Epoch 1713:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.10it/s, loss=7.03e-08, v_num=23, train_loss=6.69e-6, test_loss=7.3e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1713:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.14it/s, loss=7.03e-08, v_num=23, train_loss=6.69e-6, test_loss=7.3e-6]\u001b[A\n",
      "Epoch 1713: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.33it/s, loss=7.03e-08, v_num=23, train_loss=7.34e-6, test_loss=8.03e-6]\u001b[A\n",
      "Epoch 1714:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.35it/s, loss=6.6e-08, v_num=23, train_loss=7.34e-6, test_loss=8.03e-6]\u001b[AAdjusting learning rate of group 0 to 1.3666e-04.\n",
      "Epoch 1714:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.62it/s, loss=6.34e-08, v_num=23, train_loss=7.34e-6, test_loss=8.03e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1714:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.44it/s, loss=6.34e-08, v_num=23, train_loss=7.34e-6, test_loss=8.03e-6]\u001b[A\n",
      "Epoch 1714: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.68it/s, loss=6.34e-08, v_num=23, train_loss=7.33e-6, test_loss=7.92e-6]\u001b[A\n",
      "Epoch 1715:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.04it/s, loss=7.48e-08, v_num=23, train_loss=7.33e-6, test_loss=7.92e-6]\u001b[AAdjusting learning rate of group 0 to 1.3632e-04.\n",
      "Epoch 1715:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.07it/s, loss=7.23e-08, v_num=23, train_loss=7.33e-6, test_loss=7.92e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1715:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.32it/s, loss=7.23e-08, v_num=23, train_loss=7.33e-6, test_loss=7.92e-6]\u001b[A\n",
      "Epoch 1715: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.70it/s, loss=7.23e-08, v_num=23, train_loss=7.55e-6, test_loss=8.22e-6]\u001b[A\n",
      "Epoch 1716:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.23it/s, loss=7.38e-08, v_num=23, train_loss=7.55e-6, test_loss=8.22e-6]\u001b[AAdjusting learning rate of group 0 to 1.3597e-04.\n",
      "Epoch 1716:  50%|███████████████████                   | 79/158 [00:00<00:00, 135.59it/s, loss=7.16e-08, v_num=23, train_loss=7.55e-6, test_loss=8.22e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1716:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.40it/s, loss=7.16e-08, v_num=23, train_loss=7.55e-6, test_loss=8.22e-6]\u001b[A\n",
      "Epoch 1716: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.91it/s, loss=7.16e-08, v_num=23, train_loss=7.87e-6, test_loss=8.38e-6]\u001b[A\n",
      "Epoch 1717:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.94it/s, loss=7.36e-08, v_num=23, train_loss=7.87e-6, test_loss=8.38e-6]\u001b[AAdjusting learning rate of group 0 to 1.3563e-04.\n",
      "Epoch 1717:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.14it/s, loss=7.15e-08, v_num=23, train_loss=7.87e-6, test_loss=8.38e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1717:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.20it/s, loss=7.15e-08, v_num=23, train_loss=7.87e-6, test_loss=8.38e-6]\u001b[A\n",
      "Epoch 1717: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.24it/s, loss=7.15e-08, v_num=23, train_loss=7.5e-6, test_loss=8.05e-6]\u001b[A\n",
      "Epoch 1718:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.12it/s, loss=8.99e-08, v_num=23, train_loss=7.5e-6, test_loss=8.05e-6]\u001b[AAdjusting learning rate of group 0 to 1.3530e-04.\n",
      "Epoch 1718:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.38it/s, loss=8.65e-08, v_num=23, train_loss=7.5e-6, test_loss=8.05e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1718:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.85it/s, loss=8.65e-08, v_num=23, train_loss=7.5e-6, test_loss=8.05e-6]\u001b[A\n",
      "Epoch 1718: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.76it/s, loss=8.65e-08, v_num=23, train_loss=7.74e-6, test_loss=8.33e-6]\u001b[A\n",
      "Epoch 1719:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.72it/s, loss=7.39e-08, v_num=23, train_loss=7.74e-6, test_loss=8.33e-6]\u001b[AAdjusting learning rate of group 0 to 1.3496e-04.\n",
      "Epoch 1719:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.41it/s, loss=7.08e-08, v_num=23, train_loss=7.74e-6, test_loss=8.33e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1719:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.76it/s, loss=7.08e-08, v_num=23, train_loss=7.74e-6, test_loss=8.33e-6]\u001b[A\n",
      "Epoch 1719: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.29it/s, loss=7.08e-08, v_num=23, train_loss=7.48e-6, test_loss=8.01e-6]\u001b[A\n",
      "Epoch 1720:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.05it/s, loss=8.32e-08, v_num=23, train_loss=7.48e-6, test_loss=8.01e-6]\u001b[AAdjusting learning rate of group 0 to 1.3462e-04.\n",
      "Epoch 1720:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.53it/s, loss=7.96e-08, v_num=23, train_loss=7.48e-6, test_loss=8.01e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1720:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.09it/s, loss=7.96e-08, v_num=23, train_loss=7.48e-6, test_loss=8.01e-6]\u001b[A\n",
      "Epoch 1720: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.07it/s, loss=7.96e-08, v_num=23, train_loss=7.58e-6, test_loss=8.1e-6]\u001b[A\n",
      "Epoch 1721:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.50it/s, loss=6.97e-08, v_num=23, train_loss=7.58e-6, test_loss=8.1e-6]\u001b[AAdjusting learning rate of group 0 to 1.3428e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1721:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.77it/s, loss=6.73e-08, v_num=23, train_loss=7.58e-6, test_loss=8.1e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1721:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.54it/s, loss=6.73e-08, v_num=23, train_loss=7.58e-6, test_loss=8.1e-6]\u001b[A\n",
      "Epoch 1721: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.99it/s, loss=6.73e-08, v_num=23, train_loss=7.29e-6, test_loss=7.94e-6]\u001b[A\n",
      "Epoch 1722:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.15it/s, loss=7.75e-08, v_num=23, train_loss=7.29e-6, test_loss=7.94e-6]\u001b[AAdjusting learning rate of group 0 to 1.3395e-04.\n",
      "Epoch 1722:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.05it/s, loss=7.53e-08, v_num=23, train_loss=7.29e-6, test_loss=7.94e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1722:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.45it/s, loss=7.53e-08, v_num=23, train_loss=7.29e-6, test_loss=7.94e-6]\u001b[A\n",
      "Epoch 1722: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.17it/s, loss=7.53e-08, v_num=23, train_loss=7.14e-6, test_loss=7.77e-6]\u001b[A\n",
      "Epoch 1723:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.96it/s, loss=6.71e-08, v_num=23, train_loss=7.14e-6, test_loss=7.77e-6]\u001b[AAdjusting learning rate of group 0 to 1.3361e-04.\n",
      "Epoch 1723:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.62it/s, loss=6.39e-08, v_num=23, train_loss=7.14e-6, test_loss=7.77e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1723:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.37it/s, loss=6.39e-08, v_num=23, train_loss=7.14e-6, test_loss=7.77e-6]\u001b[A\n",
      "Epoch 1723: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.88it/s, loss=6.39e-08, v_num=23, train_loss=7.4e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1724:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.39it/s, loss=7.44e-08, v_num=23, train_loss=7.4e-6, test_loss=7.97e-6]\u001b[AAdjusting learning rate of group 0 to 1.3328e-04.\n",
      "Epoch 1724:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.80it/s, loss=6.97e-08, v_num=23, train_loss=7.4e-6, test_loss=7.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1724:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.93it/s, loss=6.97e-08, v_num=23, train_loss=7.4e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1724: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.97it/s, loss=6.97e-08, v_num=23, train_loss=7.57e-6, test_loss=8.12e-6]\u001b[A\n",
      "Epoch 1725:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.41it/s, loss=6.46e-08, v_num=23, train_loss=7.57e-6, test_loss=8.12e-6]\u001b[AAdjusting learning rate of group 0 to 1.3295e-04.\n",
      "Epoch 1725:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.29it/s, loss=6.11e-08, v_num=23, train_loss=7.57e-6, test_loss=8.12e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1725:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.48it/s, loss=6.11e-08, v_num=23, train_loss=7.57e-6, test_loss=8.12e-6]\u001b[A\n",
      "Epoch 1725: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.44it/s, loss=6.11e-08, v_num=23, train_loss=7.41e-6, test_loss=8.02e-6]\u001b[A\n",
      "Epoch 1726:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.34it/s, loss=6.84e-08, v_num=23, train_loss=7.41e-6, test_loss=8.02e-6]\u001b[AAdjusting learning rate of group 0 to 1.3261e-04.\n",
      "Epoch 1726:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.58it/s, loss=6.61e-08, v_num=23, train_loss=7.41e-6, test_loss=8.02e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1726:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.88it/s, loss=6.61e-08, v_num=23, train_loss=7.41e-6, test_loss=8.02e-6]\u001b[A\n",
      "Epoch 1726: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.67it/s, loss=6.61e-08, v_num=23, train_loss=7.44e-6, test_loss=8.07e-6]\u001b[A\n",
      "Epoch 1727:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.68it/s, loss=8.1e-08, v_num=23, train_loss=7.44e-6, test_loss=8.07e-6]\u001b[AAdjusting learning rate of group 0 to 1.3228e-04.\n",
      "Epoch 1727:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.65it/s, loss=7.87e-08, v_num=23, train_loss=7.44e-6, test_loss=8.07e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1727:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.48it/s, loss=7.87e-08, v_num=23, train_loss=7.44e-6, test_loss=8.07e-6]\u001b[A\n",
      "Epoch 1727: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.92it/s, loss=7.87e-08, v_num=23, train_loss=7.85e-6, test_loss=8.53e-6]\u001b[A\n",
      "Epoch 1728:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.00it/s, loss=9.46e-08, v_num=23, train_loss=7.85e-6, test_loss=8.53e-6]\u001b[AAdjusting learning rate of group 0 to 1.3195e-04.\n",
      "Epoch 1728:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.98it/s, loss=9.2e-08, v_num=23, train_loss=7.85e-6, test_loss=8.53e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1728:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.58it/s, loss=9.2e-08, v_num=23, train_loss=7.85e-6, test_loss=8.53e-6]\u001b[A\n",
      "Epoch 1728: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 171.39it/s, loss=9.2e-08, v_num=23, train_loss=7.37e-6, test_loss=8.02e-6]\u001b[A\n",
      "Epoch 1729:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.77it/s, loss=7.12e-08, v_num=23, train_loss=7.37e-6, test_loss=8.02e-6]\u001b[AAdjusting learning rate of group 0 to 1.3162e-04.\n",
      "Epoch 1729:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.54it/s, loss=6.86e-08, v_num=23, train_loss=7.37e-6, test_loss=8.02e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1729:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.34it/s, loss=6.86e-08, v_num=23, train_loss=7.37e-6, test_loss=8.02e-6]\u001b[A\n",
      "Epoch 1729: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.58it/s, loss=6.86e-08, v_num=23, train_loss=7.37e-6, test_loss=8.01e-6]\u001b[A\n",
      "Epoch 1730:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.51it/s, loss=7.45e-08, v_num=23, train_loss=7.37e-6, test_loss=8.01e-6]\u001b[AAdjusting learning rate of group 0 to 1.3129e-04.\n",
      "Epoch 1730:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.17it/s, loss=7.23e-08, v_num=23, train_loss=7.37e-6, test_loss=8.01e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1730:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.04it/s, loss=7.23e-08, v_num=23, train_loss=7.37e-6, test_loss=8.01e-6]\u001b[A\n",
      "Epoch 1730: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.54it/s, loss=7.23e-08, v_num=23, train_loss=7.68e-6, test_loss=8.34e-6]\u001b[A\n",
      "Epoch 1731:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.14it/s, loss=1.05e-07, v_num=23, train_loss=7.68e-6, test_loss=8.34e-6]\u001b[AAdjusting learning rate of group 0 to 1.3096e-04.\n",
      "Epoch 1731:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.34it/s, loss=1.02e-07, v_num=23, train_loss=7.68e-6, test_loss=8.34e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1731:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.51it/s, loss=1.02e-07, v_num=23, train_loss=7.68e-6, test_loss=8.34e-6]\u001b[A\n",
      "Epoch 1731: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.89it/s, loss=1.02e-07, v_num=23, train_loss=7.13e-6, test_loss=7.75e-6]\u001b[A\n",
      "Epoch 1732:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.22it/s, loss=6.94e-08, v_num=23, train_loss=7.13e-6, test_loss=7.75e-6]\u001b[AAdjusting learning rate of group 0 to 1.3064e-04.\n",
      "Epoch 1732:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.01it/s, loss=6.73e-08, v_num=23, train_loss=7.13e-6, test_loss=7.75e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1732:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.93it/s, loss=6.73e-08, v_num=23, train_loss=7.13e-6, test_loss=7.75e-6]\u001b[A\n",
      "Epoch 1732: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.36it/s, loss=6.73e-08, v_num=23, train_loss=7.33e-6, test_loss=7.98e-6]\u001b[A\n",
      "Epoch 1733:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.46it/s, loss=7.02e-08, v_num=23, train_loss=7.33e-6, test_loss=7.98e-6]\u001b[AAdjusting learning rate of group 0 to 1.3031e-04.\n",
      "Epoch 1733:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.15it/s, loss=6.83e-08, v_num=23, train_loss=7.33e-6, test_loss=7.98e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1733:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.17it/s, loss=6.83e-08, v_num=23, train_loss=7.33e-6, test_loss=7.98e-6]\u001b[A\n",
      "Epoch 1733: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.61it/s, loss=6.83e-08, v_num=23, train_loss=7.53e-6, test_loss=8.19e-6]\u001b[A\n",
      "Epoch 1734:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.15it/s, loss=6.45e-08, v_num=23, train_loss=7.53e-6, test_loss=8.19e-6]\u001b[AAdjusting learning rate of group 0 to 1.2998e-04.\n",
      "Epoch 1734:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.59it/s, loss=6.16e-08, v_num=23, train_loss=7.53e-6, test_loss=8.19e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1734:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.62it/s, loss=6.16e-08, v_num=23, train_loss=7.53e-6, test_loss=8.19e-6]\u001b[A\n",
      "Epoch 1734: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.45it/s, loss=6.16e-08, v_num=23, train_loss=7.4e-6, test_loss=8.07e-6]\u001b[A\n",
      "Epoch 1735:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.19it/s, loss=6.66e-08, v_num=23, train_loss=7.4e-6, test_loss=8.07e-6]\u001b[AAdjusting learning rate of group 0 to 1.2966e-04.\n",
      "Epoch 1735:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.86it/s, loss=6.35e-08, v_num=23, train_loss=7.4e-6, test_loss=8.07e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1735:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.87it/s, loss=6.35e-08, v_num=23, train_loss=7.4e-6, test_loss=8.07e-6]\u001b[A\n",
      "Epoch 1735: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 172.19it/s, loss=6.35e-08, v_num=23, train_loss=7.41e-6, test_loss=7.99e-6]\u001b[A\n",
      "Epoch 1736:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.65it/s, loss=6.74e-08, v_num=23, train_loss=7.41e-6, test_loss=7.99e-6]\u001b[AAdjusting learning rate of group 0 to 1.2933e-04.\n",
      "Epoch 1736:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.38it/s, loss=6.57e-08, v_num=23, train_loss=7.41e-6, test_loss=7.99e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1736:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.10it/s, loss=6.57e-08, v_num=23, train_loss=7.41e-6, test_loss=7.99e-6]\u001b[A\n",
      "Epoch 1736: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.20it/s, loss=6.57e-08, v_num=23, train_loss=7.58e-6, test_loss=8.12e-6]\u001b[A\n",
      "Epoch 1737:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.55it/s, loss=6.87e-08, v_num=23, train_loss=7.58e-6, test_loss=8.12e-6]\u001b[AAdjusting learning rate of group 0 to 1.2901e-04.\n",
      "Epoch 1737:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.86it/s, loss=6.6e-08, v_num=23, train_loss=7.58e-6, test_loss=8.12e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1737:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.17it/s, loss=6.6e-08, v_num=23, train_loss=7.58e-6, test_loss=8.12e-6]\u001b[A\n",
      "Epoch 1737: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.63it/s, loss=6.6e-08, v_num=23, train_loss=8.02e-6, test_loss=8.63e-6]\u001b[A\n",
      "Epoch 1738:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.09it/s, loss=7.07e-08, v_num=23, train_loss=8.02e-6, test_loss=8.63e-6]\u001b[AAdjusting learning rate of group 0 to 1.2869e-04.\n",
      "Epoch 1738:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.20it/s, loss=6.78e-08, v_num=23, train_loss=8.02e-6, test_loss=8.63e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1738:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.50it/s, loss=6.78e-08, v_num=23, train_loss=8.02e-6, test_loss=8.63e-6]\u001b[A\n",
      "Epoch 1738: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.66it/s, loss=6.78e-08, v_num=23, train_loss=7.22e-6, test_loss=7.82e-6]\u001b[A\n",
      "Epoch 1739:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.24it/s, loss=6.56e-08, v_num=23, train_loss=7.22e-6, test_loss=7.82e-6]\u001b[AAdjusting learning rate of group 0 to 1.2837e-04.\n",
      "Epoch 1739:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.16it/s, loss=6.39e-08, v_num=23, train_loss=7.22e-6, test_loss=7.82e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1739:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.23it/s, loss=6.39e-08, v_num=23, train_loss=7.22e-6, test_loss=7.82e-6]\u001b[A\n",
      "Epoch 1739: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.46it/s, loss=6.39e-08, v_num=23, train_loss=7.53e-6, test_loss=8.15e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1740:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.85it/s, loss=7.11e-08, v_num=23, train_loss=7.53e-6, test_loss=8.15e-6]\u001b[AAdjusting learning rate of group 0 to 1.2805e-04.\n",
      "Epoch 1740:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.29it/s, loss=6.83e-08, v_num=23, train_loss=7.53e-6, test_loss=8.15e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1740:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.53it/s, loss=6.83e-08, v_num=23, train_loss=7.53e-6, test_loss=8.15e-6]\u001b[A\n",
      "Epoch 1740: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.45it/s, loss=6.83e-08, v_num=23, train_loss=7.36e-6, test_loss=8.02e-6]\u001b[A\n",
      "Epoch 1741:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.83it/s, loss=7.19e-08, v_num=23, train_loss=7.36e-6, test_loss=8.02e-6]\u001b[AAdjusting learning rate of group 0 to 1.2773e-04.\n",
      "Epoch 1741:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.59it/s, loss=6.99e-08, v_num=23, train_loss=7.36e-6, test_loss=8.02e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1741:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.84it/s, loss=6.99e-08, v_num=23, train_loss=7.36e-6, test_loss=8.02e-6]\u001b[A\n",
      "Epoch 1741: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.76it/s, loss=6.99e-08, v_num=23, train_loss=7.11e-6, test_loss=7.69e-6]\u001b[A\n",
      "Epoch 1742:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.49it/s, loss=6.74e-08, v_num=23, train_loss=7.11e-6, test_loss=7.69e-6]\u001b[AAdjusting learning rate of group 0 to 1.2741e-04.\n",
      "Epoch 1742:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.73it/s, loss=6.45e-08, v_num=23, train_loss=7.11e-6, test_loss=7.69e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1742:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.45it/s, loss=6.45e-08, v_num=23, train_loss=7.11e-6, test_loss=7.69e-6]\u001b[A\n",
      "Epoch 1742: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.25it/s, loss=6.45e-08, v_num=23, train_loss=7.16e-6, test_loss=7.8e-6]\u001b[A\n",
      "Epoch 1743:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.40it/s, loss=6.79e-08, v_num=23, train_loss=7.16e-6, test_loss=7.8e-6]\u001b[AAdjusting learning rate of group 0 to 1.2709e-04.\n",
      "Epoch 1743:  50%|████████████████████                    | 79/158 [00:00<00:00, 136.11it/s, loss=6.5e-08, v_num=23, train_loss=7.16e-6, test_loss=7.8e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1743:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 131.85it/s, loss=6.5e-08, v_num=23, train_loss=7.16e-6, test_loss=7.8e-6]\u001b[A\n",
      "Epoch 1743: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.24it/s, loss=6.5e-08, v_num=23, train_loss=7.29e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1744:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.22it/s, loss=7.09e-08, v_num=23, train_loss=7.29e-6, test_loss=7.93e-6]\u001b[AAdjusting learning rate of group 0 to 1.2677e-04.\n",
      "Epoch 1744:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.29it/s, loss=6.72e-08, v_num=23, train_loss=7.29e-6, test_loss=7.93e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1744:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.81it/s, loss=6.72e-08, v_num=23, train_loss=7.29e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1744: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.64it/s, loss=6.72e-08, v_num=23, train_loss=7.42e-6, test_loss=8.08e-6]\u001b[A\n",
      "Epoch 1745:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.61it/s, loss=7.17e-08, v_num=23, train_loss=7.42e-6, test_loss=8.08e-6]\u001b[AAdjusting learning rate of group 0 to 1.2645e-04.\n",
      "Epoch 1745:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.86it/s, loss=6.96e-08, v_num=23, train_loss=7.42e-6, test_loss=8.08e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1745:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.49it/s, loss=6.96e-08, v_num=23, train_loss=7.42e-6, test_loss=8.08e-6]\u001b[A\n",
      "Epoch 1745: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.65it/s, loss=6.96e-08, v_num=23, train_loss=7.08e-6, test_loss=7.66e-6]\u001b[A\n",
      "Epoch 1746:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.87it/s, loss=7.04e-08, v_num=23, train_loss=7.08e-6, test_loss=7.66e-6]\u001b[AAdjusting learning rate of group 0 to 1.2614e-04.\n",
      "Epoch 1746:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.00it/s, loss=6.58e-08, v_num=23, train_loss=7.08e-6, test_loss=7.66e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1746:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.71it/s, loss=6.58e-08, v_num=23, train_loss=7.08e-6, test_loss=7.66e-6]\u001b[A\n",
      "Epoch 1746: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.45it/s, loss=6.58e-08, v_num=23, train_loss=7.63e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1747:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.84it/s, loss=7.47e-08, v_num=23, train_loss=7.63e-6, test_loss=8.17e-6]\u001b[AAdjusting learning rate of group 0 to 1.2582e-04.\n",
      "Epoch 1747:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.55it/s, loss=7.15e-08, v_num=23, train_loss=7.63e-6, test_loss=8.17e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1747:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.55it/s, loss=7.15e-08, v_num=23, train_loss=7.63e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1747: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.78it/s, loss=7.15e-08, v_num=23, train_loss=7.24e-6, test_loss=7.88e-6]\u001b[A\n",
      "Epoch 1748:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.22it/s, loss=7.02e-08, v_num=23, train_loss=7.24e-6, test_loss=7.88e-6]\u001b[AAdjusting learning rate of group 0 to 1.2551e-04.\n",
      "Epoch 1748:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.42it/s, loss=6.73e-08, v_num=23, train_loss=7.24e-6, test_loss=7.88e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1748:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.72it/s, loss=6.73e-08, v_num=23, train_loss=7.24e-6, test_loss=7.88e-6]\u001b[A\n",
      "Epoch 1748: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.35it/s, loss=6.73e-08, v_num=23, train_loss=7.23e-6, test_loss=7.83e-6]\u001b[A\n",
      "Epoch 1749:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.43it/s, loss=8.29e-08, v_num=23, train_loss=7.23e-6, test_loss=7.83e-6]\u001b[AAdjusting learning rate of group 0 to 1.2519e-04.\n",
      "Epoch 1749:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.18it/s, loss=8.05e-08, v_num=23, train_loss=7.23e-6, test_loss=7.83e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1749:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.89it/s, loss=8.05e-08, v_num=23, train_loss=7.23e-6, test_loss=7.83e-6]\u001b[A\n",
      "Epoch 1749: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.58it/s, loss=8.05e-08, v_num=23, train_loss=7.59e-6, test_loss=8.19e-6]\u001b[A\n",
      "Epoch 1750:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.72it/s, loss=7e-08, v_num=23, train_loss=7.59e-6, test_loss=8.19e-6]\u001b[AAdjusting learning rate of group 0 to 1.2488e-04.\n",
      "Epoch 1750:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.63it/s, loss=6.72e-08, v_num=23, train_loss=7.59e-6, test_loss=8.19e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1750:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.89it/s, loss=6.72e-08, v_num=23, train_loss=7.59e-6, test_loss=8.19e-6]\u001b[A\n",
      "Epoch 1750: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.59it/s, loss=6.72e-08, v_num=23, train_loss=7.24e-6, test_loss=7.84e-6]\u001b[A\n",
      "Epoch 1751:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.99it/s, loss=6.53e-08, v_num=23, train_loss=7.24e-6, test_loss=7.84e-6]\u001b[AAdjusting learning rate of group 0 to 1.2457e-04.\n",
      "Epoch 1751:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.77it/s, loss=6.32e-08, v_num=23, train_loss=7.24e-6, test_loss=7.84e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1751:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.51it/s, loss=6.32e-08, v_num=23, train_loss=7.24e-6, test_loss=7.84e-6]\u001b[A\n",
      "Epoch 1751: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.67it/s, loss=6.32e-08, v_num=23, train_loss=7.5e-6, test_loss=8.07e-6]\u001b[A\n",
      "Epoch 1752:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.59it/s, loss=7.56e-08, v_num=23, train_loss=7.5e-6, test_loss=8.07e-6]\u001b[AAdjusting learning rate of group 0 to 1.2426e-04.\n",
      "Epoch 1752:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.59it/s, loss=7.25e-08, v_num=23, train_loss=7.5e-6, test_loss=8.07e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1752:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.14it/s, loss=7.25e-08, v_num=23, train_loss=7.5e-6, test_loss=8.07e-6]\u001b[A\n",
      "Epoch 1752: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.12it/s, loss=7.25e-08, v_num=23, train_loss=7.4e-6, test_loss=8.04e-6]\u001b[A\n",
      "Epoch 1753:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.87it/s, loss=6.71e-08, v_num=23, train_loss=7.4e-6, test_loss=8.04e-6]\u001b[AAdjusting learning rate of group 0 to 1.2395e-04.\n",
      "Epoch 1753:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.74it/s, loss=6.39e-08, v_num=23, train_loss=7.4e-6, test_loss=8.04e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1753:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.46it/s, loss=6.39e-08, v_num=23, train_loss=7.4e-6, test_loss=8.04e-6]\u001b[A\n",
      "Epoch 1753: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.10it/s, loss=6.39e-08, v_num=23, train_loss=7.27e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1754:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.58it/s, loss=7.25e-08, v_num=23, train_loss=7.27e-6, test_loss=7.97e-6]\u001b[AAdjusting learning rate of group 0 to 1.2364e-04.\n",
      "Epoch 1754:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.16it/s, loss=6.95e-08, v_num=23, train_loss=7.27e-6, test_loss=7.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1754:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.33it/s, loss=6.95e-08, v_num=23, train_loss=7.27e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1754: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.54it/s, loss=6.95e-08, v_num=23, train_loss=7.17e-6, test_loss=7.86e-6]\u001b[A\n",
      "Epoch 1755:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.10it/s, loss=7.89e-08, v_num=23, train_loss=7.17e-6, test_loss=7.86e-6]\u001b[AAdjusting learning rate of group 0 to 1.2333e-04.\n",
      "Epoch 1755:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.79it/s, loss=7.55e-08, v_num=23, train_loss=7.17e-6, test_loss=7.86e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1755:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.85it/s, loss=7.55e-08, v_num=23, train_loss=7.17e-6, test_loss=7.86e-6]\u001b[A\n",
      "Epoch 1755: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.80it/s, loss=7.55e-08, v_num=23, train_loss=7.11e-6, test_loss=7.75e-6]\u001b[A\n",
      "Epoch 1756:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.02it/s, loss=7.55e-08, v_num=23, train_loss=7.11e-6, test_loss=7.75e-6]\u001b[AAdjusting learning rate of group 0 to 1.2302e-04.\n",
      "Epoch 1756:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.12it/s, loss=7.23e-08, v_num=23, train_loss=7.11e-6, test_loss=7.75e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1756:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.55it/s, loss=7.23e-08, v_num=23, train_loss=7.11e-6, test_loss=7.75e-6]\u001b[A\n",
      "Epoch 1756: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.13it/s, loss=7.23e-08, v_num=23, train_loss=7.57e-6, test_loss=8.27e-6]\u001b[A\n",
      "Epoch 1757:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.82it/s, loss=6.82e-08, v_num=23, train_loss=7.57e-6, test_loss=8.27e-6]\u001b[AAdjusting learning rate of group 0 to 1.2271e-04.\n",
      "Epoch 1757:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.59it/s, loss=6.66e-08, v_num=23, train_loss=7.57e-6, test_loss=8.27e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1757:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.37it/s, loss=6.66e-08, v_num=23, train_loss=7.57e-6, test_loss=8.27e-6]\u001b[A\n",
      "Epoch 1757: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.42it/s, loss=6.66e-08, v_num=23, train_loss=7.41e-6, test_loss=8.06e-6]\u001b[A\n",
      "Epoch 1758:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.56it/s, loss=9.44e-08, v_num=23, train_loss=7.41e-6, test_loss=8.06e-6]\u001b[AAdjusting learning rate of group 0 to 1.2240e-04.\n",
      "Epoch 1758:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.48it/s, loss=9.14e-08, v_num=23, train_loss=7.41e-6, test_loss=8.06e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1758:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.09it/s, loss=9.14e-08, v_num=23, train_loss=7.41e-6, test_loss=8.06e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1758: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.35it/s, loss=9.14e-08, v_num=23, train_loss=7.66e-6, test_loss=8.26e-6]\u001b[A\n",
      "Epoch 1759:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.65it/s, loss=7.12e-08, v_num=23, train_loss=7.66e-6, test_loss=8.26e-6]\u001b[AAdjusting learning rate of group 0 to 1.2210e-04.\n",
      "Epoch 1759:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.86it/s, loss=6.75e-08, v_num=23, train_loss=7.66e-6, test_loss=8.26e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1759:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.75it/s, loss=6.75e-08, v_num=23, train_loss=7.66e-6, test_loss=8.26e-6]\u001b[A\n",
      "Epoch 1759: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.55it/s, loss=6.75e-08, v_num=23, train_loss=7.25e-6, test_loss=7.84e-6]\u001b[A\n",
      "Epoch 1760:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.99it/s, loss=7.11e-08, v_num=23, train_loss=7.25e-6, test_loss=7.84e-6]\u001b[AAdjusting learning rate of group 0 to 1.2179e-04.\n",
      "Epoch 1760:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.34it/s, loss=6.69e-08, v_num=23, train_loss=7.25e-6, test_loss=7.84e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1760:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.71it/s, loss=6.69e-08, v_num=23, train_loss=7.25e-6, test_loss=7.84e-6]\u001b[A\n",
      "Epoch 1760: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.63it/s, loss=6.69e-08, v_num=23, train_loss=7.67e-6, test_loss=8.3e-6]\u001b[A\n",
      "Epoch 1761:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.65it/s, loss=7.11e-08, v_num=23, train_loss=7.67e-6, test_loss=8.3e-6]\u001b[AAdjusting learning rate of group 0 to 1.2149e-04.\n",
      "Epoch 1761:  50%|████████████████████                    | 79/158 [00:00<00:00, 138.41it/s, loss=6.8e-08, v_num=23, train_loss=7.67e-6, test_loss=8.3e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1761:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.40it/s, loss=6.8e-08, v_num=23, train_loss=7.67e-6, test_loss=8.3e-6]\u001b[A\n",
      "Epoch 1761: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.89it/s, loss=6.8e-08, v_num=23, train_loss=6.82e-6, test_loss=7.45e-6]\u001b[A\n",
      "Epoch 1762:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 145.61it/s, loss=6.83e-08, v_num=23, train_loss=6.82e-6, test_loss=7.45e-6]\u001b[AAdjusting learning rate of group 0 to 1.2119e-04.\n",
      "Epoch 1762:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.08it/s, loss=6.58e-08, v_num=23, train_loss=6.82e-6, test_loss=7.45e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1762:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.78it/s, loss=6.58e-08, v_num=23, train_loss=6.82e-6, test_loss=7.45e-6]\u001b[A\n",
      "Epoch 1762: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.76it/s, loss=6.58e-08, v_num=23, train_loss=7.5e-6, test_loss=8.11e-6]\u001b[A\n",
      "Epoch 1763:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.27it/s, loss=6.49e-08, v_num=23, train_loss=7.5e-6, test_loss=8.11e-6]\u001b[AAdjusting learning rate of group 0 to 1.2088e-04.\n",
      "Epoch 1763:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.46it/s, loss=6.21e-08, v_num=23, train_loss=7.5e-6, test_loss=8.11e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1763:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.74it/s, loss=6.21e-08, v_num=23, train_loss=7.5e-6, test_loss=8.11e-6]\u001b[A\n",
      "Epoch 1763: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 168.57it/s, loss=6.21e-08, v_num=23, train_loss=7e-6, test_loss=7.56e-6]\u001b[A\n",
      "Epoch 1764:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.76it/s, loss=7.01e-08, v_num=23, train_loss=7e-6, test_loss=7.56e-6]\u001b[AAdjusting learning rate of group 0 to 1.2058e-04.\n",
      "Epoch 1764:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 140.70it/s, loss=6.67e-08, v_num=23, train_loss=7e-6, test_loss=7.56e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1764:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 135.08it/s, loss=6.67e-08, v_num=23, train_loss=7e-6, test_loss=7.56e-6]\u001b[A\n",
      "Epoch 1764: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.02it/s, loss=6.67e-08, v_num=23, train_loss=8.35e-6, test_loss=9.02e-6]\u001b[A\n",
      "Epoch 1765:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.83it/s, loss=7.15e-08, v_num=23, train_loss=8.35e-6, test_loss=9.02e-6]\u001b[AAdjusting learning rate of group 0 to 1.2028e-04.\n",
      "Epoch 1765:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.48it/s, loss=6.92e-08, v_num=23, train_loss=8.35e-6, test_loss=9.02e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1765:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.95it/s, loss=6.92e-08, v_num=23, train_loss=8.35e-6, test_loss=9.02e-6]\u001b[A\n",
      "Epoch 1765: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.96it/s, loss=6.92e-08, v_num=23, train_loss=7.67e-6, test_loss=8.22e-6]\u001b[A\n",
      "Epoch 1766:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.93it/s, loss=6.79e-08, v_num=23, train_loss=7.67e-6, test_loss=8.22e-6]\u001b[AAdjusting learning rate of group 0 to 1.1998e-04.\n",
      "Epoch 1766:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.68it/s, loss=6.25e-08, v_num=23, train_loss=7.67e-6, test_loss=8.22e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1766:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.72it/s, loss=6.25e-08, v_num=23, train_loss=7.67e-6, test_loss=8.22e-6]\u001b[A\n",
      "Epoch 1766: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.66it/s, loss=6.25e-08, v_num=23, train_loss=7.32e-6, test_loss=7.96e-6]\u001b[A\n",
      "Epoch 1767:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.23it/s, loss=6.9e-08, v_num=23, train_loss=7.32e-6, test_loss=7.96e-6]\u001b[AAdjusting learning rate of group 0 to 1.1968e-04.\n",
      "Epoch 1767:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.08it/s, loss=6.7e-08, v_num=23, train_loss=7.32e-6, test_loss=7.96e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1767:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.59it/s, loss=6.7e-08, v_num=23, train_loss=7.32e-6, test_loss=7.96e-6]\u001b[A\n",
      "Epoch 1767: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.09it/s, loss=6.7e-08, v_num=23, train_loss=8.24e-6, test_loss=8.87e-6]\u001b[A\n",
      "Epoch 1768:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.30it/s, loss=7.49e-08, v_num=23, train_loss=8.24e-6, test_loss=8.87e-6]\u001b[AAdjusting learning rate of group 0 to 1.1938e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1768:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.56it/s, loss=7.09e-08, v_num=23, train_loss=8.24e-6, test_loss=8.87e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1768:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.86it/s, loss=7.09e-08, v_num=23, train_loss=8.24e-6, test_loss=8.87e-6]\u001b[A\n",
      "Epoch 1768: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.97it/s, loss=7.09e-08, v_num=23, train_loss=7.96e-6, test_loss=8.53e-6]\u001b[A\n",
      "Epoch 1769:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.57it/s, loss=6.63e-08, v_num=23, train_loss=7.96e-6, test_loss=8.53e-6]\u001b[AAdjusting learning rate of group 0 to 1.1908e-04.\n",
      "Epoch 1769:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.02it/s, loss=6.39e-08, v_num=23, train_loss=7.96e-6, test_loss=8.53e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1769:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.82it/s, loss=6.39e-08, v_num=23, train_loss=7.96e-6, test_loss=8.53e-6]\u001b[A\n",
      "Epoch 1769: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 163.86it/s, loss=6.39e-08, v_num=23, train_loss=7.3e-6, test_loss=7.94e-6]\u001b[A\n",
      "Epoch 1770:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.12it/s, loss=7.24e-08, v_num=23, train_loss=7.3e-6, test_loss=7.94e-6]\u001b[AAdjusting learning rate of group 0 to 1.1878e-04.\n",
      "Epoch 1770:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.22it/s, loss=6.91e-08, v_num=23, train_loss=7.3e-6, test_loss=7.94e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1770:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.63it/s, loss=6.91e-08, v_num=23, train_loss=7.3e-6, test_loss=7.94e-6]\u001b[A\n",
      "Epoch 1770: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.75it/s, loss=6.91e-08, v_num=23, train_loss=6.9e-6, test_loss=7.57e-6]\u001b[A\n",
      "Epoch 1771:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.44it/s, loss=6.2e-08, v_num=23, train_loss=6.9e-6, test_loss=7.57e-6]\u001b[AAdjusting learning rate of group 0 to 1.1849e-04.\n",
      "Epoch 1771:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.90it/s, loss=5.96e-08, v_num=23, train_loss=6.9e-6, test_loss=7.57e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1771:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.87it/s, loss=5.96e-08, v_num=23, train_loss=6.9e-6, test_loss=7.57e-6]\u001b[A\n",
      "Epoch 1771: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.57it/s, loss=5.96e-08, v_num=23, train_loss=7.57e-6, test_loss=8.19e-6]\u001b[A\n",
      "Epoch 1772:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.26it/s, loss=6.2e-08, v_num=23, train_loss=7.57e-6, test_loss=8.19e-6]\u001b[AAdjusting learning rate of group 0 to 1.1819e-04.\n",
      "Epoch 1772:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.86it/s, loss=5.93e-08, v_num=23, train_loss=7.57e-6, test_loss=8.19e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1772:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.68it/s, loss=5.93e-08, v_num=23, train_loss=7.57e-6, test_loss=8.19e-6]\u001b[A\n",
      "Epoch 1772: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.84it/s, loss=5.93e-08, v_num=23, train_loss=7.05e-6, test_loss=7.69e-6]\u001b[A\n",
      "Epoch 1773:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.70it/s, loss=8.09e-08, v_num=23, train_loss=7.05e-6, test_loss=7.69e-6]\u001b[AAdjusting learning rate of group 0 to 1.1789e-04.\n",
      "Epoch 1773:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.43it/s, loss=8.11e-08, v_num=23, train_loss=7.05e-6, test_loss=7.69e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1773:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.81it/s, loss=8.11e-08, v_num=23, train_loss=7.05e-6, test_loss=7.69e-6]\u001b[A\n",
      "Epoch 1773: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.67it/s, loss=8.11e-08, v_num=23, train_loss=7.85e-6, test_loss=8.48e-6]\u001b[A\n",
      "Epoch 1774:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.68it/s, loss=7.49e-08, v_num=23, train_loss=7.85e-6, test_loss=8.48e-6]\u001b[AAdjusting learning rate of group 0 to 1.1760e-04.\n",
      "Epoch 1774:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.78it/s, loss=7.2e-08, v_num=23, train_loss=7.85e-6, test_loss=8.48e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1774:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.93it/s, loss=7.2e-08, v_num=23, train_loss=7.85e-6, test_loss=8.48e-6]\u001b[A\n",
      "Epoch 1774: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.82it/s, loss=7.2e-08, v_num=23, train_loss=7.6e-6, test_loss=8.22e-6]\u001b[A\n",
      "Epoch 1775:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.56it/s, loss=7.02e-08, v_num=23, train_loss=7.6e-6, test_loss=8.22e-6]\u001b[AAdjusting learning rate of group 0 to 1.1731e-04.\n",
      "Epoch 1775:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.66it/s, loss=6.72e-08, v_num=23, train_loss=7.6e-6, test_loss=8.22e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1775:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.70it/s, loss=6.72e-08, v_num=23, train_loss=7.6e-6, test_loss=8.22e-6]\u001b[A\n",
      "Epoch 1775: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.06it/s, loss=6.72e-08, v_num=23, train_loss=7.31e-6, test_loss=7.92e-6]\u001b[A\n",
      "Epoch 1776:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.14it/s, loss=8.04e-08, v_num=23, train_loss=7.31e-6, test_loss=7.92e-6]\u001b[AAdjusting learning rate of group 0 to 1.1701e-04.\n",
      "Epoch 1776:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.15it/s, loss=7.54e-08, v_num=23, train_loss=7.31e-6, test_loss=7.92e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1776:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.31it/s, loss=7.54e-08, v_num=23, train_loss=7.31e-6, test_loss=7.92e-6]\u001b[A\n",
      "Epoch 1776: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.73it/s, loss=7.54e-08, v_num=23, train_loss=7.24e-6, test_loss=7.8e-6]\u001b[A\n",
      "Epoch 1777:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.19it/s, loss=7.03e-08, v_num=23, train_loss=7.24e-6, test_loss=7.8e-6]\u001b[AAdjusting learning rate of group 0 to 1.1672e-04.\n",
      "Epoch 1777:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.26it/s, loss=6.72e-08, v_num=23, train_loss=7.24e-6, test_loss=7.8e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1777:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.02it/s, loss=6.72e-08, v_num=23, train_loss=7.24e-6, test_loss=7.8e-6]\u001b[A\n",
      "Epoch 1777: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.77it/s, loss=6.72e-08, v_num=23, train_loss=7.39e-6, test_loss=8.07e-6]\u001b[A\n",
      "Epoch 1778:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.17it/s, loss=6.34e-08, v_num=23, train_loss=7.39e-6, test_loss=8.07e-6]\u001b[AAdjusting learning rate of group 0 to 1.1643e-04.\n",
      "Epoch 1778:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.41it/s, loss=6.15e-08, v_num=23, train_loss=7.39e-6, test_loss=8.07e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1778:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.39it/s, loss=6.15e-08, v_num=23, train_loss=7.39e-6, test_loss=8.07e-6]\u001b[A\n",
      "Epoch 1778: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.38it/s, loss=6.15e-08, v_num=23, train_loss=7.09e-6, test_loss=7.69e-6]\u001b[A\n",
      "Epoch 1779:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.93it/s, loss=9.28e-08, v_num=23, train_loss=7.09e-6, test_loss=7.69e-6]\u001b[AAdjusting learning rate of group 0 to 1.1614e-04.\n",
      "Epoch 1779:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.94it/s, loss=9.07e-08, v_num=23, train_loss=7.09e-6, test_loss=7.69e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1779:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.93it/s, loss=9.07e-08, v_num=23, train_loss=7.09e-6, test_loss=7.69e-6]\u001b[A\n",
      "Epoch 1779: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.06it/s, loss=9.07e-08, v_num=23, train_loss=7.18e-6, test_loss=7.73e-6]\u001b[A\n",
      "Epoch 1780:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.22it/s, loss=6.82e-08, v_num=23, train_loss=7.18e-6, test_loss=7.73e-6]\u001b[AAdjusting learning rate of group 0 to 1.1585e-04.\n",
      "Epoch 1780:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.48it/s, loss=6.5e-08, v_num=23, train_loss=7.18e-6, test_loss=7.73e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1780:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.25it/s, loss=6.5e-08, v_num=23, train_loss=7.18e-6, test_loss=7.73e-6]\u001b[A\n",
      "Epoch 1780: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.97it/s, loss=6.5e-08, v_num=23, train_loss=7.63e-6, test_loss=8.25e-6]\u001b[A\n",
      "Epoch 1781:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.86it/s, loss=6.91e-08, v_num=23, train_loss=7.63e-6, test_loss=8.25e-6]\u001b[AAdjusting learning rate of group 0 to 1.1556e-04.\n",
      "Epoch 1781:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.82it/s, loss=6.69e-08, v_num=23, train_loss=7.63e-6, test_loss=8.25e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1781:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.02it/s, loss=6.69e-08, v_num=23, train_loss=7.63e-6, test_loss=8.25e-6]\u001b[A\n",
      "Epoch 1781: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.06it/s, loss=6.69e-08, v_num=23, train_loss=7.03e-6, test_loss=7.67e-6]\u001b[A\n",
      "Epoch 1782:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.49it/s, loss=7.28e-08, v_num=23, train_loss=7.03e-6, test_loss=7.67e-6]\u001b[AAdjusting learning rate of group 0 to 1.1527e-04.\n",
      "Epoch 1782:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.45it/s, loss=7.04e-08, v_num=23, train_loss=7.03e-6, test_loss=7.67e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1782:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.82it/s, loss=7.04e-08, v_num=23, train_loss=7.03e-6, test_loss=7.67e-6]\u001b[A\n",
      "Epoch 1782: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.94it/s, loss=7.04e-08, v_num=23, train_loss=6.82e-6, test_loss=7.46e-6]\u001b[A\n",
      "Epoch 1783:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.32it/s, loss=6.72e-08, v_num=23, train_loss=6.82e-6, test_loss=7.46e-6]\u001b[AAdjusting learning rate of group 0 to 1.1498e-04.\n",
      "Epoch 1783:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.69it/s, loss=6.48e-08, v_num=23, train_loss=6.82e-6, test_loss=7.46e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1783:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.55it/s, loss=6.48e-08, v_num=23, train_loss=6.82e-6, test_loss=7.46e-6]\u001b[A\n",
      "Epoch 1783: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.30it/s, loss=6.48e-08, v_num=23, train_loss=7.13e-6, test_loss=7.79e-6]\u001b[A\n",
      "Epoch 1784:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.32it/s, loss=6.9e-08, v_num=23, train_loss=7.13e-6, test_loss=7.79e-6]\u001b[AAdjusting learning rate of group 0 to 1.1469e-04.\n",
      "Epoch 1784:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.95it/s, loss=6.6e-08, v_num=23, train_loss=7.13e-6, test_loss=7.79e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1784:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.66it/s, loss=6.6e-08, v_num=23, train_loss=7.13e-6, test_loss=7.79e-6]\u001b[A\n",
      "Epoch 1784: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.57it/s, loss=6.6e-08, v_num=23, train_loss=7.25e-6, test_loss=7.79e-6]\u001b[A\n",
      "Epoch 1785:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.60it/s, loss=7.63e-08, v_num=23, train_loss=7.25e-6, test_loss=7.79e-6]\u001b[AAdjusting learning rate of group 0 to 1.1441e-04.\n",
      "Epoch 1785:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.64it/s, loss=7.39e-08, v_num=23, train_loss=7.25e-6, test_loss=7.79e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1785:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.10it/s, loss=7.39e-08, v_num=23, train_loss=7.25e-6, test_loss=7.79e-6]\u001b[A\n",
      "Epoch 1785: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.33it/s, loss=7.39e-08, v_num=23, train_loss=7.36e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1786:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.71it/s, loss=7.57e-08, v_num=23, train_loss=7.36e-6, test_loss=7.97e-6]\u001b[AAdjusting learning rate of group 0 to 1.1412e-04.\n",
      "Epoch 1786:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.52it/s, loss=7.23e-08, v_num=23, train_loss=7.36e-6, test_loss=7.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1786:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.59it/s, loss=7.23e-08, v_num=23, train_loss=7.36e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1786: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.91it/s, loss=7.23e-08, v_num=23, train_loss=7.36e-6, test_loss=7.94e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1787:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.81it/s, loss=7.02e-08, v_num=23, train_loss=7.36e-6, test_loss=7.94e-6]\u001b[AAdjusting learning rate of group 0 to 1.1383e-04.\n",
      "Epoch 1787:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.63it/s, loss=6.72e-08, v_num=23, train_loss=7.36e-6, test_loss=7.94e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1787:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 127.75it/s, loss=6.72e-08, v_num=23, train_loss=7.36e-6, test_loss=7.94e-6]\u001b[A\n",
      "Epoch 1787: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 162.57it/s, loss=6.72e-08, v_num=23, train_loss=7.32e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1788:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.02it/s, loss=7.11e-08, v_num=23, train_loss=7.32e-6, test_loss=7.97e-6]\u001b[AAdjusting learning rate of group 0 to 1.1355e-04.\n",
      "Epoch 1788:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.82it/s, loss=6.7e-08, v_num=23, train_loss=7.32e-6, test_loss=7.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1788:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.95it/s, loss=6.7e-08, v_num=23, train_loss=7.32e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1788: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.42it/s, loss=6.7e-08, v_num=23, train_loss=7.62e-6, test_loss=8.27e-6]\u001b[A\n",
      "Epoch 1789:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.94it/s, loss=6.47e-08, v_num=23, train_loss=7.62e-6, test_loss=8.27e-6]\u001b[AAdjusting learning rate of group 0 to 1.1327e-04.\n",
      "Epoch 1789:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.01it/s, loss=6.09e-08, v_num=23, train_loss=7.62e-6, test_loss=8.27e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1789:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.54it/s, loss=6.09e-08, v_num=23, train_loss=7.62e-6, test_loss=8.27e-6]\u001b[A\n",
      "Epoch 1789: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.02it/s, loss=6.09e-08, v_num=23, train_loss=7.34e-6, test_loss=7.92e-6]\u001b[A\n",
      "Epoch 1790:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.16it/s, loss=7.4e-08, v_num=23, train_loss=7.34e-6, test_loss=7.92e-6]\u001b[AAdjusting learning rate of group 0 to 1.1298e-04.\n",
      "Epoch 1790:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.09it/s, loss=7.17e-08, v_num=23, train_loss=7.34e-6, test_loss=7.92e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1790:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 135.36it/s, loss=7.17e-08, v_num=23, train_loss=7.34e-6, test_loss=7.92e-6]\u001b[A\n",
      "Epoch 1790: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.94it/s, loss=7.17e-08, v_num=23, train_loss=7.63e-6, test_loss=8.29e-6]\u001b[A\n",
      "Epoch 1791:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.61it/s, loss=8.34e-08, v_num=23, train_loss=7.63e-6, test_loss=8.29e-6]\u001b[AAdjusting learning rate of group 0 to 1.1270e-04.\n",
      "Epoch 1791:  50%|███████████████████                   | 79/158 [00:00<00:00, 135.88it/s, loss=7.98e-08, v_num=23, train_loss=7.63e-6, test_loss=8.29e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1791:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.44it/s, loss=7.98e-08, v_num=23, train_loss=7.63e-6, test_loss=8.29e-6]\u001b[A\n",
      "Epoch 1791: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.74it/s, loss=7.98e-08, v_num=23, train_loss=7.33e-6, test_loss=7.95e-6]\u001b[A\n",
      "Epoch 1792:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.41it/s, loss=8.21e-08, v_num=23, train_loss=7.33e-6, test_loss=7.95e-6]\u001b[AAdjusting learning rate of group 0 to 1.1242e-04.\n",
      "Epoch 1792:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.24it/s, loss=7.95e-08, v_num=23, train_loss=7.33e-6, test_loss=7.95e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1792:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.46it/s, loss=7.95e-08, v_num=23, train_loss=7.33e-6, test_loss=7.95e-6]\u001b[A\n",
      "Epoch 1792: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.17it/s, loss=7.95e-08, v_num=23, train_loss=7.06e-6, test_loss=7.72e-6]\u001b[A\n",
      "Epoch 1793:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.26it/s, loss=6.96e-08, v_num=23, train_loss=7.06e-6, test_loss=7.72e-6]\u001b[AAdjusting learning rate of group 0 to 1.1214e-04.\n",
      "Epoch 1793:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.99it/s, loss=6.78e-08, v_num=23, train_loss=7.06e-6, test_loss=7.72e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1793:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.78it/s, loss=6.78e-08, v_num=23, train_loss=7.06e-6, test_loss=7.72e-6]\u001b[A\n",
      "Epoch 1793: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.08it/s, loss=6.78e-08, v_num=23, train_loss=7.38e-6, test_loss=7.99e-6]\u001b[A\n",
      "Epoch 1794:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.97it/s, loss=7.09e-08, v_num=23, train_loss=7.38e-6, test_loss=7.99e-6]\u001b[AAdjusting learning rate of group 0 to 1.1186e-04.\n",
      "Epoch 1794:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.50it/s, loss=6.79e-08, v_num=23, train_loss=7.38e-6, test_loss=7.99e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1794:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.73it/s, loss=6.79e-08, v_num=23, train_loss=7.38e-6, test_loss=7.99e-6]\u001b[A\n",
      "Epoch 1794: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.41it/s, loss=6.79e-08, v_num=23, train_loss=6.98e-6, test_loss=7.61e-6]\u001b[A\n",
      "Epoch 1795:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.77it/s, loss=6.88e-08, v_num=23, train_loss=6.98e-6, test_loss=7.61e-6]\u001b[AAdjusting learning rate of group 0 to 1.1158e-04.\n",
      "Epoch 1795:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.07it/s, loss=6.56e-08, v_num=23, train_loss=6.98e-6, test_loss=7.61e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1795:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.63it/s, loss=6.56e-08, v_num=23, train_loss=6.98e-6, test_loss=7.61e-6]\u001b[A\n",
      "Epoch 1795: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 172.31it/s, loss=6.56e-08, v_num=23, train_loss=7.22e-6, test_loss=7.79e-6]\u001b[A\n",
      "Epoch 1796:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.22it/s, loss=6.58e-08, v_num=23, train_loss=7.22e-6, test_loss=7.79e-6]\u001b[AAdjusting learning rate of group 0 to 1.1130e-04.\n",
      "Epoch 1796:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.49it/s, loss=6.35e-08, v_num=23, train_loss=7.22e-6, test_loss=7.79e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1796:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.88it/s, loss=6.35e-08, v_num=23, train_loss=7.22e-6, test_loss=7.79e-6]\u001b[A\n",
      "Epoch 1796: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.67it/s, loss=6.35e-08, v_num=23, train_loss=7.39e-6, test_loss=8.01e-6]\u001b[A\n",
      "Epoch 1797:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.20it/s, loss=6.64e-08, v_num=23, train_loss=7.39e-6, test_loss=8.01e-6]\u001b[AAdjusting learning rate of group 0 to 1.1102e-04.\n",
      "Epoch 1797:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.93it/s, loss=6.34e-08, v_num=23, train_loss=7.39e-6, test_loss=8.01e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1797:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.96it/s, loss=6.34e-08, v_num=23, train_loss=7.39e-6, test_loss=8.01e-6]\u001b[A\n",
      "Epoch 1797: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.60it/s, loss=6.34e-08, v_num=23, train_loss=7.17e-6, test_loss=7.75e-6]\u001b[A\n",
      "Epoch 1798:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.96it/s, loss=7.26e-08, v_num=23, train_loss=7.17e-6, test_loss=7.75e-6]\u001b[AAdjusting learning rate of group 0 to 1.1074e-04.\n",
      "Epoch 1798:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.73it/s, loss=7.09e-08, v_num=23, train_loss=7.17e-6, test_loss=7.75e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1798:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.84it/s, loss=7.09e-08, v_num=23, train_loss=7.17e-6, test_loss=7.75e-6]\u001b[A\n",
      "Epoch 1798: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.05it/s, loss=7.09e-08, v_num=23, train_loss=7.06e-6, test_loss=7.7e-6]\u001b[A\n",
      "Epoch 1799:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.55it/s, loss=6.85e-08, v_num=23, train_loss=7.06e-6, test_loss=7.7e-6]\u001b[AAdjusting learning rate of group 0 to 1.1047e-04.\n",
      "Epoch 1799:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.27it/s, loss=6.56e-08, v_num=23, train_loss=7.06e-6, test_loss=7.7e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1799:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.91it/s, loss=6.56e-08, v_num=23, train_loss=7.06e-6, test_loss=7.7e-6]\u001b[A\n",
      "Epoch 1799: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.06it/s, loss=6.56e-08, v_num=23, train_loss=7.64e-6, test_loss=8.26e-6]\u001b[A\n",
      "Epoch 1800:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.90it/s, loss=6.39e-08, v_num=23, train_loss=7.64e-6, test_loss=8.26e-6]\u001b[AAdjusting learning rate of group 0 to 1.1019e-04.\n",
      "Epoch 1800:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.12it/s, loss=5.99e-08, v_num=23, train_loss=7.64e-6, test_loss=8.26e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1800:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.70it/s, loss=5.99e-08, v_num=23, train_loss=7.64e-6, test_loss=8.26e-6]\u001b[A\n",
      "Epoch 1800: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.88it/s, loss=5.99e-08, v_num=23, train_loss=6.75e-6, test_loss=7.38e-6]\u001b[A\n",
      "Epoch 1801:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.45it/s, loss=7.29e-08, v_num=23, train_loss=6.75e-6, test_loss=7.38e-6]\u001b[AAdjusting learning rate of group 0 to 1.0991e-04.\n",
      "Epoch 1801:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.56it/s, loss=7.03e-08, v_num=23, train_loss=6.75e-6, test_loss=7.38e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1801:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.37it/s, loss=7.03e-08, v_num=23, train_loss=6.75e-6, test_loss=7.38e-6]\u001b[A\n",
      "Epoch 1801: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.55it/s, loss=7.03e-08, v_num=23, train_loss=7.13e-6, test_loss=7.72e-6]\u001b[A\n",
      "Epoch 1802:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.76it/s, loss=7.26e-08, v_num=23, train_loss=7.13e-6, test_loss=7.72e-6]\u001b[AAdjusting learning rate of group 0 to 1.0964e-04.\n",
      "Epoch 1802:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 141.66it/s, loss=6.9e-08, v_num=23, train_loss=7.13e-6, test_loss=7.72e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1802:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.97it/s, loss=6.9e-08, v_num=23, train_loss=7.13e-6, test_loss=7.72e-6]\u001b[A\n",
      "Epoch 1802: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.40it/s, loss=6.9e-08, v_num=23, train_loss=7.45e-6, test_loss=8.07e-6]\u001b[A\n",
      "Epoch 1803:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.26it/s, loss=7.28e-08, v_num=23, train_loss=7.45e-6, test_loss=8.07e-6]\u001b[AAdjusting learning rate of group 0 to 1.0937e-04.\n",
      "Epoch 1803:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.12it/s, loss=6.92e-08, v_num=23, train_loss=7.45e-6, test_loss=8.07e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1803:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.00it/s, loss=6.92e-08, v_num=23, train_loss=7.45e-6, test_loss=8.07e-6]\u001b[A\n",
      "Epoch 1803: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.81it/s, loss=6.92e-08, v_num=23, train_loss=7.55e-6, test_loss=8.16e-6]\u001b[A\n",
      "Epoch 1804:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.03it/s, loss=6.54e-08, v_num=23, train_loss=7.55e-6, test_loss=8.16e-6]\u001b[AAdjusting learning rate of group 0 to 1.0909e-04.\n",
      "Epoch 1804:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.89it/s, loss=6.2e-08, v_num=23, train_loss=7.55e-6, test_loss=8.16e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1804:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.06it/s, loss=6.2e-08, v_num=23, train_loss=7.55e-6, test_loss=8.16e-6]\u001b[A\n",
      "Epoch 1804: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.64it/s, loss=6.2e-08, v_num=23, train_loss=7.28e-6, test_loss=7.92e-6]\u001b[A\n",
      "Epoch 1805:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.80it/s, loss=8.51e-08, v_num=23, train_loss=7.28e-6, test_loss=7.92e-6]\u001b[AAdjusting learning rate of group 0 to 1.0882e-04.\n",
      "Epoch 1805:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.57it/s, loss=8.14e-08, v_num=23, train_loss=7.28e-6, test_loss=7.92e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1805:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.71it/s, loss=8.14e-08, v_num=23, train_loss=7.28e-6, test_loss=7.92e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1805: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.91it/s, loss=8.14e-08, v_num=23, train_loss=7.49e-6, test_loss=8.12e-6]\u001b[A\n",
      "Epoch 1806:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.17it/s, loss=6.71e-08, v_num=23, train_loss=7.49e-6, test_loss=8.12e-6]\u001b[AAdjusting learning rate of group 0 to 1.0855e-04.\n",
      "Epoch 1806:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.84it/s, loss=6.38e-08, v_num=23, train_loss=7.49e-6, test_loss=8.12e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1806:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.37it/s, loss=6.38e-08, v_num=23, train_loss=7.49e-6, test_loss=8.12e-6]\u001b[A\n",
      "Epoch 1806: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.89it/s, loss=6.38e-08, v_num=23, train_loss=7.47e-6, test_loss=8.04e-6]\u001b[A\n",
      "Epoch 1807:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.12it/s, loss=6.69e-08, v_num=23, train_loss=7.47e-6, test_loss=8.04e-6]\u001b[AAdjusting learning rate of group 0 to 1.0828e-04.\n",
      "Epoch 1807:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.38it/s, loss=6.43e-08, v_num=23, train_loss=7.47e-6, test_loss=8.04e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1807:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.30it/s, loss=6.43e-08, v_num=23, train_loss=7.47e-6, test_loss=8.04e-6]\u001b[A\n",
      "Epoch 1807: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.95it/s, loss=6.43e-08, v_num=23, train_loss=7.32e-6, test_loss=7.88e-6]\u001b[A\n",
      "Epoch 1808:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.75it/s, loss=7.26e-08, v_num=23, train_loss=7.32e-6, test_loss=7.88e-6]\u001b[AAdjusting learning rate of group 0 to 1.0801e-04.\n",
      "Epoch 1808:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.62it/s, loss=6.28e-08, v_num=23, train_loss=7.32e-6, test_loss=7.88e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1808:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.09it/s, loss=6.28e-08, v_num=23, train_loss=7.32e-6, test_loss=7.88e-6]\u001b[A\n",
      "Epoch 1808: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.81it/s, loss=6.28e-08, v_num=23, train_loss=7.07e-6, test_loss=7.66e-6]\u001b[A\n",
      "Epoch 1809:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.65it/s, loss=7.76e-08, v_num=23, train_loss=7.07e-6, test_loss=7.66e-6]\u001b[AAdjusting learning rate of group 0 to 1.0774e-04.\n",
      "Epoch 1809:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.60it/s, loss=7.34e-08, v_num=23, train_loss=7.07e-6, test_loss=7.66e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1809:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.20it/s, loss=7.34e-08, v_num=23, train_loss=7.07e-6, test_loss=7.66e-6]\u001b[A\n",
      "Epoch 1809: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.84it/s, loss=7.34e-08, v_num=23, train_loss=7.69e-6, test_loss=8.25e-6]\u001b[A\n",
      "Epoch 1810:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.68it/s, loss=7.15e-08, v_num=23, train_loss=7.69e-6, test_loss=8.25e-6]\u001b[AAdjusting learning rate of group 0 to 1.0747e-04.\n",
      "Epoch 1810:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.35it/s, loss=6.89e-08, v_num=23, train_loss=7.69e-6, test_loss=8.25e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1810:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.77it/s, loss=6.89e-08, v_num=23, train_loss=7.69e-6, test_loss=8.25e-6]\u001b[A\n",
      "Epoch 1810: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.26it/s, loss=6.89e-08, v_num=23, train_loss=7.43e-6, test_loss=8.05e-6]\u001b[A\n",
      "Epoch 1811:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.95it/s, loss=7.63e-08, v_num=23, train_loss=7.43e-6, test_loss=8.05e-6]\u001b[AAdjusting learning rate of group 0 to 1.0720e-04.\n",
      "Epoch 1811:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.19it/s, loss=6.61e-08, v_num=23, train_loss=7.43e-6, test_loss=8.05e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1811:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.64it/s, loss=6.61e-08, v_num=23, train_loss=7.43e-6, test_loss=8.05e-6]\u001b[A\n",
      "Epoch 1811: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.39it/s, loss=6.61e-08, v_num=23, train_loss=7.22e-6, test_loss=7.83e-6]\u001b[A\n",
      "Epoch 1812:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.82it/s, loss=6.79e-08, v_num=23, train_loss=7.22e-6, test_loss=7.83e-6]\u001b[AAdjusting learning rate of group 0 to 1.0693e-04.\n",
      "Epoch 1812:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.07it/s, loss=6.54e-08, v_num=23, train_loss=7.22e-6, test_loss=7.83e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1812:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.79it/s, loss=6.54e-08, v_num=23, train_loss=7.22e-6, test_loss=7.83e-6]\u001b[A\n",
      "Epoch 1812: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.63it/s, loss=6.54e-08, v_num=23, train_loss=7.28e-6, test_loss=7.9e-6]\u001b[A\n",
      "Epoch 1813:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.21it/s, loss=7.38e-08, v_num=23, train_loss=7.28e-6, test_loss=7.9e-6]\u001b[AAdjusting learning rate of group 0 to 1.0666e-04.\n",
      "Epoch 1813:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.31it/s, loss=7.11e-08, v_num=23, train_loss=7.28e-6, test_loss=7.9e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1813:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.79it/s, loss=7.11e-08, v_num=23, train_loss=7.28e-6, test_loss=7.9e-6]\u001b[A\n",
      "Epoch 1813: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.54it/s, loss=7.11e-08, v_num=23, train_loss=7.61e-6, test_loss=8.21e-6]\u001b[A\n",
      "Epoch 1814:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.23it/s, loss=8.33e-08, v_num=23, train_loss=7.61e-6, test_loss=8.21e-6]\u001b[AAdjusting learning rate of group 0 to 1.0640e-04.\n",
      "Epoch 1814:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.78it/s, loss=8.1e-08, v_num=23, train_loss=7.61e-6, test_loss=8.21e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1814:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.40it/s, loss=8.1e-08, v_num=23, train_loss=7.61e-6, test_loss=8.21e-6]\u001b[A\n",
      "Epoch 1814: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.41it/s, loss=8.1e-08, v_num=23, train_loss=6.85e-6, test_loss=7.47e-6]\u001b[A\n",
      "Epoch 1815:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.31it/s, loss=8.32e-08, v_num=23, train_loss=6.85e-6, test_loss=7.47e-6]\u001b[AAdjusting learning rate of group 0 to 1.0613e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1815:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.26it/s, loss=8.05e-08, v_num=23, train_loss=6.85e-6, test_loss=7.47e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1815:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.50it/s, loss=8.05e-08, v_num=23, train_loss=6.85e-6, test_loss=7.47e-6]\u001b[A\n",
      "Epoch 1815: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.23it/s, loss=8.05e-08, v_num=23, train_loss=8.08e-6, test_loss=8.79e-6]\u001b[A\n",
      "Epoch 1816:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.81it/s, loss=6.72e-08, v_num=23, train_loss=8.08e-6, test_loss=8.79e-6]\u001b[AAdjusting learning rate of group 0 to 1.0586e-04.\n",
      "Epoch 1816:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.66it/s, loss=6.4e-08, v_num=23, train_loss=8.08e-6, test_loss=8.79e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1816:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.49it/s, loss=6.4e-08, v_num=23, train_loss=8.08e-6, test_loss=8.79e-6]\u001b[A\n",
      "Epoch 1816: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.54it/s, loss=6.4e-08, v_num=23, train_loss=7.23e-6, test_loss=7.85e-6]\u001b[A\n",
      "Epoch 1817:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.40it/s, loss=6.53e-08, v_num=23, train_loss=7.23e-6, test_loss=7.85e-6]\u001b[AAdjusting learning rate of group 0 to 1.0560e-04.\n",
      "Epoch 1817:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.32it/s, loss=6.28e-08, v_num=23, train_loss=7.23e-6, test_loss=7.85e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1817:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.74it/s, loss=6.28e-08, v_num=23, train_loss=7.23e-6, test_loss=7.85e-6]\u001b[A\n",
      "Epoch 1817: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.61it/s, loss=6.28e-08, v_num=23, train_loss=7.53e-6, test_loss=8.11e-6]\u001b[A\n",
      "Epoch 1818:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.83it/s, loss=7.28e-08, v_num=23, train_loss=7.53e-6, test_loss=8.11e-6]\u001b[AAdjusting learning rate of group 0 to 1.0534e-04.\n",
      "Epoch 1818:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 140.85it/s, loss=7e-08, v_num=23, train_loss=7.53e-6, test_loss=8.11e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1818:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 134.47it/s, loss=7e-08, v_num=23, train_loss=7.53e-6, test_loss=8.11e-6]\u001b[A\n",
      "Epoch 1818: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 168.85it/s, loss=7e-08, v_num=23, train_loss=7.33e-6, test_loss=7.96e-6]\u001b[A\n",
      "Epoch 1819:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.42it/s, loss=8.07e-08, v_num=23, train_loss=7.33e-6, test_loss=7.96e-6]\u001b[AAdjusting learning rate of group 0 to 1.0507e-04.\n",
      "Epoch 1819:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.58it/s, loss=7.74e-08, v_num=23, train_loss=7.33e-6, test_loss=7.96e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1819:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.23it/s, loss=7.74e-08, v_num=23, train_loss=7.33e-6, test_loss=7.96e-6]\u001b[A\n",
      "Epoch 1819: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.20it/s, loss=7.74e-08, v_num=23, train_loss=8.03e-6, test_loss=8.63e-6]\u001b[A\n",
      "Epoch 1820:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.57it/s, loss=8.07e-08, v_num=23, train_loss=8.03e-6, test_loss=8.63e-6]\u001b[AAdjusting learning rate of group 0 to 1.0481e-04.\n",
      "Epoch 1820:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.17it/s, loss=7.79e-08, v_num=23, train_loss=8.03e-6, test_loss=8.63e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1820:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.17it/s, loss=7.79e-08, v_num=23, train_loss=8.03e-6, test_loss=8.63e-6]\u001b[A\n",
      "Epoch 1820: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.67it/s, loss=7.79e-08, v_num=23, train_loss=7.43e-6, test_loss=8.06e-6]\u001b[A\n",
      "Epoch 1821:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.64it/s, loss=7.08e-08, v_num=23, train_loss=7.43e-6, test_loss=8.06e-6]\u001b[AAdjusting learning rate of group 0 to 1.0455e-04.\n",
      "Epoch 1821:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.50it/s, loss=6.83e-08, v_num=23, train_loss=7.43e-6, test_loss=8.06e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1821:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.51it/s, loss=6.83e-08, v_num=23, train_loss=7.43e-6, test_loss=8.06e-6]\u001b[A\n",
      "Epoch 1821: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.90it/s, loss=6.83e-08, v_num=23, train_loss=7.1e-6, test_loss=7.72e-6]\u001b[A\n",
      "Epoch 1822:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 146.30it/s, loss=6.8e-08, v_num=23, train_loss=7.1e-6, test_loss=7.72e-6]\u001b[AAdjusting learning rate of group 0 to 1.0429e-04.\n",
      "Epoch 1822:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 134.80it/s, loss=6.46e-08, v_num=23, train_loss=7.1e-6, test_loss=7.72e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1822:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.84it/s, loss=6.46e-08, v_num=23, train_loss=7.1e-6, test_loss=7.72e-6]\u001b[A\n",
      "Epoch 1822: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.52it/s, loss=6.46e-08, v_num=23, train_loss=7.42e-6, test_loss=8.02e-6]\u001b[A\n",
      "Epoch 1823:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.67it/s, loss=6.61e-08, v_num=23, train_loss=7.42e-6, test_loss=8.02e-6]\u001b[AAdjusting learning rate of group 0 to 1.0402e-04.\n",
      "Epoch 1823:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.34it/s, loss=6.17e-08, v_num=23, train_loss=7.42e-6, test_loss=8.02e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1823:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.06it/s, loss=6.17e-08, v_num=23, train_loss=7.42e-6, test_loss=8.02e-6]\u001b[A\n",
      "Epoch 1823: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.99it/s, loss=6.17e-08, v_num=23, train_loss=7.2e-6, test_loss=7.87e-6]\u001b[A\n",
      "Epoch 1824:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.75it/s, loss=6.25e-08, v_num=23, train_loss=7.2e-6, test_loss=7.87e-6]\u001b[AAdjusting learning rate of group 0 to 1.0376e-04.\n",
      "Epoch 1824:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.13it/s, loss=5.97e-08, v_num=23, train_loss=7.2e-6, test_loss=7.87e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1824:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.00it/s, loss=5.97e-08, v_num=23, train_loss=7.2e-6, test_loss=7.87e-6]\u001b[A\n",
      "Epoch 1824: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 166.84it/s, loss=5.97e-08, v_num=23, train_loss=7.5e-6, test_loss=8.1e-6]\u001b[A\n",
      "Epoch 1825:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 149.14it/s, loss=7.84e-08, v_num=23, train_loss=7.5e-6, test_loss=8.1e-6]\u001b[AAdjusting learning rate of group 0 to 1.0351e-04.\n",
      "Epoch 1825:  50%|████████████████████                    | 79/158 [00:00<00:00, 140.69it/s, loss=7.38e-08, v_num=23, train_loss=7.5e-6, test_loss=8.1e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1825:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.33it/s, loss=7.38e-08, v_num=23, train_loss=7.5e-6, test_loss=8.1e-6]\u001b[A\n",
      "Epoch 1825: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.74it/s, loss=7.38e-08, v_num=23, train_loss=6.84e-6, test_loss=7.46e-6]\u001b[A\n",
      "Epoch 1826:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.78it/s, loss=6.38e-08, v_num=23, train_loss=6.84e-6, test_loss=7.46e-6]\u001b[AAdjusting learning rate of group 0 to 1.0325e-04.\n",
      "Epoch 1826:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.97it/s, loss=6.22e-08, v_num=23, train_loss=6.84e-6, test_loss=7.46e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1826:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.59it/s, loss=6.22e-08, v_num=23, train_loss=6.84e-6, test_loss=7.46e-6]\u001b[A\n",
      "Epoch 1826: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.33it/s, loss=6.22e-08, v_num=23, train_loss=7.15e-6, test_loss=7.71e-6]\u001b[A\n",
      "Epoch 1827:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.93it/s, loss=7.2e-08, v_num=23, train_loss=7.15e-6, test_loss=7.71e-6]\u001b[AAdjusting learning rate of group 0 to 1.0299e-04.\n",
      "Epoch 1827:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.13it/s, loss=6.96e-08, v_num=23, train_loss=7.15e-6, test_loss=7.71e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1827:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 135.18it/s, loss=6.96e-08, v_num=23, train_loss=7.15e-6, test_loss=7.71e-6]\u001b[A\n",
      "Epoch 1827: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.05it/s, loss=6.96e-08, v_num=23, train_loss=6.88e-6, test_loss=7.51e-6]\u001b[A\n",
      "Epoch 1828:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.03it/s, loss=7.29e-08, v_num=23, train_loss=6.88e-6, test_loss=7.51e-6]\u001b[AAdjusting learning rate of group 0 to 1.0273e-04.\n",
      "Epoch 1828:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.36it/s, loss=6.92e-08, v_num=23, train_loss=6.88e-6, test_loss=7.51e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1828:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.59it/s, loss=6.92e-08, v_num=23, train_loss=6.88e-6, test_loss=7.51e-6]\u001b[A\n",
      "Epoch 1828: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.30it/s, loss=6.92e-08, v_num=23, train_loss=7.38e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1829:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.99it/s, loss=6.68e-08, v_num=23, train_loss=7.38e-6, test_loss=7.93e-6]\u001b[AAdjusting learning rate of group 0 to 1.0247e-04.\n",
      "Epoch 1829:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.64it/s, loss=6.09e-08, v_num=23, train_loss=7.38e-6, test_loss=7.93e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1829:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 127.70it/s, loss=6.09e-08, v_num=23, train_loss=7.38e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1829: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 162.98it/s, loss=6.09e-08, v_num=23, train_loss=6.97e-6, test_loss=7.64e-6]\u001b[A\n",
      "Epoch 1830:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.89it/s, loss=6.87e-08, v_num=23, train_loss=6.97e-6, test_loss=7.64e-6]\u001b[AAdjusting learning rate of group 0 to 1.0222e-04.\n",
      "Epoch 1830:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.11it/s, loss=6.56e-08, v_num=23, train_loss=6.97e-6, test_loss=7.64e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1830:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.52it/s, loss=6.56e-08, v_num=23, train_loss=6.97e-6, test_loss=7.64e-6]\u001b[A\n",
      "Epoch 1830: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.91it/s, loss=6.56e-08, v_num=23, train_loss=7.07e-6, test_loss=7.67e-6]\u001b[A\n",
      "Epoch 1831:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.10it/s, loss=6.38e-08, v_num=23, train_loss=7.07e-6, test_loss=7.67e-6]\u001b[AAdjusting learning rate of group 0 to 1.0196e-04.\n",
      "Epoch 1831:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.91it/s, loss=6.09e-08, v_num=23, train_loss=7.07e-6, test_loss=7.67e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1831:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.69it/s, loss=6.09e-08, v_num=23, train_loss=7.07e-6, test_loss=7.67e-6]\u001b[A\n",
      "Epoch 1831: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.92it/s, loss=6.09e-08, v_num=23, train_loss=7.38e-6, test_loss=7.98e-6]\u001b[A\n",
      "Epoch 1832:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.55it/s, loss=6.5e-08, v_num=23, train_loss=7.38e-6, test_loss=7.98e-6]\u001b[AAdjusting learning rate of group 0 to 1.0171e-04.\n",
      "Epoch 1832:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.64it/s, loss=6.22e-08, v_num=23, train_loss=7.38e-6, test_loss=7.98e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1832:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.02it/s, loss=6.22e-08, v_num=23, train_loss=7.38e-6, test_loss=7.98e-6]\u001b[A\n",
      "Epoch 1832: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.52it/s, loss=6.22e-08, v_num=23, train_loss=7.14e-6, test_loss=7.76e-6]\u001b[A\n",
      "Epoch 1833:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.61it/s, loss=7.18e-08, v_num=23, train_loss=7.14e-6, test_loss=7.76e-6]\u001b[AAdjusting learning rate of group 0 to 1.0145e-04.\n",
      "Epoch 1833:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.94it/s, loss=6.57e-08, v_num=23, train_loss=7.14e-6, test_loss=7.76e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1833:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.27it/s, loss=6.57e-08, v_num=23, train_loss=7.14e-6, test_loss=7.76e-6]\u001b[A\n",
      "Epoch 1833: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.60it/s, loss=6.57e-08, v_num=23, train_loss=7.57e-6, test_loss=8.12e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1834:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 145.71it/s, loss=6.71e-08, v_num=23, train_loss=7.57e-6, test_loss=8.12e-6]\u001b[AAdjusting learning rate of group 0 to 1.0120e-04.\n",
      "Epoch 1834:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.03it/s, loss=6.39e-08, v_num=23, train_loss=7.57e-6, test_loss=8.12e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1834:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.77it/s, loss=6.39e-08, v_num=23, train_loss=7.57e-6, test_loss=8.12e-6]\u001b[A\n",
      "Epoch 1834: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.42it/s, loss=6.39e-08, v_num=23, train_loss=7.55e-6, test_loss=8.2e-6]\u001b[A\n",
      "Epoch 1835:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.84it/s, loss=6.81e-08, v_num=23, train_loss=7.55e-6, test_loss=8.2e-6]\u001b[AAdjusting learning rate of group 0 to 1.0095e-04.\n",
      "Epoch 1835:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.13it/s, loss=6.41e-08, v_num=23, train_loss=7.55e-6, test_loss=8.2e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1835:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.87it/s, loss=6.41e-08, v_num=23, train_loss=7.55e-6, test_loss=8.2e-6]\u001b[A\n",
      "Epoch 1835: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.96it/s, loss=6.41e-08, v_num=23, train_loss=7.09e-6, test_loss=7.68e-6]\u001b[A\n",
      "Epoch 1836:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.43it/s, loss=7.03e-08, v_num=23, train_loss=7.09e-6, test_loss=7.68e-6]\u001b[AAdjusting learning rate of group 0 to 1.0069e-04.\n",
      "Epoch 1836:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.14it/s, loss=6.81e-08, v_num=23, train_loss=7.09e-6, test_loss=7.68e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1836:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 135.07it/s, loss=6.81e-08, v_num=23, train_loss=7.09e-6, test_loss=7.68e-6]\u001b[A\n",
      "Epoch 1836: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.69it/s, loss=6.81e-08, v_num=23, train_loss=7.4e-6, test_loss=7.99e-6]\u001b[A\n",
      "Epoch 1837:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.04it/s, loss=6.29e-08, v_num=23, train_loss=7.4e-6, test_loss=7.99e-6]\u001b[AAdjusting learning rate of group 0 to 1.0044e-04.\n",
      "Epoch 1837:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.94it/s, loss=6.05e-08, v_num=23, train_loss=7.4e-6, test_loss=7.99e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1837:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.18it/s, loss=6.05e-08, v_num=23, train_loss=7.4e-6, test_loss=7.99e-6]\u001b[A\n",
      "Epoch 1837: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.66it/s, loss=6.05e-08, v_num=23, train_loss=7.23e-6, test_loss=7.84e-6]\u001b[A\n",
      "Epoch 1838:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.35it/s, loss=7.75e-08, v_num=23, train_loss=7.23e-6, test_loss=7.84e-6]\u001b[AAdjusting learning rate of group 0 to 1.0019e-04.\n",
      "Epoch 1838:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.12it/s, loss=7.54e-08, v_num=23, train_loss=7.23e-6, test_loss=7.84e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1838:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.28it/s, loss=7.54e-08, v_num=23, train_loss=7.23e-6, test_loss=7.84e-6]\u001b[A\n",
      "Epoch 1838: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.74it/s, loss=7.54e-08, v_num=23, train_loss=6.95e-6, test_loss=7.57e-6]\u001b[A\n",
      "Epoch 1839:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.31it/s, loss=6.89e-08, v_num=23, train_loss=6.95e-6, test_loss=7.57e-6]\u001b[AAdjusting learning rate of group 0 to 9.9941e-05.\n",
      "Epoch 1839:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.13it/s, loss=6.52e-08, v_num=23, train_loss=6.95e-6, test_loss=7.57e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1839:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.34it/s, loss=6.52e-08, v_num=23, train_loss=6.95e-6, test_loss=7.57e-6]\u001b[A\n",
      "Epoch 1839: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.19it/s, loss=6.52e-08, v_num=23, train_loss=7.33e-6, test_loss=7.96e-6]\u001b[A\n",
      "Epoch 1840:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.65it/s, loss=6.69e-08, v_num=23, train_loss=7.33e-6, test_loss=7.96e-6]\u001b[AAdjusting learning rate of group 0 to 9.9691e-05.\n",
      "Epoch 1840:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.77it/s, loss=6.36e-08, v_num=23, train_loss=7.33e-6, test_loss=7.96e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1840:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.71it/s, loss=6.36e-08, v_num=23, train_loss=7.33e-6, test_loss=7.96e-6]\u001b[A\n",
      "Epoch 1840: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.46it/s, loss=6.36e-08, v_num=23, train_loss=7.5e-6, test_loss=8.06e-6]\u001b[A\n",
      "Epoch 1841:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.17it/s, loss=6.39e-08, v_num=23, train_loss=7.5e-6, test_loss=8.06e-6]\u001b[AAdjusting learning rate of group 0 to 9.9442e-05.\n",
      "Epoch 1841:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 140.31it/s, loss=6.05e-08, v_num=23, train_loss=7.5e-6, test_loss=8.06e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1841:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.82it/s, loss=6.05e-08, v_num=23, train_loss=7.5e-6, test_loss=8.06e-6]\u001b[A\n",
      "Epoch 1841: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.59it/s, loss=6.05e-08, v_num=23, train_loss=7.46e-6, test_loss=8.14e-6]\u001b[A\n",
      "Epoch 1842:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.63it/s, loss=7.68e-08, v_num=23, train_loss=7.46e-6, test_loss=8.14e-6]\u001b[AAdjusting learning rate of group 0 to 9.9193e-05.\n",
      "Epoch 1842:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.92it/s, loss=7.29e-08, v_num=23, train_loss=7.46e-6, test_loss=8.14e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1842:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.07it/s, loss=7.29e-08, v_num=23, train_loss=7.46e-6, test_loss=8.14e-6]\u001b[A\n",
      "Epoch 1842: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.53it/s, loss=7.29e-08, v_num=23, train_loss=6.95e-6, test_loss=7.6e-6]\u001b[A\n",
      "Epoch 1843:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 146.43it/s, loss=6.45e-08, v_num=23, train_loss=6.95e-6, test_loss=7.6e-6]\u001b[AAdjusting learning rate of group 0 to 9.8945e-05.\n",
      "Epoch 1843:  50%|████████████████████                    | 79/158 [00:00<00:00, 136.58it/s, loss=6.2e-08, v_num=23, train_loss=6.95e-6, test_loss=7.6e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1843:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 132.10it/s, loss=6.2e-08, v_num=23, train_loss=6.95e-6, test_loss=7.6e-6]\u001b[A\n",
      "Epoch 1843: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.22it/s, loss=6.2e-08, v_num=23, train_loss=6.79e-6, test_loss=7.47e-6]\u001b[A\n",
      "Epoch 1844:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.77it/s, loss=6.84e-08, v_num=23, train_loss=6.79e-6, test_loss=7.47e-6]\u001b[AAdjusting learning rate of group 0 to 9.8698e-05.\n",
      "Epoch 1844:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.41it/s, loss=6.62e-08, v_num=23, train_loss=6.79e-6, test_loss=7.47e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1844:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.68it/s, loss=6.62e-08, v_num=23, train_loss=6.79e-6, test_loss=7.47e-6]\u001b[A\n",
      "Epoch 1844: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.66it/s, loss=6.62e-08, v_num=23, train_loss=7.74e-6, test_loss=8.39e-6]\u001b[A\n",
      "Epoch 1845:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.52it/s, loss=7.02e-08, v_num=23, train_loss=7.74e-6, test_loss=8.39e-6]\u001b[AAdjusting learning rate of group 0 to 9.8451e-05.\n",
      "Epoch 1845:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.27it/s, loss=6.72e-08, v_num=23, train_loss=7.74e-6, test_loss=8.39e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1845:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.19it/s, loss=6.72e-08, v_num=23, train_loss=7.74e-6, test_loss=8.39e-6]\u001b[A\n",
      "Epoch 1845: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.23it/s, loss=6.72e-08, v_num=23, train_loss=7.26e-6, test_loss=7.89e-6]\u001b[A\n",
      "Epoch 1846:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.15it/s, loss=6.56e-08, v_num=23, train_loss=7.26e-6, test_loss=7.89e-6]\u001b[AAdjusting learning rate of group 0 to 9.8205e-05.\n",
      "Epoch 1846:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.07it/s, loss=6.19e-08, v_num=23, train_loss=7.26e-6, test_loss=7.89e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1846:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.54it/s, loss=6.19e-08, v_num=23, train_loss=7.26e-6, test_loss=7.89e-6]\u001b[A\n",
      "Epoch 1846: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.51it/s, loss=6.19e-08, v_num=23, train_loss=7.15e-6, test_loss=7.79e-6]\u001b[A\n",
      "Epoch 1847:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.82it/s, loss=7.14e-08, v_num=23, train_loss=7.15e-6, test_loss=7.79e-6]\u001b[AAdjusting learning rate of group 0 to 9.7960e-05.\n",
      "Epoch 1847:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.01it/s, loss=6.78e-08, v_num=23, train_loss=7.15e-6, test_loss=7.79e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1847:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.25it/s, loss=6.78e-08, v_num=23, train_loss=7.15e-6, test_loss=7.79e-6]\u001b[A\n",
      "Epoch 1847: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 163.19it/s, loss=6.78e-08, v_num=23, train_loss=7.54e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1848:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.24it/s, loss=6.62e-08, v_num=23, train_loss=7.54e-6, test_loss=8.17e-6]\u001b[AAdjusting learning rate of group 0 to 9.7715e-05.\n",
      "Epoch 1848:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.04it/s, loss=6.28e-08, v_num=23, train_loss=7.54e-6, test_loss=8.17e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1848:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.01it/s, loss=6.28e-08, v_num=23, train_loss=7.54e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1848: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.91it/s, loss=6.28e-08, v_num=23, train_loss=7.49e-6, test_loss=8.12e-6]\u001b[A\n",
      "Epoch 1849:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.20it/s, loss=7.74e-08, v_num=23, train_loss=7.49e-6, test_loss=8.12e-6]\u001b[AAdjusting learning rate of group 0 to 9.7470e-05.\n",
      "Epoch 1849:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.31it/s, loss=7.43e-08, v_num=23, train_loss=7.49e-6, test_loss=8.12e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1849:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.48it/s, loss=7.43e-08, v_num=23, train_loss=7.49e-6, test_loss=8.12e-6]\u001b[A\n",
      "Epoch 1849: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.92it/s, loss=7.43e-08, v_num=23, train_loss=7.71e-6, test_loss=8.3e-6]\u001b[A\n",
      "Epoch 1850:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.20it/s, loss=6.84e-08, v_num=23, train_loss=7.71e-6, test_loss=8.3e-6]\u001b[AAdjusting learning rate of group 0 to 9.7227e-05.\n",
      "Epoch 1850:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.99it/s, loss=6.58e-08, v_num=23, train_loss=7.71e-6, test_loss=8.3e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1850:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.04it/s, loss=6.58e-08, v_num=23, train_loss=7.71e-6, test_loss=8.3e-6]\u001b[A\n",
      "Epoch 1850: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.83it/s, loss=6.58e-08, v_num=23, train_loss=7.47e-6, test_loss=8.08e-6]\u001b[A\n",
      "Epoch 1851:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.01it/s, loss=6.96e-08, v_num=23, train_loss=7.47e-6, test_loss=8.08e-6]\u001b[AAdjusting learning rate of group 0 to 9.6984e-05.\n",
      "Epoch 1851:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.95it/s, loss=6.64e-08, v_num=23, train_loss=7.47e-6, test_loss=8.08e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1851:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.15it/s, loss=6.64e-08, v_num=23, train_loss=7.47e-6, test_loss=8.08e-6]\u001b[A\n",
      "Epoch 1851: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.63it/s, loss=6.64e-08, v_num=23, train_loss=7.29e-6, test_loss=7.92e-6]\u001b[A\n",
      "Epoch 1852:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.67it/s, loss=7.23e-08, v_num=23, train_loss=7.29e-6, test_loss=7.92e-6]\u001b[AAdjusting learning rate of group 0 to 9.6741e-05.\n",
      "Epoch 1852:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.69it/s, loss=6.93e-08, v_num=23, train_loss=7.29e-6, test_loss=7.92e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1852:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.05it/s, loss=6.93e-08, v_num=23, train_loss=7.29e-6, test_loss=7.92e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1852: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.74it/s, loss=6.93e-08, v_num=23, train_loss=7.67e-6, test_loss=8.29e-6]\u001b[A\n",
      "Epoch 1853:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.05it/s, loss=6.72e-08, v_num=23, train_loss=7.67e-6, test_loss=8.29e-6]\u001b[AAdjusting learning rate of group 0 to 9.6499e-05.\n",
      "Epoch 1853:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.85it/s, loss=6.45e-08, v_num=23, train_loss=7.67e-6, test_loss=8.29e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1853:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.52it/s, loss=6.45e-08, v_num=23, train_loss=7.67e-6, test_loss=8.29e-6]\u001b[A\n",
      "Epoch 1853: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.43it/s, loss=6.45e-08, v_num=23, train_loss=7.3e-6, test_loss=7.91e-6]\u001b[A\n",
      "Epoch 1854:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.96it/s, loss=6.7e-08, v_num=23, train_loss=7.3e-6, test_loss=7.91e-6]\u001b[AAdjusting learning rate of group 0 to 9.6258e-05.\n",
      "Epoch 1854:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.88it/s, loss=6.37e-08, v_num=23, train_loss=7.3e-6, test_loss=7.91e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1854:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.17it/s, loss=6.37e-08, v_num=23, train_loss=7.3e-6, test_loss=7.91e-6]\u001b[A\n",
      "Epoch 1854: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 166.61it/s, loss=6.37e-08, v_num=23, train_loss=7.39e-6, test_loss=8e-6]\u001b[A\n",
      "Epoch 1855:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.78it/s, loss=6.76e-08, v_num=23, train_loss=7.39e-6, test_loss=8e-6]\u001b[AAdjusting learning rate of group 0 to 9.6018e-05.\n",
      "Epoch 1855:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 138.15it/s, loss=6.44e-08, v_num=23, train_loss=7.39e-6, test_loss=8e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1855:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 132.05it/s, loss=6.44e-08, v_num=23, train_loss=7.39e-6, test_loss=8e-6]\u001b[A\n",
      "Epoch 1855: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.55it/s, loss=6.44e-08, v_num=23, train_loss=6.87e-6, test_loss=7.49e-6]\u001b[A\n",
      "Epoch 1856:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.46it/s, loss=7.23e-08, v_num=23, train_loss=6.87e-6, test_loss=7.49e-6]\u001b[AAdjusting learning rate of group 0 to 9.5777e-05.\n",
      "Epoch 1856:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.57it/s, loss=6.99e-08, v_num=23, train_loss=6.87e-6, test_loss=7.49e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1856:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.54it/s, loss=6.99e-08, v_num=23, train_loss=6.87e-6, test_loss=7.49e-6]\u001b[A\n",
      "Epoch 1856: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.81it/s, loss=6.99e-08, v_num=23, train_loss=7.05e-6, test_loss=7.66e-6]\u001b[A\n",
      "Epoch 1857:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.47it/s, loss=7.82e-08, v_num=23, train_loss=7.05e-6, test_loss=7.66e-6]\u001b[AAdjusting learning rate of group 0 to 9.5538e-05.\n",
      "Epoch 1857:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.59it/s, loss=7.57e-08, v_num=23, train_loss=7.05e-6, test_loss=7.66e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1857:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.66it/s, loss=7.57e-08, v_num=23, train_loss=7.05e-6, test_loss=7.66e-6]\u001b[A\n",
      "Epoch 1857: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.93it/s, loss=7.57e-08, v_num=23, train_loss=7.36e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1858:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.81it/s, loss=7.5e-08, v_num=23, train_loss=7.36e-6, test_loss=7.97e-6]\u001b[AAdjusting learning rate of group 0 to 9.5299e-05.\n",
      "Epoch 1858:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.55it/s, loss=7.24e-08, v_num=23, train_loss=7.36e-6, test_loss=7.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1858:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.07it/s, loss=7.24e-08, v_num=23, train_loss=7.36e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1858: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.41it/s, loss=7.24e-08, v_num=23, train_loss=7.51e-6, test_loss=8.11e-6]\u001b[A\n",
      "Epoch 1859:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.48it/s, loss=9.52e-08, v_num=23, train_loss=7.51e-6, test_loss=8.11e-6]\u001b[AAdjusting learning rate of group 0 to 9.5061e-05.\n",
      "Epoch 1859:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.70it/s, loss=9.25e-08, v_num=23, train_loss=7.51e-6, test_loss=8.11e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1859:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.23it/s, loss=9.25e-08, v_num=23, train_loss=7.51e-6, test_loss=8.11e-6]\u001b[A\n",
      "Epoch 1859: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.24it/s, loss=9.25e-08, v_num=23, train_loss=7.28e-6, test_loss=7.92e-6]\u001b[A\n",
      "Epoch 1860:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.49it/s, loss=7.44e-08, v_num=23, train_loss=7.28e-6, test_loss=7.92e-6]\u001b[AAdjusting learning rate of group 0 to 9.4823e-05.\n",
      "Epoch 1860:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.81it/s, loss=6.37e-08, v_num=23, train_loss=7.28e-6, test_loss=7.92e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1860:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.72it/s, loss=6.37e-08, v_num=23, train_loss=7.28e-6, test_loss=7.92e-6]\u001b[A\n",
      "Epoch 1860: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.40it/s, loss=6.37e-08, v_num=23, train_loss=7.59e-6, test_loss=8.2e-6]\u001b[A\n",
      "Epoch 1861:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 148.53it/s, loss=6.4e-08, v_num=23, train_loss=7.59e-6, test_loss=8.2e-6]\u001b[AAdjusting learning rate of group 0 to 9.4586e-05.\n",
      "Epoch 1861:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.84it/s, loss=6.14e-08, v_num=23, train_loss=7.59e-6, test_loss=8.2e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1861:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.29it/s, loss=6.14e-08, v_num=23, train_loss=7.59e-6, test_loss=8.2e-6]\u001b[A\n",
      "Epoch 1861: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.42it/s, loss=6.14e-08, v_num=23, train_loss=7.51e-6, test_loss=8.1e-6]\u001b[A\n",
      "Epoch 1862:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.07it/s, loss=6.88e-08, v_num=23, train_loss=7.51e-6, test_loss=8.1e-6]\u001b[AAdjusting learning rate of group 0 to 9.4350e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1862:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.85it/s, loss=6.56e-08, v_num=23, train_loss=7.51e-6, test_loss=8.1e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1862:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.56it/s, loss=6.56e-08, v_num=23, train_loss=7.51e-6, test_loss=8.1e-6]\u001b[A\n",
      "Epoch 1862: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.61it/s, loss=6.56e-08, v_num=23, train_loss=7.74e-6, test_loss=8.35e-6]\u001b[A\n",
      "Epoch 1863:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.06it/s, loss=9.78e-08, v_num=23, train_loss=7.74e-6, test_loss=8.35e-6]\u001b[AAdjusting learning rate of group 0 to 9.4114e-05.\n",
      "Epoch 1863:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.49it/s, loss=9.41e-08, v_num=23, train_loss=7.74e-6, test_loss=8.35e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1863:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.63it/s, loss=9.41e-08, v_num=23, train_loss=7.74e-6, test_loss=8.35e-6]\u001b[A\n",
      "Epoch 1863: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.30it/s, loss=9.41e-08, v_num=23, train_loss=7.24e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1864:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.62it/s, loss=6.87e-08, v_num=23, train_loss=7.24e-6, test_loss=7.97e-6]\u001b[AAdjusting learning rate of group 0 to 9.3879e-05.\n",
      "Epoch 1864:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.15it/s, loss=6.56e-08, v_num=23, train_loss=7.24e-6, test_loss=7.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1864:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.03it/s, loss=6.56e-08, v_num=23, train_loss=7.24e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1864: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 166.41it/s, loss=6.56e-08, v_num=23, train_loss=7.41e-6, test_loss=8e-6]\u001b[A\n",
      "Epoch 1865:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.61it/s, loss=6.38e-08, v_num=23, train_loss=7.41e-6, test_loss=8e-6]\u001b[AAdjusting learning rate of group 0 to 9.3644e-05.\n",
      "Epoch 1865:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 140.93it/s, loss=6.11e-08, v_num=23, train_loss=7.41e-6, test_loss=8e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1865:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 132.71it/s, loss=6.11e-08, v_num=23, train_loss=7.41e-6, test_loss=8e-6]\u001b[A\n",
      "Epoch 1865: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.67it/s, loss=6.11e-08, v_num=23, train_loss=7.11e-6, test_loss=7.75e-6]\u001b[A\n",
      "Epoch 1866:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.31it/s, loss=7.34e-08, v_num=23, train_loss=7.11e-6, test_loss=7.75e-6]\u001b[AAdjusting learning rate of group 0 to 9.3410e-05.\n",
      "Epoch 1866:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.12it/s, loss=7.11e-08, v_num=23, train_loss=7.11e-6, test_loss=7.75e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1866:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.85it/s, loss=7.11e-08, v_num=23, train_loss=7.11e-6, test_loss=7.75e-6]\u001b[A\n",
      "Epoch 1866: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.63it/s, loss=7.11e-08, v_num=23, train_loss=7.04e-6, test_loss=7.68e-6]\u001b[A\n",
      "Epoch 1867:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.62it/s, loss=6.52e-08, v_num=23, train_loss=7.04e-6, test_loss=7.68e-6]\u001b[AAdjusting learning rate of group 0 to 9.3176e-05.\n",
      "Epoch 1867:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.67it/s, loss=6.26e-08, v_num=23, train_loss=7.04e-6, test_loss=7.68e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1867:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.09it/s, loss=6.26e-08, v_num=23, train_loss=7.04e-6, test_loss=7.68e-6]\u001b[A\n",
      "Epoch 1867: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.45it/s, loss=6.26e-08, v_num=23, train_loss=7.4e-6, test_loss=8.03e-6]\u001b[A\n",
      "Epoch 1868:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.01it/s, loss=7.08e-08, v_num=23, train_loss=7.4e-6, test_loss=8.03e-6]\u001b[AAdjusting learning rate of group 0 to 9.2943e-05.\n",
      "Epoch 1868:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.19it/s, loss=6.84e-08, v_num=23, train_loss=7.4e-6, test_loss=8.03e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1868:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.72it/s, loss=6.84e-08, v_num=23, train_loss=7.4e-6, test_loss=8.03e-6]\u001b[A\n",
      "Epoch 1868: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.60it/s, loss=6.84e-08, v_num=23, train_loss=7.38e-6, test_loss=8.03e-6]\u001b[A\n",
      "Epoch 1869:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.01it/s, loss=8.07e-08, v_num=23, train_loss=7.38e-6, test_loss=8.03e-6]\u001b[AAdjusting learning rate of group 0 to 9.2711e-05.\n",
      "Epoch 1869:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.21it/s, loss=6.84e-08, v_num=23, train_loss=7.38e-6, test_loss=8.03e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1869:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.52it/s, loss=6.84e-08, v_num=23, train_loss=7.38e-6, test_loss=8.03e-6]\u001b[A\n",
      "Epoch 1869: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.12it/s, loss=6.84e-08, v_num=23, train_loss=7.47e-6, test_loss=8.15e-6]\u001b[A\n",
      "Epoch 1870:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.70it/s, loss=7.46e-08, v_num=23, train_loss=7.47e-6, test_loss=8.15e-6]\u001b[AAdjusting learning rate of group 0 to 9.2479e-05.\n",
      "Epoch 1870:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.02it/s, loss=7.13e-08, v_num=23, train_loss=7.47e-6, test_loss=8.15e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1870:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.94it/s, loss=7.13e-08, v_num=23, train_loss=7.47e-6, test_loss=8.15e-6]\u001b[A\n",
      "Epoch 1870: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.43it/s, loss=7.13e-08, v_num=23, train_loss=7.38e-6, test_loss=8.01e-6]\u001b[A\n",
      "Epoch 1871:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.22it/s, loss=1.25e-07, v_num=23, train_loss=7.38e-6, test_loss=8.01e-6]\u001b[AAdjusting learning rate of group 0 to 9.2248e-05.\n",
      "Epoch 1871:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.27it/s, loss=1.22e-07, v_num=23, train_loss=7.38e-6, test_loss=8.01e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1871:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.72it/s, loss=1.22e-07, v_num=23, train_loss=7.38e-6, test_loss=8.01e-6]\u001b[A\n",
      "Epoch 1871: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.79it/s, loss=1.22e-07, v_num=23, train_loss=7.37e-6, test_loss=7.96e-6]\u001b[A\n",
      "Epoch 1872:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.12it/s, loss=8.03e-08, v_num=23, train_loss=7.37e-6, test_loss=7.96e-6]\u001b[AAdjusting learning rate of group 0 to 9.2017e-05.\n",
      "Epoch 1872:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.02it/s, loss=7.64e-08, v_num=23, train_loss=7.37e-6, test_loss=7.96e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1872:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.40it/s, loss=7.64e-08, v_num=23, train_loss=7.37e-6, test_loss=7.96e-6]\u001b[A\n",
      "Epoch 1872: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.14it/s, loss=7.64e-08, v_num=23, train_loss=7.29e-6, test_loss=7.99e-6]\u001b[A\n",
      "Epoch 1873:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.47it/s, loss=1.06e-07, v_num=23, train_loss=7.29e-6, test_loss=7.99e-6]\u001b[AAdjusting learning rate of group 0 to 9.1787e-05.\n",
      "Epoch 1873:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.48it/s, loss=1.03e-07, v_num=23, train_loss=7.29e-6, test_loss=7.99e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1873:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.12it/s, loss=1.03e-07, v_num=23, train_loss=7.29e-6, test_loss=7.99e-6]\u001b[A\n",
      "Epoch 1873: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.83it/s, loss=1.03e-07, v_num=23, train_loss=7.17e-6, test_loss=7.81e-6]\u001b[A\n",
      "Epoch 1874:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.17it/s, loss=6.89e-08, v_num=23, train_loss=7.17e-6, test_loss=7.81e-6]\u001b[AAdjusting learning rate of group 0 to 9.1558e-05.\n",
      "Epoch 1874:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.38it/s, loss=6.59e-08, v_num=23, train_loss=7.17e-6, test_loss=7.81e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1874:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.14it/s, loss=6.59e-08, v_num=23, train_loss=7.17e-6, test_loss=7.81e-6]\u001b[A\n",
      "Epoch 1874: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.19it/s, loss=6.59e-08, v_num=23, train_loss=7.43e-6, test_loss=8.06e-6]\u001b[A\n",
      "Epoch 1875:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.77it/s, loss=7.44e-08, v_num=23, train_loss=7.43e-6, test_loss=8.06e-6]\u001b[AAdjusting learning rate of group 0 to 9.1329e-05.\n",
      "Epoch 1875:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.74it/s, loss=7.1e-08, v_num=23, train_loss=7.43e-6, test_loss=8.06e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1875:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.06it/s, loss=7.1e-08, v_num=23, train_loss=7.43e-6, test_loss=8.06e-6]\u001b[A\n",
      "Epoch 1875: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.73it/s, loss=7.1e-08, v_num=23, train_loss=7.48e-6, test_loss=8.08e-6]\u001b[A\n",
      "Epoch 1876:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.70it/s, loss=6.94e-08, v_num=23, train_loss=7.48e-6, test_loss=8.08e-6]\u001b[AAdjusting learning rate of group 0 to 9.1101e-05.\n",
      "Epoch 1876:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.87it/s, loss=6.65e-08, v_num=23, train_loss=7.48e-6, test_loss=8.08e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1876:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.95it/s, loss=6.65e-08, v_num=23, train_loss=7.48e-6, test_loss=8.08e-6]\u001b[A\n",
      "Epoch 1876: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.08it/s, loss=6.65e-08, v_num=23, train_loss=7.46e-6, test_loss=8.03e-6]\u001b[A\n",
      "Epoch 1877:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.64it/s, loss=7.19e-08, v_num=23, train_loss=7.46e-6, test_loss=8.03e-6]\u001b[AAdjusting learning rate of group 0 to 9.0873e-05.\n",
      "Epoch 1877:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.82it/s, loss=6.94e-08, v_num=23, train_loss=7.46e-6, test_loss=8.03e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1877:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.29it/s, loss=6.94e-08, v_num=23, train_loss=7.46e-6, test_loss=8.03e-6]\u001b[A\n",
      "Epoch 1877: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.49it/s, loss=6.94e-08, v_num=23, train_loss=7.73e-6, test_loss=8.34e-6]\u001b[A\n",
      "Epoch 1878:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.02it/s, loss=7.21e-08, v_num=23, train_loss=7.73e-6, test_loss=8.34e-6]\u001b[AAdjusting learning rate of group 0 to 9.0646e-05.\n",
      "Epoch 1878:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.66it/s, loss=6.86e-08, v_num=23, train_loss=7.73e-6, test_loss=8.34e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1878:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.35it/s, loss=6.86e-08, v_num=23, train_loss=7.73e-6, test_loss=8.34e-6]\u001b[A\n",
      "Epoch 1878: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.33it/s, loss=6.86e-08, v_num=23, train_loss=7.45e-6, test_loss=8.07e-6]\u001b[A\n",
      "Epoch 1879:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.14it/s, loss=6.04e-08, v_num=23, train_loss=7.45e-6, test_loss=8.07e-6]\u001b[AAdjusting learning rate of group 0 to 9.0419e-05.\n",
      "Epoch 1879:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.03it/s, loss=5.84e-08, v_num=23, train_loss=7.45e-6, test_loss=8.07e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1879:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.50it/s, loss=5.84e-08, v_num=23, train_loss=7.45e-6, test_loss=8.07e-6]\u001b[A\n",
      "Epoch 1879: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.91it/s, loss=5.84e-08, v_num=23, train_loss=7.38e-6, test_loss=8.04e-6]\u001b[A\n",
      "Epoch 1880:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.62it/s, loss=8.14e-08, v_num=23, train_loss=7.38e-6, test_loss=8.04e-6]\u001b[AAdjusting learning rate of group 0 to 9.0193e-05.\n",
      "Epoch 1880:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.66it/s, loss=7.77e-08, v_num=23, train_loss=7.38e-6, test_loss=8.04e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1880:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.00it/s, loss=7.77e-08, v_num=23, train_loss=7.38e-6, test_loss=8.04e-6]\u001b[A\n",
      "Epoch 1880: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.24it/s, loss=7.77e-08, v_num=23, train_loss=7.84e-6, test_loss=8.46e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1881:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.70it/s, loss=7.11e-08, v_num=23, train_loss=7.84e-6, test_loss=8.46e-6]\u001b[AAdjusting learning rate of group 0 to 8.9968e-05.\n",
      "Epoch 1881:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.81it/s, loss=6.72e-08, v_num=23, train_loss=7.84e-6, test_loss=8.46e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1881:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.59it/s, loss=6.72e-08, v_num=23, train_loss=7.84e-6, test_loss=8.46e-6]\u001b[A\n",
      "Epoch 1881: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.93it/s, loss=6.72e-08, v_num=23, train_loss=7.52e-6, test_loss=8.15e-6]\u001b[A\n",
      "Epoch 1882:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.45it/s, loss=6.86e-08, v_num=23, train_loss=7.52e-6, test_loss=8.15e-6]\u001b[AAdjusting learning rate of group 0 to 8.9743e-05.\n",
      "Epoch 1882:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.68it/s, loss=6.6e-08, v_num=23, train_loss=7.52e-6, test_loss=8.15e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1882:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 134.04it/s, loss=6.6e-08, v_num=23, train_loss=7.52e-6, test_loss=8.15e-6]\u001b[A\n",
      "Epoch 1882: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.82it/s, loss=6.6e-08, v_num=23, train_loss=7.61e-6, test_loss=8.19e-6]\u001b[A\n",
      "Epoch 1883:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.96it/s, loss=7.93e-08, v_num=23, train_loss=7.61e-6, test_loss=8.19e-6]\u001b[AAdjusting learning rate of group 0 to 8.9518e-05.\n",
      "Epoch 1883:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.96it/s, loss=7.63e-08, v_num=23, train_loss=7.61e-6, test_loss=8.19e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1883:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.50it/s, loss=7.63e-08, v_num=23, train_loss=7.61e-6, test_loss=8.19e-6]\u001b[A\n",
      "Epoch 1883: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.43it/s, loss=7.63e-08, v_num=23, train_loss=7.31e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1884:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 150.33it/s, loss=7.6e-08, v_num=23, train_loss=7.31e-6, test_loss=7.93e-6]\u001b[AAdjusting learning rate of group 0 to 8.9295e-05.\n",
      "Epoch 1884:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.73it/s, loss=6.89e-08, v_num=23, train_loss=7.31e-6, test_loss=7.93e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1884:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.31it/s, loss=6.89e-08, v_num=23, train_loss=7.31e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1884: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.38it/s, loss=6.89e-08, v_num=23, train_loss=9.68e-6, test_loss=1.04e-5]\u001b[A\n",
      "Epoch 1885:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.80it/s, loss=6.66e-08, v_num=23, train_loss=9.68e-6, test_loss=1.04e-5]\u001b[AAdjusting learning rate of group 0 to 8.9071e-05.\n",
      "Epoch 1885:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.32it/s, loss=6.29e-08, v_num=23, train_loss=9.68e-6, test_loss=1.04e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1885:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.52it/s, loss=6.29e-08, v_num=23, train_loss=9.68e-6, test_loss=1.04e-5]\u001b[A\n",
      "Epoch 1885: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.66it/s, loss=6.29e-08, v_num=23, train_loss=8.11e-6, test_loss=8.77e-6]\u001b[A\n",
      "Epoch 1886:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.57it/s, loss=8.18e-08, v_num=23, train_loss=8.11e-6, test_loss=8.77e-6]\u001b[AAdjusting learning rate of group 0 to 8.8849e-05.\n",
      "Epoch 1886:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.63it/s, loss=7.87e-08, v_num=23, train_loss=8.11e-6, test_loss=8.77e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1886:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.69it/s, loss=7.87e-08, v_num=23, train_loss=8.11e-6, test_loss=8.77e-6]\u001b[A\n",
      "Epoch 1886: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.44it/s, loss=7.87e-08, v_num=23, train_loss=7.78e-6, test_loss=8.36e-6]\u001b[A\n",
      "Epoch 1887:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.63it/s, loss=6.78e-08, v_num=23, train_loss=7.78e-6, test_loss=8.36e-6]\u001b[AAdjusting learning rate of group 0 to 8.8626e-05.\n",
      "Epoch 1887:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.74it/s, loss=6.45e-08, v_num=23, train_loss=7.78e-6, test_loss=8.36e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1887:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.61it/s, loss=6.45e-08, v_num=23, train_loss=7.78e-6, test_loss=8.36e-6]\u001b[A\n",
      "Epoch 1887: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.70it/s, loss=6.45e-08, v_num=23, train_loss=7.33e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1888:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.29it/s, loss=1.02e-07, v_num=23, train_loss=7.33e-6, test_loss=7.93e-6]\u001b[AAdjusting learning rate of group 0 to 8.8405e-05.\n",
      "Epoch 1888:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.39it/s, loss=9.74e-08, v_num=23, train_loss=7.33e-6, test_loss=7.93e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1888:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.60it/s, loss=9.74e-08, v_num=23, train_loss=7.33e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1888: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.74it/s, loss=9.74e-08, v_num=23, train_loss=7.33e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1889:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.34it/s, loss=6.49e-08, v_num=23, train_loss=7.33e-6, test_loss=7.93e-6]\u001b[AAdjusting learning rate of group 0 to 8.8184e-05.\n",
      "Epoch 1889:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.51it/s, loss=6.07e-08, v_num=23, train_loss=7.33e-6, test_loss=7.93e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.20it/s]\u001b[A\n",
      "Epoch 1889:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 124.82it/s, loss=6.07e-08, v_num=23, train_loss=7.33e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1889: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 160.07it/s, loss=6.07e-08, v_num=23, train_loss=7.18e-6, test_loss=7.83e-6]\u001b[A\n",
      "Epoch 1890:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.96it/s, loss=7.78e-08, v_num=23, train_loss=7.18e-6, test_loss=7.83e-6]\u001b[AAdjusting learning rate of group 0 to 8.7963e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1890:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.22it/s, loss=7.48e-08, v_num=23, train_loss=7.18e-6, test_loss=7.83e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1890:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.41it/s, loss=7.48e-08, v_num=23, train_loss=7.18e-6, test_loss=7.83e-6]\u001b[A\n",
      "Epoch 1890: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.19it/s, loss=7.48e-08, v_num=23, train_loss=7.05e-6, test_loss=7.71e-6]\u001b[A\n",
      "Epoch 1891:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.32it/s, loss=7.31e-08, v_num=23, train_loss=7.05e-6, test_loss=7.71e-6]\u001b[AAdjusting learning rate of group 0 to 8.7744e-05.\n",
      "Epoch 1891:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.37it/s, loss=6.98e-08, v_num=23, train_loss=7.05e-6, test_loss=7.71e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1891:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.46it/s, loss=6.98e-08, v_num=23, train_loss=7.05e-6, test_loss=7.71e-6]\u001b[A\n",
      "Epoch 1891: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.69it/s, loss=6.98e-08, v_num=23, train_loss=7.32e-6, test_loss=7.99e-6]\u001b[A\n",
      "Epoch 1892:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.06it/s, loss=8.4e-08, v_num=23, train_loss=7.32e-6, test_loss=7.99e-6]\u001b[AAdjusting learning rate of group 0 to 8.7524e-05.\n",
      "Epoch 1892:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.95it/s, loss=7.99e-08, v_num=23, train_loss=7.32e-6, test_loss=7.99e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1892:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.12it/s, loss=7.99e-08, v_num=23, train_loss=7.32e-6, test_loss=7.99e-6]\u001b[A\n",
      "Epoch 1892: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 169.54it/s, loss=7.99e-08, v_num=23, train_loss=7.43e-6, test_loss=8e-6]\u001b[A\n",
      "Epoch 1893:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 147.82it/s, loss=7.02e-08, v_num=23, train_loss=7.43e-6, test_loss=8e-6]\u001b[AAdjusting learning rate of group 0 to 8.7305e-05.\n",
      "Epoch 1893:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 139.97it/s, loss=6.73e-08, v_num=23, train_loss=7.43e-6, test_loss=8e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1893:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 133.13it/s, loss=6.73e-08, v_num=23, train_loss=7.43e-6, test_loss=8e-6]\u001b[A\n",
      "Epoch 1893: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.42it/s, loss=6.73e-08, v_num=23, train_loss=7.21e-6, test_loss=7.8e-6]\u001b[A\n",
      "Epoch 1894:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.75it/s, loss=8.17e-08, v_num=23, train_loss=7.21e-6, test_loss=7.8e-6]\u001b[AAdjusting learning rate of group 0 to 8.7087e-05.\n",
      "Epoch 1894:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.74it/s, loss=7.31e-08, v_num=23, train_loss=7.21e-6, test_loss=7.8e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1894:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.90it/s, loss=7.31e-08, v_num=23, train_loss=7.21e-6, test_loss=7.8e-6]\u001b[A\n",
      "Epoch 1894: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.54it/s, loss=7.31e-08, v_num=23, train_loss=7.04e-6, test_loss=7.66e-6]\u001b[A\n",
      "Epoch 1895:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.95it/s, loss=8.29e-08, v_num=23, train_loss=7.04e-6, test_loss=7.66e-6]\u001b[AAdjusting learning rate of group 0 to 8.6869e-05.\n",
      "Epoch 1895:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.52it/s, loss=7.91e-08, v_num=23, train_loss=7.04e-6, test_loss=7.66e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1895:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.22it/s, loss=7.91e-08, v_num=23, train_loss=7.04e-6, test_loss=7.66e-6]\u001b[A\n",
      "Epoch 1895: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.54it/s, loss=7.91e-08, v_num=23, train_loss=7.32e-6, test_loss=7.99e-6]\u001b[A\n",
      "Epoch 1896:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.47it/s, loss=6.49e-08, v_num=23, train_loss=7.32e-6, test_loss=7.99e-6]\u001b[AAdjusting learning rate of group 0 to 8.6652e-05.\n",
      "Epoch 1896:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.19it/s, loss=6.15e-08, v_num=23, train_loss=7.32e-6, test_loss=7.99e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1896:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.54it/s, loss=6.15e-08, v_num=23, train_loss=7.32e-6, test_loss=7.99e-6]\u001b[A\n",
      "Epoch 1896: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.05it/s, loss=6.15e-08, v_num=23, train_loss=7.06e-6, test_loss=7.72e-6]\u001b[A\n",
      "Epoch 1897:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.56it/s, loss=6.76e-08, v_num=23, train_loss=7.06e-6, test_loss=7.72e-6]\u001b[AAdjusting learning rate of group 0 to 8.6436e-05.\n",
      "Epoch 1897:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.22it/s, loss=6.53e-08, v_num=23, train_loss=7.06e-6, test_loss=7.72e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1897:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.40it/s, loss=6.53e-08, v_num=23, train_loss=7.06e-6, test_loss=7.72e-6]\u001b[A\n",
      "Epoch 1897: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.08it/s, loss=6.53e-08, v_num=23, train_loss=6.67e-6, test_loss=7.34e-6]\u001b[A\n",
      "Epoch 1898:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.66it/s, loss=7.95e-08, v_num=23, train_loss=6.67e-6, test_loss=7.34e-6]\u001b[AAdjusting learning rate of group 0 to 8.6219e-05.\n",
      "Epoch 1898:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.28it/s, loss=7.7e-08, v_num=23, train_loss=6.67e-6, test_loss=7.34e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1898:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.87it/s, loss=7.7e-08, v_num=23, train_loss=6.67e-6, test_loss=7.34e-6]\u001b[A\n",
      "Epoch 1898: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.26it/s, loss=7.7e-08, v_num=23, train_loss=6.99e-6, test_loss=7.66e-6]\u001b[A\n",
      "Epoch 1899:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.71it/s, loss=6.78e-08, v_num=23, train_loss=6.99e-6, test_loss=7.66e-6]\u001b[AAdjusting learning rate of group 0 to 8.6004e-05.\n",
      "Epoch 1899:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.56it/s, loss=6.52e-08, v_num=23, train_loss=6.99e-6, test_loss=7.66e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1899:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.14it/s, loss=6.52e-08, v_num=23, train_loss=6.99e-6, test_loss=7.66e-6]\u001b[A\n",
      "Epoch 1899: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 169.97it/s, loss=6.52e-08, v_num=23, train_loss=6.97e-6, test_loss=7.6e-6]\u001b[A\n",
      "Epoch 1900:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.09it/s, loss=7.53e-08, v_num=23, train_loss=6.97e-6, test_loss=7.6e-6]\u001b[AAdjusting learning rate of group 0 to 8.5789e-05.\n",
      "Epoch 1900:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.73it/s, loss=7.29e-08, v_num=23, train_loss=6.97e-6, test_loss=7.6e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1900:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.29it/s, loss=7.29e-08, v_num=23, train_loss=6.97e-6, test_loss=7.6e-6]\u001b[A\n",
      "Epoch 1900: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.91it/s, loss=7.29e-08, v_num=23, train_loss=6.99e-6, test_loss=7.68e-6]\u001b[A\n",
      "Epoch 1901:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.20it/s, loss=7.06e-08, v_num=23, train_loss=6.99e-6, test_loss=7.68e-6]\u001b[AAdjusting learning rate of group 0 to 8.5574e-05.\n",
      "Epoch 1901:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.90it/s, loss=6.82e-08, v_num=23, train_loss=6.99e-6, test_loss=7.68e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1901:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.36it/s, loss=6.82e-08, v_num=23, train_loss=6.99e-6, test_loss=7.68e-6]\u001b[A\n",
      "Epoch 1901: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.53it/s, loss=6.82e-08, v_num=23, train_loss=7.06e-6, test_loss=7.66e-6]\u001b[A\n",
      "Epoch 1902:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.42it/s, loss=6.24e-08, v_num=23, train_loss=7.06e-6, test_loss=7.66e-6]\u001b[AAdjusting learning rate of group 0 to 8.5361e-05.\n",
      "Epoch 1902:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.79it/s, loss=5.95e-08, v_num=23, train_loss=7.06e-6, test_loss=7.66e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1902:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.67it/s, loss=5.95e-08, v_num=23, train_loss=7.06e-6, test_loss=7.66e-6]\u001b[A\n",
      "Epoch 1902: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.30it/s, loss=5.95e-08, v_num=23, train_loss=7.63e-6, test_loss=8.27e-6]\u001b[A\n",
      "Epoch 1903:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.89it/s, loss=6.69e-08, v_num=23, train_loss=7.63e-6, test_loss=8.27e-6]\u001b[AAdjusting learning rate of group 0 to 8.5147e-05.\n",
      "Epoch 1903:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.53it/s, loss=6.4e-08, v_num=23, train_loss=7.63e-6, test_loss=8.27e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1903:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.81it/s, loss=6.4e-08, v_num=23, train_loss=7.63e-6, test_loss=8.27e-6]\u001b[A\n",
      "Epoch 1903: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.80it/s, loss=6.4e-08, v_num=23, train_loss=7.33e-6, test_loss=7.96e-6]\u001b[A\n",
      "Epoch 1904:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.71it/s, loss=7.32e-08, v_num=23, train_loss=7.33e-6, test_loss=7.96e-6]\u001b[AAdjusting learning rate of group 0 to 8.4934e-05.\n",
      "Epoch 1904:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.22it/s, loss=7.03e-08, v_num=23, train_loss=7.33e-6, test_loss=7.96e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1904:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.06it/s, loss=7.03e-08, v_num=23, train_loss=7.33e-6, test_loss=7.96e-6]\u001b[A\n",
      "Epoch 1904: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.87it/s, loss=7.03e-08, v_num=23, train_loss=7.36e-6, test_loss=7.96e-6]\u001b[A\n",
      "Epoch 1905:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.77it/s, loss=6.91e-08, v_num=23, train_loss=7.36e-6, test_loss=7.96e-6]\u001b[AAdjusting learning rate of group 0 to 8.4722e-05.\n",
      "Epoch 1905:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.18it/s, loss=6.64e-08, v_num=23, train_loss=7.36e-6, test_loss=7.96e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1905:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.81it/s, loss=6.64e-08, v_num=23, train_loss=7.36e-6, test_loss=7.96e-6]\u001b[A\n",
      "Epoch 1905: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.29it/s, loss=6.64e-08, v_num=23, train_loss=7.18e-6, test_loss=7.83e-6]\u001b[A\n",
      "Epoch 1906:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.92it/s, loss=7.11e-08, v_num=23, train_loss=7.18e-6, test_loss=7.83e-6]\u001b[AAdjusting learning rate of group 0 to 8.4510e-05.\n",
      "Epoch 1906:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.02it/s, loss=6.74e-08, v_num=23, train_loss=7.18e-6, test_loss=7.83e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1906:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 135.15it/s, loss=6.74e-08, v_num=23, train_loss=7.18e-6, test_loss=7.83e-6]\u001b[A\n",
      "Epoch 1906: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 172.61it/s, loss=6.74e-08, v_num=23, train_loss=7.49e-6, test_loss=8.14e-6]\u001b[A\n",
      "Epoch 1907:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.21it/s, loss=6.48e-08, v_num=23, train_loss=7.49e-6, test_loss=8.14e-6]\u001b[AAdjusting learning rate of group 0 to 8.4299e-05.\n",
      "Epoch 1907:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.98it/s, loss=6.1e-08, v_num=23, train_loss=7.49e-6, test_loss=8.14e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1907:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.94it/s, loss=6.1e-08, v_num=23, train_loss=7.49e-6, test_loss=8.14e-6]\u001b[A\n",
      "Epoch 1907: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 166.26it/s, loss=6.1e-08, v_num=23, train_loss=6.94e-6, test_loss=7.58e-6]\u001b[A\n",
      "Epoch 1908:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.81it/s, loss=7.51e-08, v_num=23, train_loss=6.94e-6, test_loss=7.58e-6]\u001b[AAdjusting learning rate of group 0 to 8.4088e-05.\n",
      "Epoch 1908:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.80it/s, loss=7.15e-08, v_num=23, train_loss=6.94e-6, test_loss=7.58e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1908:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.83it/s, loss=7.15e-08, v_num=23, train_loss=6.94e-6, test_loss=7.58e-6]\u001b[A\n",
      "Epoch 1908: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.43it/s, loss=7.15e-08, v_num=23, train_loss=6.92e-6, test_loss=7.57e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1909:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.84it/s, loss=7.43e-08, v_num=23, train_loss=6.92e-6, test_loss=7.57e-6]\u001b[AAdjusting learning rate of group 0 to 8.3878e-05.\n",
      "Epoch 1909:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.70it/s, loss=7.14e-08, v_num=23, train_loss=6.92e-6, test_loss=7.57e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1909:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.94it/s, loss=7.14e-08, v_num=23, train_loss=6.92e-6, test_loss=7.57e-6]\u001b[A\n",
      "Epoch 1909: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.52it/s, loss=7.14e-08, v_num=23, train_loss=7.34e-6, test_loss=7.94e-6]\u001b[A\n",
      "Epoch 1910:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.88it/s, loss=9.97e-08, v_num=23, train_loss=7.34e-6, test_loss=7.94e-6]\u001b[AAdjusting learning rate of group 0 to 8.3668e-05.\n",
      "Epoch 1910:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.90it/s, loss=9.67e-08, v_num=23, train_loss=7.34e-6, test_loss=7.94e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1910:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.32it/s, loss=9.67e-08, v_num=23, train_loss=7.34e-6, test_loss=7.94e-6]\u001b[A\n",
      "Epoch 1910: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.45it/s, loss=9.67e-08, v_num=23, train_loss=7.47e-6, test_loss=8.13e-6]\u001b[A\n",
      "Epoch 1911:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.28it/s, loss=6.01e-08, v_num=23, train_loss=7.47e-6, test_loss=8.13e-6]\u001b[AAdjusting learning rate of group 0 to 8.3459e-05.\n",
      "Epoch 1911:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 138.83it/s, loss=6e-08, v_num=23, train_loss=7.47e-6, test_loss=8.13e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1911:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 131.43it/s, loss=6e-08, v_num=23, train_loss=7.47e-6, test_loss=8.13e-6]\u001b[A\n",
      "Epoch 1911: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 167.07it/s, loss=6e-08, v_num=23, train_loss=6.92e-6, test_loss=7.51e-6]\u001b[A\n",
      "Epoch 1912:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.06it/s, loss=6.49e-08, v_num=23, train_loss=6.92e-6, test_loss=7.51e-6]\u001b[AAdjusting learning rate of group 0 to 8.3250e-05.\n",
      "Epoch 1912:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.85it/s, loss=6.15e-08, v_num=23, train_loss=6.92e-6, test_loss=7.51e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1912:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.25it/s, loss=6.15e-08, v_num=23, train_loss=6.92e-6, test_loss=7.51e-6]\u001b[A\n",
      "Epoch 1912: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.58it/s, loss=6.15e-08, v_num=23, train_loss=7.18e-6, test_loss=7.74e-6]\u001b[A\n",
      "Epoch 1913:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.77it/s, loss=7.38e-08, v_num=23, train_loss=7.18e-6, test_loss=7.74e-6]\u001b[AAdjusting learning rate of group 0 to 8.3042e-05.\n",
      "Epoch 1913:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.69it/s, loss=7.02e-08, v_num=23, train_loss=7.18e-6, test_loss=7.74e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1913:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.24it/s, loss=7.02e-08, v_num=23, train_loss=7.18e-6, test_loss=7.74e-6]\u001b[A\n",
      "Epoch 1913: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.39it/s, loss=7.02e-08, v_num=23, train_loss=7.53e-6, test_loss=8.15e-6]\u001b[A\n",
      "Epoch 1914:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.83it/s, loss=6.74e-08, v_num=23, train_loss=7.53e-6, test_loss=8.15e-6]\u001b[AAdjusting learning rate of group 0 to 8.2835e-05.\n",
      "Epoch 1914:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.93it/s, loss=6.55e-08, v_num=23, train_loss=7.53e-6, test_loss=8.15e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1914:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.08it/s, loss=6.55e-08, v_num=23, train_loss=7.53e-6, test_loss=8.15e-6]\u001b[A\n",
      "Epoch 1914: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.14it/s, loss=6.55e-08, v_num=23, train_loss=7.24e-6, test_loss=7.86e-6]\u001b[A\n",
      "Epoch 1915:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.61it/s, loss=6.67e-08, v_num=23, train_loss=7.24e-6, test_loss=7.86e-6]\u001b[AAdjusting learning rate of group 0 to 8.2628e-05.\n",
      "Epoch 1915:  50%|███████████████████                   | 79/158 [00:00<00:00, 135.65it/s, loss=6.48e-08, v_num=23, train_loss=7.24e-6, test_loss=7.86e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1915:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.87it/s, loss=6.48e-08, v_num=23, train_loss=7.24e-6, test_loss=7.86e-6]\u001b[A\n",
      "Epoch 1915: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.42it/s, loss=6.48e-08, v_num=23, train_loss=7.31e-6, test_loss=7.95e-6]\u001b[A\n",
      "Epoch 1916:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.07it/s, loss=6.74e-08, v_num=23, train_loss=7.31e-6, test_loss=7.95e-6]\u001b[AAdjusting learning rate of group 0 to 8.2421e-05.\n",
      "Epoch 1916:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.10it/s, loss=6.36e-08, v_num=23, train_loss=7.31e-6, test_loss=7.95e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1916:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.59it/s, loss=6.36e-08, v_num=23, train_loss=7.31e-6, test_loss=7.95e-6]\u001b[A\n",
      "Epoch 1916: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.80it/s, loss=6.36e-08, v_num=23, train_loss=7.52e-6, test_loss=8.15e-6]\u001b[A\n",
      "Epoch 1917:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.80it/s, loss=6.94e-08, v_num=23, train_loss=7.52e-6, test_loss=8.15e-6]\u001b[AAdjusting learning rate of group 0 to 8.2215e-05.\n",
      "Epoch 1917:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.86it/s, loss=6.65e-08, v_num=23, train_loss=7.52e-6, test_loss=8.15e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1917:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.14it/s, loss=6.65e-08, v_num=23, train_loss=7.52e-6, test_loss=8.15e-6]\u001b[A\n",
      "Epoch 1917: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.07it/s, loss=6.65e-08, v_num=23, train_loss=6.89e-6, test_loss=7.55e-6]\u001b[A\n",
      "Epoch 1918:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.39it/s, loss=8.05e-08, v_num=23, train_loss=6.89e-6, test_loss=7.55e-6]\u001b[AAdjusting learning rate of group 0 to 8.2009e-05.\n",
      "Epoch 1918:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.99it/s, loss=7.83e-08, v_num=23, train_loss=6.89e-6, test_loss=7.55e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1918:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.40it/s, loss=7.83e-08, v_num=23, train_loss=6.89e-6, test_loss=7.55e-6]\u001b[A\n",
      "Epoch 1918: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.20it/s, loss=7.83e-08, v_num=23, train_loss=7.3e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1919:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.75it/s, loss=6.49e-08, v_num=23, train_loss=7.3e-6, test_loss=7.93e-6]\u001b[AAdjusting learning rate of group 0 to 8.1804e-05.\n",
      "Epoch 1919:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.03it/s, loss=6.21e-08, v_num=23, train_loss=7.3e-6, test_loss=7.93e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1919:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.10it/s, loss=6.21e-08, v_num=23, train_loss=7.3e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1919: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.60it/s, loss=6.21e-08, v_num=23, train_loss=7.06e-6, test_loss=7.72e-6]\u001b[A\n",
      "Epoch 1920:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.48it/s, loss=7.31e-08, v_num=23, train_loss=7.06e-6, test_loss=7.72e-6]\u001b[AAdjusting learning rate of group 0 to 8.1600e-05.\n",
      "Epoch 1920:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.58it/s, loss=6.99e-08, v_num=23, train_loss=7.06e-6, test_loss=7.72e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1920:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.17it/s, loss=6.99e-08, v_num=23, train_loss=7.06e-6, test_loss=7.72e-6]\u001b[A\n",
      "Epoch 1920: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.47it/s, loss=6.99e-08, v_num=23, train_loss=7.42e-6, test_loss=8.1e-6]\u001b[A\n",
      "Epoch 1921:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.38it/s, loss=7.11e-08, v_num=23, train_loss=7.42e-6, test_loss=8.1e-6]\u001b[AAdjusting learning rate of group 0 to 8.1396e-05.\n",
      "Epoch 1921:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.43it/s, loss=6.88e-08, v_num=23, train_loss=7.42e-6, test_loss=8.1e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1921:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.31it/s, loss=6.88e-08, v_num=23, train_loss=7.42e-6, test_loss=8.1e-6]\u001b[A\n",
      "Epoch 1921: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.25it/s, loss=6.88e-08, v_num=23, train_loss=6.95e-6, test_loss=7.62e-6]\u001b[A\n",
      "Epoch 1922:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.74it/s, loss=6.77e-08, v_num=23, train_loss=6.95e-6, test_loss=7.62e-6]\u001b[AAdjusting learning rate of group 0 to 8.1192e-05.\n",
      "Epoch 1922:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.02it/s, loss=6.5e-08, v_num=23, train_loss=6.95e-6, test_loss=7.62e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1922:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 130.78it/s, loss=6.5e-08, v_num=23, train_loss=6.95e-6, test_loss=7.62e-6]\u001b[A\n",
      "Epoch 1922: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.98it/s, loss=6.5e-08, v_num=23, train_loss=7.22e-6, test_loss=7.81e-6]\u001b[A\n",
      "Epoch 1923:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.08it/s, loss=7.13e-08, v_num=23, train_loss=7.22e-6, test_loss=7.81e-6]\u001b[AAdjusting learning rate of group 0 to 8.0989e-05.\n",
      "Epoch 1923:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.57it/s, loss=6.68e-08, v_num=23, train_loss=7.22e-6, test_loss=7.81e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1923:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.75it/s, loss=6.68e-08, v_num=23, train_loss=7.22e-6, test_loss=7.81e-6]\u001b[A\n",
      "Epoch 1923: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.66it/s, loss=6.68e-08, v_num=23, train_loss=7.81e-6, test_loss=8.38e-6]\u001b[A\n",
      "Epoch 1924:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.10it/s, loss=8.57e-08, v_num=23, train_loss=7.81e-6, test_loss=8.38e-6]\u001b[AAdjusting learning rate of group 0 to 8.0787e-05.\n",
      "Epoch 1924:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.50it/s, loss=8.24e-08, v_num=23, train_loss=7.81e-6, test_loss=8.38e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1924:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.87it/s, loss=8.24e-08, v_num=23, train_loss=7.81e-6, test_loss=8.38e-6]\u001b[A\n",
      "Epoch 1924: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.98it/s, loss=8.24e-08, v_num=23, train_loss=7.24e-6, test_loss=7.88e-6]\u001b[A\n",
      "Epoch 1925:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.81it/s, loss=7.34e-08, v_num=23, train_loss=7.24e-6, test_loss=7.88e-6]\u001b[AAdjusting learning rate of group 0 to 8.0585e-05.\n",
      "Epoch 1925:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.18it/s, loss=7.06e-08, v_num=23, train_loss=7.24e-6, test_loss=7.88e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1925:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.36it/s, loss=7.06e-08, v_num=23, train_loss=7.24e-6, test_loss=7.88e-6]\u001b[A\n",
      "Epoch 1925: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.67it/s, loss=7.06e-08, v_num=23, train_loss=7.12e-6, test_loss=7.78e-6]\u001b[A\n",
      "Epoch 1926:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.82it/s, loss=6.52e-08, v_num=23, train_loss=7.12e-6, test_loss=7.78e-6]\u001b[AAdjusting learning rate of group 0 to 8.0383e-05.\n",
      "Epoch 1926:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.86it/s, loss=6.18e-08, v_num=23, train_loss=7.12e-6, test_loss=7.78e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1926:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.71it/s, loss=6.18e-08, v_num=23, train_loss=7.12e-6, test_loss=7.78e-6]\u001b[A\n",
      "Epoch 1926: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.71it/s, loss=6.18e-08, v_num=23, train_loss=7.01e-6, test_loss=7.66e-6]\u001b[A\n",
      "Epoch 1927:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.17it/s, loss=8.47e-08, v_num=23, train_loss=7.01e-6, test_loss=7.66e-6]\u001b[AAdjusting learning rate of group 0 to 8.0183e-05.\n",
      "Epoch 1927:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.07it/s, loss=8.07e-08, v_num=23, train_loss=7.01e-6, test_loss=7.66e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1927:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.70it/s, loss=8.07e-08, v_num=23, train_loss=7.01e-6, test_loss=7.66e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1927: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.94it/s, loss=8.07e-08, v_num=23, train_loss=6.88e-6, test_loss=7.49e-6]\u001b[A\n",
      "Epoch 1928:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.46it/s, loss=7.17e-08, v_num=23, train_loss=6.88e-6, test_loss=7.49e-6]\u001b[AAdjusting learning rate of group 0 to 7.9982e-05.\n",
      "Epoch 1928:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.80it/s, loss=6.86e-08, v_num=23, train_loss=6.88e-6, test_loss=7.49e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1928:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.15it/s, loss=6.86e-08, v_num=23, train_loss=6.88e-6, test_loss=7.49e-6]\u001b[A\n",
      "Epoch 1928: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 164.80it/s, loss=6.86e-08, v_num=23, train_loss=7.21e-6, test_loss=7.82e-6]\u001b[A\n",
      "Epoch 1929:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.71it/s, loss=6.96e-08, v_num=23, train_loss=7.21e-6, test_loss=7.82e-6]\u001b[AAdjusting learning rate of group 0 to 7.9782e-05.\n",
      "Epoch 1929:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.75it/s, loss=6.62e-08, v_num=23, train_loss=7.21e-6, test_loss=7.82e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1929:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.02it/s, loss=6.62e-08, v_num=23, train_loss=7.21e-6, test_loss=7.82e-6]\u001b[A\n",
      "Epoch 1929: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.03it/s, loss=6.62e-08, v_num=23, train_loss=7.18e-6, test_loss=7.81e-6]\u001b[A\n",
      "Epoch 1930:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.58it/s, loss=7.35e-08, v_num=23, train_loss=7.18e-6, test_loss=7.81e-6]\u001b[AAdjusting learning rate of group 0 to 7.9583e-05.\n",
      "Epoch 1930:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.22it/s, loss=7.15e-08, v_num=23, train_loss=7.18e-6, test_loss=7.81e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1930:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.31it/s, loss=7.15e-08, v_num=23, train_loss=7.18e-6, test_loss=7.81e-6]\u001b[A\n",
      "Epoch 1930: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 164.24it/s, loss=7.15e-08, v_num=23, train_loss=7.34e-6, test_loss=8e-6]\u001b[A\n",
      "Epoch 1931:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 149.56it/s, loss=6.79e-08, v_num=23, train_loss=7.34e-6, test_loss=8e-6]\u001b[AAdjusting learning rate of group 0 to 7.9384e-05.\n",
      "Epoch 1931:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 141.44it/s, loss=6.39e-08, v_num=23, train_loss=7.34e-6, test_loss=8e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1931:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 135.44it/s, loss=6.39e-08, v_num=23, train_loss=7.34e-6, test_loss=8e-6]\u001b[A\n",
      "Epoch 1931: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.65it/s, loss=6.39e-08, v_num=23, train_loss=6.97e-6, test_loss=7.61e-6]\u001b[A\n",
      "Epoch 1932:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.39it/s, loss=7.07e-08, v_num=23, train_loss=6.97e-6, test_loss=7.61e-6]\u001b[AAdjusting learning rate of group 0 to 7.9185e-05.\n",
      "Epoch 1932:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.01it/s, loss=6.81e-08, v_num=23, train_loss=6.97e-6, test_loss=7.61e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1932:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.69it/s, loss=6.81e-08, v_num=23, train_loss=6.97e-6, test_loss=7.61e-6]\u001b[A\n",
      "Epoch 1932: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.17it/s, loss=6.81e-08, v_num=23, train_loss=7.54e-6, test_loss=8.22e-6]\u001b[A\n",
      "Epoch 1933:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.10it/s, loss=6.73e-08, v_num=23, train_loss=7.54e-6, test_loss=8.22e-6]\u001b[AAdjusting learning rate of group 0 to 7.8987e-05.\n",
      "Epoch 1933:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.93it/s, loss=6.52e-08, v_num=23, train_loss=7.54e-6, test_loss=8.22e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1933:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.67it/s, loss=6.52e-08, v_num=23, train_loss=7.54e-6, test_loss=8.22e-6]\u001b[A\n",
      "Epoch 1933: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.64it/s, loss=6.52e-08, v_num=23, train_loss=7.57e-6, test_loss=8.21e-6]\u001b[A\n",
      "Epoch 1934:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.16it/s, loss=6.33e-08, v_num=23, train_loss=7.57e-6, test_loss=8.21e-6]\u001b[AAdjusting learning rate of group 0 to 7.8790e-05.\n",
      "Epoch 1934:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.03it/s, loss=6.09e-08, v_num=23, train_loss=7.57e-6, test_loss=8.21e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1934:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.35it/s, loss=6.09e-08, v_num=23, train_loss=7.57e-6, test_loss=8.21e-6]\u001b[A\n",
      "Epoch 1934: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.85it/s, loss=6.09e-08, v_num=23, train_loss=7.13e-6, test_loss=7.76e-6]\u001b[A\n",
      "Epoch 1935:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.59it/s, loss=6.63e-08, v_num=23, train_loss=7.13e-6, test_loss=7.76e-6]\u001b[AAdjusting learning rate of group 0 to 7.8593e-05.\n",
      "Epoch 1935:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.99it/s, loss=6.06e-08, v_num=23, train_loss=7.13e-6, test_loss=7.76e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1935:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.18it/s, loss=6.06e-08, v_num=23, train_loss=7.13e-6, test_loss=7.76e-6]\u001b[A\n",
      "Epoch 1935: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.44it/s, loss=6.06e-08, v_num=23, train_loss=7.13e-6, test_loss=7.76e-6]\u001b[A\n",
      "Epoch 1936:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.32it/s, loss=7.15e-08, v_num=23, train_loss=7.13e-6, test_loss=7.76e-6]\u001b[AAdjusting learning rate of group 0 to 7.8396e-05.\n",
      "Epoch 1936:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.14it/s, loss=6.85e-08, v_num=23, train_loss=7.13e-6, test_loss=7.76e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1936:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.34it/s, loss=6.85e-08, v_num=23, train_loss=7.13e-6, test_loss=7.76e-6]\u001b[A\n",
      "Epoch 1936: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.39it/s, loss=6.85e-08, v_num=23, train_loss=7.3e-6, test_loss=7.85e-6]\u001b[A\n",
      "Epoch 1937:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.28it/s, loss=6.87e-08, v_num=23, train_loss=7.3e-6, test_loss=7.85e-6]\u001b[AAdjusting learning rate of group 0 to 7.8200e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1937:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.00it/s, loss=6.48e-08, v_num=23, train_loss=7.3e-6, test_loss=7.85e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1937:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.92it/s, loss=6.48e-08, v_num=23, train_loss=7.3e-6, test_loss=7.85e-6]\u001b[A\n",
      "Epoch 1937: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.34it/s, loss=6.48e-08, v_num=23, train_loss=7.68e-6, test_loss=8.28e-6]\u001b[A\n",
      "Epoch 1938:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.48it/s, loss=7.08e-08, v_num=23, train_loss=7.68e-6, test_loss=8.28e-6]\u001b[AAdjusting learning rate of group 0 to 7.8005e-05.\n",
      "Epoch 1938:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.37it/s, loss=6.77e-08, v_num=23, train_loss=7.68e-6, test_loss=8.28e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1938:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.41it/s, loss=6.77e-08, v_num=23, train_loss=7.68e-6, test_loss=8.28e-6]\u001b[A\n",
      "Epoch 1938: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.15it/s, loss=6.77e-08, v_num=23, train_loss=7.55e-6, test_loss=8.12e-6]\u001b[A\n",
      "Epoch 1939:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.31it/s, loss=8.51e-08, v_num=23, train_loss=7.55e-6, test_loss=8.12e-6]\u001b[AAdjusting learning rate of group 0 to 7.7810e-05.\n",
      "Epoch 1939:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.93it/s, loss=8.1e-08, v_num=23, train_loss=7.55e-6, test_loss=8.12e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1939:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.27it/s, loss=8.1e-08, v_num=23, train_loss=7.55e-6, test_loss=8.12e-6]\u001b[A\n",
      "Epoch 1939: 100%|███████████████████████████████████████| 158/158 [00:00<00:00, 169.55it/s, loss=8.1e-08, v_num=23, train_loss=8.82e-6, test_loss=9.5e-6]\u001b[A\n",
      "Epoch 1940:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.75it/s, loss=6.73e-08, v_num=23, train_loss=8.82e-6, test_loss=9.5e-6]\u001b[AAdjusting learning rate of group 0 to 7.7615e-05.\n",
      "Epoch 1940:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 137.76it/s, loss=6.38e-08, v_num=23, train_loss=8.82e-6, test_loss=9.5e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1940:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.58it/s, loss=6.38e-08, v_num=23, train_loss=8.82e-6, test_loss=9.5e-6]\u001b[A\n",
      "Epoch 1940: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.54it/s, loss=6.38e-08, v_num=23, train_loss=7.35e-6, test_loss=7.94e-6]\u001b[A\n",
      "Epoch 1941:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.81it/s, loss=6.36e-08, v_num=23, train_loss=7.35e-6, test_loss=7.94e-6]\u001b[AAdjusting learning rate of group 0 to 7.7421e-05.\n",
      "Epoch 1941:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.78it/s, loss=6.03e-08, v_num=23, train_loss=7.35e-6, test_loss=7.94e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1941:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.10it/s, loss=6.03e-08, v_num=23, train_loss=7.35e-6, test_loss=7.94e-6]\u001b[A\n",
      "Epoch 1941: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.22it/s, loss=6.03e-08, v_num=23, train_loss=7.27e-6, test_loss=7.87e-6]\u001b[A\n",
      "Epoch 1942:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.61it/s, loss=6.62e-08, v_num=23, train_loss=7.27e-6, test_loss=7.87e-6]\u001b[AAdjusting learning rate of group 0 to 7.7228e-05.\n",
      "Epoch 1942:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.63it/s, loss=6.27e-08, v_num=23, train_loss=7.27e-6, test_loss=7.87e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1942:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.69it/s, loss=6.27e-08, v_num=23, train_loss=7.27e-6, test_loss=7.87e-6]\u001b[A\n",
      "Epoch 1942: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.47it/s, loss=6.27e-08, v_num=23, train_loss=7.16e-6, test_loss=7.74e-6]\u001b[A\n",
      "Epoch 1943:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.33it/s, loss=6.56e-08, v_num=23, train_loss=7.16e-6, test_loss=7.74e-6]\u001b[AAdjusting learning rate of group 0 to 7.7035e-05.\n",
      "Epoch 1943:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.44it/s, loss=6.19e-08, v_num=23, train_loss=7.16e-6, test_loss=7.74e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1943:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.82it/s, loss=6.19e-08, v_num=23, train_loss=7.16e-6, test_loss=7.74e-6]\u001b[A\n",
      "Epoch 1943: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.70it/s, loss=6.19e-08, v_num=23, train_loss=7.28e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1944:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.37it/s, loss=6.63e-08, v_num=23, train_loss=7.28e-6, test_loss=7.93e-6]\u001b[AAdjusting learning rate of group 0 to 7.6842e-05.\n",
      "Epoch 1944:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.64it/s, loss=6.37e-08, v_num=23, train_loss=7.28e-6, test_loss=7.93e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1944:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.93it/s, loss=6.37e-08, v_num=23, train_loss=7.28e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1944: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.68it/s, loss=6.37e-08, v_num=23, train_loss=7.56e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1945:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.35it/s, loss=6.93e-08, v_num=23, train_loss=7.56e-6, test_loss=8.17e-6]\u001b[AAdjusting learning rate of group 0 to 7.6650e-05.\n",
      "Epoch 1945:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.93it/s, loss=6.64e-08, v_num=23, train_loss=7.56e-6, test_loss=8.17e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1945:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.26it/s, loss=6.64e-08, v_num=23, train_loss=7.56e-6, test_loss=8.17e-6]\u001b[A\n",
      "Epoch 1945: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.43it/s, loss=6.64e-08, v_num=23, train_loss=7.06e-6, test_loss=7.7e-6]\u001b[A\n",
      "Epoch 1946:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 126.19it/s, loss=6.58e-08, v_num=23, train_loss=7.06e-6, test_loss=7.7e-6]\u001b[AAdjusting learning rate of group 0 to 7.6458e-05.\n",
      "Epoch 1946:  50%|████████████████████                    | 79/158 [00:00<00:00, 118.60it/s, loss=6.3e-08, v_num=23, train_loss=7.06e-6, test_loss=7.7e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1946:  67%|██████████████████████████▏            | 106/158 [00:00<00:00, 119.12it/s, loss=6.3e-08, v_num=23, train_loss=7.06e-6, test_loss=7.7e-6]\u001b[A\n",
      "Validating:  59%|█████████████████████████████████████████████████████████████▎                                         | 47/79 [00:00<00:00, 218.44it/s]\u001b[A\n",
      "Epoch 1946: 100%|██████████████████████████████████████| 158/158 [00:01<00:00, 133.25it/s, loss=6.3e-08, v_num=23, train_loss=7.21e-6, test_loss=7.81e-6]\u001b[A\n",
      "Epoch 1947:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 120.69it/s, loss=7.52e-08, v_num=23, train_loss=7.21e-6, test_loss=7.81e-6]\u001b[AAdjusting learning rate of group 0 to 7.6267e-05.\n",
      "Epoch 1947:  50%|███████████████████                   | 79/158 [00:00<00:00, 112.56it/s, loss=7.39e-08, v_num=23, train_loss=7.21e-6, test_loss=7.81e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1947:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 113.64it/s, loss=7.39e-08, v_num=23, train_loss=7.21e-6, test_loss=7.81e-6]\u001b[A\n",
      "Validating:  54%|████████████████████████████████████████████████████████                                               | 43/79 [00:00<00:00, 200.69it/s]\u001b[A\n",
      "Epoch 1947: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 127.55it/s, loss=7.39e-08, v_num=23, train_loss=7.17e-6, test_loss=7.82e-6]\u001b[A\n",
      "Epoch 1948:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 120.02it/s, loss=7.05e-08, v_num=23, train_loss=7.17e-6, test_loss=7.82e-6]\u001b[AAdjusting learning rate of group 0 to 7.6077e-05.\n",
      "Epoch 1948:  50%|███████████████████                   | 79/158 [00:00<00:00, 112.79it/s, loss=6.83e-08, v_num=23, train_loss=7.17e-6, test_loss=7.82e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1948:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 114.30it/s, loss=6.83e-08, v_num=23, train_loss=7.17e-6, test_loss=7.82e-6]\u001b[A\n",
      "Epoch 1948: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 128.20it/s, loss=6.83e-08, v_num=23, train_loss=7.11e-6, test_loss=7.77e-6]\u001b[A\n",
      "Epoch 1949:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 119.14it/s, loss=6.67e-08, v_num=23, train_loss=7.11e-6, test_loss=7.77e-6]\u001b[AAdjusting learning rate of group 0 to 7.5886e-05.\n",
      "Epoch 1949:  50%|███████████████████                   | 79/158 [00:00<00:00, 113.02it/s, loss=6.35e-08, v_num=23, train_loss=7.11e-6, test_loss=7.77e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.22it/s]\u001b[A\n",
      "Validating:   5%|█████▎                                                                                                   | 4/79 [00:00<00:04, 16.53it/s]\u001b[A\n",
      "Validating:   8%|███████▉                                                                                                 | 6/79 [00:00<00:04, 17.47it/s]\u001b[A\n",
      "Validating:  13%|█████████████▏                                                                                          | 10/79 [00:00<00:02, 25.31it/s]\u001b[A\n",
      "Epoch 1949:  67%|█████████████████████████▍            | 106/158 [00:01<00:00, 81.51it/s, loss=6.35e-08, v_num=23, train_loss=7.11e-6, test_loss=7.77e-6]\u001b[A\n",
      "Epoch 1949: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 106.88it/s, loss=6.35e-08, v_num=23, train_loss=7.21e-6, test_loss=7.86e-6]\u001b[A\n",
      "Epoch 1950:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.19it/s, loss=7.34e-08, v_num=23, train_loss=7.21e-6, test_loss=7.86e-6]\u001b[AAdjusting learning rate of group 0 to 7.5697e-05.\n",
      "Epoch 1950:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.94it/s, loss=7.04e-08, v_num=23, train_loss=7.21e-6, test_loss=7.86e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:24,  3.25it/s]\u001b[A\n",
      "Epoch 1950:  67%|████████████████████████▊            | 106/158 [00:01<00:00, 104.40it/s, loss=7.04e-08, v_num=23, train_loss=7.21e-6, test_loss=7.86e-6]\u001b[A\n",
      "Epoch 1950: 100%|█████████████████████████████████████| 158/158 [00:01<00:00, 136.19it/s, loss=7.04e-08, v_num=23, train_loss=7.01e-6, test_loss=7.64e-6]\u001b[A\n",
      "Epoch 1951:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.31it/s, loss=6.42e-08, v_num=23, train_loss=7.01e-6, test_loss=7.64e-6]\u001b[AAdjusting learning rate of group 0 to 7.5507e-05.\n",
      "Epoch 1951:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.82it/s, loss=6.16e-08, v_num=23, train_loss=7.01e-6, test_loss=7.64e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1951:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.35it/s, loss=6.16e-08, v_num=23, train_loss=7.01e-6, test_loss=7.64e-6]\u001b[A\n",
      "Epoch 1951: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.52it/s, loss=6.16e-08, v_num=23, train_loss=7.29e-6, test_loss=7.86e-6]\u001b[A\n",
      "Epoch 1952:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.89it/s, loss=7.76e-08, v_num=23, train_loss=7.29e-6, test_loss=7.86e-6]\u001b[AAdjusting learning rate of group 0 to 7.5319e-05.\n",
      "Epoch 1952:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.74it/s, loss=7.49e-08, v_num=23, train_loss=7.29e-6, test_loss=7.86e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1952:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.29it/s, loss=7.49e-08, v_num=23, train_loss=7.29e-6, test_loss=7.86e-6]\u001b[A\n",
      "Epoch 1952: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.51it/s, loss=7.49e-08, v_num=23, train_loss=7.11e-6, test_loss=7.79e-6]\u001b[A\n",
      "Epoch 1953:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.54it/s, loss=1.04e-07, v_num=23, train_loss=7.11e-6, test_loss=7.79e-6]\u001b[AAdjusting learning rate of group 0 to 7.5130e-05.\n",
      "Epoch 1953:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.66it/s, loss=1.01e-07, v_num=23, train_loss=7.11e-6, test_loss=7.79e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1953:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.57it/s, loss=1.01e-07, v_num=23, train_loss=7.11e-6, test_loss=7.79e-6]\u001b[A\n",
      "Epoch 1953: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 170.03it/s, loss=1.01e-07, v_num=23, train_loss=7.31e-6, test_loss=8e-6]\u001b[A\n",
      "Epoch 1954:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 149.12it/s, loss=7.52e-08, v_num=23, train_loss=7.31e-6, test_loss=8e-6]\u001b[AAdjusting learning rate of group 0 to 7.4942e-05.\n",
      "Epoch 1954:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 141.17it/s, loss=7.17e-08, v_num=23, train_loss=7.31e-6, test_loss=8e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1954:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 135.02it/s, loss=7.17e-08, v_num=23, train_loss=7.31e-6, test_loss=8e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1954: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 170.47it/s, loss=7.17e-08, v_num=23, train_loss=7.06e-6, test_loss=7.7e-6]\u001b[A\n",
      "Epoch 1955:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 149.71it/s, loss=7.74e-08, v_num=23, train_loss=7.06e-6, test_loss=7.7e-6]\u001b[AAdjusting learning rate of group 0 to 7.4755e-05.\n",
      "Epoch 1955:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.75it/s, loss=7.45e-08, v_num=23, train_loss=7.06e-6, test_loss=7.7e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1955:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.55it/s, loss=7.45e-08, v_num=23, train_loss=7.06e-6, test_loss=7.7e-6]\u001b[A\n",
      "Epoch 1955: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.02it/s, loss=7.45e-08, v_num=23, train_loss=7.23e-6, test_loss=7.89e-6]\u001b[A\n",
      "Epoch 1956:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.20it/s, loss=6.76e-08, v_num=23, train_loss=7.23e-6, test_loss=7.89e-6]\u001b[AAdjusting learning rate of group 0 to 7.4568e-05.\n",
      "Epoch 1956:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.45it/s, loss=6.46e-08, v_num=23, train_loss=7.23e-6, test_loss=7.89e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.13it/s]\u001b[A\n",
      "Epoch 1956: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 160.33it/s, loss=6.46e-08, v_num=23, train_loss=6.98e-6, test_loss=7.62e-6]\u001b[A\n",
      "Epoch 1957:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.97it/s, loss=8.37e-08, v_num=23, train_loss=6.98e-6, test_loss=7.62e-6]\u001b[AAdjusting learning rate of group 0 to 7.4382e-05.\n",
      "Epoch 1957:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.23it/s, loss=7.04e-08, v_num=23, train_loss=6.98e-6, test_loss=7.62e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1957:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.33it/s, loss=7.04e-08, v_num=23, train_loss=6.98e-6, test_loss=7.62e-6]\u001b[A\n",
      "Epoch 1957: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.55it/s, loss=7.04e-08, v_num=23, train_loss=7.16e-6, test_loss=7.83e-6]\u001b[A\n",
      "Epoch 1958:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.96it/s, loss=6.75e-08, v_num=23, train_loss=7.16e-6, test_loss=7.83e-6]\u001b[AAdjusting learning rate of group 0 to 7.4196e-05.\n",
      "Epoch 1958:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.77it/s, loss=6.48e-08, v_num=23, train_loss=7.16e-6, test_loss=7.83e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1958:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.85it/s, loss=6.48e-08, v_num=23, train_loss=7.16e-6, test_loss=7.83e-6]\u001b[A\n",
      "Epoch 1958: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.97it/s, loss=6.48e-08, v_num=23, train_loss=6.86e-6, test_loss=7.53e-6]\u001b[A\n",
      "Epoch 1959:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.08it/s, loss=6.74e-08, v_num=23, train_loss=6.86e-6, test_loss=7.53e-6]\u001b[AAdjusting learning rate of group 0 to 7.4010e-05.\n",
      "Epoch 1959:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.15it/s, loss=6.39e-08, v_num=23, train_loss=6.86e-6, test_loss=7.53e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1959:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.64it/s, loss=6.39e-08, v_num=23, train_loss=6.86e-6, test_loss=7.53e-6]\u001b[A\n",
      "Epoch 1959: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.35it/s, loss=6.39e-08, v_num=23, train_loss=6.87e-6, test_loss=7.5e-6]\u001b[A\n",
      "Epoch 1960:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.92it/s, loss=6.59e-08, v_num=23, train_loss=6.87e-6, test_loss=7.5e-6]\u001b[AAdjusting learning rate of group 0 to 7.3825e-05.\n",
      "Epoch 1960:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.65it/s, loss=6.31e-08, v_num=23, train_loss=6.87e-6, test_loss=7.5e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1960:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.47it/s, loss=6.31e-08, v_num=23, train_loss=6.87e-6, test_loss=7.5e-6]\u001b[A\n",
      "Epoch 1960: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.02it/s, loss=6.31e-08, v_num=23, train_loss=7.25e-6, test_loss=7.83e-6]\u001b[A\n",
      "Epoch 1961:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 150.60it/s, loss=6.14e-08, v_num=23, train_loss=7.25e-6, test_loss=7.83e-6]\u001b[AAdjusting learning rate of group 0 to 7.3641e-05.\n",
      "Epoch 1961:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.43it/s, loss=5.77e-08, v_num=23, train_loss=7.25e-6, test_loss=7.83e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1961:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 134.26it/s, loss=5.77e-08, v_num=23, train_loss=7.25e-6, test_loss=7.83e-6]\u001b[A\n",
      "Epoch 1961: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 171.80it/s, loss=5.77e-08, v_num=23, train_loss=6.98e-6, test_loss=7.63e-6]\u001b[A\n",
      "Epoch 1962:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.11it/s, loss=6.1e-08, v_num=23, train_loss=6.98e-6, test_loss=7.63e-6]\u001b[AAdjusting learning rate of group 0 to 7.3457e-05.\n",
      "Epoch 1962:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.04it/s, loss=5.9e-08, v_num=23, train_loss=6.98e-6, test_loss=7.63e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1962:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.15it/s, loss=5.9e-08, v_num=23, train_loss=6.98e-6, test_loss=7.63e-6]\u001b[A\n",
      "Epoch 1962: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.17it/s, loss=5.9e-08, v_num=23, train_loss=6.81e-6, test_loss=7.46e-6]\u001b[A\n",
      "Epoch 1963:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.37it/s, loss=6.21e-08, v_num=23, train_loss=6.81e-6, test_loss=7.46e-6]\u001b[AAdjusting learning rate of group 0 to 7.3273e-05.\n",
      "Epoch 1963:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.09it/s, loss=5.95e-08, v_num=23, train_loss=6.81e-6, test_loss=7.46e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1963:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.27it/s, loss=5.95e-08, v_num=23, train_loss=6.81e-6, test_loss=7.46e-6]\u001b[A\n",
      "Epoch 1963: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.04it/s, loss=5.95e-08, v_num=23, train_loss=7.18e-6, test_loss=7.86e-6]\u001b[A\n",
      "Epoch 1964:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.44it/s, loss=6.79e-08, v_num=23, train_loss=7.18e-6, test_loss=7.86e-6]\u001b[AAdjusting learning rate of group 0 to 7.3090e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1964:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.35it/s, loss=6.56e-08, v_num=23, train_loss=7.18e-6, test_loss=7.86e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1964:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.46it/s, loss=6.56e-08, v_num=23, train_loss=7.18e-6, test_loss=7.86e-6]\u001b[A\n",
      "Epoch 1964: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 167.57it/s, loss=6.56e-08, v_num=23, train_loss=7.26e-6, test_loss=7.9e-6]\u001b[A\n",
      "Epoch 1965:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.10it/s, loss=8.57e-08, v_num=23, train_loss=7.26e-6, test_loss=7.9e-6]\u001b[AAdjusting learning rate of group 0 to 7.2907e-05.\n",
      "Epoch 1965:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 136.82it/s, loss=8.35e-08, v_num=23, train_loss=7.26e-6, test_loss=7.9e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1965:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.81it/s, loss=8.35e-08, v_num=23, train_loss=7.26e-6, test_loss=7.9e-6]\u001b[A\n",
      "Epoch 1965: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 165.03it/s, loss=8.35e-08, v_num=23, train_loss=6.84e-6, test_loss=7.5e-6]\u001b[A\n",
      "Epoch 1966:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.89it/s, loss=6.45e-08, v_num=23, train_loss=6.84e-6, test_loss=7.5e-6]\u001b[AAdjusting learning rate of group 0 to 7.2725e-05.\n",
      "Epoch 1966:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.60it/s, loss=6.14e-08, v_num=23, train_loss=6.84e-6, test_loss=7.5e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1966:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.00it/s, loss=6.14e-08, v_num=23, train_loss=6.84e-6, test_loss=7.5e-6]\u001b[A\n",
      "Epoch 1966: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.38it/s, loss=6.14e-08, v_num=23, train_loss=7.17e-6, test_loss=7.72e-6]\u001b[A\n",
      "Epoch 1967:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.52it/s, loss=1.08e-07, v_num=23, train_loss=7.17e-6, test_loss=7.72e-6]\u001b[AAdjusting learning rate of group 0 to 7.2543e-05.\n",
      "Epoch 1967:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.28it/s, loss=1.06e-07, v_num=23, train_loss=7.17e-6, test_loss=7.72e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1967:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.44it/s, loss=1.06e-07, v_num=23, train_loss=7.17e-6, test_loss=7.72e-6]\u001b[A\n",
      "Epoch 1967: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.89it/s, loss=1.06e-07, v_num=23, train_loss=7.02e-6, test_loss=7.62e-6]\u001b[A\n",
      "Epoch 1968:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.54it/s, loss=6.79e-08, v_num=23, train_loss=7.02e-6, test_loss=7.62e-6]\u001b[AAdjusting learning rate of group 0 to 7.2362e-05.\n",
      "Epoch 1968:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.38it/s, loss=6.36e-08, v_num=23, train_loss=7.02e-6, test_loss=7.62e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1968:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.88it/s, loss=6.36e-08, v_num=23, train_loss=7.02e-6, test_loss=7.62e-6]\u001b[A\n",
      "Epoch 1968: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.69it/s, loss=6.36e-08, v_num=23, train_loss=7.08e-6, test_loss=7.68e-6]\u001b[A\n",
      "Epoch 1969:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.27it/s, loss=6.29e-08, v_num=23, train_loss=7.08e-6, test_loss=7.68e-6]\u001b[AAdjusting learning rate of group 0 to 7.2181e-05.\n",
      "Epoch 1969:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.49it/s, loss=6.08e-08, v_num=23, train_loss=7.08e-6, test_loss=7.68e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1969:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.60it/s, loss=6.08e-08, v_num=23, train_loss=7.08e-6, test_loss=7.68e-6]\u001b[A\n",
      "Epoch 1969: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.74it/s, loss=6.08e-08, v_num=23, train_loss=7.49e-6, test_loss=8.11e-6]\u001b[A\n",
      "Epoch 1970:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.68it/s, loss=6.55e-08, v_num=23, train_loss=7.49e-6, test_loss=8.11e-6]\u001b[AAdjusting learning rate of group 0 to 7.2000e-05.\n",
      "Epoch 1970:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.32it/s, loss=6.21e-08, v_num=23, train_loss=7.49e-6, test_loss=8.11e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1970:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.10it/s, loss=6.21e-08, v_num=23, train_loss=7.49e-6, test_loss=8.11e-6]\u001b[A\n",
      "Epoch 1970: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.71it/s, loss=6.21e-08, v_num=23, train_loss=7.13e-6, test_loss=7.81e-6]\u001b[A\n",
      "Epoch 1971:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.69it/s, loss=7.48e-08, v_num=23, train_loss=7.13e-6, test_loss=7.81e-6]\u001b[AAdjusting learning rate of group 0 to 7.1820e-05.\n",
      "Epoch 1971:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.51it/s, loss=7.24e-08, v_num=23, train_loss=7.13e-6, test_loss=7.81e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1971:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.36it/s, loss=7.24e-08, v_num=23, train_loss=7.13e-6, test_loss=7.81e-6]\u001b[A\n",
      "Epoch 1971: 100%|████████████████████████████████████████| 158/158 [00:00<00:00, 166.67it/s, loss=7.24e-08, v_num=23, train_loss=7e-6, test_loss=7.62e-6]\u001b[A\n",
      "Epoch 1972:  49%|████████████████████▏                    | 78/158 [00:00<00:00, 148.33it/s, loss=7.61e-08, v_num=23, train_loss=7e-6, test_loss=7.62e-6]\u001b[AAdjusting learning rate of group 0 to 7.1641e-05.\n",
      "Epoch 1972:  50%|████████████████████▌                    | 79/158 [00:00<00:00, 138.15it/s, loss=7.38e-08, v_num=23, train_loss=7e-6, test_loss=7.62e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1972:  67%|██████████████████████████▊             | 106/158 [00:00<00:00, 130.37it/s, loss=7.38e-08, v_num=23, train_loss=7e-6, test_loss=7.62e-6]\u001b[A\n",
      "Epoch 1972: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.94it/s, loss=7.38e-08, v_num=23, train_loss=7.31e-6, test_loss=7.98e-6]\u001b[A\n",
      "Epoch 1973:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.72it/s, loss=6.63e-08, v_num=23, train_loss=7.31e-6, test_loss=7.98e-6]\u001b[AAdjusting learning rate of group 0 to 7.1462e-05.\n",
      "Epoch 1973:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.27it/s, loss=6.44e-08, v_num=23, train_loss=7.31e-6, test_loss=7.98e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1973:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.94it/s, loss=6.44e-08, v_num=23, train_loss=7.31e-6, test_loss=7.98e-6]\u001b[A\n",
      "Epoch 1973: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.28it/s, loss=6.44e-08, v_num=23, train_loss=7.32e-6, test_loss=8.04e-6]\u001b[A\n",
      "Epoch 1974:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.55it/s, loss=7.46e-08, v_num=23, train_loss=7.32e-6, test_loss=8.04e-6]\u001b[AAdjusting learning rate of group 0 to 7.1283e-05.\n",
      "Epoch 1974:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.14it/s, loss=7.27e-08, v_num=23, train_loss=7.32e-6, test_loss=8.04e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1974:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.60it/s, loss=7.27e-08, v_num=23, train_loss=7.32e-6, test_loss=8.04e-6]\u001b[A\n",
      "Epoch 1974: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.22it/s, loss=7.27e-08, v_num=23, train_loss=7.08e-6, test_loss=7.74e-6]\u001b[A\n",
      "Epoch 1975:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.40it/s, loss=6.59e-08, v_num=23, train_loss=7.08e-6, test_loss=7.74e-6]\u001b[AAdjusting learning rate of group 0 to 7.1105e-05.\n",
      "Epoch 1975:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.71it/s, loss=6.36e-08, v_num=23, train_loss=7.08e-6, test_loss=7.74e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1975:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.96it/s, loss=6.36e-08, v_num=23, train_loss=7.08e-6, test_loss=7.74e-6]\u001b[A\n",
      "Epoch 1975: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.11it/s, loss=6.36e-08, v_num=23, train_loss=7.11e-6, test_loss=7.71e-6]\u001b[A\n",
      "Epoch 1976:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.25it/s, loss=6.38e-08, v_num=23, train_loss=7.11e-6, test_loss=7.71e-6]\u001b[AAdjusting learning rate of group 0 to 7.0927e-05.\n",
      "Epoch 1976:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.62it/s, loss=6.24e-08, v_num=23, train_loss=7.11e-6, test_loss=7.71e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1976:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.04it/s, loss=6.24e-08, v_num=23, train_loss=7.11e-6, test_loss=7.71e-6]\u001b[A\n",
      "Epoch 1976: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 170.05it/s, loss=6.24e-08, v_num=23, train_loss=6.96e-6, test_loss=7.58e-6]\u001b[A\n",
      "Epoch 1977:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.38it/s, loss=5.98e-08, v_num=23, train_loss=6.96e-6, test_loss=7.58e-6]\u001b[AAdjusting learning rate of group 0 to 7.0750e-05.\n",
      "Epoch 1977:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.01it/s, loss=5.74e-08, v_num=23, train_loss=6.96e-6, test_loss=7.58e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1977:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.49it/s, loss=5.74e-08, v_num=23, train_loss=6.96e-6, test_loss=7.58e-6]\u001b[A\n",
      "Epoch 1977: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.17it/s, loss=5.74e-08, v_num=23, train_loss=7.02e-6, test_loss=7.66e-6]\u001b[A\n",
      "Epoch 1978:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.19it/s, loss=8.07e-08, v_num=23, train_loss=7.02e-6, test_loss=7.66e-6]\u001b[AAdjusting learning rate of group 0 to 7.0573e-05.\n",
      "Epoch 1978:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.49it/s, loss=7.77e-08, v_num=23, train_loss=7.02e-6, test_loss=7.66e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1978:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.18it/s, loss=7.77e-08, v_num=23, train_loss=7.02e-6, test_loss=7.66e-6]\u001b[A\n",
      "Epoch 1978: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.74it/s, loss=7.77e-08, v_num=23, train_loss=6.84e-6, test_loss=7.53e-6]\u001b[A\n",
      "Epoch 1979:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.26it/s, loss=6.74e-08, v_num=23, train_loss=6.84e-6, test_loss=7.53e-6]\u001b[AAdjusting learning rate of group 0 to 7.0396e-05.\n",
      "Epoch 1979:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.72it/s, loss=6.53e-08, v_num=23, train_loss=6.84e-6, test_loss=7.53e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1979:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.14it/s, loss=6.53e-08, v_num=23, train_loss=6.84e-6, test_loss=7.53e-6]\u001b[A\n",
      "Epoch 1979: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.19it/s, loss=6.53e-08, v_num=23, train_loss=7.28e-6, test_loss=7.95e-6]\u001b[A\n",
      "Epoch 1980:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.95it/s, loss=6.58e-08, v_num=23, train_loss=7.28e-6, test_loss=7.95e-6]\u001b[AAdjusting learning rate of group 0 to 7.0220e-05.\n",
      "Epoch 1980:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.78it/s, loss=6.37e-08, v_num=23, train_loss=7.28e-6, test_loss=7.95e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1980:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 130.36it/s, loss=6.37e-08, v_num=23, train_loss=7.28e-6, test_loss=7.95e-6]\u001b[A\n",
      "Epoch 1980: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.40it/s, loss=6.37e-08, v_num=23, train_loss=7.66e-6, test_loss=8.31e-6]\u001b[A\n",
      "Epoch 1981:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.14it/s, loss=6.25e-08, v_num=23, train_loss=7.66e-6, test_loss=8.31e-6]\u001b[AAdjusting learning rate of group 0 to 7.0045e-05.\n",
      "Epoch 1981:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.75it/s, loss=5.9e-08, v_num=23, train_loss=7.66e-6, test_loss=8.31e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1981:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 129.34it/s, loss=5.9e-08, v_num=23, train_loss=7.66e-6, test_loss=8.31e-6]\u001b[A\n",
      "Epoch 1981: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 164.27it/s, loss=5.9e-08, v_num=23, train_loss=7.24e-6, test_loss=7.91e-6]\u001b[A\n",
      "Epoch 1982:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.81it/s, loss=6.85e-08, v_num=23, train_loss=7.24e-6, test_loss=7.91e-6]\u001b[AAdjusting learning rate of group 0 to 6.9870e-05.\n",
      "Epoch 1982:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.55it/s, loss=6.57e-08, v_num=23, train_loss=7.24e-6, test_loss=7.91e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1982:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.76it/s, loss=6.57e-08, v_num=23, train_loss=7.24e-6, test_loss=7.91e-6]\u001b[A\n",
      "Epoch 1982: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.19it/s, loss=6.57e-08, v_num=23, train_loss=7.18e-6, test_loss=7.81e-6]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1983:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.17it/s, loss=7.43e-08, v_num=23, train_loss=7.18e-6, test_loss=7.81e-6]\u001b[AAdjusting learning rate of group 0 to 6.9695e-05.\n",
      "Epoch 1983:  50%|███████████████████                   | 79/158 [00:00<00:00, 141.13it/s, loss=7.16e-08, v_num=23, train_loss=7.18e-6, test_loss=7.81e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|█▎                                                                                                       | 1/79 [00:00<00:12,  6.33it/s]\u001b[A\n",
      "Epoch 1983:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 126.14it/s, loss=7.16e-08, v_num=23, train_loss=7.18e-6, test_loss=7.81e-6]\u001b[A\n",
      "Epoch 1983: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 161.11it/s, loss=7.16e-08, v_num=23, train_loss=7.26e-6, test_loss=7.89e-6]\u001b[A\n",
      "Epoch 1984:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.84it/s, loss=6.1e-08, v_num=23, train_loss=7.26e-6, test_loss=7.89e-6]\u001b[AAdjusting learning rate of group 0 to 6.9521e-05.\n",
      "Epoch 1984:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.11it/s, loss=5.87e-08, v_num=23, train_loss=7.26e-6, test_loss=7.89e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1984:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.30it/s, loss=5.87e-08, v_num=23, train_loss=7.26e-6, test_loss=7.89e-6]\u001b[A\n",
      "Epoch 1984: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.42it/s, loss=5.87e-08, v_num=23, train_loss=6.89e-6, test_loss=7.52e-6]\u001b[A\n",
      "Epoch 1985:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.64it/s, loss=9.66e-08, v_num=23, train_loss=6.89e-6, test_loss=7.52e-6]\u001b[AAdjusting learning rate of group 0 to 6.9347e-05.\n",
      "Epoch 1985:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.45it/s, loss=9.31e-08, v_num=23, train_loss=6.89e-6, test_loss=7.52e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1985:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.85it/s, loss=9.31e-08, v_num=23, train_loss=6.89e-6, test_loss=7.52e-6]\u001b[A\n",
      "Epoch 1985: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.44it/s, loss=9.31e-08, v_num=23, train_loss=7.1e-6, test_loss=7.66e-6]\u001b[A\n",
      "Epoch 1986:  49%|███████████████████▋                    | 78/158 [00:00<00:00, 147.54it/s, loss=7.3e-08, v_num=23, train_loss=7.1e-6, test_loss=7.66e-6]\u001b[AAdjusting learning rate of group 0 to 6.9174e-05.\n",
      "Epoch 1986:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.63it/s, loss=7.04e-08, v_num=23, train_loss=7.1e-6, test_loss=7.66e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1986:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 132.55it/s, loss=7.04e-08, v_num=23, train_loss=7.1e-6, test_loss=7.66e-6]\u001b[A\n",
      "Epoch 1986: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.87it/s, loss=7.04e-08, v_num=23, train_loss=7.22e-6, test_loss=7.79e-6]\u001b[A\n",
      "Epoch 1987:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.19it/s, loss=6.43e-08, v_num=23, train_loss=7.22e-6, test_loss=7.79e-6]\u001b[AAdjusting learning rate of group 0 to 6.9001e-05.\n",
      "Epoch 1987:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.96it/s, loss=6.29e-08, v_num=23, train_loss=7.22e-6, test_loss=7.79e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1987:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.45it/s, loss=6.29e-08, v_num=23, train_loss=7.22e-6, test_loss=7.79e-6]\u001b[A\n",
      "Epoch 1987: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.72it/s, loss=6.29e-08, v_num=23, train_loss=7.35e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1988:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 146.87it/s, loss=6.62e-08, v_num=23, train_loss=7.35e-6, test_loss=7.97e-6]\u001b[AAdjusting learning rate of group 0 to 6.8828e-05.\n",
      "Epoch 1988:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.88it/s, loss=6.09e-08, v_num=23, train_loss=7.35e-6, test_loss=7.97e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1988:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.21it/s, loss=6.09e-08, v_num=23, train_loss=7.35e-6, test_loss=7.97e-6]\u001b[A\n",
      "Epoch 1988: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.21it/s, loss=6.09e-08, v_num=23, train_loss=7.24e-6, test_loss=7.85e-6]\u001b[A\n",
      "Epoch 1989:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.88it/s, loss=7.11e-08, v_num=23, train_loss=7.24e-6, test_loss=7.85e-6]\u001b[AAdjusting learning rate of group 0 to 6.8656e-05.\n",
      "Epoch 1989:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.98it/s, loss=6.84e-08, v_num=23, train_loss=7.24e-6, test_loss=7.85e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1989:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.72it/s, loss=6.84e-08, v_num=23, train_loss=7.24e-6, test_loss=7.85e-6]\u001b[A\n",
      "Epoch 1989: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.80it/s, loss=6.84e-08, v_num=23, train_loss=7.32e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1990:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.26it/s, loss=7.49e-08, v_num=23, train_loss=7.32e-6, test_loss=7.93e-6]\u001b[AAdjusting learning rate of group 0 to 6.8485e-05.\n",
      "Epoch 1990:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.20it/s, loss=7.18e-08, v_num=23, train_loss=7.32e-6, test_loss=7.93e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1990:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.14it/s, loss=7.18e-08, v_num=23, train_loss=7.32e-6, test_loss=7.93e-6]\u001b[A\n",
      "Epoch 1990: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.99it/s, loss=7.18e-08, v_num=23, train_loss=7.9e-6, test_loss=8.53e-6]\u001b[A\n",
      "Epoch 1991:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 148.72it/s, loss=6.77e-08, v_num=23, train_loss=7.9e-6, test_loss=8.53e-6]\u001b[AAdjusting learning rate of group 0 to 6.8313e-05.\n",
      "Epoch 1991:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 138.28it/s, loss=6.69e-08, v_num=23, train_loss=7.9e-6, test_loss=8.53e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1991:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 131.84it/s, loss=6.69e-08, v_num=23, train_loss=7.9e-6, test_loss=8.53e-6]\u001b[A\n",
      "Epoch 1991: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.10it/s, loss=6.69e-08, v_num=23, train_loss=7.28e-6, test_loss=7.92e-6]\u001b[A\n",
      "Epoch 1992:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 147.85it/s, loss=6.88e-08, v_num=23, train_loss=7.28e-6, test_loss=7.92e-6]\u001b[AAdjusting learning rate of group 0 to 6.8143e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1992:  50%|███████████████████                   | 79/158 [00:00<00:00, 136.25it/s, loss=6.53e-08, v_num=23, train_loss=7.28e-6, test_loss=7.92e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1992:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 129.58it/s, loss=6.53e-08, v_num=23, train_loss=7.28e-6, test_loss=7.92e-6]\u001b[A\n",
      "Epoch 1992: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.48it/s, loss=6.53e-08, v_num=23, train_loss=6.99e-6, test_loss=7.64e-6]\u001b[A\n",
      "Epoch 1993:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.31it/s, loss=7.34e-08, v_num=23, train_loss=6.99e-6, test_loss=7.64e-6]\u001b[AAdjusting learning rate of group 0 to 6.7972e-05.\n",
      "Epoch 1993:  50%|███████████████████                   | 79/158 [00:00<00:00, 139.15it/s, loss=6.85e-08, v_num=23, train_loss=6.99e-6, test_loss=7.64e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1993:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.60it/s, loss=6.85e-08, v_num=23, train_loss=6.99e-6, test_loss=7.64e-6]\u001b[A\n",
      "Epoch 1993: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 168.40it/s, loss=6.85e-08, v_num=23, train_loss=7.04e-6, test_loss=7.72e-6]\u001b[A\n",
      "Epoch 1994:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.33it/s, loss=7.03e-08, v_num=23, train_loss=7.04e-6, test_loss=7.72e-6]\u001b[AAdjusting learning rate of group 0 to 6.7802e-05.\n",
      "Epoch 1994:  50%|███████████████████                   | 79/158 [00:00<00:00, 140.34it/s, loss=6.72e-08, v_num=23, train_loss=7.04e-6, test_loss=7.72e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1994:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 133.88it/s, loss=6.72e-08, v_num=23, train_loss=7.04e-6, test_loss=7.72e-6]\u001b[A\n",
      "Epoch 1994: 100%|██████████████████████████████████████| 158/158 [00:00<00:00, 168.87it/s, loss=6.72e-08, v_num=23, train_loss=7.2e-6, test_loss=7.77e-6]\u001b[A\n",
      "Epoch 1995:  49%|███████████████████▎                   | 78/158 [00:00<00:00, 147.50it/s, loss=6.57e-08, v_num=23, train_loss=7.2e-6, test_loss=7.77e-6]\u001b[AAdjusting learning rate of group 0 to 6.7633e-05.\n",
      "Epoch 1995:  50%|███████████████████▌                   | 79/158 [00:00<00:00, 139.62it/s, loss=6.28e-08, v_num=23, train_loss=7.2e-6, test_loss=7.77e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1995:  67%|█████████████████████████▍            | 106/158 [00:00<00:00, 133.56it/s, loss=6.28e-08, v_num=23, train_loss=7.2e-6, test_loss=7.77e-6]\u001b[A\n",
      "Epoch 1995: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 169.13it/s, loss=6.28e-08, v_num=23, train_loss=7.08e-6, test_loss=7.72e-6]\u001b[A\n",
      "Epoch 1996:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.16it/s, loss=7.39e-08, v_num=23, train_loss=7.08e-6, test_loss=7.72e-6]\u001b[AAdjusting learning rate of group 0 to 6.7464e-05.\n",
      "Epoch 1996:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.75it/s, loss=7.06e-08, v_num=23, train_loss=7.08e-6, test_loss=7.72e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1996:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 132.07it/s, loss=7.06e-08, v_num=23, train_loss=7.08e-6, test_loss=7.72e-6]\u001b[A\n",
      "Epoch 1996: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.02it/s, loss=7.06e-08, v_num=23, train_loss=7.16e-6, test_loss=7.78e-6]\u001b[A\n",
      "Epoch 1997:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.08it/s, loss=6.12e-08, v_num=23, train_loss=7.16e-6, test_loss=7.78e-6]\u001b[AAdjusting learning rate of group 0 to 6.7295e-05.\n",
      "Epoch 1997:  50%|███████████████████                   | 79/158 [00:00<00:00, 138.10it/s, loss=5.82e-08, v_num=23, train_loss=7.16e-6, test_loss=7.78e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1997:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.54it/s, loss=5.82e-08, v_num=23, train_loss=7.16e-6, test_loss=7.78e-6]\u001b[A\n",
      "Epoch 1997: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 166.32it/s, loss=5.82e-08, v_num=23, train_loss=7.12e-6, test_loss=7.74e-6]\u001b[A\n",
      "Epoch 1998:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 149.24it/s, loss=7.29e-08, v_num=23, train_loss=7.12e-6, test_loss=7.74e-6]\u001b[AAdjusting learning rate of group 0 to 6.7127e-05.\n",
      "Epoch 1998:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.48it/s, loss=6.99e-08, v_num=23, train_loss=7.12e-6, test_loss=7.74e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1998:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 128.92it/s, loss=6.99e-08, v_num=23, train_loss=7.12e-6, test_loss=7.74e-6]\u001b[A\n",
      "Epoch 1998: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 163.92it/s, loss=6.99e-08, v_num=23, train_loss=7.25e-6, test_loss=7.88e-6]\u001b[A\n",
      "Epoch 1999:  49%|██████████████████▊                   | 78/158 [00:00<00:00, 148.14it/s, loss=6.92e-08, v_num=23, train_loss=7.25e-6, test_loss=7.88e-6]\u001b[AAdjusting learning rate of group 0 to 6.6959e-05.\n",
      "Epoch 1999:  50%|███████████████████                   | 79/158 [00:00<00:00, 137.02it/s, loss=6.65e-08, v_num=23, train_loss=7.25e-6, test_loss=7.88e-6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                 | 0/79 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1999:  67%|████████████████████████▊            | 106/158 [00:00<00:00, 131.82it/s, loss=6.65e-08, v_num=23, train_loss=7.25e-6, test_loss=7.88e-6]\u001b[A\n",
      "Epoch 1999: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 167.01it/s, loss=6.65e-08, v_num=23, train_loss=7.15e-6, test_loss=7.77e-6]\u001b[A\n",
      "Epoch 1999: 100%|█████████████████████████████████████| 158/158 [00:00<00:00, 165.67it/s, loss=6.65e-08, v_num=23, train_loss=7.15e-6, test_loss=7.77e-6]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "    print(f\"Training model {model_index}\")\n",
    "    omegas = torch.Tensor(dirichlet.rvs(np.ones(n_prior_samples))).T\n",
    "    omegas = omegas.type(torch.FloatTensor)\n",
    "    omegas_0 = torch.ones_like(omegas) / len(omegas)\n",
    "    area = torch.ones_like(omegas)\n",
    "    train_size = 1.0\n",
    "    num_workers = 8\n",
    "    hparams = {\"n_layers\": 5, \"n_hidden\": 128, \"batch_size\": 128, \"learning_rate\": 0.01}\n",
    "    \n",
    "    if train_size == 1.0:\n",
    "        data_loader = PDDDataModule(X_train_norm, Y_train, omegas, omegas_0, num_workers=num_workers)\n",
    "    else:\n",
    "        data_loader = PDDDataModule(\n",
    "            X_train_norm, Y_train, omegas, omegas_0, train_size=train_size, num_workers=num_workers\n",
    "        )\n",
    "\n",
    "    data_loader.setup()\n",
    "    e = PDDEmulator(\n",
    "        n_parameters,\n",
    "        n_outputs,\n",
    "        hparams,\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        auto_lr_find=True,\n",
    "        max_epochs=2000,\n",
    "        gpus=1,\n",
    "#        deterministic=True,\n",
    "        num_sanity_val_steps=0,\n",
    "    )\n",
    "    if train_size == 1.0:\n",
    "        train_loader = data_loader.train_all_loader\n",
    "        val_loader = data_loader.val_all_loader\n",
    "    else:\n",
    "        train_loader = data_loader.train_loader\n",
    "        val_loader = data_loader.val_loader\n",
    "\n",
    "        \n",
    "    # lr_finder = trainer.tuner.lr_find(e, train_loader, val_loader)\n",
    "    # fig = lr_finder.plot(suggest=True) # Plot\n",
    "    # fig.show()\n",
    "    trainer.fit(e, train_loader, val_loader)\n",
    "    torch.save(e.state_dict(), f\"{emulator_dir}/emulator/emulator_{model_index}.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20de572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_val_samples = 1000\n",
    "np.random.seed(3)\n",
    "\n",
    "distributions = {\n",
    "    \"T\": uniform(loc=-20, scale=40),\n",
    "    \"P\": uniform(loc=0, scale=1), \n",
    "    \"f_snow\": uniform(\n",
    "        loc=2.0, scale=4.0\n",
    "    ), \n",
    "    \"f_ice\": uniform(\n",
    "        loc=3.0, scale=9\n",
    "    ),  # uniform between 3 and 3.5  AS16 best value: 3.25\n",
    "    \"refreeze\": uniform(loc=0, scale=1.0),  # uniform between 0.25 and 0.95\n",
    "}\n",
    "# Names of all the variables\n",
    "keys = [x for x in distributions.keys()]\n",
    "\n",
    "# Describe the Problem\n",
    "problem = {\"num_vars\": len(keys), \"names\": keys, \"bounds\": [[0, 1]] * len(keys)}\n",
    "\n",
    "unif_sample = lhs(len(keys), n_val_samples)\n",
    "\n",
    "# To hold the transformed variables\n",
    "dist_sample = np.zeros_like(unif_sample)\n",
    "\n",
    "# Now transform the unit hypercube to the prescribed distributions\n",
    "# For each variable, transform with the inverse of the CDF (inv(CDF)=ppf)\n",
    "for i, key in enumerate(keys):\n",
    "    dist_sample[:, i] = distributions[key].ppf(unif_sample[:, i])\n",
    "\n",
    "# Save to CSV file using Pandas DataFrame and to_csv method\n",
    "header = keys\n",
    "# Convert to Pandas dataframe, append column headers, output as csv\n",
    "df = pd.DataFrame(data=dist_sample, columns=header)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8761667",
   "metadata": {},
   "outputs": [],
   "source": [
    "    X = []\n",
    "    Y = []\n",
    "    for k, row in df.iterrows():   \n",
    "        m_f_snow = row[\"f_snow\"]\n",
    "        m_f_ice = row[\"f_ice\"]\n",
    "        m_refreeze = row[\"refreeze\"]\n",
    "        m_T = np.copy(row[\"T\"])\n",
    "        m_P = np.copy(row[\"P\"])\n",
    "\n",
    "        pdd = TorchPDDModel(\n",
    "            pdd_factor_snow=m_f_snow,\n",
    "            pdd_factor_ice=m_f_ice,\n",
    "            refreeze_snow=m_refreeze,\n",
    "            refreeze_ice=m_refreeze,\n",
    "        )\n",
    "        result = pdd(m_T, m_P)\n",
    "\n",
    "        M = result[\"melt_rate\"]\n",
    "        A = result[\"accu_rate\"]\n",
    "        R = result[\"refreeze_rate\"]\n",
    "        B = result[\"smb_rate\"]\n",
    "        m_Y = torch.vstack((M, A, R)).T\n",
    "        Y.append(m_Y)\n",
    "        X.append(torch.from_numpy(np.hstack((m_P, m_T, m_f_snow, m_f_ice, m_refreeze))))\n",
    "\n",
    "    X_val = torch.vstack(X).type(torch.FloatTensor)\n",
    "    Y_val = torch.vstack(Y).type(torch.FloatTensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f097205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2640296, 0.20207557, 0.077476814]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "device = \"cuda\"\n",
    "e.to(device)\n",
    "X_val = X_val.to(device)\n",
    "e.eval()\n",
    "Y_pred = e(X_val).detach().cpu()\n",
    "rmse = [np.sqrt(mean_squared_error(Y_pred.detach().cpu().numpy()[:,i], Y_val.detach().cpu().numpy()[:,i])) for i in range(Y_val.shape[1])]\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6249f798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4905e-04,  5.3684e-01, -3.4038e-05],\n",
       "        [-2.7396e-04,  5.0049e-01, -3.7227e-05],\n",
       "        [ 4.1160e-01, -8.9377e-03,  1.0617e-01],\n",
       "        ...,\n",
       "        [ 4.0093e-01, -8.0647e-03,  1.0722e-01],\n",
       "        [ 4.1815e-01, -8.7119e-03,  1.0450e-01],\n",
       "        [-1.8474e-04,  5.7529e-01, -1.4560e-04]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d1a2de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4905e-04,  1.0309e-01, -3.4038e-05],\n",
       "        [-2.7396e-04,  4.1235e-01, -3.7227e-05],\n",
       "        [ 3.2737e-01, -8.9377e-03,  2.7891e-02],\n",
       "        ...,\n",
       "        [ 3.5212e-01, -8.0647e-03,  7.1847e-02],\n",
       "        [ 3.4208e-01, -8.7119e-03,  7.4483e-02],\n",
       "        [-1.8474e-04,  2.4207e-01, -1.4560e-04]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred - Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24e61c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MALASampler(object):\n",
    "    \"\"\"\n",
    "    MALA Sampler\n",
    "\n",
    "    Author: Douglas C Brinkerhoff, University of Montana\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(\n",
    "        self, model, alpha_b=3.0, beta_b=3.0, alpha=0.01, emulator_dir=\"./emulator\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = model.eval()\n",
    "        self.alpha = alpha\n",
    "        self.alpha_b = alpha_b\n",
    "        self.beta_b = beta_b\n",
    "        self.emulator_dir = emulator_dir\n",
    "\n",
    "    def find_MAP(self, X, X_I, Y_target, X_min, X_max, n_iters=50, print_interval=10):\n",
    "        print(\"***********************************************\")\n",
    "        print(\"***********************************************\")\n",
    "        print(\"Finding MAP point\")\n",
    "        print(\"***********************************************\")\n",
    "        print(\"***********************************************\")\n",
    "        # Line search distances\n",
    "        alphas = np.logspace(-4, 0, 11)\n",
    "        # Find MAP point\n",
    "        for i in range(n_iters):\n",
    "            log_pi, g, _, Hinv, log_det_Hinv = self.get_log_like_gradient_and_hessian(\n",
    "                X, X_I, Y_target, X_min, X_max, compute_hessian=True\n",
    "            )\n",
    "            p = Hinv @ -g\n",
    "            alpha_index = np.nanargmin(\n",
    "                [\n",
    "                    self.get_log_like_gradient_and_hessian(\n",
    "                        X + alpha * p, X_I, Y_target, X_min, X_max, compute_hessian=False\n",
    "                    )\n",
    "                    .detach()\n",
    "                    .cpu()\n",
    "                    .numpy()\n",
    "                    for alpha in alphas\n",
    "                ]\n",
    "            )\n",
    "            mu = X + alphas[alpha_index] * p\n",
    "            X.data = mu.data\n",
    "            if i % print_interval == 0:\n",
    "                print(\"===============================================\")\n",
    "                print(f\"iter: {i:d}, log(P): {log_pi:.1f}\\n\")\n",
    "                print(\n",
    "                    \"\".join(\n",
    "                        [\n",
    "                            f\"{key}: {(val * std + mean):.3f}\\n\"\n",
    "                            for key, val, std, mean in zip(\n",
    "                                X_P_keys,\n",
    "                                X.data.cpu().numpy(),\n",
    "                                X_P_std,\n",
    "                                X_P_mean,\n",
    "                            )\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "\n",
    "                print(\"===============================================\")\n",
    "        return X\n",
    "\n",
    "    def V(self, X, X_I, Y_target, X_bar):\n",
    "        # model result is in log space\n",
    "        X_IP = torch.hstack((X, X_I))\n",
    "        Y_pred = self.model(X_IP)\n",
    "        r = Y_pred - Y_target\n",
    "        L1 = torch.sum(\n",
    "            np.log(gamma((nu + 1) / 2.0))\n",
    "            - np.log(gamma(nu / 2.0))\n",
    "            - np.log(np.sqrt(np.pi * nu) * sigma_hat)\n",
    "            - (nu + 1) / 2.0 * torch.log(1 + 1.0 / nu * (r / sigma_hat) ** 2)\n",
    "        )\n",
    "        L2 = torch.sum(\n",
    "            (self.alpha_b - 1) * torch.log(X_bar)\n",
    "            + (self.beta_b - 1) * torch.log(1 - X_bar)\n",
    "        )\n",
    "\n",
    "        return -(self.alpha * L1 + L2)\n",
    "\n",
    "    def get_log_like_gradient_and_hessian(\n",
    "        self, X, X_I, Y_target, X_min, X_max, eps=1e-2, compute_hessian=False\n",
    "    ):\n",
    "\n",
    "        X_bar = (X - X_min) / (X_max - X_min)\n",
    "        log_pi = self.V(X, X_I, Y_target, X_bar)\n",
    "        if compute_hessian:\n",
    "            g = torch.autograd.grad(log_pi, X, retain_graph=True, create_graph=True)[0]\n",
    "            H = torch.stack(\n",
    "                [torch.autograd.grad(e, X, retain_graph=True)[0] for e in g]\n",
    "            )\n",
    "            lamda, Q = torch.linalg.eig(H)\n",
    "            lamda, Q = lamda.type(torch.float), Q.type(torch.float)\n",
    "            lamda_prime = torch.sqrt(lamda ** 2 + eps)\n",
    "            lamda_prime_inv = 1.0 / torch.sqrt(lamda ** 2 + eps)\n",
    "            H = Q @ torch.diag(lamda_prime) @ Q.T\n",
    "            Hinv = Q @ torch.diag(lamda_prime_inv) @ Q.T\n",
    "            log_det_Hinv = torch.sum(torch.log(lamda_prime_inv))\n",
    "            return log_pi, g, H, Hinv, log_det_Hinv\n",
    "        else:\n",
    "            return log_pi\n",
    "\n",
    "    def draw_sample(self, mu, cov, eps=1e-10):\n",
    "        L = torch.linalg.cholesky(cov + eps * torch.eye(cov.shape[0], device=device))\n",
    "        return mu + L @ torch.randn(L.shape[0], device=device)\n",
    "\n",
    "    def get_proposal_likelihood(self, Y, mu, inverse_cov, log_det_cov):\n",
    "        return -0.5 * log_det_cov - 0.5 * (Y - mu) @ inverse_cov @ (Y - mu)\n",
    "\n",
    "    def MALA_step(self, X, X_I, Y_target, X_min, X_max, h, local_data=None):\n",
    "        if local_data is not None:\n",
    "            pass\n",
    "        else:\n",
    "            local_data = self.get_log_like_gradient_and_hessian(\n",
    "                X, X_I, Y_target, X_min, X_max, compute_hessian=True\n",
    "            )\n",
    "\n",
    "        log_pi, _, H, Hinv, log_det_Hinv = local_data\n",
    "\n",
    "        X_ = self.draw_sample(X, 2 * h * Hinv).detach()\n",
    "        X_.requires_grad = True\n",
    "\n",
    "        log_pi_ = self.get_log_like_gradient_and_hessian(\n",
    "            X_, X_I, Y_target, X_min, X_max, compute_hessian=False\n",
    "        )\n",
    "\n",
    "        logq = self.get_proposal_likelihood(X_, X, H / (2 * h), log_det_Hinv)\n",
    "        logq_ = self.get_proposal_likelihood(X, X_, H / (2 * h), log_det_Hinv)\n",
    "\n",
    "        log_alpha = -log_pi_ + logq_ + log_pi - logq\n",
    "        alpha = torch.exp(min(log_alpha, torch.tensor([0.0], device=device)))\n",
    "        u = torch.rand(1, device=device)\n",
    "        if u <= alpha and log_alpha != np.inf:\n",
    "            X.data = X_.data\n",
    "            local_data = self.get_log_like_gradient_and_hessian(\n",
    "                X, X_I, Y_target, X_min, X_max, compute_hessian=True\n",
    "            )\n",
    "            s = 1\n",
    "        else:\n",
    "            s = 0\n",
    "        return X, local_data, s\n",
    "\n",
    "    def MALA(\n",
    "        self,\n",
    "        X,\n",
    "        X_I,\n",
    "        X_min,\n",
    "        X_max,\n",
    "        Y_target,\n",
    "        n_iters=10001,\n",
    "        h=0.1,\n",
    "        h_max=1.0,\n",
    "        acc_target=0.25,\n",
    "        k=0.01,\n",
    "        beta=0.99,\n",
    "        model_index=0,\n",
    "        save_interval=1000,\n",
    "        print_interval=50,\n",
    "    ):\n",
    "        print(\"***********************************************\")\n",
    "        print(\"***********************************************\")\n",
    "        print(\n",
    "            \"Running Metropolis-Adjusted Langevin Algorithm for model index {0}\".format(\n",
    "                model_index\n",
    "            )\n",
    "        )\n",
    "        print(\"***********************************************\")\n",
    "        print(\"***********************************************\")\n",
    "\n",
    "        posterior_dir = f\"{self.emulator_dir}/posterior_samples/\"\n",
    "        if not os.path.isdir(posterior_dir):\n",
    "            os.makedirs(posterior_dir)\n",
    "\n",
    "        local_data = None\n",
    "        m_vars = []\n",
    "        acc = acc_target\n",
    "        print(n_iters)\n",
    "        for i in range(n_iters):\n",
    "            X, local_data, s = self.MALA_step(\n",
    "                X, X_I, Y_target, X_min, X_max, h, local_data=local_data\n",
    "            )\n",
    "            m_vars.append(X.detach())\n",
    "            acc = beta * acc + (1 - beta) * s\n",
    "            h = min(h * (1 + k * np.sign(acc - acc_target)), h_max)\n",
    "            if i % print_interval == 0:\n",
    "                print(\"===============================================\")\n",
    "                print(\n",
    "                    \"sample: {0:d}, acc. rate: {1:4.2f}, log(P): {2:6.1f}\".format(\n",
    "                        i, acc, local_data[0].item()\n",
    "                    )\n",
    "                )\n",
    "                print(\n",
    "                    \" \".join(\n",
    "                        [\n",
    "                            f\"{key}: {(val * std + mean):.3f}\\n\"\n",
    "                            for key, val, std, mean in zip(\n",
    "                                X_P_keys,\n",
    "                                X.data.cpu().numpy(),\n",
    "                                X_P_std,\n",
    "                                X_P_mean,\n",
    "                            )\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "\n",
    "                print(\"===============================================\")\n",
    "\n",
    "            if i % save_interval == 0:\n",
    "                print(\"///////////////////////////////////////////////\")\n",
    "                print(\"Saving samples for model {0}\".format(model_index))\n",
    "                print(\"///////////////////////////////////////////////\")\n",
    "                X_posterior = torch.stack(m_vars).cpu().numpy()\n",
    "                df = pd.DataFrame(\n",
    "                    data=X_posterior.astype(\"float32\") * X_P_std.cpu().numpy()\n",
    "                    + X_P_mean.cpu().numpy(),\n",
    "                    columns=X_P_keys,\n",
    "                )\n",
    "                df.to_csv(\n",
    "                    posterior_dir + \"X_posterior_model_{0}.csv.gz\".format(model_index),\n",
    "                    compression=\"infer\",\n",
    "                )\n",
    "        X_posterior = torch.stack(m_vars).cpu().numpy()\n",
    "        return X_posterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18975c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a069a21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************\n",
      "***********************************************\n",
      "Finding MAP point\n",
      "***********************************************\n",
      "***********************************************\n",
      "===============================================\n",
      "iter: 0, log(P): -1483.4\n",
      "\n",
      "f_snow: 3.526\n",
      "f_ice: 8.024\n",
      "refreeze: 0.451\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2585/2570728466.py:97: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/native/Copy.cpp:239.)\n",
      "  lamda, Q = lamda.type(torch.float), Q.type(torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "iter: 10, log(P): -3408.8\n",
      "\n",
      "f_snow: 2.466\n",
      "f_ice: 7.915\n",
      "refreeze: 0.488\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "iter: 20, log(P): -3408.8\n",
      "\n",
      "f_snow: 2.466\n",
      "f_ice: 7.915\n",
      "refreeze: 0.488\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "iter: 30, log(P): -3408.8\n",
      "\n",
      "f_snow: 2.466\n",
      "f_ice: 7.915\n",
      "refreeze: 0.488\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "iter: 40, log(P): -3408.8\n",
      "\n",
      "f_snow: 2.466\n",
      "f_ice: 7.915\n",
      "refreeze: 0.488\n",
      "\n",
      "===============================================\n",
      "***********************************************\n",
      "***********************************************\n",
      "Running Metropolis-Adjusted Langevin Algorithm for model index 0\n",
      "***********************************************\n",
      "***********************************************\n",
      "100000\n",
      "===============================================\n",
      "sample: 0, acc. rate: 0.26, log(P): -3408.7\n",
      "f_snow: 2.482\n",
      " f_ice: 7.916\n",
      " refreeze: 0.560\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 100, acc. rate: 0.41, log(P): -3403.9\n",
      "f_snow: 2.441\n",
      " f_ice: 7.915\n",
      " refreeze: 0.034\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 200, acc. rate: 0.42, log(P): -3407.7\n",
      "f_snow: 2.353\n",
      " f_ice: 7.902\n",
      " refreeze: 0.564\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 300, acc. rate: 0.33, log(P): -3408.2\n",
      "f_snow: 2.483\n",
      " f_ice: 7.914\n",
      " refreeze: 0.556\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 400, acc. rate: 0.24, log(P): -3407.2\n",
      "f_snow: 2.230\n",
      " f_ice: 7.885\n",
      " refreeze: 0.604\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 500, acc. rate: 0.27, log(P): -3407.7\n",
      "f_snow: 2.361\n",
      " f_ice: 7.909\n",
      " refreeze: 0.652\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 600, acc. rate: 0.26, log(P): -3406.8\n",
      "f_snow: 2.269\n",
      " f_ice: 7.891\n",
      " refreeze: 0.669\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 700, acc. rate: 0.28, log(P): -3404.5\n",
      "f_snow: 2.160\n",
      " f_ice: 7.837\n",
      " refreeze: 0.412\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 800, acc. rate: 0.20, log(P): -3407.2\n",
      "f_snow: 2.534\n",
      " f_ice: 7.923\n",
      " refreeze: 0.651\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 900, acc. rate: 0.27, log(P): -3408.4\n",
      "f_snow: 2.382\n",
      " f_ice: 7.907\n",
      " refreeze: 0.358\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 1000, acc. rate: 0.24, log(P): -3407.2\n",
      "f_snow: 2.262\n",
      " f_ice: 7.890\n",
      " refreeze: 0.508\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 1100, acc. rate: 0.23, log(P): -3406.9\n",
      "f_snow: 2.575\n",
      " f_ice: 7.921\n",
      " refreeze: 0.468\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 1200, acc. rate: 0.29, log(P): -3406.6\n",
      "f_snow: 2.583\n",
      " f_ice: 7.926\n",
      " refreeze: 0.313\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 1300, acc. rate: 0.27, log(P): -3408.3\n",
      "f_snow: 2.521\n",
      " f_ice: 7.921\n",
      " refreeze: 0.394\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 1400, acc. rate: 0.30, log(P): -3406.4\n",
      "f_snow: 2.165\n",
      " f_ice: 7.861\n",
      " refreeze: 0.702\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 1500, acc. rate: 0.27, log(P): -3407.4\n",
      "f_snow: 2.523\n",
      " f_ice: 7.923\n",
      " refreeze: 0.571\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 1600, acc. rate: 0.28, log(P): -3407.9\n",
      "f_snow: 2.417\n",
      " f_ice: 7.911\n",
      " refreeze: 0.783\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 1700, acc. rate: 0.20, log(P): -3407.1\n",
      "f_snow: 2.401\n",
      " f_ice: 7.915\n",
      " refreeze: 0.360\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 1800, acc. rate: 0.29, log(P): -3407.3\n",
      "f_snow: 2.379\n",
      " f_ice: 7.913\n",
      " refreeze: 0.740\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 1900, acc. rate: 0.24, log(P): -3406.0\n",
      "f_snow: 2.502\n",
      " f_ice: 7.914\n",
      " refreeze: 0.159\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 2000, acc. rate: 0.30, log(P): -3401.2\n",
      "f_snow: 2.133\n",
      " f_ice: 7.870\n",
      " refreeze: 0.878\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 2100, acc. rate: 0.26, log(P): -3405.6\n",
      "f_snow: 2.152\n",
      " f_ice: 7.864\n",
      " refreeze: 0.784\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 2200, acc. rate: 0.26, log(P): -3406.2\n",
      "f_snow: 2.453\n",
      " f_ice: 7.917\n",
      " refreeze: 0.912\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 2300, acc. rate: 0.20, log(P): -3405.8\n",
      "f_snow: 2.155\n",
      " f_ice: 7.863\n",
      " refreeze: 0.784\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 2400, acc. rate: 0.32, log(P): -3408.5\n",
      "f_snow: 2.427\n",
      " f_ice: 7.913\n",
      " refreeze: 0.383\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 2500, acc. rate: 0.38, log(P): -3406.0\n",
      "f_snow: 2.220\n",
      " f_ice: 7.874\n",
      " refreeze: 0.569\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 2600, acc. rate: 0.32, log(P): -3407.6\n",
      "f_snow: 2.265\n",
      " f_ice: 7.892\n",
      " refreeze: 0.397\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 2700, acc. rate: 0.30, log(P): -3406.8\n",
      "f_snow: 2.225\n",
      " f_ice: 7.885\n",
      " refreeze: 0.243\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 2800, acc. rate: 0.23, log(P): -3405.4\n",
      "f_snow: 2.157\n",
      " f_ice: 7.870\n",
      " refreeze: 0.685\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 2900, acc. rate: 0.31, log(P): -3406.0\n",
      "f_snow: 2.171\n",
      " f_ice: 7.853\n",
      " refreeze: 0.592\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 3000, acc. rate: 0.25, log(P): -3407.4\n",
      "f_snow: 2.553\n",
      " f_ice: 7.924\n",
      " refreeze: 0.394\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 3100, acc. rate: 0.25, log(P): -3408.7\n",
      "f_snow: 2.465\n",
      " f_ice: 7.915\n",
      " refreeze: 0.534\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 3200, acc. rate: 0.27, log(P): -3408.4\n",
      "f_snow: 2.381\n",
      " f_ice: 7.907\n",
      " refreeze: 0.518\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 3300, acc. rate: 0.22, log(P): -3406.9\n",
      "f_snow: 2.229\n",
      " f_ice: 7.883\n",
      " refreeze: 0.282\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 3400, acc. rate: 0.28, log(P): -3407.6\n",
      "f_snow: 2.312\n",
      " f_ice: 7.899\n",
      " refreeze: 0.282\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 3500, acc. rate: 0.35, log(P): -3405.6\n",
      "f_snow: 2.190\n",
      " f_ice: 7.861\n",
      " refreeze: 0.529\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 3600, acc. rate: 0.28, log(P): -3408.5\n",
      "f_snow: 2.491\n",
      " f_ice: 7.919\n",
      " refreeze: 0.594\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 3700, acc. rate: 0.26, log(P): -3407.0\n",
      "f_snow: 2.539\n",
      " f_ice: 7.925\n",
      " refreeze: 0.325\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 3800, acc. rate: 0.31, log(P): -3406.6\n",
      "f_snow: 2.595\n",
      " f_ice: 7.922\n",
      " refreeze: 0.339\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 3900, acc. rate: 0.26, log(P): -3407.1\n",
      "f_snow: 2.471\n",
      " f_ice: 7.922\n",
      " refreeze: 0.660\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 4000, acc. rate: 0.25, log(P): -3407.9\n",
      "f_snow: 2.350\n",
      " f_ice: 7.906\n",
      " refreeze: 0.720\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 4100, acc. rate: 0.17, log(P): -3407.2\n",
      "f_snow: 2.249\n",
      " f_ice: 7.892\n",
      " refreeze: 0.257\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 4200, acc. rate: 0.34, log(P): -3408.4\n",
      "f_snow: 2.356\n",
      " f_ice: 7.906\n",
      " refreeze: 0.499\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 4300, acc. rate: 0.28, log(P): -3405.3\n",
      "f_snow: 2.155\n",
      " f_ice: 7.855\n",
      " refreeze: 0.863\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 4400, acc. rate: 0.34, log(P): -3403.7\n",
      "f_snow: 2.179\n",
      " f_ice: 7.860\n",
      " refreeze: 0.055\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 4500, acc. rate: 0.28, log(P): -3404.5\n",
      "f_snow: 2.149\n",
      " f_ice: 7.855\n",
      " refreeze: 0.910\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 4600, acc. rate: 0.35, log(P): -3407.8\n",
      "f_snow: 2.377\n",
      " f_ice: 7.904\n",
      " refreeze: 0.308\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 4700, acc. rate: 0.31, log(P): -3408.7\n",
      "f_snow: 2.430\n",
      " f_ice: 7.911\n",
      " refreeze: 0.503\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 4800, acc. rate: 0.22, log(P): -3408.1\n",
      "f_snow: 2.291\n",
      " f_ice: 7.899\n",
      " refreeze: 0.462\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 4900, acc. rate: 0.24, log(P): -3407.7\n",
      "f_snow: 2.324\n",
      " f_ice: 7.901\n",
      " refreeze: 0.685\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 5000, acc. rate: 0.28, log(P): -3407.1\n",
      "f_snow: 2.381\n",
      " f_ice: 7.914\n",
      " refreeze: 0.758\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 5100, acc. rate: 0.23, log(P): -3405.4\n",
      "f_snow: 2.162\n",
      " f_ice: 7.849\n",
      " refreeze: 0.754\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 5200, acc. rate: 0.30, log(P): -3405.4\n",
      "f_snow: 2.143\n",
      " f_ice: 7.844\n",
      " refreeze: 0.781\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 5300, acc. rate: 0.28, log(P): -3405.9\n",
      "f_snow: 2.154\n",
      " f_ice: 7.846\n",
      " refreeze: 0.258\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 5400, acc. rate: 0.23, log(P): -3408.7\n",
      "f_snow: 2.484\n",
      " f_ice: 7.916\n",
      " refreeze: 0.500\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 5500, acc. rate: 0.32, log(P): -3403.4\n",
      "f_snow: 2.110\n",
      " f_ice: 7.829\n",
      " refreeze: 0.844\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 5600, acc. rate: 0.32, log(P): -3408.7\n",
      "f_snow: 2.480\n",
      " f_ice: 7.917\n",
      " refreeze: 0.421\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 5700, acc. rate: 0.27, log(P): -3407.5\n",
      "f_snow: 2.474\n",
      " f_ice: 7.922\n",
      " refreeze: 0.547\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 5800, acc. rate: 0.28, log(P): -3407.8\n",
      "f_snow: 2.265\n",
      " f_ice: 7.893\n",
      " refreeze: 0.529\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 5900, acc. rate: 0.26, log(P): -3407.7\n",
      "f_snow: 2.337\n",
      " f_ice: 7.903\n",
      " refreeze: 0.231\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 6000, acc. rate: 0.27, log(P): -3404.1\n",
      "f_snow: 2.135\n",
      " f_ice: 7.832\n",
      " refreeze: 0.449\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 6100, acc. rate: 0.33, log(P): -3406.2\n",
      "f_snow: 2.310\n",
      " f_ice: 7.898\n",
      " refreeze: 0.744\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 6200, acc. rate: 0.30, log(P): -3404.0\n",
      "f_snow: 2.170\n",
      " f_ice: 7.839\n",
      " refreeze: 0.294\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 6300, acc. rate: 0.26, log(P): -3403.0\n",
      "f_snow: 2.093\n",
      " f_ice: 7.802\n",
      " refreeze: 0.183\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 6400, acc. rate: 0.26, log(P): -3405.4\n",
      "f_snow: 2.186\n",
      " f_ice: 7.858\n",
      " refreeze: 0.531\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 6500, acc. rate: 0.24, log(P): -3405.8\n",
      "f_snow: 2.293\n",
      " f_ice: 7.896\n",
      " refreeze: 0.117\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 6600, acc. rate: 0.24, log(P): -3407.9\n",
      "f_snow: 2.289\n",
      " f_ice: 7.901\n",
      " refreeze: 0.445\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 6700, acc. rate: 0.25, log(P): -3404.9\n",
      "f_snow: 2.444\n",
      " f_ice: 7.923\n",
      " refreeze: 0.820\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 6800, acc. rate: 0.33, log(P): -3407.3\n",
      "f_snow: 2.257\n",
      " f_ice: 7.894\n",
      " refreeze: 0.709\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 6900, acc. rate: 0.28, log(P): -3404.4\n",
      "f_snow: 2.591\n",
      " f_ice: 7.920\n",
      " refreeze: 0.507\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 7000, acc. rate: 0.28, log(P): -3408.1\n",
      "f_snow: 2.437\n",
      " f_ice: 7.917\n",
      " refreeze: 0.643\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 7100, acc. rate: 0.36, log(P): -3406.9\n",
      "f_snow: 2.316\n",
      " f_ice: 7.900\n",
      " refreeze: 0.802\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 7200, acc. rate: 0.23, log(P): -3408.1\n",
      "f_snow: 2.448\n",
      " f_ice: 7.916\n",
      " refreeze: 0.741\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 7300, acc. rate: 0.25, log(P): -3407.3\n",
      "f_snow: 2.330\n",
      " f_ice: 7.904\n",
      " refreeze: 0.796\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 7400, acc. rate: 0.25, log(P): -3406.6\n",
      "f_snow: 2.160\n",
      " f_ice: 7.860\n",
      " refreeze: 0.665\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 7500, acc. rate: 0.27, log(P): -3408.0\n",
      "f_snow: 2.539\n",
      " f_ice: 7.920\n",
      " refreeze: 0.281\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 7600, acc. rate: 0.29, log(P): -3408.2\n",
      "f_snow: 2.366\n",
      " f_ice: 7.905\n",
      " refreeze: 0.342\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 7700, acc. rate: 0.28, log(P): -3404.7\n",
      "f_snow: 2.192\n",
      " f_ice: 7.869\n",
      " refreeze: 0.282\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 7800, acc. rate: 0.26, log(P): -3406.8\n",
      "f_snow: 2.167\n",
      " f_ice: 7.859\n",
      " refreeze: 0.531\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 7900, acc. rate: 0.30, log(P): -3403.7\n",
      "f_snow: 2.637\n",
      " f_ice: 7.925\n",
      " refreeze: 0.718\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 8000, acc. rate: 0.24, log(P): -3405.7\n",
      "f_snow: 2.151\n",
      " f_ice: 7.862\n",
      " refreeze: 0.792\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 8100, acc. rate: 0.31, log(P): -3405.5\n",
      "f_snow: 2.191\n",
      " f_ice: 7.867\n",
      " refreeze: 0.530\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 8200, acc. rate: 0.29, log(P): -3406.0\n",
      "f_snow: 2.173\n",
      " f_ice: 7.871\n",
      " refreeze: 0.423\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 8300, acc. rate: 0.35, log(P): -3407.7\n",
      "f_snow: 2.282\n",
      " f_ice: 7.899\n",
      " refreeze: 0.689\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 8400, acc. rate: 0.29, log(P): -3407.3\n",
      "f_snow: 2.254\n",
      " f_ice: 7.895\n",
      " refreeze: 0.609\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 8500, acc. rate: 0.31, log(P): -3407.6\n",
      "f_snow: 2.371\n",
      " f_ice: 7.911\n",
      " refreeze: 0.456\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 8600, acc. rate: 0.30, log(P): -3408.5\n",
      "f_snow: 2.475\n",
      " f_ice: 7.915\n",
      " refreeze: 0.339\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 8700, acc. rate: 0.29, log(P): -3406.2\n",
      "f_snow: 2.261\n",
      " f_ice: 7.890\n",
      " refreeze: 0.167\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 8800, acc. rate: 0.30, log(P): -3408.4\n",
      "f_snow: 2.418\n",
      " f_ice: 7.911\n",
      " refreeze: 0.685\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 8900, acc. rate: 0.25, log(P): -3405.9\n",
      "f_snow: 2.201\n",
      " f_ice: 7.865\n",
      " refreeze: 0.335\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 9000, acc. rate: 0.27, log(P): -3404.9\n",
      "f_snow: 2.166\n",
      " f_ice: 7.872\n",
      " refreeze: 0.246\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 9100, acc. rate: 0.27, log(P): -3406.6\n",
      "f_snow: 2.167\n",
      " f_ice: 7.860\n",
      " refreeze: 0.607\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 9200, acc. rate: 0.27, log(P): -3408.2\n",
      "f_snow: 2.518\n",
      " f_ice: 7.918\n",
      " refreeze: 0.538\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 9300, acc. rate: 0.27, log(P): -3406.8\n",
      "f_snow: 2.311\n",
      " f_ice: 7.900\n",
      " refreeze: 0.816\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 9400, acc. rate: 0.32, log(P): -3404.3\n",
      "f_snow: 2.162\n",
      " f_ice: 7.878\n",
      " refreeze: 0.662\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 9500, acc. rate: 0.33, log(P): -3408.0\n",
      "f_snow: 2.280\n",
      " f_ice: 7.898\n",
      " refreeze: 0.434\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 9600, acc. rate: 0.28, log(P): -3406.6\n",
      "f_snow: 2.450\n",
      " f_ice: 7.911\n",
      " refreeze: 0.800\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 9700, acc. rate: 0.27, log(P): -3404.4\n",
      "f_snow: 2.277\n",
      " f_ice: 7.909\n",
      " refreeze: 0.829\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 9800, acc. rate: 0.23, log(P): -3405.8\n",
      "f_snow: 2.251\n",
      " f_ice: 7.897\n",
      " refreeze: 0.215\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 9900, acc. rate: 0.27, log(P): -3407.5\n",
      "f_snow: 2.237\n",
      " f_ice: 7.889\n",
      " refreeze: 0.429\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 10000, acc. rate: 0.25, log(P): -3407.7\n",
      "f_snow: 2.363\n",
      " f_ice: 7.903\n",
      " refreeze: 0.491\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 10100, acc. rate: 0.30, log(P): -3407.3\n",
      "f_snow: 2.368\n",
      " f_ice: 7.907\n",
      " refreeze: 0.170\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 10200, acc. rate: 0.27, log(P): -3406.3\n",
      "f_snow: 2.159\n",
      " f_ice: 7.846\n",
      " refreeze: 0.414\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 10300, acc. rate: 0.26, log(P): -3407.2\n",
      "f_snow: 2.374\n",
      " f_ice: 7.911\n",
      " refreeze: 0.320\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 10400, acc. rate: 0.23, log(P): -3405.9\n",
      "f_snow: 2.395\n",
      " f_ice: 7.911\n",
      " refreeze: 0.094\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 10500, acc. rate: 0.26, log(P): -3407.8\n",
      "f_snow: 2.436\n",
      " f_ice: 7.916\n",
      " refreeze: 0.787\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 10600, acc. rate: 0.25, log(P): -3405.9\n",
      "f_snow: 2.221\n",
      " f_ice: 7.885\n",
      " refreeze: 0.837\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 10700, acc. rate: 0.30, log(P): -3408.1\n",
      "f_snow: 2.503\n",
      " f_ice: 7.916\n",
      " refreeze: 0.422\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 10800, acc. rate: 0.25, log(P): -3408.4\n",
      "f_snow: 2.440\n",
      " f_ice: 7.911\n",
      " refreeze: 0.581\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 10900, acc. rate: 0.32, log(P): -3404.4\n",
      "f_snow: 2.462\n",
      " f_ice: 7.917\n",
      " refreeze: 0.042\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 11000, acc. rate: 0.39, log(P): -3403.2\n",
      "f_snow: 2.175\n",
      " f_ice: 7.874\n",
      " refreeze: 0.889\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 11100, acc. rate: 0.25, log(P): -3407.6\n",
      "f_snow: 2.423\n",
      " f_ice: 7.916\n",
      " refreeze: 0.762\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 11200, acc. rate: 0.27, log(P): -3405.3\n",
      "f_snow: 2.163\n",
      " f_ice: 7.861\n",
      " refreeze: 0.149\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 11300, acc. rate: 0.26, log(P): -3406.4\n",
      "f_snow: 2.221\n",
      " f_ice: 7.876\n",
      " refreeze: 0.473\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 11400, acc. rate: 0.27, log(P): -3403.0\n",
      "f_snow: 2.105\n",
      " f_ice: 7.834\n",
      " refreeze: 0.681\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 11500, acc. rate: 0.28, log(P): -3405.9\n",
      "f_snow: 2.165\n",
      " f_ice: 7.868\n",
      " refreeze: 0.699\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 11600, acc. rate: 0.30, log(P): -3406.3\n",
      "f_snow: 2.160\n",
      " f_ice: 7.847\n",
      " refreeze: 0.436\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 11700, acc. rate: 0.25, log(P): -3406.8\n",
      "f_snow: 2.396\n",
      " f_ice: 7.911\n",
      " refreeze: 0.149\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 11800, acc. rate: 0.25, log(P): -3408.1\n",
      "f_snow: 2.496\n",
      " f_ice: 7.921\n",
      " refreeze: 0.607\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 11900, acc. rate: 0.32, log(P): -3407.7\n",
      "f_snow: 2.484\n",
      " f_ice: 7.918\n",
      " refreeze: 0.186\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 12000, acc. rate: 0.31, log(P): -3407.1\n",
      "f_snow: 2.491\n",
      " f_ice: 7.913\n",
      " refreeze: 0.283\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 12100, acc. rate: 0.22, log(P): -3403.8\n",
      "f_snow: 2.187\n",
      " f_ice: 7.865\n",
      " refreeze: 0.884\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 12200, acc. rate: 0.29, log(P): -3404.1\n",
      "f_snow: 2.167\n",
      " f_ice: 7.877\n",
      " refreeze: 0.291\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 12300, acc. rate: 0.37, log(P): -3403.5\n",
      "f_snow: 2.100\n",
      " f_ice: 7.825\n",
      " refreeze: 0.617\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 12400, acc. rate: 0.31, log(P): -3406.3\n",
      "f_snow: 2.215\n",
      " f_ice: 7.881\n",
      " refreeze: 0.262\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 12500, acc. rate: 0.28, log(P): -3408.4\n",
      "f_snow: 2.409\n",
      " f_ice: 7.912\n",
      " refreeze: 0.600\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 12600, acc. rate: 0.26, log(P): -3405.8\n",
      "f_snow: 2.249\n",
      " f_ice: 7.898\n",
      " refreeze: 0.669\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 12700, acc. rate: 0.27, log(P): -3408.4\n",
      "f_snow: 2.479\n",
      " f_ice: 7.916\n",
      " refreeze: 0.646\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 12800, acc. rate: 0.26, log(P): -3407.0\n",
      "f_snow: 2.502\n",
      " f_ice: 7.915\n",
      " refreeze: 0.624\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 12900, acc. rate: 0.27, log(P): -3407.7\n",
      "f_snow: 2.406\n",
      " f_ice: 7.907\n",
      " refreeze: 0.347\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 13000, acc. rate: 0.16, log(P): -3403.1\n",
      "f_snow: 2.665\n",
      " f_ice: 7.931\n",
      " refreeze: 0.103\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 13100, acc. rate: 0.30, log(P): -3404.5\n",
      "f_snow: 2.608\n",
      " f_ice: 7.927\n",
      " refreeze: 0.073\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 13200, acc. rate: 0.32, log(P): -3408.1\n",
      "f_snow: 2.529\n",
      " f_ice: 7.922\n",
      " refreeze: 0.457\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 13300, acc. rate: 0.25, log(P): -3400.6\n",
      "f_snow: 2.652\n",
      " f_ice: 7.935\n",
      " refreeze: 0.186\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 13400, acc. rate: 0.23, log(P): -3408.5\n",
      "f_snow: 2.417\n",
      " f_ice: 7.912\n",
      " refreeze: 0.624\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 13500, acc. rate: 0.23, log(P): -3407.2\n",
      "f_snow: 2.412\n",
      " f_ice: 7.917\n",
      " refreeze: 0.766\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 13600, acc. rate: 0.26, log(P): -3406.1\n",
      "f_snow: 2.254\n",
      " f_ice: 7.891\n",
      " refreeze: 0.111\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 13700, acc. rate: 0.24, log(P): -3408.4\n",
      "f_snow: 2.357\n",
      " f_ice: 7.905\n",
      " refreeze: 0.494\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 13800, acc. rate: 0.25, log(P): -3407.6\n",
      "f_snow: 2.255\n",
      " f_ice: 7.893\n",
      " refreeze: 0.336\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 13900, acc. rate: 0.28, log(P): -3402.2\n",
      "f_snow: 2.120\n",
      " f_ice: 7.829\n",
      " refreeze: 0.905\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 14000, acc. rate: 0.31, log(P): -3406.2\n",
      "f_snow: 2.169\n",
      " f_ice: 7.869\n",
      " refreeze: 0.416\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 14100, acc. rate: 0.29, log(P): -3405.9\n",
      "f_snow: 2.233\n",
      " f_ice: 7.890\n",
      " refreeze: 0.129\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 14200, acc. rate: 0.29, log(P): -3408.4\n",
      "f_snow: 2.482\n",
      " f_ice: 7.915\n",
      " refreeze: 0.432\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 14300, acc. rate: 0.27, log(P): -3402.9\n",
      "f_snow: 2.206\n",
      " f_ice: 7.855\n",
      " refreeze: 0.471\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 14400, acc. rate: 0.24, log(P): -3408.0\n",
      "f_snow: 2.332\n",
      " f_ice: 7.906\n",
      " refreeze: 0.510\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 14500, acc. rate: 0.27, log(P): -3408.7\n",
      "f_snow: 2.478\n",
      " f_ice: 7.917\n",
      " refreeze: 0.422\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 14600, acc. rate: 0.24, log(P): -3406.9\n",
      "f_snow: 2.466\n",
      " f_ice: 7.912\n",
      " refreeze: 0.133\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 14700, acc. rate: 0.25, log(P): -3407.5\n",
      "f_snow: 2.248\n",
      " f_ice: 7.891\n",
      " refreeze: 0.317\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 14800, acc. rate: 0.27, log(P): -3408.2\n",
      "f_snow: 2.462\n",
      " f_ice: 7.918\n",
      " refreeze: 0.404\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 14900, acc. rate: 0.32, log(P): -3406.1\n",
      "f_snow: 2.150\n",
      " f_ice: 7.847\n",
      " refreeze: 0.698\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 15000, acc. rate: 0.29, log(P): -3407.8\n",
      "f_snow: 2.551\n",
      " f_ice: 7.920\n",
      " refreeze: 0.302\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 15100, acc. rate: 0.27, log(P): -3407.3\n",
      "f_snow: 2.366\n",
      " f_ice: 7.905\n",
      " refreeze: 0.167\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 15200, acc. rate: 0.33, log(P): -3404.5\n",
      "f_snow: 2.174\n",
      " f_ice: 7.851\n",
      " refreeze: 0.100\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 15300, acc. rate: 0.31, log(P): -3403.6\n",
      "f_snow: 2.099\n",
      " f_ice: 7.794\n",
      " refreeze: 0.715\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 15400, acc. rate: 0.29, log(P): -3406.3\n",
      "f_snow: 2.145\n",
      " f_ice: 7.848\n",
      " refreeze: 0.522\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 15500, acc. rate: 0.33, log(P): -3406.7\n",
      "f_snow: 2.163\n",
      " f_ice: 7.861\n",
      " refreeze: 0.626\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 15600, acc. rate: 0.33, log(P): -3407.3\n",
      "f_snow: 2.263\n",
      " f_ice: 7.892\n",
      " refreeze: 0.256\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 15700, acc. rate: 0.24, log(P): -3408.3\n",
      "f_snow: 2.389\n",
      " f_ice: 7.909\n",
      " refreeze: 0.322\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 15800, acc. rate: 0.28, log(P): -3408.4\n",
      "f_snow: 2.399\n",
      " f_ice: 7.908\n",
      " refreeze: 0.349\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 15900, acc. rate: 0.25, log(P): -3407.5\n",
      "f_snow: 2.533\n",
      " f_ice: 7.924\n",
      " refreeze: 0.339\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 16000, acc. rate: 0.28, log(P): -3407.5\n",
      "f_snow: 2.559\n",
      " f_ice: 7.921\n",
      " refreeze: 0.475\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 16100, acc. rate: 0.26, log(P): -3408.3\n",
      "f_snow: 2.438\n",
      " f_ice: 7.917\n",
      " refreeze: 0.521\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 16200, acc. rate: 0.27, log(P): -3408.6\n",
      "f_snow: 2.485\n",
      " f_ice: 7.917\n",
      " refreeze: 0.570\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 16300, acc. rate: 0.24, log(P): -3408.3\n",
      "f_snow: 2.431\n",
      " f_ice: 7.910\n",
      " refreeze: 0.554\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 16400, acc. rate: 0.32, log(P): -3406.0\n",
      "f_snow: 2.178\n",
      " f_ice: 7.866\n",
      " refreeze: 0.285\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 16500, acc. rate: 0.26, log(P): -3408.1\n",
      "f_snow: 2.449\n",
      " f_ice: 7.912\n",
      " refreeze: 0.263\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 16600, acc. rate: 0.30, log(P): -3407.6\n",
      "f_snow: 2.518\n",
      " f_ice: 7.916\n",
      " refreeze: 0.479\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 16700, acc. rate: 0.27, log(P): -3406.1\n",
      "f_snow: 2.548\n",
      " f_ice: 7.927\n",
      " refreeze: 0.551\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 16800, acc. rate: 0.26, log(P): -3408.2\n",
      "f_snow: 2.436\n",
      " f_ice: 7.916\n",
      " refreeze: 0.702\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 16900, acc. rate: 0.28, log(P): -3407.4\n",
      "f_snow: 2.472\n",
      " f_ice: 7.922\n",
      " refreeze: 0.553\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 17000, acc. rate: 0.29, log(P): -3407.9\n",
      "f_snow: 2.478\n",
      " f_ice: 7.921\n",
      " refreeze: 0.539\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 17100, acc. rate: 0.25, log(P): -3406.3\n",
      "f_snow: 2.302\n",
      " f_ice: 7.903\n",
      " refreeze: 0.160\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 17200, acc. rate: 0.24, log(P): -3407.3\n",
      "f_snow: 2.458\n",
      " f_ice: 7.910\n",
      " refreeze: 0.398\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 17300, acc. rate: 0.26, log(P): -3407.5\n",
      "f_snow: 2.278\n",
      " f_ice: 7.897\n",
      " refreeze: 0.244\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 17400, acc. rate: 0.25, log(P): -3408.0\n",
      "f_snow: 2.459\n",
      " f_ice: 7.912\n",
      " refreeze: 0.426\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 17500, acc. rate: 0.25, log(P): -3407.7\n",
      "f_snow: 2.430\n",
      " f_ice: 7.910\n",
      " refreeze: 0.196\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 17600, acc. rate: 0.25, log(P): -3407.3\n",
      "f_snow: 2.420\n",
      " f_ice: 7.913\n",
      " refreeze: 0.172\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 17700, acc. rate: 0.25, log(P): -3406.6\n",
      "f_snow: 2.569\n",
      " f_ice: 7.924\n",
      " refreeze: 0.146\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 17800, acc. rate: 0.24, log(P): -3406.7\n",
      "f_snow: 2.534\n",
      " f_ice: 7.923\n",
      " refreeze: 0.138\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 17900, acc. rate: 0.26, log(P): -3408.4\n",
      "f_snow: 2.414\n",
      " f_ice: 7.910\n",
      " refreeze: 0.355\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 18000, acc. rate: 0.24, log(P): -3407.2\n",
      "f_snow: 2.225\n",
      " f_ice: 7.886\n",
      " refreeze: 0.564\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 18100, acc. rate: 0.31, log(P): -3404.6\n",
      "f_snow: 2.100\n",
      " f_ice: 7.810\n",
      " refreeze: 0.504\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 18200, acc. rate: 0.31, log(P): -3404.4\n",
      "f_snow: 2.092\n",
      " f_ice: 7.805\n",
      " refreeze: 0.491\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 18300, acc. rate: 0.27, log(P): -3406.3\n",
      "f_snow: 2.162\n",
      " f_ice: 7.848\n",
      " refreeze: 0.343\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 18400, acc. rate: 0.25, log(P): -3406.2\n",
      "f_snow: 2.226\n",
      " f_ice: 7.891\n",
      " refreeze: 0.429\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 18500, acc. rate: 0.28, log(P): -3408.1\n",
      "f_snow: 2.406\n",
      " f_ice: 7.913\n",
      " refreeze: 0.711\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 18600, acc. rate: 0.23, log(P): -3406.3\n",
      "f_snow: 2.219\n",
      " f_ice: 7.884\n",
      " refreeze: 0.236\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 18700, acc. rate: 0.25, log(P): -3407.9\n",
      "f_snow: 2.479\n",
      " f_ice: 7.921\n",
      " refreeze: 0.610\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 18800, acc. rate: 0.23, log(P): -3407.0\n",
      "f_snow: 2.299\n",
      " f_ice: 7.898\n",
      " refreeze: 0.178\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 18900, acc. rate: 0.31, log(P): -3406.9\n",
      "f_snow: 2.461\n",
      " f_ice: 7.917\n",
      " refreeze: 0.871\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 19000, acc. rate: 0.29, log(P): -3407.1\n",
      "f_snow: 2.557\n",
      " f_ice: 7.921\n",
      " refreeze: 0.173\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 19100, acc. rate: 0.30, log(P): -3408.4\n",
      "f_snow: 2.406\n",
      " f_ice: 7.909\n",
      " refreeze: 0.336\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 19200, acc. rate: 0.25, log(P): -3406.7\n",
      "f_snow: 2.281\n",
      " f_ice: 7.895\n",
      " refreeze: 0.188\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 19300, acc. rate: 0.31, log(P): -3406.0\n",
      "f_snow: 2.163\n",
      " f_ice: 7.860\n",
      " refreeze: 0.216\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 19400, acc. rate: 0.28, log(P): -3407.0\n",
      "f_snow: 2.222\n",
      " f_ice: 7.880\n",
      " refreeze: 0.344\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 19500, acc. rate: 0.26, log(P): -3400.9\n",
      "f_snow: 2.094\n",
      " f_ice: 7.802\n",
      " refreeze: 0.063\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 19600, acc. rate: 0.25, log(P): -3403.6\n",
      "f_snow: 2.113\n",
      " f_ice: 7.816\n",
      " refreeze: 0.395\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 19700, acc. rate: 0.28, log(P): -3405.7\n",
      "f_snow: 2.139\n",
      " f_ice: 7.849\n",
      " refreeze: 0.702\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 19800, acc. rate: 0.28, log(P): -3405.8\n",
      "f_snow: 2.167\n",
      " f_ice: 7.865\n",
      " refreeze: 0.744\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 19900, acc. rate: 0.25, log(P): -3407.7\n",
      "f_snow: 2.431\n",
      " f_ice: 7.918\n",
      " refreeze: 0.653\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 20000, acc. rate: 0.25, log(P): -3406.8\n",
      "f_snow: 2.481\n",
      " f_ice: 7.921\n",
      " refreeze: 0.214\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 20100, acc. rate: 0.26, log(P): -3403.3\n",
      "f_snow: 2.654\n",
      " f_ice: 7.932\n",
      " refreeze: 0.189\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 20200, acc. rate: 0.27, log(P): -3407.5\n",
      "f_snow: 2.538\n",
      " f_ice: 7.924\n",
      " refreeze: 0.309\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 20300, acc. rate: 0.29, log(P): -3408.0\n",
      "f_snow: 2.368\n",
      " f_ice: 7.909\n",
      " refreeze: 0.640\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 20400, acc. rate: 0.24, log(P): -3407.8\n",
      "f_snow: 2.473\n",
      " f_ice: 7.920\n",
      " refreeze: 0.349\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 20500, acc. rate: 0.30, log(P): -3407.3\n",
      "f_snow: 2.338\n",
      " f_ice: 7.906\n",
      " refreeze: 0.791\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 20600, acc. rate: 0.23, log(P): -3407.9\n",
      "f_snow: 2.271\n",
      " f_ice: 7.896\n",
      " refreeze: 0.420\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 20700, acc. rate: 0.31, log(P): -3405.5\n",
      "f_snow: 2.144\n",
      " f_ice: 7.861\n",
      " refreeze: 0.530\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 20800, acc. rate: 0.31, log(P): -3406.0\n",
      "f_snow: 2.148\n",
      " f_ice: 7.861\n",
      " refreeze: 0.706\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 20900, acc. rate: 0.37, log(P): -3404.9\n",
      "f_snow: 2.183\n",
      " f_ice: 7.876\n",
      " refreeze: 0.327\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 21000, acc. rate: 0.40, log(P): -3404.5\n",
      "f_snow: 2.109\n",
      " f_ice: 7.812\n",
      " refreeze: 0.594\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 21100, acc. rate: 0.32, log(P): -3407.5\n",
      "f_snow: 2.489\n",
      " f_ice: 7.922\n",
      " refreeze: 0.424\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 21200, acc. rate: 0.30, log(P): -3404.8\n",
      "f_snow: 2.356\n",
      " f_ice: 7.915\n",
      " refreeze: 0.455\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 21300, acc. rate: 0.22, log(P): -3408.2\n",
      "f_snow: 2.479\n",
      " f_ice: 7.917\n",
      " refreeze: 0.254\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 21400, acc. rate: 0.37, log(P): -3402.2\n",
      "f_snow: 2.581\n",
      " f_ice: 7.932\n",
      " refreeze: 0.228\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 21500, acc. rate: 0.36, log(P): -3406.7\n",
      "f_snow: 2.167\n",
      " f_ice: 7.856\n",
      " refreeze: 0.332\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 21600, acc. rate: 0.26, log(P): -3406.1\n",
      "f_snow: 2.259\n",
      " f_ice: 7.900\n",
      " refreeze: 0.662\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 21700, acc. rate: 0.28, log(P): -3407.4\n",
      "f_snow: 2.263\n",
      " f_ice: 7.898\n",
      " refreeze: 0.469\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 21800, acc. rate: 0.25, log(P): -3407.2\n",
      "f_snow: 2.381\n",
      " f_ice: 7.914\n",
      " refreeze: 0.720\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 21900, acc. rate: 0.28, log(P): -3406.4\n",
      "f_snow: 2.157\n",
      " f_ice: 7.863\n",
      " refreeze: 0.476\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 22000, acc. rate: 0.33, log(P): -3406.3\n",
      "f_snow: 2.463\n",
      " f_ice: 7.916\n",
      " refreeze: 0.910\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 22100, acc. rate: 0.31, log(P): -3406.1\n",
      "f_snow: 2.613\n",
      " f_ice: 7.925\n",
      " refreeze: 0.424\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 22200, acc. rate: 0.31, log(P): -3407.8\n",
      "f_snow: 2.442\n",
      " f_ice: 7.918\n",
      " refreeze: 0.469\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 22300, acc. rate: 0.27, log(P): -3406.4\n",
      "f_snow: 2.485\n",
      " f_ice: 7.923\n",
      " refreeze: 0.753\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 22400, acc. rate: 0.26, log(P): -3408.5\n",
      "f_snow: 2.481\n",
      " f_ice: 7.917\n",
      " refreeze: 0.626\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 22500, acc. rate: 0.25, log(P): -3407.9\n",
      "f_snow: 2.491\n",
      " f_ice: 7.921\n",
      " refreeze: 0.336\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 22600, acc. rate: 0.26, log(P): -3407.4\n",
      "f_snow: 2.377\n",
      " f_ice: 7.904\n",
      " refreeze: 0.233\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 22700, acc. rate: 0.31, log(P): -3406.6\n",
      "f_snow: 2.171\n",
      " f_ice: 7.856\n",
      " refreeze: 0.369\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 22800, acc. rate: 0.25, log(P): -3408.4\n",
      "f_snow: 2.501\n",
      " f_ice: 7.920\n",
      " refreeze: 0.540\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 22900, acc. rate: 0.25, log(P): -3406.9\n",
      "f_snow: 2.162\n",
      " f_ice: 7.860\n",
      " refreeze: 0.457\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 23000, acc. rate: 0.26, log(P): -3407.5\n",
      "f_snow: 2.523\n",
      " f_ice: 7.923\n",
      " refreeze: 0.591\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 23100, acc. rate: 0.22, log(P): -3405.1\n",
      "f_snow: 2.269\n",
      " f_ice: 7.897\n",
      " refreeze: 0.061\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 23200, acc. rate: 0.29, log(P): -3404.7\n",
      "f_snow: 2.369\n",
      " f_ice: 7.911\n",
      " refreeze: 0.111\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 23300, acc. rate: 0.33, log(P): -3404.7\n",
      "f_snow: 2.270\n",
      " f_ice: 7.887\n",
      " refreeze: 0.687\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 23400, acc. rate: 0.27, log(P): -3407.0\n",
      "f_snow: 2.339\n",
      " f_ice: 7.908\n",
      " refreeze: 0.405\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 23500, acc. rate: 0.26, log(P): -3405.6\n",
      "f_snow: 2.192\n",
      " f_ice: 7.862\n",
      " refreeze: 0.384\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 23600, acc. rate: 0.28, log(P): -3408.1\n",
      "f_snow: 2.308\n",
      " f_ice: 7.902\n",
      " refreeze: 0.531\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 23700, acc. rate: 0.26, log(P): -3408.1\n",
      "f_snow: 2.472\n",
      " f_ice: 7.915\n",
      " refreeze: 0.708\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 23800, acc. rate: 0.32, log(P): -3407.1\n",
      "f_snow: 2.515\n",
      " f_ice: 7.924\n",
      " refreeze: 0.610\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 23900, acc. rate: 0.27, log(P): -3407.5\n",
      "f_snow: 2.317\n",
      " f_ice: 7.905\n",
      " refreeze: 0.688\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 24000, acc. rate: 0.24, log(P): -3407.7\n",
      "f_snow: 2.495\n",
      " f_ice: 7.914\n",
      " refreeze: 0.510\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 24100, acc. rate: 0.28, log(P): -3407.3\n",
      "f_snow: 2.284\n",
      " f_ice: 7.895\n",
      " refreeze: 0.493\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 24200, acc. rate: 0.21, log(P): -3408.0\n",
      "f_snow: 2.283\n",
      " f_ice: 7.898\n",
      " refreeze: 0.446\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 24300, acc. rate: 0.30, log(P): -3407.4\n",
      "f_snow: 2.307\n",
      " f_ice: 7.904\n",
      " refreeze: 0.428\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 24400, acc. rate: 0.27, log(P): -3408.5\n",
      "f_snow: 2.380\n",
      " f_ice: 7.909\n",
      " refreeze: 0.516\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 24500, acc. rate: 0.29, log(P): -3406.6\n",
      "f_snow: 2.151\n",
      " f_ice: 7.854\n",
      " refreeze: 0.431\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 24600, acc. rate: 0.35, log(P): -3405.2\n",
      "f_snow: 2.163\n",
      " f_ice: 7.869\n",
      " refreeze: 0.238\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 24700, acc. rate: 0.27, log(P): -3406.3\n",
      "f_snow: 2.466\n",
      " f_ice: 7.923\n",
      " refreeze: 0.430\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 24800, acc. rate: 0.23, log(P): -3408.4\n",
      "f_snow: 2.509\n",
      " f_ice: 7.919\n",
      " refreeze: 0.547\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 24900, acc. rate: 0.28, log(P): -3407.1\n",
      "f_snow: 2.238\n",
      " f_ice: 7.885\n",
      " refreeze: 0.538\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 25000, acc. rate: 0.27, log(P): -3408.5\n",
      "f_snow: 2.513\n",
      " f_ice: 7.919\n",
      " refreeze: 0.419\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 25100, acc. rate: 0.34, log(P): -3404.9\n",
      "f_snow: 2.523\n",
      " f_ice: 7.914\n",
      " refreeze: 0.221\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 25200, acc. rate: 0.29, log(P): -3408.7\n",
      "f_snow: 2.486\n",
      " f_ice: 7.916\n",
      " refreeze: 0.466\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 25300, acc. rate: 0.26, log(P): -3406.1\n",
      "f_snow: 2.567\n",
      " f_ice: 7.920\n",
      " refreeze: 0.653\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 25400, acc. rate: 0.29, log(P): -3402.0\n",
      "f_snow: 2.142\n",
      " f_ice: 7.875\n",
      " refreeze: 0.791\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 25500, acc. rate: 0.28, log(P): -3408.5\n",
      "f_snow: 2.481\n",
      " f_ice: 7.917\n",
      " refreeze: 0.636\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 25600, acc. rate: 0.24, log(P): -3408.3\n",
      "f_snow: 2.513\n",
      " f_ice: 7.920\n",
      " refreeze: 0.540\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 25700, acc. rate: 0.24, log(P): -3407.1\n",
      "f_snow: 2.316\n",
      " f_ice: 7.901\n",
      " refreeze: 0.164\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 25800, acc. rate: 0.31, log(P): -3405.8\n",
      "f_snow: 2.597\n",
      " f_ice: 7.922\n",
      " refreeze: 0.505\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 25900, acc. rate: 0.24, log(P): -3405.6\n",
      "f_snow: 2.165\n",
      " f_ice: 7.865\n",
      " refreeze: 0.802\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 26000, acc. rate: 0.26, log(P): -3406.7\n",
      "f_snow: 2.232\n",
      " f_ice: 7.892\n",
      " refreeze: 0.463\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 26100, acc. rate: 0.24, log(P): -3408.1\n",
      "f_snow: 2.400\n",
      " f_ice: 7.907\n",
      " refreeze: 0.353\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 26200, acc. rate: 0.22, log(P): -3408.2\n",
      "f_snow: 2.363\n",
      " f_ice: 7.907\n",
      " refreeze: 0.364\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 26300, acc. rate: 0.24, log(P): -3407.7\n",
      "f_snow: 2.522\n",
      " f_ice: 7.920\n",
      " refreeze: 0.190\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 26400, acc. rate: 0.28, log(P): -3408.5\n",
      "f_snow: 2.422\n",
      " f_ice: 7.911\n",
      " refreeze: 0.350\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 26500, acc. rate: 0.24, log(P): -3405.9\n",
      "f_snow: 2.397\n",
      " f_ice: 7.912\n",
      " refreeze: 0.115\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 26600, acc. rate: 0.23, log(P): -3406.2\n",
      "f_snow: 2.380\n",
      " f_ice: 7.914\n",
      " refreeze: 0.333\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 26700, acc. rate: 0.28, log(P): -3406.7\n",
      "f_snow: 2.536\n",
      " f_ice: 7.922\n",
      " refreeze: 0.749\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 26800, acc. rate: 0.26, log(P): -3408.0\n",
      "f_snow: 2.476\n",
      " f_ice: 7.919\n",
      " refreeze: 0.701\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 26900, acc. rate: 0.26, log(P): -3407.5\n",
      "f_snow: 2.462\n",
      " f_ice: 7.914\n",
      " refreeze: 0.805\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 27000, acc. rate: 0.28, log(P): -3408.1\n",
      "f_snow: 2.490\n",
      " f_ice: 7.920\n",
      " refreeze: 0.305\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 27100, acc. rate: 0.25, log(P): -3408.7\n",
      "f_snow: 2.464\n",
      " f_ice: 7.914\n",
      " refreeze: 0.470\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 27200, acc. rate: 0.26, log(P): -3406.2\n",
      "f_snow: 2.540\n",
      " f_ice: 7.926\n",
      " refreeze: 0.240\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 27300, acc. rate: 0.24, log(P): -3407.2\n",
      "f_snow: 2.530\n",
      " f_ice: 7.919\n",
      " refreeze: 0.149\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 27400, acc. rate: 0.32, log(P): -3408.7\n",
      "f_snow: 2.422\n",
      " f_ice: 7.912\n",
      " refreeze: 0.494\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 27500, acc. rate: 0.24, log(P): -3408.6\n",
      "f_snow: 2.438\n",
      " f_ice: 7.912\n",
      " refreeze: 0.599\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 27600, acc. rate: 0.31, log(P): -3406.2\n",
      "f_snow: 2.492\n",
      " f_ice: 7.925\n",
      " refreeze: 0.434\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 27700, acc. rate: 0.27, log(P): -3406.6\n",
      "f_snow: 2.467\n",
      " f_ice: 7.910\n",
      " refreeze: 0.494\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 27800, acc. rate: 0.30, log(P): -3400.8\n",
      "f_snow: 2.076\n",
      " f_ice: 7.754\n",
      " refreeze: 0.300\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 27900, acc. rate: 0.30, log(P): -3408.6\n",
      "f_snow: 2.500\n",
      " f_ice: 7.919\n",
      " refreeze: 0.459\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 28000, acc. rate: 0.32, log(P): -3403.3\n",
      "f_snow: 2.391\n",
      " f_ice: 7.913\n",
      " refreeze: 0.981\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 28100, acc. rate: 0.29, log(P): -3404.4\n",
      "f_snow: 2.471\n",
      " f_ice: 7.910\n",
      " refreeze: 0.101\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 28200, acc. rate: 0.27, log(P): -3406.4\n",
      "f_snow: 2.152\n",
      " f_ice: 7.853\n",
      " refreeze: 0.362\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 28300, acc. rate: 0.35, log(P): -3406.3\n",
      "f_snow: 2.175\n",
      " f_ice: 7.867\n",
      " refreeze: 0.431\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 28400, acc. rate: 0.33, log(P): -3408.5\n",
      "f_snow: 2.453\n",
      " f_ice: 7.917\n",
      " refreeze: 0.640\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 28500, acc. rate: 0.37, log(P): -3406.2\n",
      "f_snow: 2.151\n",
      " f_ice: 7.859\n",
      " refreeze: 0.735\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 28600, acc. rate: 0.35, log(P): -3407.9\n",
      "f_snow: 2.490\n",
      " f_ice: 7.917\n",
      " refreeze: 0.202\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 28700, acc. rate: 0.28, log(P): -3408.1\n",
      "f_snow: 2.460\n",
      " f_ice: 7.912\n",
      " refreeze: 0.300\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 28800, acc. rate: 0.28, log(P): -3408.7\n",
      "f_snow: 2.488\n",
      " f_ice: 7.917\n",
      " refreeze: 0.514\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 28900, acc. rate: 0.26, log(P): -3408.4\n",
      "f_snow: 2.494\n",
      " f_ice: 7.916\n",
      " refreeze: 0.452\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 29000, acc. rate: 0.25, log(P): -3406.3\n",
      "f_snow: 2.354\n",
      " f_ice: 7.906\n",
      " refreeze: 0.111\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 29100, acc. rate: 0.26, log(P): -3408.1\n",
      "f_snow: 2.314\n",
      " f_ice: 7.901\n",
      " refreeze: 0.558\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 29200, acc. rate: 0.24, log(P): -3406.2\n",
      "f_snow: 2.176\n",
      " f_ice: 7.862\n",
      " refreeze: 0.573\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 29300, acc. rate: 0.33, log(P): -3404.4\n",
      "f_snow: 2.177\n",
      " f_ice: 7.845\n",
      " refreeze: 0.226\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 29400, acc. rate: 0.30, log(P): -3405.4\n",
      "f_snow: 2.229\n",
      " f_ice: 7.879\n",
      " refreeze: 0.138\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 29500, acc. rate: 0.19, log(P): -3407.1\n",
      "f_snow: 2.277\n",
      " f_ice: 7.898\n",
      " refreeze: 0.789\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 29600, acc. rate: 0.30, log(P): -3408.6\n",
      "f_snow: 2.465\n",
      " f_ice: 7.915\n",
      " refreeze: 0.612\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 29700, acc. rate: 0.26, log(P): -3408.0\n",
      "f_snow: 2.470\n",
      " f_ice: 7.912\n",
      " refreeze: 0.471\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 29800, acc. rate: 0.24, log(P): -3407.9\n",
      "f_snow: 2.286\n",
      " f_ice: 7.899\n",
      " refreeze: 0.326\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 29900, acc. rate: 0.27, log(P): -3408.1\n",
      "f_snow: 2.361\n",
      " f_ice: 7.904\n",
      " refreeze: 0.466\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 30000, acc. rate: 0.24, log(P): -3408.1\n",
      "f_snow: 2.382\n",
      " f_ice: 7.907\n",
      " refreeze: 0.267\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 30100, acc. rate: 0.30, log(P): -3408.1\n",
      "f_snow: 2.411\n",
      " f_ice: 7.908\n",
      " refreeze: 0.422\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 30200, acc. rate: 0.27, log(P): -3407.6\n",
      "f_snow: 2.249\n",
      " f_ice: 7.893\n",
      " refreeze: 0.475\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 30300, acc. rate: 0.27, log(P): -3406.5\n",
      "f_snow: 2.363\n",
      " f_ice: 7.908\n",
      " refreeze: 0.890\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 30400, acc. rate: 0.28, log(P): -3408.2\n",
      "f_snow: 2.325\n",
      " f_ice: 7.902\n",
      " refreeze: 0.569\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 30500, acc. rate: 0.25, log(P): -3408.5\n",
      "f_snow: 2.503\n",
      " f_ice: 7.917\n",
      " refreeze: 0.344\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 30600, acc. rate: 0.31, log(P): -3407.9\n",
      "f_snow: 2.552\n",
      " f_ice: 7.921\n",
      " refreeze: 0.418\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 30700, acc. rate: 0.25, log(P): -3406.2\n",
      "f_snow: 2.341\n",
      " f_ice: 7.901\n",
      " refreeze: 0.805\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 30800, acc. rate: 0.29, log(P): -3404.2\n",
      "f_snow: 2.193\n",
      " f_ice: 7.853\n",
      " refreeze: 0.535\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 30900, acc. rate: 0.29, log(P): -3406.2\n",
      "f_snow: 2.171\n",
      " f_ice: 7.856\n",
      " refreeze: 0.621\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 31000, acc. rate: 0.28, log(P): -3406.0\n",
      "f_snow: 2.154\n",
      " f_ice: 7.843\n",
      " refreeze: 0.529\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 31100, acc. rate: 0.30, log(P): -3408.0\n",
      "f_snow: 2.465\n",
      " f_ice: 7.916\n",
      " refreeze: 0.235\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 31200, acc. rate: 0.23, log(P): -3407.4\n",
      "f_snow: 2.515\n",
      " f_ice: 7.916\n",
      " refreeze: 0.305\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 31300, acc. rate: 0.35, log(P): -3404.6\n",
      "f_snow: 2.171\n",
      " f_ice: 7.877\n",
      " refreeze: 0.708\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 31400, acc. rate: 0.36, log(P): -3403.2\n",
      "f_snow: 2.140\n",
      " f_ice: 7.869\n",
      " refreeze: 0.801\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 31500, acc. rate: 0.31, log(P): -3406.0\n",
      "f_snow: 2.399\n",
      " f_ice: 7.917\n",
      " refreeze: 0.316\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 31600, acc. rate: 0.34, log(P): -3404.9\n",
      "f_snow: 2.633\n",
      " f_ice: 7.924\n",
      " refreeze: 0.525\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 31700, acc. rate: 0.30, log(P): -3407.6\n",
      "f_snow: 2.540\n",
      " f_ice: 7.922\n",
      " refreeze: 0.242\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 31800, acc. rate: 0.29, log(P): -3404.6\n",
      "f_snow: 2.164\n",
      " f_ice: 7.846\n",
      " refreeze: 0.106\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 31900, acc. rate: 0.30, log(P): -3408.7\n",
      "f_snow: 2.453\n",
      " f_ice: 7.914\n",
      " refreeze: 0.539\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 32000, acc. rate: 0.18, log(P): -3407.7\n",
      "f_snow: 2.284\n",
      " f_ice: 7.896\n",
      " refreeze: 0.518\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 32100, acc. rate: 0.28, log(P): -3406.5\n",
      "f_snow: 2.320\n",
      " f_ice: 7.902\n",
      " refreeze: 0.864\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 32200, acc. rate: 0.37, log(P): -3407.2\n",
      "f_snow: 2.537\n",
      " f_ice: 7.925\n",
      " refreeze: 0.379\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 32300, acc. rate: 0.29, log(P): -3404.6\n",
      "f_snow: 2.147\n",
      " f_ice: 7.834\n",
      " refreeze: 0.385\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 32400, acc. rate: 0.34, log(P): -3405.3\n",
      "f_snow: 2.192\n",
      " f_ice: 7.869\n",
      " refreeze: 0.713\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 32500, acc. rate: 0.26, log(P): -3408.0\n",
      "f_snow: 2.323\n",
      " f_ice: 7.903\n",
      " refreeze: 0.353\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 32600, acc. rate: 0.21, log(P): -3406.7\n",
      "f_snow: 2.513\n",
      " f_ice: 7.925\n",
      " refreeze: 0.487\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 32700, acc. rate: 0.30, log(P): -3406.7\n",
      "f_snow: 2.596\n",
      " f_ice: 7.924\n",
      " refreeze: 0.266\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 32800, acc. rate: 0.37, log(P): -3403.2\n",
      "f_snow: 2.164\n",
      " f_ice: 7.873\n",
      " refreeze: 0.918\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 32900, acc. rate: 0.21, log(P): -3404.1\n",
      "f_snow: 2.764\n",
      " f_ice: 7.932\n",
      " refreeze: 0.138\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 33000, acc. rate: 0.30, log(P): -3406.3\n",
      "f_snow: 2.547\n",
      " f_ice: 7.926\n",
      " refreeze: 0.329\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 33100, acc. rate: 0.34, log(P): -3408.2\n",
      "f_snow: 2.506\n",
      " f_ice: 7.921\n",
      " refreeze: 0.481\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 33200, acc. rate: 0.30, log(P): -3405.6\n",
      "f_snow: 2.551\n",
      " f_ice: 7.926\n",
      " refreeze: 0.719\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 33300, acc. rate: 0.26, log(P): -3407.6\n",
      "f_snow: 2.360\n",
      " f_ice: 7.907\n",
      " refreeze: 0.228\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 33400, acc. rate: 0.25, log(P): -3408.5\n",
      "f_snow: 2.373\n",
      " f_ice: 7.908\n",
      " refreeze: 0.526\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 33500, acc. rate: 0.25, log(P): -3408.1\n",
      "f_snow: 2.479\n",
      " f_ice: 7.917\n",
      " refreeze: 0.235\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 33600, acc. rate: 0.26, log(P): -3407.7\n",
      "f_snow: 2.518\n",
      " f_ice: 7.918\n",
      " refreeze: 0.666\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 33700, acc. rate: 0.29, log(P): -3407.6\n",
      "f_snow: 2.422\n",
      " f_ice: 7.918\n",
      " refreeze: 0.618\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 33800, acc. rate: 0.27, log(P): -3406.6\n",
      "f_snow: 2.172\n",
      " f_ice: 7.858\n",
      " refreeze: 0.403\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 33900, acc. rate: 0.26, log(P): -3406.7\n",
      "f_snow: 2.236\n",
      " f_ice: 7.891\n",
      " refreeze: 0.234\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 34000, acc. rate: 0.27, log(P): -3408.2\n",
      "f_snow: 2.467\n",
      " f_ice: 7.914\n",
      " refreeze: 0.682\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 34100, acc. rate: 0.26, log(P): -3408.5\n",
      "f_snow: 2.457\n",
      " f_ice: 7.913\n",
      " refreeze: 0.398\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 34200, acc. rate: 0.28, log(P): -3408.1\n",
      "f_snow: 2.323\n",
      " f_ice: 7.901\n",
      " refreeze: 0.490\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 34300, acc. rate: 0.30, log(P): -3407.2\n",
      "f_snow: 2.299\n",
      " f_ice: 7.898\n",
      " refreeze: 0.676\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 34400, acc. rate: 0.27, log(P): -3407.5\n",
      "f_snow: 2.429\n",
      " f_ice: 7.912\n",
      " refreeze: 0.164\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 34500, acc. rate: 0.26, log(P): -3407.1\n",
      "f_snow: 2.333\n",
      " f_ice: 7.907\n",
      " refreeze: 0.309\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 34600, acc. rate: 0.31, log(P): -3408.1\n",
      "f_snow: 2.397\n",
      " f_ice: 7.912\n",
      " refreeze: 0.635\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 34700, acc. rate: 0.27, log(P): -3407.4\n",
      "f_snow: 2.568\n",
      " f_ice: 7.922\n",
      " refreeze: 0.263\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 34800, acc. rate: 0.21, log(P): -3408.8\n",
      "f_snow: 2.462\n",
      " f_ice: 7.915\n",
      " refreeze: 0.442\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 34900, acc. rate: 0.27, log(P): -3408.6\n",
      "f_snow: 2.456\n",
      " f_ice: 7.914\n",
      " refreeze: 0.621\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 35000, acc. rate: 0.27, log(P): -3406.8\n",
      "f_snow: 2.534\n",
      " f_ice: 7.917\n",
      " refreeze: 0.276\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 35100, acc. rate: 0.33, log(P): -3407.4\n",
      "f_snow: 2.552\n",
      " f_ice: 7.924\n",
      " refreeze: 0.400\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 35200, acc. rate: 0.23, log(P): -3407.3\n",
      "f_snow: 2.485\n",
      " f_ice: 7.920\n",
      " refreeze: 0.796\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 35300, acc. rate: 0.33, log(P): -3405.7\n",
      "f_snow: 2.330\n",
      " f_ice: 7.899\n",
      " refreeze: 0.098\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 35400, acc. rate: 0.22, log(P): -3407.5\n",
      "f_snow: 2.375\n",
      " f_ice: 7.905\n",
      " refreeze: 0.214\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 35500, acc. rate: 0.28, log(P): -3408.5\n",
      "f_snow: 2.477\n",
      " f_ice: 7.919\n",
      " refreeze: 0.426\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 35600, acc. rate: 0.28, log(P): -3407.7\n",
      "f_snow: 2.268\n",
      " f_ice: 7.896\n",
      " refreeze: 0.630\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 35700, acc. rate: 0.30, log(P): -3407.5\n",
      "f_snow: 2.377\n",
      " f_ice: 7.911\n",
      " refreeze: 0.718\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 35800, acc. rate: 0.30, log(P): -3404.1\n",
      "f_snow: 2.157\n",
      " f_ice: 7.856\n",
      " refreeze: 0.080\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 35900, acc. rate: 0.31, log(P): -3404.6\n",
      "f_snow: 2.405\n",
      " f_ice: 7.918\n",
      " refreeze: 0.246\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 36000, acc. rate: 0.28, log(P): -3405.5\n",
      "f_snow: 2.377\n",
      " f_ice: 7.904\n",
      " refreeze: 0.865\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 36100, acc. rate: 0.29, log(P): -3408.7\n",
      "f_snow: 2.452\n",
      " f_ice: 7.915\n",
      " refreeze: 0.573\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 36200, acc. rate: 0.28, log(P): -3407.9\n",
      "f_snow: 2.308\n",
      " f_ice: 7.899\n",
      " refreeze: 0.359\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 36300, acc. rate: 0.24, log(P): -3406.0\n",
      "f_snow: 2.621\n",
      " f_ice: 7.925\n",
      " refreeze: 0.388\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 36400, acc. rate: 0.28, log(P): -3408.0\n",
      "f_snow: 2.397\n",
      " f_ice: 7.908\n",
      " refreeze: 0.729\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 36500, acc. rate: 0.30, log(P): -3403.7\n",
      "f_snow: 2.100\n",
      " f_ice: 7.789\n",
      " refreeze: 0.399\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 36600, acc. rate: 0.28, log(P): -3408.1\n",
      "f_snow: 2.366\n",
      " f_ice: 7.904\n",
      " refreeze: 0.351\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 36700, acc. rate: 0.27, log(P): -3407.3\n",
      "f_snow: 2.567\n",
      " f_ice: 7.923\n",
      " refreeze: 0.232\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 36800, acc. rate: 0.30, log(P): -3406.9\n",
      "f_snow: 2.339\n",
      " f_ice: 7.901\n",
      " refreeze: 0.727\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 36900, acc. rate: 0.24, log(P): -3407.5\n",
      "f_snow: 2.482\n",
      " f_ice: 7.914\n",
      " refreeze: 0.628\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 37000, acc. rate: 0.26, log(P): -3406.9\n",
      "f_snow: 2.247\n",
      " f_ice: 7.887\n",
      " refreeze: 0.678\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 37100, acc. rate: 0.28, log(P): -3408.5\n",
      "f_snow: 2.408\n",
      " f_ice: 7.912\n",
      " refreeze: 0.604\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 37200, acc. rate: 0.27, log(P): -3406.4\n",
      "f_snow: 2.170\n",
      " f_ice: 7.854\n",
      " refreeze: 0.272\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 37300, acc. rate: 0.27, log(P): -3406.5\n",
      "f_snow: 2.173\n",
      " f_ice: 7.863\n",
      " refreeze: 0.503\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 37400, acc. rate: 0.26, log(P): -3405.2\n",
      "f_snow: 2.162\n",
      " f_ice: 7.861\n",
      " refreeze: 0.860\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 37500, acc. rate: 0.29, log(P): -3403.4\n",
      "f_snow: 2.104\n",
      " f_ice: 7.815\n",
      " refreeze: 0.877\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 37600, acc. rate: 0.29, log(P): -3406.8\n",
      "f_snow: 2.288\n",
      " f_ice: 7.898\n",
      " refreeze: 0.148\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 37700, acc. rate: 0.30, log(P): -3402.6\n",
      "f_snow: 2.092\n",
      " f_ice: 7.820\n",
      " refreeze: 0.822\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 37800, acc. rate: 0.30, log(P): -3406.2\n",
      "f_snow: 2.156\n",
      " f_ice: 7.851\n",
      " refreeze: 0.247\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 37900, acc. rate: 0.32, log(P): -3407.5\n",
      "f_snow: 2.233\n",
      " f_ice: 7.887\n",
      " refreeze: 0.471\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 38000, acc. rate: 0.24, log(P): -3405.8\n",
      "f_snow: 2.276\n",
      " f_ice: 7.906\n",
      " refreeze: 0.735\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 38100, acc. rate: 0.28, log(P): -3408.3\n",
      "f_snow: 2.409\n",
      " f_ice: 7.912\n",
      " refreeze: 0.658\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 38200, acc. rate: 0.25, log(P): -3405.8\n",
      "f_snow: 2.152\n",
      " f_ice: 7.847\n",
      " refreeze: 0.736\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 38300, acc. rate: 0.29, log(P): -3408.6\n",
      "f_snow: 2.386\n",
      " f_ice: 7.908\n",
      " refreeze: 0.511\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 38400, acc. rate: 0.26, log(P): -3407.9\n",
      "f_snow: 2.309\n",
      " f_ice: 7.901\n",
      " refreeze: 0.305\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 38500, acc. rate: 0.23, log(P): -3408.2\n",
      "f_snow: 2.388\n",
      " f_ice: 7.911\n",
      " refreeze: 0.447\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 38600, acc. rate: 0.37, log(P): -3406.5\n",
      "f_snow: 2.169\n",
      " f_ice: 7.859\n",
      " refreeze: 0.294\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 38700, acc. rate: 0.35, log(P): -3408.3\n",
      "f_snow: 2.466\n",
      " f_ice: 7.913\n",
      " refreeze: 0.457\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 38800, acc. rate: 0.19, log(P): -3408.5\n",
      "f_snow: 2.438\n",
      " f_ice: 7.911\n",
      " refreeze: 0.507\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 38900, acc. rate: 0.33, log(P): -3406.7\n",
      "f_snow: 2.502\n",
      " f_ice: 7.913\n",
      " refreeze: 0.337\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 39000, acc. rate: 0.39, log(P): -3406.3\n",
      "f_snow: 2.147\n",
      " f_ice: 7.850\n",
      " refreeze: 0.681\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 39100, acc. rate: 0.35, log(P): -3407.3\n",
      "f_snow: 2.556\n",
      " f_ice: 7.924\n",
      " refreeze: 0.283\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 39200, acc. rate: 0.26, log(P): -3408.2\n",
      "f_snow: 2.334\n",
      " f_ice: 7.904\n",
      " refreeze: 0.607\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 39300, acc. rate: 0.22, log(P): -3407.5\n",
      "f_snow: 2.563\n",
      " f_ice: 7.923\n",
      " refreeze: 0.286\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 39400, acc. rate: 0.26, log(P): -3405.6\n",
      "f_snow: 2.148\n",
      " f_ice: 7.859\n",
      " refreeze: 0.815\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 39500, acc. rate: 0.26, log(P): -3407.8\n",
      "f_snow: 2.298\n",
      " f_ice: 7.902\n",
      " refreeze: 0.389\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 39600, acc. rate: 0.23, log(P): -3408.0\n",
      "f_snow: 2.386\n",
      " f_ice: 7.910\n",
      " refreeze: 0.748\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 39700, acc. rate: 0.34, log(P): -3407.6\n",
      "f_snow: 2.519\n",
      " f_ice: 7.919\n",
      " refreeze: 0.686\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 39800, acc. rate: 0.30, log(P): -3407.4\n",
      "f_snow: 2.543\n",
      " f_ice: 7.924\n",
      " refreeze: 0.377\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 39900, acc. rate: 0.25, log(P): -3402.8\n",
      "f_snow: 2.116\n",
      " f_ice: 7.837\n",
      " refreeze: 0.842\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 40000, acc. rate: 0.31, log(P): -3403.7\n",
      "f_snow: 2.109\n",
      " f_ice: 7.811\n",
      " refreeze: 0.342\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 40100, acc. rate: 0.31, log(P): -3406.4\n",
      "f_snow: 2.599\n",
      " f_ice: 7.923\n",
      " refreeze: 0.207\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 40200, acc. rate: 0.25, log(P): -3407.3\n",
      "f_snow: 2.304\n",
      " f_ice: 7.903\n",
      " refreeze: 0.771\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 40300, acc. rate: 0.23, log(P): -3403.8\n",
      "f_snow: 2.785\n",
      " f_ice: 7.934\n",
      " refreeze: 0.236\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 40400, acc. rate: 0.35, log(P): -3406.4\n",
      "f_snow: 2.171\n",
      " f_ice: 7.855\n",
      " refreeze: 0.532\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 40500, acc. rate: 0.27, log(P): -3406.4\n",
      "f_snow: 2.157\n",
      " f_ice: 7.864\n",
      " refreeze: 0.497\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 40600, acc. rate: 0.26, log(P): -3408.3\n",
      "f_snow: 2.511\n",
      " f_ice: 7.920\n",
      " refreeze: 0.570\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 40700, acc. rate: 0.27, log(P): -3407.7\n",
      "f_snow: 2.375\n",
      " f_ice: 7.907\n",
      " refreeze: 0.196\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 40800, acc. rate: 0.31, log(P): -3408.1\n",
      "f_snow: 2.352\n",
      " f_ice: 7.904\n",
      " refreeze: 0.592\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 40900, acc. rate: 0.28, log(P): -3407.6\n",
      "f_snow: 2.264\n",
      " f_ice: 7.894\n",
      " refreeze: 0.640\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 41000, acc. rate: 0.25, log(P): -3406.8\n",
      "f_snow: 2.485\n",
      " f_ice: 7.922\n",
      " refreeze: 0.297\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 41100, acc. rate: 0.31, log(P): -3408.2\n",
      "f_snow: 2.471\n",
      " f_ice: 7.915\n",
      " refreeze: 0.703\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 41200, acc. rate: 0.29, log(P): -3408.2\n",
      "f_snow: 2.442\n",
      " f_ice: 7.917\n",
      " refreeze: 0.696\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 41300, acc. rate: 0.24, log(P): -3403.4\n",
      "f_snow: 2.144\n",
      " f_ice: 7.830\n",
      " refreeze: 0.609\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 41400, acc. rate: 0.21, log(P): -3406.3\n",
      "f_snow: 2.220\n",
      " f_ice: 7.887\n",
      " refreeze: 0.263\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 41500, acc. rate: 0.29, log(P): -3405.7\n",
      "f_snow: 2.194\n",
      " f_ice: 7.867\n",
      " refreeze: 0.628\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 41600, acc. rate: 0.38, log(P): -3401.8\n",
      "f_snow: 2.103\n",
      " f_ice: 7.815\n",
      " refreeze: 0.952\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 41700, acc. rate: 0.34, log(P): -3403.5\n",
      "f_snow: 2.185\n",
      " f_ice: 7.883\n",
      " refreeze: 0.454\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 41800, acc. rate: 0.29, log(P): -3405.9\n",
      "f_snow: 2.203\n",
      " f_ice: 7.879\n",
      " refreeze: 0.644\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 41900, acc. rate: 0.27, log(P): -3408.6\n",
      "f_snow: 2.394\n",
      " f_ice: 7.909\n",
      " refreeze: 0.574\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 42000, acc. rate: 0.29, log(P): -3408.3\n",
      "f_snow: 2.431\n",
      " f_ice: 7.916\n",
      " refreeze: 0.518\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 42100, acc. rate: 0.27, log(P): -3408.6\n",
      "f_snow: 2.433\n",
      " f_ice: 7.913\n",
      " refreeze: 0.379\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 42200, acc. rate: 0.25, log(P): -3407.2\n",
      "f_snow: 2.235\n",
      " f_ice: 7.887\n",
      " refreeze: 0.652\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 42300, acc. rate: 0.29, log(P): -3405.0\n",
      "f_snow: 2.205\n",
      " f_ice: 7.874\n",
      " refreeze: 0.177\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 42400, acc. rate: 0.35, log(P): -3404.8\n",
      "f_snow: 2.131\n",
      " f_ice: 7.842\n",
      " refreeze: 0.577\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 42500, acc. rate: 0.26, log(P): -3408.0\n",
      "f_snow: 2.501\n",
      " f_ice: 7.916\n",
      " refreeze: 0.329\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 42600, acc. rate: 0.29, log(P): -3408.6\n",
      "f_snow: 2.480\n",
      " f_ice: 7.916\n",
      " refreeze: 0.328\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 42700, acc. rate: 0.23, log(P): -3407.3\n",
      "f_snow: 2.223\n",
      " f_ice: 7.886\n",
      " refreeze: 0.448\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 42800, acc. rate: 0.23, log(P): -3408.1\n",
      "f_snow: 2.418\n",
      " f_ice: 7.911\n",
      " refreeze: 0.246\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 42900, acc. rate: 0.32, log(P): -3408.6\n",
      "f_snow: 2.458\n",
      " f_ice: 7.915\n",
      " refreeze: 0.645\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 43000, acc. rate: 0.29, log(P): -3407.7\n",
      "f_snow: 2.263\n",
      " f_ice: 7.892\n",
      " refreeze: 0.392\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 43100, acc. rate: 0.25, log(P): -3407.1\n",
      "f_snow: 2.540\n",
      " f_ice: 7.918\n",
      " refreeze: 0.443\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 43200, acc. rate: 0.33, log(P): -3404.4\n",
      "f_snow: 2.556\n",
      " f_ice: 7.928\n",
      " refreeze: 0.760\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 43300, acc. rate: 0.21, log(P): -3408.7\n",
      "f_snow: 2.494\n",
      " f_ice: 7.918\n",
      " refreeze: 0.445\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 43400, acc. rate: 0.21, log(P): -3406.1\n",
      "f_snow: 2.230\n",
      " f_ice: 7.885\n",
      " refreeze: 0.134\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 43500, acc. rate: 0.27, log(P): -3406.7\n",
      "f_snow: 2.385\n",
      " f_ice: 7.916\n",
      " refreeze: 0.660\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 43600, acc. rate: 0.28, log(P): -3408.3\n",
      "f_snow: 2.341\n",
      " f_ice: 7.904\n",
      " refreeze: 0.406\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 43700, acc. rate: 0.28, log(P): -3408.7\n",
      "f_snow: 2.484\n",
      " f_ice: 7.917\n",
      " refreeze: 0.423\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 43800, acc. rate: 0.25, log(P): -3406.3\n",
      "f_snow: 2.255\n",
      " f_ice: 7.899\n",
      " refreeze: 0.625\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 43900, acc. rate: 0.33, log(P): -3407.9\n",
      "f_snow: 2.307\n",
      " f_ice: 7.902\n",
      " refreeze: 0.667\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 44000, acc. rate: 0.31, log(P): -3406.0\n",
      "f_snow: 2.496\n",
      " f_ice: 7.912\n",
      " refreeze: 0.590\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 44100, acc. rate: 0.29, log(P): -3408.5\n",
      "f_snow: 2.432\n",
      " f_ice: 7.914\n",
      " refreeze: 0.639\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 44200, acc. rate: 0.25, log(P): -3407.2\n",
      "f_snow: 2.553\n",
      " f_ice: 7.925\n",
      " refreeze: 0.333\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 44300, acc. rate: 0.30, log(P): -3408.3\n",
      "f_snow: 2.485\n",
      " f_ice: 7.915\n",
      " refreeze: 0.523\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 44400, acc. rate: 0.24, log(P): -3408.3\n",
      "f_snow: 2.411\n",
      " f_ice: 7.913\n",
      " refreeze: 0.549\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 44500, acc. rate: 0.25, log(P): -3406.0\n",
      "f_snow: 2.178\n",
      " f_ice: 7.864\n",
      " refreeze: 0.567\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 44600, acc. rate: 0.26, log(P): -3407.7\n",
      "f_snow: 2.255\n",
      " f_ice: 7.892\n",
      " refreeze: 0.574\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 44700, acc. rate: 0.27, log(P): -3407.9\n",
      "f_snow: 2.301\n",
      " f_ice: 7.903\n",
      " refreeze: 0.440\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 44800, acc. rate: 0.23, log(P): -3408.2\n",
      "f_snow: 2.460\n",
      " f_ice: 7.912\n",
      " refreeze: 0.389\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 44900, acc. rate: 0.21, log(P): -3408.0\n",
      "f_snow: 2.274\n",
      " f_ice: 7.897\n",
      " refreeze: 0.413\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 45000, acc. rate: 0.25, log(P): -3407.9\n",
      "f_snow: 2.267\n",
      " f_ice: 7.896\n",
      " refreeze: 0.440\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 45100, acc. rate: 0.30, log(P): -3406.6\n",
      "f_snow: 2.155\n",
      " f_ice: 7.850\n",
      " refreeze: 0.594\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 45200, acc. rate: 0.28, log(P): -3406.6\n",
      "f_snow: 2.153\n",
      " f_ice: 7.858\n",
      " refreeze: 0.507\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 45300, acc. rate: 0.28, log(P): -3408.8\n",
      "f_snow: 2.462\n",
      " f_ice: 7.915\n",
      " refreeze: 0.502\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 45400, acc. rate: 0.25, log(P): -3406.1\n",
      "f_snow: 2.165\n",
      " f_ice: 7.855\n",
      " refreeze: 0.200\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 45500, acc. rate: 0.26, log(P): -3405.6\n",
      "f_snow: 2.326\n",
      " f_ice: 7.910\n",
      " refreeze: 0.772\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 45600, acc. rate: 0.25, log(P): -3403.0\n",
      "f_snow: 2.098\n",
      " f_ice: 7.789\n",
      " refreeze: 0.713\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 45700, acc. rate: 0.27, log(P): -3403.6\n",
      "f_snow: 2.195\n",
      " f_ice: 7.880\n",
      " refreeze: 0.836\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 45800, acc. rate: 0.30, log(P): -3408.5\n",
      "f_snow: 2.453\n",
      " f_ice: 7.913\n",
      " refreeze: 0.617\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 45900, acc. rate: 0.27, log(P): -3405.6\n",
      "f_snow: 2.492\n",
      " f_ice: 7.913\n",
      " refreeze: 0.789\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 46000, acc. rate: 0.29, log(P): -3408.2\n",
      "f_snow: 2.453\n",
      " f_ice: 7.913\n",
      " refreeze: 0.249\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 46100, acc. rate: 0.28, log(P): -3405.0\n",
      "f_snow: 2.573\n",
      " f_ice: 7.929\n",
      " refreeze: 0.450\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 46200, acc. rate: 0.25, log(P): -3406.2\n",
      "f_snow: 2.466\n",
      " f_ice: 7.922\n",
      " refreeze: 0.832\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 46300, acc. rate: 0.22, log(P): -3408.7\n",
      "f_snow: 2.452\n",
      " f_ice: 7.913\n",
      " refreeze: 0.412\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 46400, acc. rate: 0.30, log(P): -3402.2\n",
      "f_snow: 2.075\n",
      " f_ice: 7.774\n",
      " refreeze: 0.379\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 46500, acc. rate: 0.31, log(P): -3405.8\n",
      "f_snow: 2.171\n",
      " f_ice: 7.872\n",
      " refreeze: 0.433\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 46600, acc. rate: 0.30, log(P): -3406.8\n",
      "f_snow: 2.485\n",
      " f_ice: 7.923\n",
      " refreeze: 0.577\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 46700, acc. rate: 0.22, log(P): -3406.6\n",
      "f_snow: 2.235\n",
      " f_ice: 7.892\n",
      " refreeze: 0.291\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 46800, acc. rate: 0.34, log(P): -3404.5\n",
      "f_snow: 2.163\n",
      " f_ice: 7.871\n",
      " refreeze: 0.853\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 46900, acc. rate: 0.31, log(P): -3398.2\n",
      "f_snow: 2.158\n",
      " f_ice: 7.863\n",
      " refreeze: 0.006\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 47000, acc. rate: 0.30, log(P): -3407.1\n",
      "f_snow: 2.241\n",
      " f_ice: 7.886\n",
      " refreeze: 0.599\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 47100, acc. rate: 0.28, log(P): -3407.1\n",
      "f_snow: 2.525\n",
      " f_ice: 7.924\n",
      " refreeze: 0.554\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 47200, acc. rate: 0.28, log(P): -3408.2\n",
      "f_snow: 2.503\n",
      " f_ice: 7.920\n",
      " refreeze: 0.606\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 47300, acc. rate: 0.23, log(P): -3407.6\n",
      "f_snow: 2.449\n",
      " f_ice: 7.910\n",
      " refreeze: 0.364\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 47400, acc. rate: 0.29, log(P): -3407.8\n",
      "f_snow: 2.334\n",
      " f_ice: 7.904\n",
      " refreeze: 0.728\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 47500, acc. rate: 0.31, log(P): -3404.6\n",
      "f_snow: 2.152\n",
      " f_ice: 7.864\n",
      " refreeze: 0.224\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 47600, acc. rate: 0.27, log(P): -3405.8\n",
      "f_snow: 2.164\n",
      " f_ice: 7.852\n",
      " refreeze: 0.752\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 47700, acc. rate: 0.27, log(P): -3405.9\n",
      "f_snow: 2.222\n",
      " f_ice: 7.877\n",
      " refreeze: 0.167\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 47800, acc. rate: 0.25, log(P): -3407.1\n",
      "f_snow: 2.325\n",
      " f_ice: 7.902\n",
      " refreeze: 0.798\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 47900, acc. rate: 0.28, log(P): -3408.0\n",
      "f_snow: 2.531\n",
      " f_ice: 7.922\n",
      " refreeze: 0.320\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 48000, acc. rate: 0.30, log(P): -3407.7\n",
      "f_snow: 2.371\n",
      " f_ice: 7.910\n",
      " refreeze: 0.428\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 48100, acc. rate: 0.29, log(P): -3405.4\n",
      "f_snow: 2.155\n",
      " f_ice: 7.869\n",
      " refreeze: 0.615\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 48200, acc. rate: 0.25, log(P): -3406.5\n",
      "f_snow: 2.164\n",
      " f_ice: 7.854\n",
      " refreeze: 0.626\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 48300, acc. rate: 0.29, log(P): -3400.1\n",
      "f_snow: 2.164\n",
      " f_ice: 7.890\n",
      " refreeze: 0.811\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 48400, acc. rate: 0.36, log(P): -3404.3\n",
      "f_snow: 2.127\n",
      " f_ice: 7.840\n",
      " refreeze: 0.601\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 48500, acc. rate: 0.33, log(P): -3406.5\n",
      "f_snow: 2.153\n",
      " f_ice: 7.848\n",
      " refreeze: 0.589\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 48600, acc. rate: 0.30, log(P): -3406.6\n",
      "f_snow: 2.155\n",
      " f_ice: 7.851\n",
      " refreeze: 0.638\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 48700, acc. rate: 0.27, log(P): -3405.2\n",
      "f_snow: 2.204\n",
      " f_ice: 7.874\n",
      " refreeze: 0.217\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 48800, acc. rate: 0.33, log(P): -3406.3\n",
      "f_snow: 2.169\n",
      " f_ice: 7.864\n",
      " refreeze: 0.652\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 48900, acc. rate: 0.38, log(P): -3407.8\n",
      "f_snow: 2.359\n",
      " f_ice: 7.903\n",
      " refreeze: 0.353\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 49000, acc. rate: 0.27, log(P): -3406.2\n",
      "f_snow: 2.409\n",
      " f_ice: 7.919\n",
      " refreeze: 0.490\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 49100, acc. rate: 0.21, log(P): -3408.0\n",
      "f_snow: 2.507\n",
      " f_ice: 7.917\n",
      " refreeze: 0.647\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 49200, acc. rate: 0.29, log(P): -3407.9\n",
      "f_snow: 2.422\n",
      " f_ice: 7.909\n",
      " refreeze: 0.239\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 49300, acc. rate: 0.27, log(P): -3408.3\n",
      "f_snow: 2.511\n",
      " f_ice: 7.917\n",
      " refreeze: 0.558\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 49400, acc. rate: 0.29, log(P): -3403.4\n",
      "f_snow: 2.197\n",
      " f_ice: 7.852\n",
      " refreeze: 0.490\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 49500, acc. rate: 0.31, log(P): -3408.4\n",
      "f_snow: 2.441\n",
      " f_ice: 7.917\n",
      " refreeze: 0.515\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 49600, acc. rate: 0.27, log(P): -3407.8\n",
      "f_snow: 2.449\n",
      " f_ice: 7.918\n",
      " refreeze: 0.758\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 49700, acc. rate: 0.33, log(P): -3402.0\n",
      "f_snow: 2.116\n",
      " f_ice: 7.829\n",
      " refreeze: 0.935\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 49800, acc. rate: 0.30, log(P): -3406.7\n",
      "f_snow: 2.159\n",
      " f_ice: 7.861\n",
      " refreeze: 0.585\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 49900, acc. rate: 0.36, log(P): -3405.1\n",
      "f_snow: 2.162\n",
      " f_ice: 7.874\n",
      " refreeze: 0.500\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 50000, acc. rate: 0.27, log(P): -3406.5\n",
      "f_snow: 2.252\n",
      " f_ice: 7.886\n",
      " refreeze: 0.604\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 50100, acc. rate: 0.28, log(P): -3407.3\n",
      "f_snow: 2.373\n",
      " f_ice: 7.906\n",
      " refreeze: 0.810\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 50200, acc. rate: 0.19, log(P): -3406.5\n",
      "f_snow: 2.214\n",
      " f_ice: 7.882\n",
      " refreeze: 0.736\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 50300, acc. rate: 0.39, log(P): -3406.1\n",
      "f_snow: 2.173\n",
      " f_ice: 7.869\n",
      " refreeze: 0.377\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 50400, acc. rate: 0.34, log(P): -3407.5\n",
      "f_snow: 2.264\n",
      " f_ice: 7.898\n",
      " refreeze: 0.410\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 50500, acc. rate: 0.30, log(P): -3403.5\n",
      "f_snow: 2.110\n",
      " f_ice: 7.803\n",
      " refreeze: 0.677\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 50600, acc. rate: 0.27, log(P): -3405.2\n",
      "f_snow: 2.145\n",
      " f_ice: 7.862\n",
      " refreeze: 0.425\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 50700, acc. rate: 0.29, log(P): -3407.3\n",
      "f_snow: 2.285\n",
      " f_ice: 7.902\n",
      " refreeze: 0.738\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 50800, acc. rate: 0.23, log(P): -3407.9\n",
      "f_snow: 2.280\n",
      " f_ice: 7.897\n",
      " refreeze: 0.345\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 50900, acc. rate: 0.23, log(P): -3407.1\n",
      "f_snow: 2.268\n",
      " f_ice: 7.891\n",
      " refreeze: 0.338\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 51000, acc. rate: 0.25, log(P): -3406.2\n",
      "f_snow: 2.213\n",
      " f_ice: 7.874\n",
      " refreeze: 0.248\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 51100, acc. rate: 0.29, log(P): -3402.4\n",
      "f_snow: 2.235\n",
      " f_ice: 7.902\n",
      " refreeze: 0.506\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 51200, acc. rate: 0.30, log(P): -3407.1\n",
      "f_snow: 2.385\n",
      " f_ice: 7.912\n",
      " refreeze: 0.322\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 51300, acc. rate: 0.27, log(P): -3406.9\n",
      "f_snow: 2.310\n",
      " f_ice: 7.898\n",
      " refreeze: 0.693\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 51400, acc. rate: 0.27, log(P): -3405.6\n",
      "f_snow: 2.175\n",
      " f_ice: 7.873\n",
      " refreeze: 0.383\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 51500, acc. rate: 0.29, log(P): -3405.0\n",
      "f_snow: 2.182\n",
      " f_ice: 7.853\n",
      " refreeze: 0.397\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 51600, acc. rate: 0.25, log(P): -3407.9\n",
      "f_snow: 2.332\n",
      " f_ice: 7.902\n",
      " refreeze: 0.570\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 51700, acc. rate: 0.28, log(P): -3407.9\n",
      "f_snow: 2.332\n",
      " f_ice: 7.906\n",
      " refreeze: 0.642\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 51800, acc. rate: 0.27, log(P): -3405.3\n",
      "f_snow: 2.393\n",
      " f_ice: 7.916\n",
      " refreeze: 0.253\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 51900, acc. rate: 0.27, log(P): -3408.0\n",
      "f_snow: 2.535\n",
      " f_ice: 7.922\n",
      " refreeze: 0.341\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 52000, acc. rate: 0.23, log(P): -3406.9\n",
      "f_snow: 2.350\n",
      " f_ice: 7.901\n",
      " refreeze: 0.271\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 52100, acc. rate: 0.28, log(P): -3404.4\n",
      "f_snow: 2.212\n",
      " f_ice: 7.874\n",
      " refreeze: 0.086\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 52200, acc. rate: 0.29, log(P): -3406.7\n",
      "f_snow: 2.359\n",
      " f_ice: 7.909\n",
      " refreeze: 0.214\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 52300, acc. rate: 0.26, log(P): -3407.1\n",
      "f_snow: 2.242\n",
      " f_ice: 7.893\n",
      " refreeze: 0.555\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 52400, acc. rate: 0.27, log(P): -3408.0\n",
      "f_snow: 2.386\n",
      " f_ice: 7.909\n",
      " refreeze: 0.264\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 52500, acc. rate: 0.26, log(P): -3407.6\n",
      "f_snow: 2.492\n",
      " f_ice: 7.920\n",
      " refreeze: 0.237\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 52600, acc. rate: 0.25, log(P): -3407.2\n",
      "f_snow: 2.503\n",
      " f_ice: 7.923\n",
      " refreeze: 0.342\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 52700, acc. rate: 0.28, log(P): -3407.7\n",
      "f_snow: 2.265\n",
      " f_ice: 7.896\n",
      " refreeze: 0.330\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 52800, acc. rate: 0.26, log(P): -3408.3\n",
      "f_snow: 2.444\n",
      " f_ice: 7.917\n",
      " refreeze: 0.687\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 52900, acc. rate: 0.24, log(P): -3407.4\n",
      "f_snow: 2.355\n",
      " f_ice: 7.909\n",
      " refreeze: 0.525\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 53000, acc. rate: 0.34, log(P): -3408.3\n",
      "f_snow: 2.431\n",
      " f_ice: 7.916\n",
      " refreeze: 0.671\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 53100, acc. rate: 0.32, log(P): -3404.3\n",
      "f_snow: 2.164\n",
      " f_ice: 7.846\n",
      " refreeze: 0.089\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 53200, acc. rate: 0.28, log(P): -3408.7\n",
      "f_snow: 2.417\n",
      " f_ice: 7.912\n",
      " refreeze: 0.499\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 53300, acc. rate: 0.25, log(P): -3406.6\n",
      "f_snow: 2.161\n",
      " f_ice: 7.853\n",
      " refreeze: 0.323\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 53400, acc. rate: 0.27, log(P): -3407.3\n",
      "f_snow: 2.503\n",
      " f_ice: 7.922\n",
      " refreeze: 0.265\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 53500, acc. rate: 0.26, log(P): -3406.2\n",
      "f_snow: 2.263\n",
      " f_ice: 7.893\n",
      " refreeze: 0.116\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 53600, acc. rate: 0.24, log(P): -3408.4\n",
      "f_snow: 2.431\n",
      " f_ice: 7.914\n",
      " refreeze: 0.687\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 53700, acc. rate: 0.28, log(P): -3405.9\n",
      "f_snow: 2.368\n",
      " f_ice: 7.906\n",
      " refreeze: 0.072\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 53800, acc. rate: 0.33, log(P): -3408.0\n",
      "f_snow: 2.350\n",
      " f_ice: 7.908\n",
      " refreeze: 0.591\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 53900, acc. rate: 0.23, log(P): -3408.3\n",
      "f_snow: 2.462\n",
      " f_ice: 7.913\n",
      " refreeze: 0.562\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 54000, acc. rate: 0.25, log(P): -3406.6\n",
      "f_snow: 2.548\n",
      " f_ice: 7.926\n",
      " refreeze: 0.245\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 54100, acc. rate: 0.30, log(P): -3408.5\n",
      "f_snow: 2.382\n",
      " f_ice: 7.909\n",
      " refreeze: 0.510\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 54200, acc. rate: 0.24, log(P): -3407.7\n",
      "f_snow: 2.457\n",
      " f_ice: 7.919\n",
      " refreeze: 0.734\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 54300, acc. rate: 0.25, log(P): -3408.2\n",
      "f_snow: 2.507\n",
      " f_ice: 7.919\n",
      " refreeze: 0.621\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 54400, acc. rate: 0.27, log(P): -3406.9\n",
      "f_snow: 2.270\n",
      " f_ice: 7.897\n",
      " refreeze: 0.167\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 54500, acc. rate: 0.30, log(P): -3407.5\n",
      "f_snow: 2.242\n",
      " f_ice: 7.888\n",
      " refreeze: 0.405\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 54600, acc. rate: 0.24, log(P): -3404.4\n",
      "f_snow: 2.176\n",
      " f_ice: 7.879\n",
      " refreeze: 0.411\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 54700, acc. rate: 0.29, log(P): -3406.7\n",
      "f_snow: 2.162\n",
      " f_ice: 7.860\n",
      " refreeze: 0.617\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 54800, acc. rate: 0.34, log(P): -3408.4\n",
      "f_snow: 2.432\n",
      " f_ice: 7.915\n",
      " refreeze: 0.657\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 54900, acc. rate: 0.29, log(P): -3408.6\n",
      "f_snow: 2.410\n",
      " f_ice: 7.909\n",
      " refreeze: 0.403\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 55000, acc. rate: 0.23, log(P): -3407.0\n",
      "f_snow: 2.534\n",
      " f_ice: 7.919\n",
      " refreeze: 0.150\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 55100, acc. rate: 0.24, log(P): -3407.6\n",
      "f_snow: 2.333\n",
      " f_ice: 7.907\n",
      " refreeze: 0.453\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 55200, acc. rate: 0.27, log(P): -3406.9\n",
      "f_snow: 2.352\n",
      " f_ice: 7.910\n",
      " refreeze: 0.722\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 55300, acc. rate: 0.23, log(P): -3408.2\n",
      "f_snow: 2.339\n",
      " f_ice: 7.904\n",
      " refreeze: 0.601\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 55400, acc. rate: 0.31, log(P): -3407.8\n",
      "f_snow: 2.356\n",
      " f_ice: 7.903\n",
      " refreeze: 0.283\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 55500, acc. rate: 0.28, log(P): -3407.1\n",
      "f_snow: 2.382\n",
      " f_ice: 7.913\n",
      " refreeze: 0.473\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 55600, acc. rate: 0.22, log(P): -3408.1\n",
      "f_snow: 2.313\n",
      " f_ice: 7.902\n",
      " refreeze: 0.599\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 55700, acc. rate: 0.27, log(P): -3407.5\n",
      "f_snow: 2.262\n",
      " f_ice: 7.891\n",
      " refreeze: 0.443\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 55800, acc. rate: 0.26, log(P): -3406.2\n",
      "f_snow: 2.543\n",
      " f_ice: 7.920\n",
      " refreeze: 0.078\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 55900, acc. rate: 0.31, log(P): -3406.7\n",
      "f_snow: 2.426\n",
      " f_ice: 7.912\n",
      " refreeze: 0.893\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 56000, acc. rate: 0.28, log(P): -3408.3\n",
      "f_snow: 2.409\n",
      " f_ice: 7.911\n",
      " refreeze: 0.699\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 56100, acc. rate: 0.26, log(P): -3407.2\n",
      "f_snow: 2.443\n",
      " f_ice: 7.909\n",
      " refreeze: 0.283\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 56200, acc. rate: 0.25, log(P): -3405.3\n",
      "f_snow: 2.161\n",
      " f_ice: 7.872\n",
      " refreeze: 0.702\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 56300, acc. rate: 0.27, log(P): -3407.9\n",
      "f_snow: 2.282\n",
      " f_ice: 7.900\n",
      " refreeze: 0.602\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 56400, acc. rate: 0.19, log(P): -3408.0\n",
      "f_snow: 2.540\n",
      " f_ice: 7.922\n",
      " refreeze: 0.334\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 56500, acc. rate: 0.31, log(P): -3408.6\n",
      "f_snow: 2.419\n",
      " f_ice: 7.912\n",
      " refreeze: 0.587\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 56600, acc. rate: 0.26, log(P): -3407.7\n",
      "f_snow: 2.532\n",
      " f_ice: 7.920\n",
      " refreeze: 0.184\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 56700, acc. rate: 0.25, log(P): -3408.2\n",
      "f_snow: 2.509\n",
      " f_ice: 7.917\n",
      " refreeze: 0.374\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 56800, acc. rate: 0.27, log(P): -3405.0\n",
      "f_snow: 2.165\n",
      " f_ice: 7.851\n",
      " refreeze: 0.107\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 56900, acc. rate: 0.23, log(P): -3407.0\n",
      "f_snow: 2.514\n",
      " f_ice: 7.917\n",
      " refreeze: 0.767\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 57000, acc. rate: 0.26, log(P): -3407.9\n",
      "f_snow: 2.542\n",
      " f_ice: 7.920\n",
      " refreeze: 0.514\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 57100, acc. rate: 0.25, log(P): -3408.6\n",
      "f_snow: 2.436\n",
      " f_ice: 7.912\n",
      " refreeze: 0.524\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 57200, acc. rate: 0.27, log(P): -3406.6\n",
      "f_snow: 2.509\n",
      " f_ice: 7.925\n",
      " refreeze: 0.506\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 57300, acc. rate: 0.22, log(P): -3408.6\n",
      "f_snow: 2.468\n",
      " f_ice: 7.917\n",
      " refreeze: 0.616\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 57400, acc. rate: 0.29, log(P): -3406.3\n",
      "f_snow: 2.223\n",
      " f_ice: 7.889\n",
      " refreeze: 0.721\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 57500, acc. rate: 0.27, log(P): -3406.6\n",
      "f_snow: 2.456\n",
      " f_ice: 7.920\n",
      " refreeze: 0.263\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 57600, acc. rate: 0.27, log(P): -3407.1\n",
      "f_snow: 2.230\n",
      " f_ice: 7.885\n",
      " refreeze: 0.300\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 57700, acc. rate: 0.23, log(P): -3406.5\n",
      "f_snow: 2.207\n",
      " f_ice: 7.872\n",
      " refreeze: 0.449\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 57800, acc. rate: 0.31, log(P): -3406.2\n",
      "f_snow: 2.159\n",
      " f_ice: 7.846\n",
      " refreeze: 0.343\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 57900, acc. rate: 0.27, log(P): -3406.4\n",
      "f_snow: 2.167\n",
      " f_ice: 7.852\n",
      " refreeze: 0.510\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 58000, acc. rate: 0.26, log(P): -3405.3\n",
      "f_snow: 2.409\n",
      " f_ice: 7.916\n",
      " refreeze: 0.940\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 58100, acc. rate: 0.25, log(P): -3407.5\n",
      "f_snow: 2.260\n",
      " f_ice: 7.891\n",
      " refreeze: 0.542\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 58200, acc. rate: 0.25, log(P): -3402.9\n",
      "f_snow: 2.718\n",
      " f_ice: 7.934\n",
      " refreeze: 0.236\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 58300, acc. rate: 0.09, log(P): -3402.9\n",
      "f_snow: 2.718\n",
      " f_ice: 7.934\n",
      " refreeze: 0.236\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 58400, acc. rate: 0.32, log(P): -3403.3\n",
      "f_snow: 2.184\n",
      " f_ice: 7.869\n",
      " refreeze: 0.063\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 58500, acc. rate: 0.48, log(P): -3406.7\n",
      "f_snow: 2.153\n",
      " f_ice: 7.852\n",
      " refreeze: 0.553\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 58600, acc. rate: 0.38, log(P): -3406.2\n",
      "f_snow: 2.157\n",
      " f_ice: 7.847\n",
      " refreeze: 0.297\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 58700, acc. rate: 0.35, log(P): -3407.8\n",
      "f_snow: 2.290\n",
      " f_ice: 7.898\n",
      " refreeze: 0.484\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 58800, acc. rate: 0.30, log(P): -3406.4\n",
      "f_snow: 2.336\n",
      " f_ice: 7.910\n",
      " refreeze: 0.706\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 58900, acc. rate: 0.27, log(P): -3406.2\n",
      "f_snow: 2.341\n",
      " f_ice: 7.911\n",
      " refreeze: 0.752\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 59000, acc. rate: 0.24, log(P): -3406.7\n",
      "f_snow: 2.313\n",
      " f_ice: 7.897\n",
      " refreeze: 0.452\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 59100, acc. rate: 0.26, log(P): -3407.9\n",
      "f_snow: 2.496\n",
      " f_ice: 7.917\n",
      " refreeze: 0.193\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 59200, acc. rate: 0.23, log(P): -3408.6\n",
      "f_snow: 2.417\n",
      " f_ice: 7.912\n",
      " refreeze: 0.597\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 59300, acc. rate: 0.29, log(P): -3407.3\n",
      "f_snow: 2.572\n",
      " f_ice: 7.921\n",
      " refreeze: 0.321\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 59400, acc. rate: 0.25, log(P): -3408.3\n",
      "f_snow: 2.475\n",
      " f_ice: 7.919\n",
      " refreeze: 0.367\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 59500, acc. rate: 0.21, log(P): -3408.6\n",
      "f_snow: 2.464\n",
      " f_ice: 7.914\n",
      " refreeze: 0.610\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 59600, acc. rate: 0.30, log(P): -3407.1\n",
      "f_snow: 2.494\n",
      " f_ice: 7.913\n",
      " refreeze: 0.365\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 59700, acc. rate: 0.23, log(P): -3407.8\n",
      "f_snow: 2.531\n",
      " f_ice: 7.921\n",
      " refreeze: 0.219\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 59800, acc. rate: 0.34, log(P): -3403.0\n",
      "f_snow: 2.128\n",
      " f_ice: 7.861\n",
      " refreeze: 0.758\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 59900, acc. rate: 0.29, log(P): -3404.5\n",
      "f_snow: 2.158\n",
      " f_ice: 7.864\n",
      " refreeze: 0.137\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 60000, acc. rate: 0.35, log(P): -3403.3\n",
      "f_snow: 2.090\n",
      " f_ice: 7.790\n",
      " refreeze: 0.731\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 60100, acc. rate: 0.34, log(P): -3406.5\n",
      "f_snow: 2.165\n",
      " f_ice: 7.850\n",
      " refreeze: 0.388\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 60200, acc. rate: 0.28, log(P): -3407.3\n",
      "f_snow: 2.566\n",
      " f_ice: 7.922\n",
      " refreeze: 0.471\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 60300, acc. rate: 0.30, log(P): -3407.3\n",
      "f_snow: 2.553\n",
      " f_ice: 7.924\n",
      " refreeze: 0.260\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 60400, acc. rate: 0.26, log(P): -3407.0\n",
      "f_snow: 2.387\n",
      " f_ice: 7.905\n",
      " refreeze: 0.706\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 60500, acc. rate: 0.29, log(P): -3407.8\n",
      "f_snow: 2.278\n",
      " f_ice: 7.897\n",
      " refreeze: 0.620\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 60600, acc. rate: 0.25, log(P): -3406.4\n",
      "f_snow: 2.253\n",
      " f_ice: 7.897\n",
      " refreeze: 0.278\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 60700, acc. rate: 0.31, log(P): -3408.4\n",
      "f_snow: 2.503\n",
      " f_ice: 7.919\n",
      " refreeze: 0.329\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 60800, acc. rate: 0.29, log(P): -3405.0\n",
      "f_snow: 2.142\n",
      " f_ice: 7.860\n",
      " refreeze: 0.388\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 60900, acc. rate: 0.28, log(P): -3408.5\n",
      "f_snow: 2.375\n",
      " f_ice: 7.907\n",
      " refreeze: 0.478\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 61000, acc. rate: 0.22, log(P): -3407.4\n",
      "f_snow: 2.376\n",
      " f_ice: 7.911\n",
      " refreeze: 0.466\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 61100, acc. rate: 0.25, log(P): -3408.6\n",
      "f_snow: 2.428\n",
      " f_ice: 7.914\n",
      " refreeze: 0.626\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 61200, acc. rate: 0.25, log(P): -3406.6\n",
      "f_snow: 2.340\n",
      " f_ice: 7.907\n",
      " refreeze: 0.851\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 61300, acc. rate: 0.25, log(P): -3408.6\n",
      "f_snow: 2.497\n",
      " f_ice: 7.917\n",
      " refreeze: 0.369\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 61400, acc. rate: 0.28, log(P): -3406.0\n",
      "f_snow: 2.604\n",
      " f_ice: 7.927\n",
      " refreeze: 0.246\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 61500, acc. rate: 0.27, log(P): -3407.5\n",
      "f_snow: 2.564\n",
      " f_ice: 7.921\n",
      " refreeze: 0.350\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 61600, acc. rate: 0.26, log(P): -3405.8\n",
      "f_snow: 2.393\n",
      " f_ice: 7.918\n",
      " refreeze: 0.553\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 61700, acc. rate: 0.23, log(P): -3407.5\n",
      "f_snow: 2.426\n",
      " f_ice: 7.914\n",
      " refreeze: 0.239\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 61800, acc. rate: 0.24, log(P): -3407.7\n",
      "f_snow: 2.341\n",
      " f_ice: 7.907\n",
      " refreeze: 0.441\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 61900, acc. rate: 0.30, log(P): -3407.3\n",
      "f_snow: 2.528\n",
      " f_ice: 7.917\n",
      " refreeze: 0.240\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 62000, acc. rate: 0.29, log(P): -3408.2\n",
      "f_snow: 2.419\n",
      " f_ice: 7.913\n",
      " refreeze: 0.734\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 62100, acc. rate: 0.29, log(P): -3403.2\n",
      "f_snow: 2.367\n",
      " f_ice: 7.913\n",
      " refreeze: 0.110\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 62200, acc. rate: 0.19, log(P): -3407.7\n",
      "f_snow: 2.268\n",
      " f_ice: 7.897\n",
      " refreeze: 0.593\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 62300, acc. rate: 0.29, log(P): -3408.1\n",
      "f_snow: 2.499\n",
      " f_ice: 7.921\n",
      " refreeze: 0.619\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 62400, acc. rate: 0.33, log(P): -3404.7\n",
      "f_snow: 2.508\n",
      " f_ice: 7.920\n",
      " refreeze: 0.038\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 62500, acc. rate: 0.25, log(P): -3406.2\n",
      "f_snow: 2.535\n",
      " f_ice: 7.927\n",
      " refreeze: 0.384\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 62600, acc. rate: 0.25, log(P): -3406.2\n",
      "f_snow: 2.254\n",
      " f_ice: 7.898\n",
      " refreeze: 0.253\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 62700, acc. rate: 0.26, log(P): -3406.5\n",
      "f_snow: 2.236\n",
      " f_ice: 7.888\n",
      " refreeze: 0.159\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 62800, acc. rate: 0.34, log(P): -3407.2\n",
      "f_snow: 2.382\n",
      " f_ice: 7.913\n",
      " refreeze: 0.797\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 62900, acc. rate: 0.23, log(P): -3407.6\n",
      "f_snow: 2.269\n",
      " f_ice: 7.899\n",
      " refreeze: 0.438\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 63000, acc. rate: 0.33, log(P): -3406.4\n",
      "f_snow: 2.173\n",
      " f_ice: 7.863\n",
      " refreeze: 0.575\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 63100, acc. rate: 0.31, log(P): -3408.3\n",
      "f_snow: 2.522\n",
      " f_ice: 7.920\n",
      " refreeze: 0.304\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 63200, acc. rate: 0.26, log(P): -3403.1\n",
      "f_snow: 2.107\n",
      " f_ice: 7.833\n",
      " refreeze: 0.678\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 63300, acc. rate: 0.29, log(P): -3404.5\n",
      "f_snow: 2.143\n",
      " f_ice: 7.837\n",
      " refreeze: 0.730\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 63400, acc. rate: 0.34, log(P): -3404.5\n",
      "f_snow: 2.094\n",
      " f_ice: 7.808\n",
      " refreeze: 0.522\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 63500, acc. rate: 0.35, log(P): -3403.1\n",
      "f_snow: 2.089\n",
      " f_ice: 7.799\n",
      " refreeze: 0.808\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 63600, acc. rate: 0.27, log(P): -3407.8\n",
      "f_snow: 2.261\n",
      " f_ice: 7.893\n",
      " refreeze: 0.411\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 63700, acc. rate: 0.26, log(P): -3406.5\n",
      "f_snow: 2.345\n",
      " f_ice: 7.909\n",
      " refreeze: 0.814\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 63800, acc. rate: 0.28, log(P): -3406.1\n",
      "f_snow: 2.230\n",
      " f_ice: 7.892\n",
      " refreeze: 0.692\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 63900, acc. rate: 0.27, log(P): -3405.8\n",
      "f_snow: 2.243\n",
      " f_ice: 7.897\n",
      " refreeze: 0.389\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 64000, acc. rate: 0.25, log(P): -3407.4\n",
      "f_snow: 2.265\n",
      " f_ice: 7.896\n",
      " refreeze: 0.256\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 64100, acc. rate: 0.33, log(P): -3408.8\n",
      "f_snow: 2.442\n",
      " f_ice: 7.914\n",
      " refreeze: 0.463\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 64200, acc. rate: 0.22, log(P): -3407.0\n",
      "f_snow: 2.256\n",
      " f_ice: 7.894\n",
      " refreeze: 0.205\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 64300, acc. rate: 0.32, log(P): -3406.3\n",
      "f_snow: 2.166\n",
      " f_ice: 7.851\n",
      " refreeze: 0.270\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 64400, acc. rate: 0.29, log(P): -3406.5\n",
      "f_snow: 2.384\n",
      " f_ice: 7.908\n",
      " refreeze: 0.892\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 64500, acc. rate: 0.27, log(P): -3406.2\n",
      "f_snow: 2.292\n",
      " f_ice: 7.895\n",
      " refreeze: 0.701\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 64600, acc. rate: 0.26, log(P): -3404.6\n",
      "f_snow: 2.157\n",
      " f_ice: 7.854\n",
      " refreeze: 0.896\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 64700, acc. rate: 0.28, log(P): -3406.8\n",
      "f_snow: 2.164\n",
      " f_ice: 7.862\n",
      " refreeze: 0.499\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 64800, acc. rate: 0.29, log(P): -3400.8\n",
      "f_snow: 2.095\n",
      " f_ice: 7.821\n",
      " refreeze: 0.196\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 64900, acc. rate: 0.33, log(P): -3407.2\n",
      "f_snow: 2.464\n",
      " f_ice: 7.914\n",
      " refreeze: 0.812\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 65000, acc. rate: 0.31, log(P): -3407.7\n",
      "f_snow: 2.274\n",
      " f_ice: 7.900\n",
      " refreeze: 0.585\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 65100, acc. rate: 0.29, log(P): -3408.6\n",
      "f_snow: 2.403\n",
      " f_ice: 7.911\n",
      " refreeze: 0.495\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 65200, acc. rate: 0.26, log(P): -3408.7\n",
      "f_snow: 2.452\n",
      " f_ice: 7.913\n",
      " refreeze: 0.429\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 65300, acc. rate: 0.30, log(P): -3407.8\n",
      "f_snow: 2.521\n",
      " f_ice: 7.922\n",
      " refreeze: 0.372\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 65400, acc. rate: 0.24, log(P): -3407.7\n",
      "f_snow: 2.406\n",
      " f_ice: 7.908\n",
      " refreeze: 0.697\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 65500, acc. rate: 0.25, log(P): -3406.8\n",
      "f_snow: 2.461\n",
      " f_ice: 7.911\n",
      " refreeze: 0.699\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 65600, acc. rate: 0.25, log(P): -3407.3\n",
      "f_snow: 2.381\n",
      " f_ice: 7.906\n",
      " refreeze: 0.166\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 65700, acc. rate: 0.29, log(P): -3406.2\n",
      "f_snow: 2.478\n",
      " f_ice: 7.911\n",
      " refreeze: 0.289\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 65800, acc. rate: 0.25, log(P): -3406.6\n",
      "f_snow: 2.509\n",
      " f_ice: 7.915\n",
      " refreeze: 0.205\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 65900, acc. rate: 0.20, log(P): -3407.5\n",
      "f_snow: 2.467\n",
      " f_ice: 7.912\n",
      " refreeze: 0.301\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 66000, acc. rate: 0.38, log(P): -3404.8\n",
      "f_snow: 2.368\n",
      " f_ice: 7.909\n",
      " refreeze: 0.955\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 66100, acc. rate: 0.34, log(P): -3407.4\n",
      "f_snow: 2.386\n",
      " f_ice: 7.912\n",
      " refreeze: 0.394\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 66200, acc. rate: 0.25, log(P): -3407.5\n",
      "f_snow: 2.270\n",
      " f_ice: 7.898\n",
      " refreeze: 0.275\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 66300, acc. rate: 0.27, log(P): -3407.3\n",
      "f_snow: 2.531\n",
      " f_ice: 7.923\n",
      " refreeze: 0.613\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 66400, acc. rate: 0.24, log(P): -3408.0\n",
      "f_snow: 2.330\n",
      " f_ice: 7.905\n",
      " refreeze: 0.619\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 66500, acc. rate: 0.25, log(P): -3406.8\n",
      "f_snow: 2.159\n",
      " f_ice: 7.855\n",
      " refreeze: 0.591\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 66600, acc. rate: 0.27, log(P): -3407.9\n",
      "f_snow: 2.355\n",
      " f_ice: 7.905\n",
      " refreeze: 0.706\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 66700, acc. rate: 0.26, log(P): -3404.2\n",
      "f_snow: 2.595\n",
      " f_ice: 7.930\n",
      " refreeze: 0.162\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 66800, acc. rate: 0.27, log(P): -3406.2\n",
      "f_snow: 2.494\n",
      " f_ice: 7.924\n",
      " refreeze: 0.229\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 66900, acc. rate: 0.30, log(P): -3403.2\n",
      "f_snow: 2.198\n",
      " f_ice: 7.882\n",
      " refreeze: 0.379\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 67000, acc. rate: 0.29, log(P): -3404.6\n",
      "f_snow: 2.153\n",
      " f_ice: 7.872\n",
      " refreeze: 0.487\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 67100, acc. rate: 0.23, log(P): -3406.7\n",
      "f_snow: 2.152\n",
      " f_ice: 7.856\n",
      " refreeze: 0.566\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 67200, acc. rate: 0.28, log(P): -3406.0\n",
      "f_snow: 2.145\n",
      " f_ice: 7.846\n",
      " refreeze: 0.686\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 67300, acc. rate: 0.33, log(P): -3405.3\n",
      "f_snow: 2.248\n",
      " f_ice: 7.897\n",
      " refreeze: 0.798\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 67400, acc. rate: 0.30, log(P): -3408.1\n",
      "f_snow: 2.396\n",
      " f_ice: 7.907\n",
      " refreeze: 0.561\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 67500, acc. rate: 0.26, log(P): -3406.3\n",
      "f_snow: 2.209\n",
      " f_ice: 7.875\n",
      " refreeze: 0.304\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 67600, acc. rate: 0.24, log(P): -3407.5\n",
      "f_snow: 2.257\n",
      " f_ice: 7.893\n",
      " refreeze: 0.663\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 67700, acc. rate: 0.25, log(P): -3405.5\n",
      "f_snow: 2.181\n",
      " f_ice: 7.871\n",
      " refreeze: 0.511\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 67800, acc. rate: 0.30, log(P): -3405.8\n",
      "f_snow: 2.477\n",
      " f_ice: 7.914\n",
      " refreeze: 0.063\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 67900, acc. rate: 0.32, log(P): -3408.0\n",
      "f_snow: 2.307\n",
      " f_ice: 7.900\n",
      " refreeze: 0.398\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 68000, acc. rate: 0.27, log(P): -3407.6\n",
      "f_snow: 2.329\n",
      " f_ice: 7.906\n",
      " refreeze: 0.465\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 68100, acc. rate: 0.29, log(P): -3407.0\n",
      "f_snow: 2.244\n",
      " f_ice: 7.886\n",
      " refreeze: 0.515\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 68200, acc. rate: 0.25, log(P): -3407.7\n",
      "f_snow: 2.379\n",
      " f_ice: 7.908\n",
      " refreeze: 0.778\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 68300, acc. rate: 0.26, log(P): -3406.1\n",
      "f_snow: 2.566\n",
      " f_ice: 7.919\n",
      " refreeze: 0.548\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 68400, acc. rate: 0.18, log(P): -3397.9\n",
      "f_snow: 2.831\n",
      " f_ice: 7.935\n",
      " refreeze: 0.017\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 68500, acc. rate: 0.29, log(P): -3406.4\n",
      "f_snow: 2.458\n",
      " f_ice: 7.915\n",
      " refreeze: 0.086\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 68600, acc. rate: 0.24, log(P): -3408.0\n",
      "f_snow: 2.454\n",
      " f_ice: 7.911\n",
      " refreeze: 0.435\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 68700, acc. rate: 0.23, log(P): -3408.4\n",
      "f_snow: 2.426\n",
      " f_ice: 7.910\n",
      " refreeze: 0.470\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 68800, acc. rate: 0.31, log(P): -3407.2\n",
      "f_snow: 2.273\n",
      " f_ice: 7.898\n",
      " refreeze: 0.754\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 68900, acc. rate: 0.30, log(P): -3407.3\n",
      "f_snow: 2.529\n",
      " f_ice: 7.924\n",
      " refreeze: 0.424\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 69000, acc. rate: 0.30, log(P): -3407.9\n",
      "f_snow: 2.357\n",
      " f_ice: 7.908\n",
      " refreeze: 0.504\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 69100, acc. rate: 0.34, log(P): -3407.6\n",
      "f_snow: 2.539\n",
      " f_ice: 7.922\n",
      " refreeze: 0.590\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 69200, acc. rate: 0.25, log(P): -3408.4\n",
      "f_snow: 2.463\n",
      " f_ice: 7.914\n",
      " refreeze: 0.679\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 69300, acc. rate: 0.21, log(P): -3406.5\n",
      "f_snow: 2.214\n",
      " f_ice: 7.882\n",
      " refreeze: 0.337\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 69400, acc. rate: 0.30, log(P): -3403.4\n",
      "f_snow: 2.118\n",
      " f_ice: 7.820\n",
      " refreeze: 0.511\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 69500, acc. rate: 0.31, log(P): -3406.6\n",
      "f_snow: 2.214\n",
      " f_ice: 7.885\n",
      " refreeze: 0.490\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 69600, acc. rate: 0.31, log(P): -3401.5\n",
      "f_snow: 2.425\n",
      " f_ice: 7.924\n",
      " refreeze: 0.917\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 69700, acc. rate: 0.28, log(P): -3408.0\n",
      "f_snow: 2.277\n",
      " f_ice: 7.899\n",
      " refreeze: 0.461\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 69800, acc. rate: 0.23, log(P): -3408.0\n",
      "f_snow: 2.359\n",
      " f_ice: 7.908\n",
      " refreeze: 0.663\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 69900, acc. rate: 0.32, log(P): -3402.4\n",
      "f_snow: 2.322\n",
      " f_ice: 7.907\n",
      " refreeze: 0.981\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 70000, acc. rate: 0.28, log(P): -3404.6\n",
      "f_snow: 2.093\n",
      " f_ice: 7.802\n",
      " refreeze: 0.527\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 70100, acc. rate: 0.27, log(P): -3405.9\n",
      "f_snow: 2.161\n",
      " f_ice: 7.849\n",
      " refreeze: 0.211\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 70200, acc. rate: 0.32, log(P): -3408.7\n",
      "f_snow: 2.423\n",
      " f_ice: 7.912\n",
      " refreeze: 0.552\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 70300, acc. rate: 0.24, log(P): -3407.0\n",
      "f_snow: 2.561\n",
      " f_ice: 7.925\n",
      " refreeze: 0.306\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 70400, acc. rate: 0.23, log(P): -3405.7\n",
      "f_snow: 2.172\n",
      " f_ice: 7.866\n",
      " refreeze: 0.206\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 70500, acc. rate: 0.33, log(P): -3405.1\n",
      "f_snow: 2.156\n",
      " f_ice: 7.862\n",
      " refreeze: 0.870\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 70600, acc. rate: 0.32, log(P): -3406.6\n",
      "f_snow: 2.169\n",
      " f_ice: 7.865\n",
      " refreeze: 0.504\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 70700, acc. rate: 0.35, log(P): -3408.6\n",
      "f_snow: 2.397\n",
      " f_ice: 7.909\n",
      " refreeze: 0.569\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 70800, acc. rate: 0.24, log(P): -3404.7\n",
      "f_snow: 2.622\n",
      " f_ice: 7.929\n",
      " refreeze: 0.127\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 70900, acc. rate: 0.24, log(P): -3407.8\n",
      "f_snow: 2.554\n",
      " f_ice: 7.920\n",
      " refreeze: 0.373\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 71000, acc. rate: 0.30, log(P): -3408.4\n",
      "f_snow: 2.435\n",
      " f_ice: 7.911\n",
      " refreeze: 0.581\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 71100, acc. rate: 0.30, log(P): -3407.0\n",
      "f_snow: 2.359\n",
      " f_ice: 7.902\n",
      " refreeze: 0.575\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 71200, acc. rate: 0.32, log(P): -3408.0\n",
      "f_snow: 2.447\n",
      " f_ice: 7.915\n",
      " refreeze: 0.776\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 71300, acc. rate: 0.28, log(P): -3407.4\n",
      "f_snow: 2.543\n",
      " f_ice: 7.919\n",
      " refreeze: 0.541\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 71400, acc. rate: 0.24, log(P): -3406.4\n",
      "f_snow: 2.493\n",
      " f_ice: 7.923\n",
      " refreeze: 0.748\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 71500, acc. rate: 0.30, log(P): -3406.8\n",
      "f_snow: 2.511\n",
      " f_ice: 7.921\n",
      " refreeze: 0.797\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 71600, acc. rate: 0.34, log(P): -3403.4\n",
      "f_snow: 2.707\n",
      " f_ice: 7.930\n",
      " refreeze: 0.068\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 71700, acc. rate: 0.32, log(P): -3406.1\n",
      "f_snow: 2.467\n",
      " f_ice: 7.915\n",
      " refreeze: 0.908\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 71800, acc. rate: 0.33, log(P): -3403.5\n",
      "f_snow: 2.093\n",
      " f_ice: 7.786\n",
      " refreeze: 0.250\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 71900, acc. rate: 0.28, log(P): -3406.6\n",
      "f_snow: 2.167\n",
      " f_ice: 7.856\n",
      " refreeze: 0.299\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 72000, acc. rate: 0.25, log(P): -3403.4\n",
      "f_snow: 2.683\n",
      " f_ice: 7.932\n",
      " refreeze: 0.155\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 72100, acc. rate: 0.28, log(P): -3407.8\n",
      "f_snow: 2.539\n",
      " f_ice: 7.922\n",
      " refreeze: 0.511\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 72200, acc. rate: 0.27, log(P): -3407.6\n",
      "f_snow: 2.343\n",
      " f_ice: 7.905\n",
      " refreeze: 0.224\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 72300, acc. rate: 0.31, log(P): -3406.7\n",
      "f_snow: 2.534\n",
      " f_ice: 7.923\n",
      " refreeze: 0.150\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 72400, acc. rate: 0.23, log(P): -3407.7\n",
      "f_snow: 2.380\n",
      " f_ice: 7.904\n",
      " refreeze: 0.453\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 72500, acc. rate: 0.26, log(P): -3406.0\n",
      "f_snow: 2.319\n",
      " f_ice: 7.899\n",
      " refreeze: 0.802\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 72600, acc. rate: 0.26, log(P): -3408.4\n",
      "f_snow: 2.454\n",
      " f_ice: 7.913\n",
      " refreeze: 0.586\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 72700, acc. rate: 0.23, log(P): -3405.6\n",
      "f_snow: 2.142\n",
      " f_ice: 7.851\n",
      " refreeze: 0.373\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 72800, acc. rate: 0.31, log(P): -3404.8\n",
      "f_snow: 2.233\n",
      " f_ice: 7.889\n",
      " refreeze: 0.065\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 72900, acc. rate: 0.26, log(P): -3405.4\n",
      "f_snow: 2.222\n",
      " f_ice: 7.892\n",
      " refreeze: 0.381\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 73000, acc. rate: 0.25, log(P): -3407.8\n",
      "f_snow: 2.303\n",
      " f_ice: 7.903\n",
      " refreeze: 0.652\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 73100, acc. rate: 0.26, log(P): -3406.1\n",
      "f_snow: 2.362\n",
      " f_ice: 7.902\n",
      " refreeze: 0.704\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 73200, acc. rate: 0.29, log(P): -3407.2\n",
      "f_snow: 2.523\n",
      " f_ice: 7.919\n",
      " refreeze: 0.731\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 73300, acc. rate: 0.22, log(P): -3406.1\n",
      "f_snow: 2.263\n",
      " f_ice: 7.890\n",
      " refreeze: 0.175\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 73400, acc. rate: 0.29, log(P): -3406.3\n",
      "f_snow: 2.177\n",
      " f_ice: 7.860\n",
      " refreeze: 0.333\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 73500, acc. rate: 0.26, log(P): -3408.3\n",
      "f_snow: 2.403\n",
      " f_ice: 7.909\n",
      " refreeze: 0.322\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 73600, acc. rate: 0.26, log(P): -3406.3\n",
      "f_snow: 2.164\n",
      " f_ice: 7.863\n",
      " refreeze: 0.705\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 73700, acc. rate: 0.26, log(P): -3407.3\n",
      "f_snow: 2.225\n",
      " f_ice: 7.884\n",
      " refreeze: 0.565\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 73800, acc. rate: 0.28, log(P): -3402.0\n",
      "f_snow: 2.142\n",
      " f_ice: 7.862\n",
      " refreeze: 0.120\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 73900, acc. rate: 0.31, log(P): -3404.9\n",
      "f_snow: 2.136\n",
      " f_ice: 7.844\n",
      " refreeze: 0.800\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 74000, acc. rate: 0.27, log(P): -3406.9\n",
      "f_snow: 2.349\n",
      " f_ice: 7.905\n",
      " refreeze: 0.850\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 74100, acc. rate: 0.24, log(P): -3407.6\n",
      "f_snow: 2.374\n",
      " f_ice: 7.911\n",
      " refreeze: 0.680\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 74200, acc. rate: 0.29, log(P): -3404.5\n",
      "f_snow: 2.421\n",
      " f_ice: 7.918\n",
      " refreeze: 0.147\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 74300, acc. rate: 0.26, log(P): -3408.7\n",
      "f_snow: 2.436\n",
      " f_ice: 7.912\n",
      " refreeze: 0.491\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 74400, acc. rate: 0.37, log(P): -3403.8\n",
      "f_snow: 2.561\n",
      " f_ice: 7.926\n",
      " refreeze: 0.048\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 74500, acc. rate: 0.31, log(P): -3406.3\n",
      "f_snow: 2.275\n",
      " f_ice: 7.902\n",
      " refreeze: 0.277\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 74600, acc. rate: 0.29, log(P): -3402.7\n",
      "f_snow: 2.079\n",
      " f_ice: 7.798\n",
      " refreeze: 0.669\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 74700, acc. rate: 0.28, log(P): -3408.2\n",
      "f_snow: 2.470\n",
      " f_ice: 7.920\n",
      " refreeze: 0.563\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 74800, acc. rate: 0.30, log(P): -3406.7\n",
      "f_snow: 2.240\n",
      " f_ice: 7.884\n",
      " refreeze: 0.469\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 74900, acc. rate: 0.30, log(P): -3407.8\n",
      "f_snow: 2.294\n",
      " f_ice: 7.898\n",
      " refreeze: 0.528\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 75000, acc. rate: 0.31, log(P): -3408.3\n",
      "f_snow: 2.521\n",
      " f_ice: 7.918\n",
      " refreeze: 0.475\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 75100, acc. rate: 0.33, log(P): -3406.3\n",
      "f_snow: 2.161\n",
      " f_ice: 7.867\n",
      " refreeze: 0.525\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 75200, acc. rate: 0.30, log(P): -3407.2\n",
      "f_snow: 2.546\n",
      " f_ice: 7.919\n",
      " refreeze: 0.606\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 75300, acc. rate: 0.25, log(P): -3405.8\n",
      "f_snow: 2.557\n",
      " f_ice: 7.928\n",
      " refreeze: 0.408\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 75400, acc. rate: 0.26, log(P): -3408.4\n",
      "f_snow: 2.450\n",
      " f_ice: 7.914\n",
      " refreeze: 0.306\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 75500, acc. rate: 0.28, log(P): -3408.0\n",
      "f_snow: 2.434\n",
      " f_ice: 7.916\n",
      " refreeze: 0.734\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 75600, acc. rate: 0.30, log(P): -3407.3\n",
      "f_snow: 2.364\n",
      " f_ice: 7.911\n",
      " refreeze: 0.551\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 75700, acc. rate: 0.28, log(P): -3404.1\n",
      "f_snow: 2.445\n",
      " f_ice: 7.915\n",
      " refreeze: 0.033\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 75800, acc. rate: 0.29, log(P): -3407.5\n",
      "f_snow: 2.468\n",
      " f_ice: 7.918\n",
      " refreeze: 0.797\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 75900, acc. rate: 0.29, log(P): -3402.4\n",
      "f_snow: 2.152\n",
      " f_ice: 7.865\n",
      " refreeze: 0.090\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 76000, acc. rate: 0.33, log(P): -3407.4\n",
      "f_snow: 2.260\n",
      " f_ice: 7.897\n",
      " refreeze: 0.356\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 76100, acc. rate: 0.31, log(P): -3407.6\n",
      "f_snow: 2.253\n",
      " f_ice: 7.894\n",
      " refreeze: 0.364\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 76200, acc. rate: 0.24, log(P): -3404.3\n",
      "f_snow: 2.198\n",
      " f_ice: 7.882\n",
      " refreeze: 0.767\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 76300, acc. rate: 0.28, log(P): -3404.8\n",
      "f_snow: 2.193\n",
      " f_ice: 7.875\n",
      " refreeze: 0.769\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 76400, acc. rate: 0.24, log(P): -3408.7\n",
      "f_snow: 2.484\n",
      " f_ice: 7.918\n",
      " refreeze: 0.539\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 76500, acc. rate: 0.25, log(P): -3404.8\n",
      "f_snow: 2.540\n",
      " f_ice: 7.920\n",
      " refreeze: 0.886\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 76600, acc. rate: 0.29, log(P): -3408.0\n",
      "f_snow: 2.410\n",
      " f_ice: 7.913\n",
      " refreeze: 0.358\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 76700, acc. rate: 0.26, log(P): -3407.8\n",
      "f_snow: 2.551\n",
      " f_ice: 7.920\n",
      " refreeze: 0.312\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 76800, acc. rate: 0.29, log(P): -3406.1\n",
      "f_snow: 2.162\n",
      " f_ice: 7.869\n",
      " refreeze: 0.551\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 76900, acc. rate: 0.26, log(P): -3408.6\n",
      "f_snow: 2.437\n",
      " f_ice: 7.914\n",
      " refreeze: 0.405\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 77000, acc. rate: 0.32, log(P): -3405.7\n",
      "f_snow: 2.169\n",
      " f_ice: 7.847\n",
      " refreeze: 0.277\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 77100, acc. rate: 0.30, log(P): -3405.5\n",
      "f_snow: 2.155\n",
      " f_ice: 7.850\n",
      " refreeze: 0.174\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 77200, acc. rate: 0.27, log(P): -3405.5\n",
      "f_snow: 2.162\n",
      " f_ice: 7.872\n",
      " refreeze: 0.646\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 77300, acc. rate: 0.28, log(P): -3406.3\n",
      "f_snow: 2.165\n",
      " f_ice: 7.860\n",
      " refreeze: 0.254\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 77400, acc. rate: 0.28, log(P): -3406.0\n",
      "f_snow: 2.167\n",
      " f_ice: 7.871\n",
      " refreeze: 0.481\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 77500, acc. rate: 0.27, log(P): -3403.8\n",
      "f_snow: 2.135\n",
      " f_ice: 7.839\n",
      " refreeze: 0.858\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 77600, acc. rate: 0.32, log(P): -3406.3\n",
      "f_snow: 2.163\n",
      " f_ice: 7.848\n",
      " refreeze: 0.359\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 77700, acc. rate: 0.29, log(P): -3406.5\n",
      "f_snow: 2.157\n",
      " f_ice: 7.863\n",
      " refreeze: 0.526\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 77800, acc. rate: 0.24, log(P): -3406.8\n",
      "f_snow: 2.223\n",
      " f_ice: 7.882\n",
      " refreeze: 0.265\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 77900, acc. rate: 0.33, log(P): -3404.7\n",
      "f_snow: 2.130\n",
      " f_ice: 7.842\n",
      " refreeze: 0.713\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 78000, acc. rate: 0.36, log(P): -3404.8\n",
      "f_snow: 2.157\n",
      " f_ice: 7.871\n",
      " refreeze: 0.344\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 78100, acc. rate: 0.33, log(P): -3404.5\n",
      "f_snow: 2.169\n",
      " f_ice: 7.849\n",
      " refreeze: 0.767\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 78200, acc. rate: 0.27, log(P): -3406.9\n",
      "f_snow: 2.573\n",
      " f_ice: 7.921\n",
      " refreeze: 0.280\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 78300, acc. rate: 0.27, log(P): -3408.3\n",
      "f_snow: 2.378\n",
      " f_ice: 7.909\n",
      " refreeze: 0.599\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 78400, acc. rate: 0.27, log(P): -3407.2\n",
      "f_snow: 2.288\n",
      " f_ice: 7.899\n",
      " refreeze: 0.763\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 78500, acc. rate: 0.27, log(P): -3406.2\n",
      "f_snow: 2.250\n",
      " f_ice: 7.889\n",
      " refreeze: 0.134\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 78600, acc. rate: 0.28, log(P): -3407.0\n",
      "f_snow: 2.343\n",
      " f_ice: 7.908\n",
      " refreeze: 0.367\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 78700, acc. rate: 0.24, log(P): -3407.4\n",
      "f_snow: 2.348\n",
      " f_ice: 7.905\n",
      " refreeze: 0.795\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 78800, acc. rate: 0.26, log(P): -3400.3\n",
      "f_snow: 2.145\n",
      " f_ice: 7.869\n",
      " refreeze: 0.098\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 78900, acc. rate: 0.33, log(P): -3408.6\n",
      "f_snow: 2.448\n",
      " f_ice: 7.916\n",
      " refreeze: 0.606\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 79000, acc. rate: 0.23, log(P): -3407.5\n",
      "f_snow: 2.245\n",
      " f_ice: 7.891\n",
      " refreeze: 0.352\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 79100, acc. rate: 0.33, log(P): -3406.4\n",
      "f_snow: 2.437\n",
      " f_ice: 7.921\n",
      " refreeze: 0.500\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 79200, acc. rate: 0.28, log(P): -3408.0\n",
      "f_snow: 2.442\n",
      " f_ice: 7.914\n",
      " refreeze: 0.239\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 79300, acc. rate: 0.30, log(P): -3405.9\n",
      "f_snow: 2.237\n",
      " f_ice: 7.892\n",
      " refreeze: 0.829\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 79400, acc. rate: 0.28, log(P): -3402.3\n",
      "f_snow: 2.145\n",
      " f_ice: 7.865\n",
      " refreeze: 0.957\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 79500, acc. rate: 0.25, log(P): -3405.6\n",
      "f_snow: 2.168\n",
      " f_ice: 7.852\n",
      " refreeze: 0.158\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 79600, acc. rate: 0.33, log(P): -3404.6\n",
      "f_snow: 2.316\n",
      " f_ice: 7.906\n",
      " refreeze: 0.936\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 79700, acc. rate: 0.23, log(P): -3408.3\n",
      "f_snow: 2.360\n",
      " f_ice: 7.905\n",
      " refreeze: 0.378\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 79800, acc. rate: 0.26, log(P): -3406.6\n",
      "f_snow: 2.150\n",
      " f_ice: 7.854\n",
      " refreeze: 0.577\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 79900, acc. rate: 0.28, log(P): -3406.6\n",
      "f_snow: 2.163\n",
      " f_ice: 7.865\n",
      " refreeze: 0.489\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 80000, acc. rate: 0.25, log(P): -3408.6\n",
      "f_snow: 2.479\n",
      " f_ice: 7.917\n",
      " refreeze: 0.365\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 80100, acc. rate: 0.27, log(P): -3406.7\n",
      "f_snow: 2.498\n",
      " f_ice: 7.921\n",
      " refreeze: 0.830\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 80200, acc. rate: 0.28, log(P): -3406.4\n",
      "f_snow: 2.607\n",
      " f_ice: 7.925\n",
      " refreeze: 0.263\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 80300, acc. rate: 0.25, log(P): -3408.4\n",
      "f_snow: 2.473\n",
      " f_ice: 7.915\n",
      " refreeze: 0.653\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 80400, acc. rate: 0.26, log(P): -3407.5\n",
      "f_snow: 2.379\n",
      " f_ice: 7.912\n",
      " refreeze: 0.522\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 80500, acc. rate: 0.26, log(P): -3408.6\n",
      "f_snow: 2.413\n",
      " f_ice: 7.910\n",
      " refreeze: 0.385\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 80600, acc. rate: 0.25, log(P): -3406.2\n",
      "f_snow: 2.409\n",
      " f_ice: 7.912\n",
      " refreeze: 0.920\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 80700, acc. rate: 0.22, log(P): -3408.7\n",
      "f_snow: 2.497\n",
      " f_ice: 7.917\n",
      " refreeze: 0.436\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 80800, acc. rate: 0.30, log(P): -3406.3\n",
      "f_snow: 2.164\n",
      " f_ice: 7.853\n",
      " refreeze: 0.653\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 80900, acc. rate: 0.29, log(P): -3404.2\n",
      "f_snow: 2.130\n",
      " f_ice: 7.848\n",
      " refreeze: 0.843\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 81000, acc. rate: 0.28, log(P): -3402.6\n",
      "f_snow: 2.129\n",
      " f_ice: 7.849\n",
      " refreeze: 0.231\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 81100, acc. rate: 0.25, log(P): -3408.0\n",
      "f_snow: 2.400\n",
      " f_ice: 7.907\n",
      " refreeze: 0.321\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 81200, acc. rate: 0.27, log(P): -3407.9\n",
      "f_snow: 2.392\n",
      " f_ice: 7.911\n",
      " refreeze: 0.304\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 81300, acc. rate: 0.34, log(P): -3405.0\n",
      "f_snow: 2.440\n",
      " f_ice: 7.909\n",
      " refreeze: 0.059\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 81400, acc. rate: 0.26, log(P): -3408.5\n",
      "f_snow: 2.470\n",
      " f_ice: 7.915\n",
      " refreeze: 0.323\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 81500, acc. rate: 0.26, log(P): -3407.8\n",
      "f_snow: 2.522\n",
      " f_ice: 7.923\n",
      " refreeze: 0.487\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 81600, acc. rate: 0.15, log(P): -3402.8\n",
      "f_snow: 2.688\n",
      " f_ice: 7.933\n",
      " refreeze: 0.183\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 81700, acc. rate: 0.36, log(P): -3406.4\n",
      "f_snow: 2.411\n",
      " f_ice: 7.908\n",
      " refreeze: 0.091\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 81800, acc. rate: 0.34, log(P): -3404.0\n",
      "f_snow: 2.086\n",
      " f_ice: 7.799\n",
      " refreeze: 0.517\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 81900, acc. rate: 0.28, log(P): -3404.7\n",
      "f_snow: 2.098\n",
      " f_ice: 7.801\n",
      " refreeze: 0.504\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 82000, acc. rate: 0.36, log(P): -3404.2\n",
      "f_snow: 2.088\n",
      " f_ice: 7.796\n",
      " refreeze: 0.413\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 82100, acc. rate: 0.26, log(P): -3406.4\n",
      "f_snow: 2.236\n",
      " f_ice: 7.886\n",
      " refreeze: 0.171\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 82200, acc. rate: 0.30, log(P): -3406.4\n",
      "f_snow: 2.253\n",
      " f_ice: 7.888\n",
      " refreeze: 0.185\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 82300, acc. rate: 0.28, log(P): -3408.7\n",
      "f_snow: 2.466\n",
      " f_ice: 7.915\n",
      " refreeze: 0.611\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 82400, acc. rate: 0.27, log(P): -3407.8\n",
      "f_snow: 2.264\n",
      " f_ice: 7.895\n",
      " refreeze: 0.583\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 82500, acc. rate: 0.26, log(P): -3407.8\n",
      "f_snow: 2.423\n",
      " f_ice: 7.913\n",
      " refreeze: 0.235\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 82600, acc. rate: 0.30, log(P): -3404.0\n",
      "f_snow: 2.416\n",
      " f_ice: 7.910\n",
      " refreeze: 0.968\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 82700, acc. rate: 0.26, log(P): -3407.5\n",
      "f_snow: 2.441\n",
      " f_ice: 7.912\n",
      " refreeze: 0.785\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 82800, acc. rate: 0.26, log(P): -3403.4\n",
      "f_snow: 2.483\n",
      " f_ice: 7.926\n",
      " refreeze: 0.862\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 82900, acc. rate: 0.27, log(P): -3406.2\n",
      "f_snow: 2.498\n",
      " f_ice: 7.923\n",
      " refreeze: 0.793\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 83000, acc. rate: 0.26, log(P): -3407.2\n",
      "f_snow: 2.219\n",
      " f_ice: 7.885\n",
      " refreeze: 0.551\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 83100, acc. rate: 0.28, log(P): -3406.9\n",
      "f_snow: 2.214\n",
      " f_ice: 7.880\n",
      " refreeze: 0.563\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 83200, acc. rate: 0.25, log(P): -3407.0\n",
      "f_snow: 2.543\n",
      " f_ice: 7.920\n",
      " refreeze: 0.687\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 83300, acc. rate: 0.28, log(P): -3408.6\n",
      "f_snow: 2.449\n",
      " f_ice: 7.913\n",
      " refreeze: 0.552\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 83400, acc. rate: 0.27, log(P): -3406.0\n",
      "f_snow: 2.176\n",
      " f_ice: 7.864\n",
      " refreeze: 0.242\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 83500, acc. rate: 0.30, log(P): -3406.3\n",
      "f_snow: 2.165\n",
      " f_ice: 7.849\n",
      " refreeze: 0.360\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 83600, acc. rate: 0.29, log(P): -3408.2\n",
      "f_snow: 2.508\n",
      " f_ice: 7.917\n",
      " refreeze: 0.536\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 83700, acc. rate: 0.24, log(P): -3406.5\n",
      "f_snow: 2.533\n",
      " f_ice: 7.917\n",
      " refreeze: 0.727\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 83800, acc. rate: 0.23, log(P): -3407.3\n",
      "f_snow: 2.320\n",
      " f_ice: 7.906\n",
      " refreeze: 0.709\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 83900, acc. rate: 0.31, log(P): -3405.0\n",
      "f_snow: 2.550\n",
      " f_ice: 7.925\n",
      " refreeze: 0.075\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 84000, acc. rate: 0.24, log(P): -3407.3\n",
      "f_snow: 2.474\n",
      " f_ice: 7.917\n",
      " refreeze: 0.156\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 84100, acc. rate: 0.25, log(P): -3406.2\n",
      "f_snow: 2.545\n",
      " f_ice: 7.921\n",
      " refreeze: 0.778\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 84200, acc. rate: 0.28, log(P): -3406.6\n",
      "f_snow: 2.394\n",
      " f_ice: 7.913\n",
      " refreeze: 0.890\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 84300, acc. rate: 0.29, log(P): -3405.6\n",
      "f_snow: 2.220\n",
      " f_ice: 7.881\n",
      " refreeze: 0.138\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 84400, acc. rate: 0.29, log(P): -3407.0\n",
      "f_snow: 2.422\n",
      " f_ice: 7.918\n",
      " refreeze: 0.768\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 84500, acc. rate: 0.26, log(P): -3408.4\n",
      "f_snow: 2.411\n",
      " f_ice: 7.912\n",
      " refreeze: 0.404\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 84600, acc. rate: 0.25, log(P): -3407.9\n",
      "f_snow: 2.347\n",
      " f_ice: 7.908\n",
      " refreeze: 0.545\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 84700, acc. rate: 0.26, log(P): -3408.3\n",
      "f_snow: 2.361\n",
      " f_ice: 7.905\n",
      " refreeze: 0.535\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 84800, acc. rate: 0.28, log(P): -3407.1\n",
      "f_snow: 2.249\n",
      " f_ice: 7.887\n",
      " refreeze: 0.476\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 84900, acc. rate: 0.23, log(P): -3408.2\n",
      "f_snow: 2.465\n",
      " f_ice: 7.918\n",
      " refreeze: 0.313\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 85000, acc. rate: 0.27, log(P): -3406.7\n",
      "f_snow: 2.472\n",
      " f_ice: 7.919\n",
      " refreeze: 0.167\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 85100, acc. rate: 0.36, log(P): -3408.7\n",
      "f_snow: 2.493\n",
      " f_ice: 7.918\n",
      " refreeze: 0.439\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 85200, acc. rate: 0.31, log(P): -3408.2\n",
      "f_snow: 2.422\n",
      " f_ice: 7.910\n",
      " refreeze: 0.275\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 85300, acc. rate: 0.24, log(P): -3408.3\n",
      "f_snow: 2.508\n",
      " f_ice: 7.920\n",
      " refreeze: 0.311\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 85400, acc. rate: 0.29, log(P): -3407.8\n",
      "f_snow: 2.415\n",
      " f_ice: 7.916\n",
      " refreeze: 0.680\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 85500, acc. rate: 0.26, log(P): -3408.4\n",
      "f_snow: 2.519\n",
      " f_ice: 7.920\n",
      " refreeze: 0.497\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 85600, acc. rate: 0.22, log(P): -3407.1\n",
      "f_snow: 2.224\n",
      " f_ice: 7.881\n",
      " refreeze: 0.377\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 85700, acc. rate: 0.32, log(P): -3408.1\n",
      "f_snow: 2.341\n",
      " f_ice: 7.903\n",
      " refreeze: 0.513\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 85800, acc. rate: 0.27, log(P): -3407.8\n",
      "f_snow: 2.468\n",
      " f_ice: 7.914\n",
      " refreeze: 0.778\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 85900, acc. rate: 0.21, log(P): -3406.0\n",
      "f_snow: 2.145\n",
      " f_ice: 7.843\n",
      " refreeze: 0.475\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 86000, acc. rate: 0.32, log(P): -3406.2\n",
      "f_snow: 2.477\n",
      " f_ice: 7.920\n",
      " refreeze: 0.892\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 86100, acc. rate: 0.26, log(P): -3404.0\n",
      "f_snow: 2.404\n",
      " f_ice: 7.902\n",
      " refreeze: 0.278\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 86200, acc. rate: 0.30, log(P): -3403.7\n",
      "f_snow: 2.115\n",
      " f_ice: 7.826\n",
      " refreeze: 0.567\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 86300, acc. rate: 0.33, log(P): -3404.7\n",
      "f_snow: 2.177\n",
      " f_ice: 7.849\n",
      " refreeze: 0.565\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 86400, acc. rate: 0.38, log(P): -3405.6\n",
      "f_snow: 2.175\n",
      " f_ice: 7.860\n",
      " refreeze: 0.151\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 86500, acc. rate: 0.31, log(P): -3408.0\n",
      "f_snow: 2.317\n",
      " f_ice: 7.904\n",
      " refreeze: 0.623\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 86600, acc. rate: 0.24, log(P): -3407.5\n",
      "f_snow: 2.439\n",
      " f_ice: 7.919\n",
      " refreeze: 0.654\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 86700, acc. rate: 0.28, log(P): -3406.2\n",
      "f_snow: 2.160\n",
      " f_ice: 7.846\n",
      " refreeze: 0.539\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 86800, acc. rate: 0.18, log(P): -3407.5\n",
      "f_snow: 2.289\n",
      " f_ice: 7.900\n",
      " refreeze: 0.744\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 86900, acc. rate: 0.30, log(P): -3406.6\n",
      "f_snow: 2.479\n",
      " f_ice: 7.911\n",
      " refreeze: 0.481\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 87000, acc. rate: 0.36, log(P): -3403.3\n",
      "f_snow: 2.145\n",
      " f_ice: 7.832\n",
      " refreeze: 0.764\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 87100, acc. rate: 0.33, log(P): -3405.7\n",
      "f_snow: 2.168\n",
      " f_ice: 7.852\n",
      " refreeze: 0.168\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 87200, acc. rate: 0.32, log(P): -3406.0\n",
      "f_snow: 2.143\n",
      " f_ice: 7.855\n",
      " refreeze: 0.672\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 87300, acc. rate: 0.22, log(P): -3408.0\n",
      "f_snow: 2.280\n",
      " f_ice: 7.900\n",
      " refreeze: 0.548\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 87400, acc. rate: 0.27, log(P): -3407.7\n",
      "f_snow: 2.473\n",
      " f_ice: 7.920\n",
      " refreeze: 0.287\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 87500, acc. rate: 0.28, log(P): -3403.3\n",
      "f_snow: 2.659\n",
      " f_ice: 7.931\n",
      " refreeze: 0.084\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 87600, acc. rate: 0.27, log(P): -3408.3\n",
      "f_snow: 2.405\n",
      " f_ice: 7.908\n",
      " refreeze: 0.619\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 87700, acc. rate: 0.20, log(P): -3405.8\n",
      "f_snow: 2.268\n",
      " f_ice: 7.899\n",
      " refreeze: 0.103\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 87800, acc. rate: 0.33, log(P): -3408.2\n",
      "f_snow: 2.318\n",
      " f_ice: 7.903\n",
      " refreeze: 0.472\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 87900, acc. rate: 0.24, log(P): -3407.7\n",
      "f_snow: 2.394\n",
      " f_ice: 7.905\n",
      " refreeze: 0.452\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 88000, acc. rate: 0.26, log(P): -3406.7\n",
      "f_snow: 2.227\n",
      " f_ice: 7.890\n",
      " refreeze: 0.397\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 88100, acc. rate: 0.27, log(P): -3407.8\n",
      "f_snow: 2.264\n",
      " f_ice: 7.896\n",
      " refreeze: 0.497\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 88200, acc. rate: 0.32, log(P): -3405.2\n",
      "f_snow: 2.175\n",
      " f_ice: 7.873\n",
      " refreeze: 0.670\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 88300, acc. rate: 0.32, log(P): -3408.1\n",
      "f_snow: 2.310\n",
      " f_ice: 7.900\n",
      " refreeze: 0.464\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 88400, acc. rate: 0.26, log(P): -3405.4\n",
      "f_snow: 2.203\n",
      " f_ice: 7.882\n",
      " refreeze: 0.507\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 88500, acc. rate: 0.27, log(P): -3406.9\n",
      "f_snow: 2.267\n",
      " f_ice: 7.898\n",
      " refreeze: 0.770\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 88600, acc. rate: 0.23, log(P): -3408.5\n",
      "f_snow: 2.399\n",
      " f_ice: 7.909\n",
      " refreeze: 0.566\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 88700, acc. rate: 0.33, log(P): -3406.1\n",
      "f_snow: 2.230\n",
      " f_ice: 7.891\n",
      " refreeze: 0.193\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 88800, acc. rate: 0.32, log(P): -3408.0\n",
      "f_snow: 2.465\n",
      " f_ice: 7.913\n",
      " refreeze: 0.232\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 88900, acc. rate: 0.24, log(P): -3407.2\n",
      "f_snow: 2.291\n",
      " f_ice: 7.897\n",
      " refreeze: 0.233\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 89000, acc. rate: 0.27, log(P): -3406.1\n",
      "f_snow: 2.168\n",
      " f_ice: 7.853\n",
      " refreeze: 0.648\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 89100, acc. rate: 0.25, log(P): -3406.4\n",
      "f_snow: 2.161\n",
      " f_ice: 7.857\n",
      " refreeze: 0.272\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 89200, acc. rate: 0.25, log(P): -3407.6\n",
      "f_snow: 2.249\n",
      " f_ice: 7.889\n",
      " refreeze: 0.455\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 89300, acc. rate: 0.29, log(P): -3407.2\n",
      "f_snow: 2.419\n",
      " f_ice: 7.909\n",
      " refreeze: 0.758\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 89400, acc. rate: 0.23, log(P): -3406.8\n",
      "f_snow: 2.497\n",
      " f_ice: 7.924\n",
      " refreeze: 0.470\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 89500, acc. rate: 0.25, log(P): -3406.4\n",
      "f_snow: 2.172\n",
      " f_ice: 7.867\n",
      " refreeze: 0.447\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 89600, acc. rate: 0.34, log(P): -3405.3\n",
      "f_snow: 2.184\n",
      " f_ice: 7.869\n",
      " refreeze: 0.248\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 89700, acc. rate: 0.28, log(P): -3406.5\n",
      "f_snow: 2.159\n",
      " f_ice: 7.851\n",
      " refreeze: 0.649\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 89800, acc. rate: 0.31, log(P): -3406.3\n",
      "f_snow: 2.163\n",
      " f_ice: 7.867\n",
      " refreeze: 0.525\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 89900, acc. rate: 0.31, log(P): -3405.8\n",
      "f_snow: 2.155\n",
      " f_ice: 7.845\n",
      " refreeze: 0.680\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 90000, acc. rate: 0.26, log(P): -3407.6\n",
      "f_snow: 2.253\n",
      " f_ice: 7.893\n",
      " refreeze: 0.592\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 90100, acc. rate: 0.26, log(P): -3404.4\n",
      "f_snow: 2.155\n",
      " f_ice: 7.873\n",
      " refreeze: 0.434\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 90200, acc. rate: 0.29, log(P): -3403.0\n",
      "f_snow: 2.174\n",
      " f_ice: 7.885\n",
      " refreeze: 0.635\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 90300, acc. rate: 0.27, log(P): -3407.2\n",
      "f_snow: 2.550\n",
      " f_ice: 7.925\n",
      " refreeze: 0.327\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 90400, acc. rate: 0.21, log(P): -3408.4\n",
      "f_snow: 2.447\n",
      " f_ice: 7.917\n",
      " refreeze: 0.523\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 90500, acc. rate: 0.28, log(P): -3408.4\n",
      "f_snow: 2.459\n",
      " f_ice: 7.918\n",
      " refreeze: 0.617\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 90600, acc. rate: 0.30, log(P): -3405.4\n",
      "f_snow: 2.147\n",
      " f_ice: 7.852\n",
      " refreeze: 0.842\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 90700, acc. rate: 0.31, log(P): -3406.7\n",
      "f_snow: 2.161\n",
      " f_ice: 7.861\n",
      " refreeze: 0.606\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 90800, acc. rate: 0.32, log(P): -3404.7\n",
      "f_snow: 2.449\n",
      " f_ice: 7.923\n",
      " refreeze: 0.262\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 90900, acc. rate: 0.27, log(P): -3407.4\n",
      "f_snow: 2.517\n",
      " f_ice: 7.924\n",
      " refreeze: 0.568\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 91000, acc. rate: 0.25, log(P): -3407.7\n",
      "f_snow: 2.375\n",
      " f_ice: 7.911\n",
      " refreeze: 0.655\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 91100, acc. rate: 0.19, log(P): -3406.7\n",
      "f_snow: 2.239\n",
      " f_ice: 7.894\n",
      " refreeze: 0.436\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 91200, acc. rate: 0.27, log(P): -3406.3\n",
      "f_snow: 2.163\n",
      " f_ice: 7.867\n",
      " refreeze: 0.456\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 91300, acc. rate: 0.30, log(P): -3407.8\n",
      "f_snow: 2.386\n",
      " f_ice: 7.910\n",
      " refreeze: 0.764\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 91400, acc. rate: 0.27, log(P): -3408.3\n",
      "f_snow: 2.513\n",
      " f_ice: 7.920\n",
      " refreeze: 0.309\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 91500, acc. rate: 0.28, log(P): -3408.4\n",
      "f_snow: 2.399\n",
      " f_ice: 7.908\n",
      " refreeze: 0.381\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 91600, acc. rate: 0.30, log(P): -3404.3\n",
      "f_snow: 2.184\n",
      " f_ice: 7.868\n",
      " refreeze: 0.783\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 91700, acc. rate: 0.33, log(P): -3403.1\n",
      "f_snow: 2.081\n",
      " f_ice: 7.781\n",
      " refreeze: 0.500\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 91800, acc. rate: 0.32, log(P): -3407.8\n",
      "f_snow: 2.290\n",
      " f_ice: 7.902\n",
      " refreeze: 0.380\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 91900, acc. rate: 0.29, log(P): -3404.4\n",
      "f_snow: 2.179\n",
      " f_ice: 7.880\n",
      " refreeze: 0.392\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 92000, acc. rate: 0.28, log(P): -3407.6\n",
      "f_snow: 2.254\n",
      " f_ice: 7.891\n",
      " refreeze: 0.374\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 92100, acc. rate: 0.24, log(P): -3406.1\n",
      "f_snow: 2.153\n",
      " f_ice: 7.858\n",
      " refreeze: 0.782\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 92200, acc. rate: 0.31, log(P): -3404.5\n",
      "f_snow: 2.184\n",
      " f_ice: 7.851\n",
      " refreeze: 0.551\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 92300, acc. rate: 0.30, log(P): -3408.8\n",
      "f_snow: 2.462\n",
      " f_ice: 7.915\n",
      " refreeze: 0.499\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 92400, acc. rate: 0.21, log(P): -3407.0\n",
      "f_snow: 2.282\n",
      " f_ice: 7.900\n",
      " refreeze: 0.805\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 92500, acc. rate: 0.28, log(P): -3408.1\n",
      "f_snow: 2.350\n",
      " f_ice: 7.906\n",
      " refreeze: 0.652\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 92600, acc. rate: 0.27, log(P): -3408.0\n",
      "f_snow: 2.284\n",
      " f_ice: 7.898\n",
      " refreeze: 0.435\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 92700, acc. rate: 0.26, log(P): -3405.0\n",
      "f_snow: 2.192\n",
      " f_ice: 7.867\n",
      " refreeze: 0.296\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 92800, acc. rate: 0.27, log(P): -3405.8\n",
      "f_snow: 2.157\n",
      " f_ice: 7.842\n",
      " refreeze: 0.391\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 92900, acc. rate: 0.27, log(P): -3406.6\n",
      "f_snow: 2.159\n",
      " f_ice: 7.858\n",
      " refreeze: 0.664\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 93000, acc. rate: 0.23, log(P): -3406.2\n",
      "f_snow: 2.243\n",
      " f_ice: 7.889\n",
      " refreeze: 0.128\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 93100, acc. rate: 0.33, log(P): -3405.0\n",
      "f_snow: 2.221\n",
      " f_ice: 7.882\n",
      " refreeze: 0.092\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 93200, acc. rate: 0.29, log(P): -3402.8\n",
      "f_snow: 2.097\n",
      " f_ice: 7.791\n",
      " refreeze: 0.145\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 93300, acc. rate: 0.36, log(P): -3404.0\n",
      "f_snow: 2.110\n",
      " f_ice: 7.815\n",
      " refreeze: 0.787\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 93400, acc. rate: 0.32, log(P): -3404.9\n",
      "f_snow: 2.156\n",
      " f_ice: 7.838\n",
      " refreeze: 0.551\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 93500, acc. rate: 0.27, log(P): -3407.6\n",
      "f_snow: 2.406\n",
      " f_ice: 7.906\n",
      " refreeze: 0.460\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 93600, acc. rate: 0.26, log(P): -3407.1\n",
      "f_snow: 2.234\n",
      " f_ice: 7.888\n",
      " refreeze: 0.677\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 93700, acc. rate: 0.27, log(P): -3407.9\n",
      "f_snow: 2.439\n",
      " f_ice: 7.916\n",
      " refreeze: 0.779\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 93800, acc. rate: 0.25, log(P): -3408.1\n",
      "f_snow: 2.312\n",
      " f_ice: 7.902\n",
      " refreeze: 0.591\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 93900, acc. rate: 0.25, log(P): -3406.5\n",
      "f_snow: 2.253\n",
      " f_ice: 7.897\n",
      " refreeze: 0.713\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 94000, acc. rate: 0.29, log(P): -3408.6\n",
      "f_snow: 2.457\n",
      " f_ice: 7.915\n",
      " refreeze: 0.656\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 94100, acc. rate: 0.26, log(P): -3406.8\n",
      "f_snow: 2.235\n",
      " f_ice: 7.891\n",
      " refreeze: 0.666\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 94200, acc. rate: 0.30, log(P): -3406.4\n",
      "f_snow: 2.157\n",
      " f_ice: 7.864\n",
      " refreeze: 0.533\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 94300, acc. rate: 0.36, log(P): -3404.2\n",
      "f_snow: 2.186\n",
      " f_ice: 7.852\n",
      " refreeze: 0.663\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 94400, acc. rate: 0.24, log(P): -3403.2\n",
      "f_snow: 2.156\n",
      " f_ice: 7.863\n",
      " refreeze: 0.954\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 94500, acc. rate: 0.33, log(P): -3404.4\n",
      "f_snow: 2.180\n",
      " f_ice: 7.871\n",
      " refreeze: 0.776\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 94600, acc. rate: 0.24, log(P): -3406.8\n",
      "f_snow: 2.444\n",
      " f_ice: 7.910\n",
      " refreeze: 0.156\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 94700, acc. rate: 0.29, log(P): -3404.6\n",
      "f_snow: 2.146\n",
      " f_ice: 7.836\n",
      " refreeze: 0.265\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 94800, acc. rate: 0.39, log(P): -3408.0\n",
      "f_snow: 2.363\n",
      " f_ice: 7.904\n",
      " refreeze: 0.424\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 94900, acc. rate: 0.32, log(P): -3408.0\n",
      "f_snow: 2.341\n",
      " f_ice: 7.902\n",
      " refreeze: 0.562\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 95000, acc. rate: 0.30, log(P): -3404.1\n",
      "f_snow: 2.214\n",
      " f_ice: 7.886\n",
      " refreeze: 0.152\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 95100, acc. rate: 0.30, log(P): -3408.6\n",
      "f_snow: 2.424\n",
      " f_ice: 7.911\n",
      " refreeze: 0.467\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 95200, acc. rate: 0.27, log(P): -3406.0\n",
      "f_snow: 2.625\n",
      " f_ice: 7.925\n",
      " refreeze: 0.283\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 95300, acc. rate: 0.27, log(P): -3406.6\n",
      "f_snow: 2.419\n",
      " f_ice: 7.907\n",
      " refreeze: 0.613\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 95400, acc. rate: 0.34, log(P): -3404.9\n",
      "f_snow: 2.132\n",
      " f_ice: 7.842\n",
      " refreeze: 0.703\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 95500, acc. rate: 0.29, log(P): -3406.0\n",
      "f_snow: 2.353\n",
      " f_ice: 7.903\n",
      " refreeze: 0.082\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 95600, acc. rate: 0.26, log(P): -3408.3\n",
      "f_snow: 2.484\n",
      " f_ice: 7.916\n",
      " refreeze: 0.258\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 95700, acc. rate: 0.23, log(P): -3407.0\n",
      "f_snow: 2.301\n",
      " f_ice: 7.901\n",
      " refreeze: 0.822\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 95800, acc. rate: 0.30, log(P): -3404.1\n",
      "f_snow: 2.098\n",
      " f_ice: 7.814\n",
      " refreeze: 0.440\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 95900, acc. rate: 0.33, log(P): -3405.4\n",
      "f_snow: 2.162\n",
      " f_ice: 7.868\n",
      " refreeze: 0.278\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 96000, acc. rate: 0.36, log(P): -3406.4\n",
      "f_snow: 2.292\n",
      " f_ice: 7.900\n",
      " refreeze: 0.120\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 96100, acc. rate: 0.26, log(P): -3408.2\n",
      "f_snow: 2.452\n",
      " f_ice: 7.915\n",
      " refreeze: 0.275\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 96200, acc. rate: 0.26, log(P): -3406.8\n",
      "f_snow: 2.231\n",
      " f_ice: 7.887\n",
      " refreeze: 0.734\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 96300, acc. rate: 0.23, log(P): -3407.7\n",
      "f_snow: 2.372\n",
      " f_ice: 7.911\n",
      " refreeze: 0.453\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 96400, acc. rate: 0.34, log(P): -3403.8\n",
      "f_snow: 2.202\n",
      " f_ice: 7.888\n",
      " refreeze: 0.812\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 96500, acc. rate: 0.24, log(P): -3408.7\n",
      "f_snow: 2.468\n",
      " f_ice: 7.915\n",
      " refreeze: 0.521\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 96600, acc. rate: 0.24, log(P): -3408.6\n",
      "f_snow: 2.427\n",
      " f_ice: 7.912\n",
      " refreeze: 0.364\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 96700, acc. rate: 0.26, log(P): -3407.6\n",
      "f_snow: 2.348\n",
      " f_ice: 7.903\n",
      " refreeze: 0.214\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 96800, acc. rate: 0.23, log(P): -3406.8\n",
      "f_snow: 2.166\n",
      " f_ice: 7.859\n",
      " refreeze: 0.397\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 96900, acc. rate: 0.30, log(P): -3406.1\n",
      "f_snow: 2.156\n",
      " f_ice: 7.844\n",
      " refreeze: 0.429\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 97000, acc. rate: 0.29, log(P): -3407.3\n",
      "f_snow: 2.518\n",
      " f_ice: 7.923\n",
      " refreeze: 0.274\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 97100, acc. rate: 0.32, log(P): -3406.1\n",
      "f_snow: 2.574\n",
      " f_ice: 7.925\n",
      " refreeze: 0.122\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 97200, acc. rate: 0.23, log(P): -3407.9\n",
      "f_snow: 2.397\n",
      " f_ice: 7.909\n",
      " refreeze: 0.743\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 97300, acc. rate: 0.32, log(P): -3403.6\n",
      "f_snow: 2.094\n",
      " f_ice: 7.806\n",
      " refreeze: 0.276\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 97400, acc. rate: 0.29, log(P): -3405.9\n",
      "f_snow: 2.225\n",
      " f_ice: 7.887\n",
      " refreeze: 0.837\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 97500, acc. rate: 0.22, log(P): -3406.8\n",
      "f_snow: 2.229\n",
      " f_ice: 7.886\n",
      " refreeze: 0.740\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 97600, acc. rate: 0.25, log(P): -3406.4\n",
      "f_snow: 2.470\n",
      " f_ice: 7.922\n",
      " refreeze: 0.305\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 97700, acc. rate: 0.31, log(P): -3408.1\n",
      "f_snow: 2.472\n",
      " f_ice: 7.913\n",
      " refreeze: 0.550\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 97800, acc. rate: 0.23, log(P): -3406.5\n",
      "f_snow: 2.244\n",
      " f_ice: 7.894\n",
      " refreeze: 0.724\n",
      "\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "sample: 97900, acc. rate: 0.33, log(P): -3406.4\n",
      "f_snow: 2.166\n",
      " f_ice: 7.866\n",
      " refreeze: 0.385\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 98000, acc. rate: 0.22, log(P): -3405.9\n",
      "f_snow: 2.161\n",
      " f_ice: 7.861\n",
      " refreeze: 0.789\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 98100, acc. rate: 0.30, log(P): -3404.1\n",
      "f_snow: 2.178\n",
      " f_ice: 7.845\n",
      " refreeze: 0.326\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 98200, acc. rate: 0.33, log(P): -3407.1\n",
      "f_snow: 2.250\n",
      " f_ice: 7.893\n",
      " refreeze: 0.237\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 98300, acc. rate: 0.28, log(P): -3408.0\n",
      "f_snow: 2.303\n",
      " f_ice: 7.899\n",
      " refreeze: 0.431\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 98400, acc. rate: 0.23, log(P): -3407.4\n",
      "f_snow: 2.317\n",
      " f_ice: 7.906\n",
      " refreeze: 0.592\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 98500, acc. rate: 0.29, log(P): -3408.2\n",
      "f_snow: 2.408\n",
      " f_ice: 7.912\n",
      " refreeze: 0.689\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 98600, acc. rate: 0.27, log(P): -3407.8\n",
      "f_snow: 2.256\n",
      " f_ice: 7.893\n",
      " refreeze: 0.461\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 98700, acc. rate: 0.27, log(P): -3408.5\n",
      "f_snow: 2.434\n",
      " f_ice: 7.913\n",
      " refreeze: 0.672\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 98800, acc. rate: 0.28, log(P): -3408.4\n",
      "f_snow: 2.367\n",
      " f_ice: 7.906\n",
      " refreeze: 0.598\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 98900, acc. rate: 0.26, log(P): -3408.1\n",
      "f_snow: 2.444\n",
      " f_ice: 7.911\n",
      " refreeze: 0.473\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 99000, acc. rate: 0.28, log(P): -3405.7\n",
      "f_snow: 2.171\n",
      " f_ice: 7.852\n",
      " refreeze: 0.175\n",
      "\n",
      "===============================================\n",
      "///////////////////////////////////////////////\n",
      "Saving samples for model 0\n",
      "///////////////////////////////////////////////\n",
      "===============================================\n",
      "sample: 99100, acc. rate: 0.26, log(P): -3408.1\n",
      "f_snow: 2.366\n",
      " f_ice: 7.909\n",
      " refreeze: 0.615\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 99200, acc. rate: 0.29, log(P): -3408.4\n",
      "f_snow: 2.474\n",
      " f_ice: 7.914\n",
      " refreeze: 0.540\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 99300, acc. rate: 0.30, log(P): -3406.5\n",
      "f_snow: 2.242\n",
      " f_ice: 7.891\n",
      " refreeze: 0.165\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 99400, acc. rate: 0.22, log(P): -3408.5\n",
      "f_snow: 2.437\n",
      " f_ice: 7.914\n",
      " refreeze: 0.370\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 99500, acc. rate: 0.31, log(P): -3407.8\n",
      "f_snow: 2.343\n",
      " f_ice: 7.904\n",
      " refreeze: 0.722\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 99600, acc. rate: 0.34, log(P): -3403.5\n",
      "f_snow: 2.384\n",
      " f_ice: 7.916\n",
      " refreeze: 0.959\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 99700, acc. rate: 0.34, log(P): -3405.3\n",
      "f_snow: 2.252\n",
      " f_ice: 7.894\n",
      " refreeze: 0.081\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 99800, acc. rate: 0.25, log(P): -3408.6\n",
      "f_snow: 2.481\n",
      " f_ice: 7.916\n",
      " refreeze: 0.582\n",
      "\n",
      "===============================================\n",
      "===============================================\n",
      "sample: 99900, acc. rate: 0.31, log(P): -3406.0\n",
      "f_snow: 2.221\n",
      " f_ice: 7.887\n",
      " refreeze: 0.214\n",
      "\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "    from scipy.stats import beta, uniform\n",
    "    from scipy.special import gamma\n",
    "\n",
    "    device=\"cuda\"\n",
    "    nu = 1\n",
    "    n_iters=100000\n",
    "    n_draws=100000\n",
    "    n_prior_samples=100000\n",
    "\n",
    "    distributions = {\n",
    "        \"T\": uniform(loc=-20, scale=40),\n",
    "        \"P\": uniform(loc=0, scale=1), \n",
    "        \"f_snow\": uniform(\n",
    "            loc=2.0, scale=4.0\n",
    "        ), \n",
    "        \"f_ice\": uniform(\n",
    "            loc=3.0, scale=9\n",
    "        ),  # uniform between 3 and 3.5  AS16 best value: 3.25\n",
    "        \"refreeze\": uniform(loc=0, scale=1.0),  # uniform between 0.25 and 0.95    \n",
    "    }\n",
    "    # Names of all the variables\n",
    "    keys = [x for x in distributions.keys()]\n",
    "\n",
    "    # Describe the Problem\n",
    "    problem = {\"num_vars\": len(keys), \"names\": keys, \"bounds\": [[0, 1]] * len(keys)}\n",
    "\n",
    "    # Generate uniform samples (i.e. one unit hypercube)\n",
    "    if method == \"saltelli\":\n",
    "        unif_sample = saltelli.sample(problem, n_prior_samples, calc_second_order=False)\n",
    "    elif method == \"lhs\":\n",
    "        unif_sample = lhs(len(keys), n_prior_samples)\n",
    "    else:\n",
    "        print(f\"Method {method} not available\")\n",
    "\n",
    "    # To hold the transformed variables\n",
    "    dist_sample = np.zeros_like(unif_sample)\n",
    "\n",
    "    # Now transform the unit hypercube to the prescribed distributions\n",
    "    # For each variable, transform with the inverse of the CDF (inv(CDF)=ppf)\n",
    "    for i, key in enumerate(keys):\n",
    "        dist_sample[:, i] = distributions[key].ppf(unif_sample[:, i])\n",
    "\n",
    "    # Save to CSV file using Pandas DataFrame and to_csv method\n",
    "    header = keys\n",
    "    # Convert to Pandas dataframe, append column headers, output as csv\n",
    "    df = pd.DataFrame(data=dist_sample, columns=header)\n",
    "    \n",
    "    f_snow_test = 3.0\n",
    "    f_ice_test = 8.0\n",
    "    refreeze_test = 0.0\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    for k, row in df.iterrows():   \n",
    "\n",
    "        m_T = np.copy(row[\"T\"])\n",
    "        m_P = np.copy(row[\"P\"])\n",
    "        m_f_snow = np.copy(row[\"f_snow\"])\n",
    "        m_f_ice = np.copy(row[\"f_ice\"])\n",
    "        m_refreeze = np.copy(row[\"refreeze\"])\n",
    "\n",
    "        pdd = TorchPDDModel(\n",
    "            pdd_factor_snow=f_snow_test,\n",
    "            pdd_factor_ice=f_ice_test,\n",
    "            refreeze_snow=refreeze_test,\n",
    "            refreeze_ice=refreeze_test,\n",
    "        )\n",
    "        result = pdd(m_T, m_P)\n",
    "\n",
    "        M_train = result[\"melt_rate\"]\n",
    "        A_train = result[\"accu_rate\"]\n",
    "        R_train = result[\"refreeze_rate\"]\n",
    "        B_train = result[\"smb_rate\"]\n",
    "        m_Y = torch.vstack((M_train, A_train, R_train)).T\n",
    "        Y.append(m_Y)\n",
    "        X.append(torch.from_numpy(np.hstack((m_P, m_T, m_f_snow, m_f_ice, m_refreeze))))\n",
    "\n",
    "    X_test = torch.vstack(X).type(torch.FloatTensor)\n",
    "    Y_test = torch.vstack(Y).type(torch.FloatTensor)\n",
    "\n",
    "    X_test_mean = X_test.mean(axis=0)\n",
    "    X_test_std = X_test.std(axis=0)\n",
    "    \n",
    "    X_test_norm = (X_test - X_test_mean) / X_test_std\n",
    "    \n",
    "    X_P_mean = X_test_mean[-3::].to(device)\n",
    "    X_P_std = X_test_std[-3::].to(device)\n",
    "    \n",
    "    X_min = X_train_norm.cpu().numpy().min(axis=0)\n",
    "    X_max = X_train_norm.cpu().numpy().max(axis=0)\n",
    "\n",
    "    sigma = 0.001\n",
    "\n",
    "    rho = 1.0 / (1e4**2)\n",
    "    point_area = 1800 ** 2\n",
    "    K = point_area * rho\n",
    "    sigma_hat = np.sqrt(sigma**2 / K**2)\n",
    "\n",
    "    # Eq 52\n",
    "    # this is 2.0 in the paper\n",
    "    alpha_b = 3.0\n",
    "    beta_b = 3.0\n",
    "    X_P_prior =  beta.rvs(alpha_b, beta_b, size=(n_draws, 3)) * (X_max[-3:] - X_min[-3:]) + X_min[-3:]\n",
    "    X_I_prior = uniform.rvs(0, 1, size=(n_draws, 2)) * (X_max[:-3] - X_min[:-3]) + X_min[:-3]\n",
    "    # X_I_prior = beta.rvs(alpha_b, beta_b, size=(n_draws, 2)) * (X_max[:-3] - X_min[:-3]) + X_min[:-3]\n",
    "\n",
    "\n",
    "    X_min = torch.tensor(X_min, dtype=torch.float32, device=device)\n",
    "    X_max = torch.tensor(X_max, dtype=torch.float32, device=device)\n",
    "\n",
    "    # Needs\n",
    "    # alpha_b, beta_b: float\n",
    "    # alpha: float\n",
    "    # nu: float\n",
    "    # gamma\n",
    "    # sigma_hat\n",
    "    X_P_0 = torch.tensor(X_P_prior.mean(axis=0),\n",
    "                         requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "    X_I_0 = torch.tensor(X_I_prior.mean(axis=0),\n",
    "                         requires_grad=True, dtype=torch.float, device=device)\n",
    "    X_I_prior = torch.tensor(X_I_prior, dtype=torch.float, device=device)\n",
    "    \n",
    "    X_P_min = X_min[-3:]\n",
    "    X_P_max = X_max[-3:]\n",
    "    \n",
    "    U_target = Y_test.to(device)\n",
    "\n",
    "    X_P_keys = [\"f_snow\", \"f_ice\", \"refreeze\"]\n",
    "    mala = MALASampler(e.to(device), emulator_dir=emulator_dir)\n",
    "    X_map = mala.find_MAP(X_P_0, X_I_0, U_target, X_P_min, X_P_max)\n",
    "    \n",
    "    # To reproduce the paper, n_iters should be 10^5\n",
    "    X_posterior = mala.MALA(\n",
    "        X_map,\n",
    "        X_I_0,\n",
    "        X_P_min,\n",
    "        X_P_max,\n",
    "        U_target,\n",
    "        n_iters=n_iters,\n",
    "        model_index=int(model_index),\n",
    "        save_interval=1000,\n",
    "        print_interval=100,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b78268f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_prior_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "103cb1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import beta, gaussian_kde\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7567f409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_I_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57e292ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading posterior samples\n",
      "\n",
      "  -- pddemulator/posterior_samples/X_posterior_model_0.csv.gz\n",
      "Merging posteriors into dataframe\n",
      "Saving figure to pddemulator/posterior.pdf\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_keys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 173>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m             axs[i, j]\u001b[38;5;241m.\u001b[39mremove()\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(axs[:, \u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m--> 174\u001b[0m     ax\u001b[38;5;241m.\u001b[39mset_ylabel(keys_dict[\u001b[43mX_keys\u001b[49m[i]])\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(axs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]):\n\u001b[1;32m    177\u001b[0m     ax\u001b[38;5;241m.\u001b[39mset_xlabel(keys_dict[X_keys[j]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_keys' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAC3CAYAAACmAh0uAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfCklEQVR4nO3dfXRc9ZnY8e8jjUbvL5aMvUQya3xEXMvUGDIOzqGhEBIMSiM4XWLsnA24kFVI7CQNOQnZtnGDmxDvcqBNYppWwMbJZistJd1aTW2zwMbpORAwMgQSRGP5YIOlhYKNJfQ+mtHTPzRSJFkvI2nu6zyfczjM3Pn53mfmzjz63d/9vYiqYowxJrNyvA7AGGPCyJKrMcY4wJKrMcY4wJKrMcY4wJKrMcY4wJKrMcY4IOLVgZcvX66rV6/26vBmBqdOncLOiX/Y+fCXY8eOnVHVC9It71lyXb16NW1tbV4d3swgFovZOfEROx/+IiJvLKS8NQsYY4wDLLkaY4wDLLkaY4wDLLkaY4wDApVc+/r66Onp8ToMExAjIyOMjIx4HYZJUVXOnTvndRiu8ay3wEL09PSQTCYpLi4mkUh4HY4JiPHEmpeX53EkRlU5e/YsOTk5jI6OkpMTqHrdovg+ufb29lJQUEB+fj4Ag4ODHkdkgmJ0dBQR8TqMrDM4OEg8HqesrGzi8z937hwVFRWICL29vZSXl3scpfN8n1xHRkYoLS31OgwTQKqKzVfsvqGhIUpKSnjvvfcoKCggmUxSVFREJDKWbpLJpMcRusPXdfO+vj5KSkq8DsME1OjoqCVXl41/3nl5eVRVVZGbm0skEqGgoGCiTCQSyYrmPV8n13g8TjQa9ToME1CqyujoqNdhZJW+vr4pV5oFBQUUFRVNKVNaWkpvb6/bobnOt8nVaq3GBE8ikZi4/J+NiGTFFYVvk6vVWk2QHD58mLVr11JbW8vevXvPe/3NN9/k2muv5fLLL2fDhg0cPHjQgygza/pVwUISZn5+PsPDw5kOyVd8mVz7+vooLi72Ogxj0pJMJtm5cyeHDh2ivb2d5uZm2tvbp5T5zne+w9atW3nppZdoaWnhi1/8okfRZsbo6CidnZ1T+hH39vamffO5uLiY/v5+p8LzBV8m13g8PtH1ypzvjjvuYMWKFVx66aUzvn7kyBHKy8vZuHEjGzduZM+ePS5HmF2OHj1KbW0ta9asIRqNsm3bNg4cODCljIjw/vvvA2P9tj/wgQ94EWrGvP/++1RXV9PT0zNRY00mk/M2CUwX5uYB33XFGhkZsU7f89ixYwe7du3itttum7XMRz/6UX7xi1+4GFX26urqYtWqVRPPa2pqeP7556eU+fa3v83111/PD3/4Q/r7+3nqqadm3FdTUxNNTU0AvPvuu84FvUSjo6Pk5uZSWVnJe++9R2Vl5YL7FFdUVNDd3c2yZcscitJbvqu59vb22o2seVx99dVUVlZ6HYZZgObmZnbs2EFnZycHDx7ks5/97Iw9GRobG2lra6OtrY0LLkh7XmZXTa4A5eTkUFJSQldX14L7o+fk5CAioe336qvkqqqIiI2qyYBf//rXXHbZZdx44428+uqrXocTatXV1Zw+fXrieWdnJ9XV1VPKPProo2zduhWAj3zkIwwNDXHmzBlX48yU6RWg/Px8Vq5cSW5u7oL3VV5eHtr5QnyVXBfSIG5md8UVV/DGG2/w8ssv86UvfYmbb7551rJNTU3EYjFisZivL0P9bNOmTXR0dHDy5Eni8TgtLS00NDRMKXPRRRfx9NNPA/Daa68xNDTk25ppOqZXgBbblCciRKPRUPYc8FVyTaePnJlfWVnZRM2ivr6ekZGRWWtJQbgM9btIJMK+ffvYsmUL69atY+vWraxfv57du3fT2toKwAMPPMDDDz/MZZddxvbt29m/f38gr9AGBgbOGxSwVCUlJfT19WV0n37gm0w2PDxsPQQy5O2332blypWICEePHmV0dJSqqiqvwwq1+vp66uvrp2yb3Eujrq6OZ555xu2wMm5oaMiR9v6ioiIGBwcpLCzM+L694pvkmkgkrG9rmrZv386RI0c4c+YMNTU13HvvvRP9De+66y4ef/xxfvSjHxGJRCgsLKSlpSWQtSTjL+P3RJxQWFjIuXPnLLk6wRJr+pqbm+d8fdeuXezatculaEy2sHsiC5NWm6uI3CAivxeREyLyzRlev0hEfikiL4nIKyJSP9N+MiXMHY+N8avFDBJYiLy8POLxuGP7d9u8yVVEcoGHgBuBOmC7iNRNK/bvgMdU9XJgG/CfMx3ouPGZzI0x7nGjQhO2IbHp1Fw/DJxQ1ddVNQ60ADdNK6NAWepxOfCPmQtxKkuuxrjPjVnqwnZfIJ06fjVwetLzTuDKaWW+Dfy9iHwJKAY+npHoZpAt05UZ4yeJRMKVYek5OTkkk8lFDUjwm0z1c90O7FfVGqAe+GsROW/fItIoIm0i0rbYDutWczXGXW5WZsI0kXY6ybULWDXpeU1q22R3Ao8BqOqvgQJg+fQdqWqTqsZUNbbYDuuWXI1xV39/v2u9eXJyckJzZZpOcn0BuERELhaRKGM3rFqnlXkTuA5ARNYxllwdGUtpzQLGuGtkZMTVievD8hufN7mqagLYBTwBvMZYr4BXRWSPiIwPoP4a8Gci8jLQDOxQhz4dq7ka46yzZ8/y3nvvebaIYFiaBtLqtKaqB4GD07btnvS4Hbgqs6HNzJKrMc7KycmhoqKC3t5ehoaGKC8vd/X4ubm5oZiG0DcjtNIVlksGY/xo/LclIpSVlVFWVjbPvzCz8dWsWOkIW184Y/xkeHiYgoICr8MIRSUqcMnVGOOcwcFBXyTXMIzWsuRqjJnCD1eHeXl5U1aWDSJLrsYY4wBLrsYY4wBLrsYYYGz+AD+N6Q/62lqWXI0xwNj6WH6atL6oqIiBgQGvw1g0S67GGADfzUblhxtrS2HJ1RgDBD+Z+Y0lVxNKkzugB70zejYbn981iCy5mlAaX6nUamPp8esfoJKSksAOJrDkakJpdHSUnJwcRMQm+knD0NCQL0ZmTRfkSVwsuZpQGq+5ujX58uHDh1m7di21tbXs3bt3xjKPPfYYdXV1rF+/ns985jOOx7QQw8PD5Ofnex1GqARuVixj0jFec1VVx2uuyWSSnTt38uSTT1JTU8OmTZtoaGigru4PiyR3dHTwve99j2eeeYZly5bxzjvvOBrTYvi5CWX8j2WQWM3VhJKbNdejR49SW1vLmjVriEajbNu2jQMHDkwp8/DDD7Nz506WLVsGwIoVKxyNKUyKi4sD2d/VkqsJJTfbXLu6uli16g/LzNXU1NDVNXWZuePHj3P8+HGuuuoqNm/ezOHDhx2NaSH8ejNrXDQaJR6Pex3GglmzgAmlyb0FvFquZLJEIkFHRwdHjhyhs7OTq6++mt/+9rdUVFRMKdfU1ERTUxMAi10heaF6e3spLS115VjZxGquJpTcrLlWV1dz+vTpieednZ1UV1dPKVNTU0NDQwN5eXlcfPHFfPCDH6Sjo+O8fTU2NtLW1kZbWxuLXSF5ofw2MissLLmaUHKzzXXTpk10dHRw8uRJ4vE4LS0tNDQ0TClz8803c+TIEQDOnDnD8ePHWbNmjaNxpcPvTQLj8vPzAzeJiyVXE0pu1lwjkQj79u1jy5YtrFu3jq1bt7J+/Xp2795Na+vYKvRbtmyhqqqKuro6rr32Wu6//36qqqocjSsdfpusZTaFhYWBu6kl6fzlEpEbgO8DucAjqnpeRz4R2Qp8G1DgZVWdsyNfLBbTtra2xcRMd3f3eW1VZulisRiLPSd+M/4dUVV6enoC+X1x43ycO3duogeD33kdq4gcU9VYuuXnvaElIrnAQ8AngE7gBRFpTS2nPV7mEuDPgatU9ZyIWD8T4wtB6xtpwiOdZoEPAydU9XVVjQMtwE3TyvwZ8JCqngNQVf/1kDbGTBG0UVmRSMQXPT/SlU5yrQZOT3remdo22QeBD4rIMyLyXKoZ4Twi0igibSLS5lY3kzC64447WLFiBZdeeumMr6sqX/7yl6mtrWXDhg28+OKLLkdogmBgYIDCwkKvw0hbcXExfX19XoeRtkzd0IoAlwDXANuBh0WkYnohVW1S1ZiqxtzqZhJGO3bsmLMT+qFDh+jo6KCjo4Ompia+8IUvuBidCZIgNZu4NU9EpqSTXLuAVZOe16S2TdYJtKrqiKqeBI4zlmyNA66++moqKytnff3AgQPcdtttiAibN2+mu7ubt956y8UIjd/5bb2sMEonub4AXCIiF4tIFNgGtE4r8z8Zq7UiIssZayZ4PXNhmoVIZzimyW5BHZUVpMmz502uqpoAdgFPAK8Bj6nqqyKyR0TGe0o/AZwVkXbgl8DXVfWsU0GbzGlqaiIWixGLxVwbbmn8IUhNAuNKS0sD0+6a1twCqnoQODht2+5JjxW4O/WfK4I4BZlb0hmOOa6xsZHGxkZgrF+lCb/R0dHA/nZycnICM/l5IEdoiUigGrbd1tDQwE9/+lNUleeee47y8nIuvPBCr8MyPtHb20tZWZnXYYReIGfFGv/rlZMTyL8NS7Z9+3aOHDnCmTNnqKmp4d5772VkZASAu+66i/r6eg4ePEhtbS1FRUX8+Mc/9jhi4ydB/+1Eo9FA9NENbHLN5pprc3PznK+LCA899JBL0ZggCcPvpqioiO7ubt8n10D++bJF54xZnKD2EpgsKO3FgUyuQWrUNsZPkskkkUggL1jP4/daeGCTq98/WGP8Jky/meLiYvr7+70OY06BTK7WLGDMwg0MDFBUVOR1GBkRjUYnbuL6VSCTqzULGLNw8Xjc9zeBwiSQydX6uRqzMGH8vfh9KKwlV2OyQH9/fyCWc1mIsrIyenp6fDscNrDJ1RiTvpGREaLRqNdhZJSIUFlZSSQS4ezZs76bSDuQydUYk76wX+UVFBRQWVlJb2+v16FMYcnVmJDr6+ujpKTE6zAc5cerWUuuxoRcIpEgLy/P6zBc4adauiVXY0LMT8nGaQUFBQwPD3sdxgRLrsaEWBjmEkhXQUEBg4ODXocxwZKrMSEWprkE5uO3dldLrsZkwOHDh1m7di21tbXs3bt31nI///nPERHa2tpcjM54wZKrMUuUTCbZuXMnhw4dor29nebmZtrb288r19vby/e//32uvPJKV+IK+qTYi+GnAUbZ9ckb44CjR49SW1vLmjVriEajbNu2jQMHDpxX7lvf+hb33HMPBQUFrsQVxlFZ8/HTbFlpJVcRuUFEfi8iJ0Tkm3OU+xMRURGxle5M1khnKfMXX3yR06dP88lPfnLOfWVyNd5EIpE17a3j8vLyfDNb1rzJVURygYeAG4E6YLuI1M1QrhT4CvB8poM0JshGR0e5++67eeCBB+Yt29jYSFtbG21tbVxwwQUuRGeckk7N9cPACVV9XVXjQAtw0wzl/gPwF8BQBuMzZsHcbnObbynz3t5efve733HNNdewevVqnnvuORoaGuymVsilk1yrgdOTnnemtk0QkSuAVar6v+fakYg0ikibiLQt9ZLHmLlM75bjZMLdtGkTHR0dnDx5kng8TktLCw0NDROvl5eXc+bMGU6dOsWpU6fYvHkzra2txGLOtZ4lEglyc3Md27+f5ebm+mIqwiXf0BKRHOBB4GvzlVXVJlWNqWrMLnmMU0ZHR6ckV6fvIEciEfbt28eWLVtYt24dW7duZf369ezevZvW1lbHjjuX/v7+0M8nMJvi4mJfTEOYTmt3F7Bq0vOa1LZxpcClwJHUF/qPgFYRaVBVu+4xrlPVKV2QxleucLJbUn19PfX19VO27dmzZ8ayR44ccSyOcdnYDWtcbm6uL1YqSefTfwG4REQuFpEosA2Y+HOsqj2qulxVV6vqauA5wBKr8YzbNVdjZjJvclXVBLALeAJ4DXhMVV8VkT0i0jD3vzbGfbPVXI1xU1qd4FT1IHBw2rbds5S9ZulhGbN42V5zjcfjWTPF4Gzy8vKIx+Oerr6QnY0yJtSyveY6MDCQdSOzpisuLmZgYMDTGCy5mtDJ9pqrqvpuhii3+eGcW3I1oZPtNVfjD5ZcTehkc811+nvPdl6ed0uuJnSmXxZnU821t7eXsrIyr8PwBa+XfbHkakJpes01W2Tz4IHpvF72xc6CMSFhN7Km8vqzsOQaQPMtKbJ//34uuOACNm7cyMaNG3nkkUc8iNK4LZsWIwyC7JpJNwTGlxR58sknqampYdOmTTQ0NFBXN3WK3VtvvZV9+/Z5FKXxQjKZzNqZsGYzfjPTi1psoGuu2XIHeLJ0lxQx2SUbfwvpKCws9GwwQWCTazbdAZ4snSVFYGyV0Q0bNnDLLbdMmcjZhFNfX1/WTjE4l/z8fOLxuCfHtuQaQp/61Kc4deoUr7zyCp/4xCe4/fbbZy2byTWbjHcSiUTWzyfgN4FNrtnUMXyy+ZYUAaiqqiI/Px+Az33ucxw7dmzW/dmaTcGXjb+DIAhscs3Wmut8S4oAvPXWWxOPW1tbWbdundthGhcNDQ1RWFjodRi+lZubSyKRcP24ge0tkJOT44t1ctw2eUmRZDLJHXfcMbGkSCwWo6GhgR/84Ae0trYSiUSorKxk//79XodtHDQ0NERFRYXXYfhWaWkpPT09rn9G4tUlRSwW06WsfhmPxxkZGcn6qdUyKRaLhWJF0u7u7vN+SDNt87t0z8e5c+dYtmyZCxEFVyY+IxE5pqppryppzQLGmKzgdkUy0MnVGvKNMekoLi6mv7/f1WMGNrmKiNVcTdZLJpM2UUsaotEoIyMjrh4zsGfF60kZjPEDW9LFv9JKriJyg4j8XkROiMg3Z3j9bhFpF5FXRORpEfnjzIdqjJkukUgQiQS204+rxhctdMu8yVVEcoGHgBuBOmC7iNRNK/YSEFPVDcDjwF9mOlBj/Gy+mcoefPBB6urq2LBhA9dddx1vvPGGB1FmN7fbXdOpuX4YOKGqr6tqHGgBbppcQFV/qarjsyM8B9RkNkxj/Gt8prJDhw7R3t5Oc3Mz7e3tU8pcfvnltLW18corr3DLLbfwjW98w6Nos5fbTYnpJNdqYPLMH52pbbO5Ezi0lKCMCZJ0Ziq79tprKSoqAmDz5s10dnZ6EWrWc/NGeEZvaInInwIx4P5ZXm8UkTYRabNJQkxYpDtT2bhHH32UG2+8ccnHjcfjRKPRJe8nm5SWltLX1+fKsdJpCe8CVk16XpPaNoWIfBz4t8A/V9UZVwVT1SagCcZGaC04WmMC7mc/+xltbW386le/mvH1pqYmmpqaAOadpWxgYMAWI1yg3Nxc14bNp1NzfQG4REQuFpEosA1onVxARC4H/ivQoKrvZD5MY/wrnZnKAJ566im++93v0traOjFr2XQLmaVMVa2Pq4/Ne2ZUNQHsAp4AXgMeU9VXRWSPiIxPx3Q/UAL8dxH5jYi0zrI7Y0InnZnKXnrpJT7/+c/T2trKihUrPIrUwNjkR24MKEirg5yqHgQOTtu2e9Ljj2c4LmMCI52Zyr7+9a/T19fHpz/9aQAuuugiWlutDuKFkpISuru7HZ/sxnofG5MB9fX11NfXT9m2Z8+eicdPPfVURo9ny2gvnlufmzXYGBNAg4ODFBQUeB1GoDk98VOgk6vNimWy1fDw8Kw3xcz8CgsLGRoacvQYgU6uxmQzaxZYvIKCAkuuc7EvlzHGrwKdXI0xZrGcHgprydWYgLFhr5lRUlLi6FBYS64mVOa6yRmWG6ADAwMTk8CYxYtEIo4OhbXkakJltiGhYWqftz6umeVU04AlVxMqo6OjMyYeW3PNzKS8vJz333/fkX1bcjWhMlvN1ZZiNzNx8nsR+OQalnY0kxlz1VzD8F2xNbMyLz8/n+HhGWdJXZJAJ1en7/aZ4Al7zbW/v99We82w4uJiBgYG5i+4QIFOrpFIhEQi4XUYxkfCXnMdHR21OVwdkunvh50lEyphr7kaZ5SWltLb25vRfQY+uRYUFDA4OOh1GMYnwl5zNc5w4io48MnVjdltTHCEueaaTCatScBBmV6hwM6UCZUw11wHBgbsZpaDMr0ybCiSq93YMpOFNblaNyxnjX9HMvU9CUVyLSkpyXhjtAmXMAwXzcvL8zqE0Mtk7TWt5CoiN4jI70XkhIh8c4bX80Xkb1OvPy8iqzMSXZrC8MNZiMOHD7N27Vpqa2vZu3fvea8PDw9z6623Ultby5VXXsmpU6fcD9JkXElJidchhF5eXl7G2l3nTa4ikgs8BNwI1AHbRaRuWrE7gXOqWgv8R+AvMhLdAoiIozPc+EUymWTnzp0cOnSI9vZ2mpubaW9vn1Lm0UcfZdmyZZw4cYKvfvWr3HPPPR5Fa0zwZKqZMZ2a64eBE6r6uqrGgRbgpmllbgJ+knr8OHCduFydLC8vp7e3l+7u7sC3rc3l6NGj1NbWsmbNGqLRKNu2bePAgQNTyhw4cIDbb78dgFtuuYWnn3461J+JMZlUWlqakclc0mkdrwZOT3reCVw5WxlVTYhID1AFnFlyhGkSESoqKkgmk5w7dw4RmWigDlOzwfHjx1m5ciXd3d0ALFu2jGPHjk08B3jzzTcpKyub2FZaWsrrr79OVVXVRJmysrI5u/WoKj09PU68BUcNDg5SUVEx42tODHHMlIKCAlvN1ScylS9cvfUoIo1AI8BFF13kyDFyc3OprKycsi1MtbaioiLy8vIoLy+feB6NRieew9hnUFZWNrEtJydnyvPJmpqaaGpqAuDdd9+d8tpM5f1urpgvvPBCFyMxQbZs2bIl7yOd5NoFrJr0vCa1baYynSISAcqBs9N3pKpNQBNALBZzLeOFqeZaU1NDZ2fnxHvq6uqipqZmynusrq6ms7OTVatWkUgk6OnpYfny5TN+Do2NjTQ2NgIQi8UmtofpMxsXxvdknJGJ70o6ba4vAJeIyMUiEgW2Aa3TyrQCt6ce3wL8g4apuugjmzZtoqOjg5MnTxKPx2lpaaGhoWFKmYaGBn7yk7Em8Mcff5yPfexjllgcZj04zHTzJldVTQC7gCeA14DHVPVVEdkjIuO/6keBKhE5AdwNnNddy2RGJBJh3759bNmyhXXr1rF161bWr1/P7t27aW0d+5t35513cvbsWWpra3nwwQdn/LGbzLEeHGZG4yMS3P7vQx/6kBp/sXOyOM8++6xef/31E8/vu+8+ve+++6aUuf766/XZZ59VVdWRkRGtqqrS0dHROfdr58NfgDZdQI4LxQgtY7zU1dXFqlV/uC1RU1NDV1fXrGUikQjl5eWcPXvebQkTIjZQ2Rgfmav3hgkWUY/uO4nIu8AbwHJc7A/rgKDHD394D1cALzp8jLBZDgwCHwA6Utv+KPX/tyeVuwT4R6A/9fwy4OV59j1+PoL+2YUl/j9W1QvS/UeeJdeJAETaVDU2f0l/Cnr84M57CMPnNBMRaQM2A8eB6xjrlvgC8BlVfXVSuZ3AP1XVu0RkG/AvVXVruscI8meXrfFbs4AxS6RjoxLHe9TkAn+lqR41jN0EaWWsR81fp3rUvMdYl0YTYpZcjckAVT0IHJy2bfekx0PAp92Oy3jHD70FmrwOYImCHj+48x7C8DnNxD67+WVl/J63uRpjTBj5oeZqjDGh40lyFZFVIvJLEWkXkVdF5CtexJEJIpIrIi+JyC+8jmWhRKRCRB4Xkf8rIq+JyEccOs4pEfmtiPwmdXc9cETkr0TkHRH53aRtlSLypIh0pP6/pKmU/L7ix3zSiH+HiLyb+h78RkQ+50WcM5np/E57XUTkB6n39oqIXDHfPr2quSaAr6lqHWPdWHbOsLpBUHyFsTkXguj7wGFV/SeM9bt08n1cq6obA9wlZz9ww7Rt3wSeVtVLgKdZwpwaQVnxYzZpxg/wt6nvwUZVfcTVIOe2n/PP72Q3MtZX+RLGpk390Xw79CS5qupbqvpi6nEvYz/qai9iWQoRqQE+CfjpS5IWESkHrmasixCqGlfVbk+D8jFV/T+MdaGabPIKHD8Bbl7CIQKx4scc0onft2Y5v5PdBPw0Nc3Ac0CFiMw5QbDnba6pS5vLgec9DmUx/hPwDWDU4zgW42LgXeDHqWaNR0Sk2KFjKfD3InIsNWF6WKxU1bdSj98GVi5hXzOt+DG9wjFlxQ9gfMUPP0gnfoA/SV1WPy4iq2Z43a/SfX8TPE2uIlIC/Bz416q69EVrXCQi/wJ4R1WPeR3LIkUYG175I1W9nLFhmU5NFfnPVPUKxi6tdorI1Q4dxzOpWZOs683c/hewWlU3AE/yh1p4KHmWXEUkj7HE+jeq+j+8imMJrgIaROQUY5dAHxORn3kb0oJ0Ap2qOn7F8DhjyTbjVLUr9f93gL9j7BIyDP7f+KVh6v/vLGFfC1nxg7lW/PDIvPGr6llVHU49fQT4kEuxZUI652cKr3oLCGNtfa+p6oNexLBUqvrnqlqjqqsZG8r4D6r6px6HlTZVfRs4LSJrU5uuA9rn+CeLIiLFIlI6/hi4HpjxjmwATV6B43bgwBxl5xP0FT/mjX9aG2UDwboR3Arcluo1sBnomdQkNCOvhr9eBXwW+K2I/Ca17d+khhAa93wJ+JvUj+F14F85cIyVwN+l7rtEgP+mqocdOI6jRKQZuAZYLiKdwL8H9gKPicidjM3wltZELDMJ+vwEacb/5dTqJQnG4t/hWcDTzHJ+8wBU9b8wNrS5HjgBDJDGb8VGaBljjAM87y1gjDFhZMnVGGMcYMnVGGMcYMnVGGMcYMnVGGMcYMnVGGMcYMnVGGMcYMnVGGMc8P8B/asbdfgs6YoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 388.8x201.6 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 388.8x403.2 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    X_std = X_P_std\n",
    "    X_mean = X_P_mean\n",
    "    frac = 1.0\n",
    "    lw = 1\n",
    "    color_prior = \"b\"\n",
    "    X_list = []\n",
    "    X_prior = (X_P_prior* X_P_std[-3::] .detach().cpu().numpy() + X_P_mean[-3::] .detach().cpu().numpy())\n",
    "    keys_dict = {\"f_ice\": \"$f_{\\mathrm{ice}}$\", \"f_snow\": \"$f_{\\mathrm{snoe}}$\", \"refreeze\": \"$r$\"}\n",
    "    p = Path(f\"{emulator_dir}/posterior_samples/\")\n",
    "    print(\"Loading posterior samples\\n\")\n",
    "    for m, m_file in enumerate(sorted(p.glob(\"X_posterior_model_*.csv.gz\"))):\n",
    "        print(f\"  -- {m_file}\")\n",
    "        df = pd.read_csv(m_file).sample(frac=frac)\n",
    "        if \"Unnamed: 0\" in df.columns:\n",
    "            df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "        model = m_file.name.split(\"_\")[-1].split(\".\")[0]\n",
    "        df[\"Model\"] = int(model)\n",
    "        X_list.append(df)\n",
    "\n",
    "    print(f\"Merging posteriors into dataframe\")\n",
    "    posterior_df = pd.concat(X_list)\n",
    "\n",
    "    X_posterior = posterior_df.drop(columns=[\"Model\"]).values\n",
    "    C_0 = np.corrcoef((X_posterior - X_posterior.mean(axis=0)).T)\n",
    "    Cn_0 = (np.sign(C_0) * C_0 ** 2 + 1) / 2.0\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(5.4, 2.8))\n",
    "    fig.subplots_adjust(hspace=0.0, wspace=0.0)\n",
    "    for i in range(3):\n",
    "        min_val = min(X_prior[:, i].min(), X_posterior[:, i].min())\n",
    "        max_val = max(X_prior[:, i].max(), X_posterior[:, i].max())\n",
    "        bins = np.linspace(min_val, max_val, 30)\n",
    "        X_prior_hist, b = np.histogram(X_prior[:, i] , bins, density=True)\n",
    "        X_posterior_hist, _ = np.histogram(X_posterior[:, i], bins, density=True)\n",
    "        b = 0.5 * (b[1:] + b[:-1])\n",
    "        axs[i].plot(\n",
    "            b,\n",
    "            X_posterior_hist * 0.5,\n",
    "            color=\"0.5\",\n",
    "            linewidth=lw * 0.25,\n",
    "            linestyle=\"solid\",\n",
    "            alpha=0.5,\n",
    "        )\n",
    "\n",
    "    figfile = f\"{emulator_dir}/posterior.pdf\"\n",
    "    print(f\"Saving figure to {figfile}\")\n",
    "    fig.savefig(figfile)\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(5.4, 5.6))\n",
    "    fig.subplots_adjust(hspace=0.0, wspace=0.0)\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if i > j:\n",
    "\n",
    "                axs[i, j].scatter(\n",
    "                    X_posterior[:, j],\n",
    "                    X_posterior[:, i],\n",
    "                    c=\"#31a354\",\n",
    "                    s=0.05,\n",
    "                    alpha=0.01,\n",
    "                    label=\"Posterior\",\n",
    "                    rasterized=True,\n",
    "                )\n",
    "\n",
    "                min_val = min(X_prior[:, i].min(), X_posterior[:, i].min())\n",
    "                max_val = max(X_prior[:, i].max(), X_posterior[:, i].max())\n",
    "                bins_y = np.linspace(min_val, max_val, 30)\n",
    "\n",
    "                min_val = min(X_prior[:, j].min(), X_posterior[:, j].min())\n",
    "                max_val = max(X_prior[:, j].max(), X_posterior[:, j].max())\n",
    "                bins_x = np.linspace(min_val, max_val, 30)\n",
    "\n",
    "                v = gaussian_kde(X_posterior[:, [j, i]].T)\n",
    "                bx = 0.5 * (bins_x[1:] + bins_x[:-1])\n",
    "                by = 0.5 * (bins_y[1:] + bins_y[:-1])\n",
    "                Bx, By = np.meshgrid(bx, by)\n",
    "\n",
    "                axs[i, j].contour(\n",
    "                    Bx,\n",
    "                    By,\n",
    "                    v(np.vstack((Bx.ravel(), By.ravel()))).reshape(Bx.shape),\n",
    "                    7,\n",
    "                    linewidths=0.5,\n",
    "                    colors=\"black\",\n",
    "                )\n",
    "\n",
    "                axs[i, j].set_xlim(X_prior[:, j].min(), X_prior[:, j].max())\n",
    "                axs[i, j].set_ylim(X_prior[:, i].min(), X_prior[:, i].max())\n",
    "\n",
    "            elif i < j:\n",
    "                patch_upper = Polygon(\n",
    "                    np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 1.0], [1.0, 0.0]]),\n",
    "                    facecolor=plt.cm.seismic(Cn_0[i, j]),\n",
    "                )\n",
    "                axs[i, j].add_patch(patch_upper)\n",
    "                if C_0[i, j] > -0.5:\n",
    "                    color = \"black\"\n",
    "                else:\n",
    "                    color = \"white\"\n",
    "                axs[i, j].text(\n",
    "                    0.5,\n",
    "                    0.5,\n",
    "                    \"{0:.2f}\".format(C_0[i, j]),\n",
    "                    fontsize=6,\n",
    "                    horizontalalignment=\"center\",\n",
    "                    verticalalignment=\"center\",\n",
    "                    transform=axs[i, j].transAxes,\n",
    "                    color=color,\n",
    "                )\n",
    "\n",
    "            elif i == j:\n",
    "                min_val = min(X_prior[:, i].min(), X_posterior[:, i].min())\n",
    "                max_val = max(X_prior[:, i].max(), X_posterior[:, i].max())\n",
    "                bins = np.linspace(min_val, max_val, 30)\n",
    "                X_prior_hist, b = np.histogram(X_prior[:, i], bins, density=True)\n",
    "                X_posterior_hist, _ = np.histogram(\n",
    "                    X_posterior[:, i], bins, density=True\n",
    "                )\n",
    "                b = 0.5 * (b[1:] + b[:-1])\n",
    "\n",
    "                axs[i, j].plot(\n",
    "                    b,\n",
    "                    X_prior_hist,\n",
    "                    color=color_prior,\n",
    "                    linewidth=lw,\n",
    "                    label=\"Prior\",\n",
    "                    linestyle=\"solid\",\n",
    "                )\n",
    "\n",
    "                all_models = posterior_df[\"Model\"].unique()\n",
    "                for k, m_model in enumerate(all_models):\n",
    "                    m_df = posterior_df[posterior_df[\"Model\"] == m_model].drop(\n",
    "                        columns=[\"Model\"]\n",
    "                    )\n",
    "                    X_model_posterior = m_df.values\n",
    "                    X_model_posterior_hist, _ = np.histogram(\n",
    "                        X_model_posterior[:, i], _, density=True\n",
    "                    )\n",
    "                    if k == 0:\n",
    "                        axs[i, j].plot(\n",
    "                            b,\n",
    "                            X_model_posterior_hist * 0.5,\n",
    "                            color=\"0.5\",\n",
    "                            linewidth=lw * 0.25,\n",
    "                            linestyle=\"solid\",\n",
    "                            alpha=0.5,\n",
    "                            label=\"Posterior (BayesBag)\",\n",
    "                        )\n",
    "                    else:\n",
    "                        axs[i, j].plot(\n",
    "                            b,\n",
    "                            X_model_posterior_hist * 0.5,\n",
    "                            color=\"0.5\",\n",
    "                            linewidth=lw * 0.25,\n",
    "                            linestyle=\"solid\",\n",
    "                            alpha=0.5,\n",
    "                        )\n",
    "\n",
    "                axs[i, j].plot(\n",
    "                    b,\n",
    "                    X_posterior_hist,\n",
    "                    color=\"black\",\n",
    "                    linewidth=lw,\n",
    "                    linestyle=\"solid\",\n",
    "                    label=\"Posterior\",\n",
    "                )\n",
    "\n",
    "                axs[i, j].set_xlim(min_val, max_val)\n",
    "\n",
    "            else:\n",
    "                axs[i, j].remove()\n",
    "\n",
    "    for i, ax in enumerate(axs[:, 0]):\n",
    "        ax.set_ylabel(keys_dict[X_keys[i]])\n",
    "\n",
    "    for j, ax in enumerate(axs[-1, :]):\n",
    "        ax.set_xlabel(keys_dict[X_keys[j]])\n",
    "        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "        plt.setp(ax.xaxis.get_minorticklabels(), rotation=45)\n",
    "        if j > 0:\n",
    "            ax.tick_params(axis=\"y\", which=\"both\", length=0)\n",
    "            ax.yaxis.set_minor_formatter(NullFormatter())\n",
    "            ax.yaxis.set_major_formatter(NullFormatter())\n",
    "\n",
    "    for ax in axs[:-1, 0].ravel():\n",
    "        ax.xaxis.set_major_formatter(NullFormatter())\n",
    "        ax.xaxis.set_minor_formatter(NullFormatter())\n",
    "        ax.tick_params(axis=\"x\", which=\"both\", length=0)\n",
    "\n",
    "    for ax in axs[:-1, 1:].ravel():\n",
    "        ax.xaxis.set_major_formatter(NullFormatter())\n",
    "        ax.xaxis.set_minor_formatter(NullFormatter())\n",
    "        ax.yaxis.set_major_formatter(NullFormatter())\n",
    "        ax.yaxis.set_minor_formatter(NullFormatter())\n",
    "        ax.tick_params(axis=\"both\", which=\"both\", length=0)\n",
    "\n",
    "    l_prior = Line2D([], [], c=color_prior, lw=lw, ls=\"solid\", label=\"Prior\")\n",
    "    l_post = Line2D([], [], c=\"k\", lw=lw, ls=\"solid\", label=\"Posterior\")\n",
    "    l_post_b = Line2D(\n",
    "        [], [], c=\"0.25\", lw=lw * 0.25, ls=\"solid\", label=\"Posterior (BayesBag)\"\n",
    "    )\n",
    "\n",
    "    legend = fig.legend(\n",
    "        handles=[l_prior, l_post, l_post_b], bbox_to_anchor=(0.3, 0.955)\n",
    "    )\n",
    "    legend.get_frame().set_linewidth(0.0)\n",
    "    legend.get_frame().set_alpha(0.0)\n",
    "\n",
    "    figfile = f\"{emulator_dir}/emulator_posterior.pdf\"\n",
    "    print(f\"Saving figure to {figfile}\")\n",
    "    fig.savefig(figfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed74959",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84257391",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5e5a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02617982",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7ce49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join([f\"-{k} {d[k]}\" for k in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3727a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 100)\n",
    "a = torch.distributions.Binomial(total_count=9,probs=torch.tensor(x)).log_prob(torch.tensor([6])).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62557bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "plt.plot(x, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec308745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
