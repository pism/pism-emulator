{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95516590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.add(\"Turing\")\n",
    "Pkg.add(\"Flux\")\n",
    "Pkg.add(\"NCDatasets\")\n",
    "Pkg.add(\"TSVD\")\n",
    "Pkg.add(\"Statistics\")\n",
    "Pkg.add(\"Compat\")\n",
    "Pkg.add(\"LinearAlgebra\")\n",
    "Pkg.add(\"Glob\")\n",
    "Pkg.add(\"CSV\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"Distributions\")\n",
    "Pkg.add(\"ProgressMeter\")\n",
    "Pkg.add(\"PyPlot\")\n",
    "Pkg.add(\"Random\")\n",
    "Pkg.add(\"StatsPlots\")\n",
    "Pkg.add(\"SpecialFunctions\")\n",
    "Pkg.add(\"ReverseDiff\")\n",
    "using Turing\n",
    "using Flux\n",
    "using Flux: train!\n",
    "using Plots\n",
    "using TSVD\n",
    "using Statistics\n",
    "using LinearAlgebra\n",
    "using Compat\n",
    "using Glob\n",
    "using NCDatasets\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Distributions: Categorical, Dirichlet, Gamma, Beta\n",
    "using ProgressMeter\n",
    "using PyPlot\n",
    "using Random\n",
    "using StatsPlots\n",
    "using SpecialFunctions: loggamma\n",
    "using ReverseDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dbeac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_file =\"../data/observed_speeds/greenland_vel_mosaic250_v1_g9000m.nc\"\n",
    "d_obs = NCDataset(obs_file)\n",
    "v_obs = d_obs[\"velsurf_mag\"][:]\n",
    "v_obs = nomissing(v_obs, 0.0);\n",
    "idx = findall(v_obs .> 0)\n",
    "Obs = v_obs[idx];\n",
    "\n",
    "n_grid_points = size(idx)[1];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dc033e",
   "metadata": {},
   "source": [
    "## Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65fd3002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "training_files = sort(glob(\"../tests/training_data/*.nc\"))\n",
    "\n",
    "nf = length(training_files)\n",
    "d = NCDataset(training_files[1], \"r\")\n",
    "v = d[\"velsurf_mag\"]\n",
    "nx, ny, nt = size(v)\n",
    "\n",
    "Data = zeros(n_grid_points, nf * nt)\n",
    "ids = zeros(Int64, nf)\n",
    "@showprogress for (k, training_file) in enumerate(training_files)\n",
    "    m_id = match(r\"id_(.+?)_\", training_file)\n",
    "    ids[k] = parse(Int, m_id[1])\n",
    "    d = NCDataset(training_file, \"r\")\n",
    "    v = d[\"velsurf_mag\"][:]\n",
    "    v = nomissing(v, 0.0)\n",
    "    Data[:, k] = v[idx]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031e1c0a",
   "metadata": {},
   "source": [
    "## Read training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fee568a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = DataFrame(CSV.File(\"../data/samples/velocity_calibration_samples_50.csv\"))\n",
    "X_df = X_df[ [x in ids for x in X_df[!, :id]] ,:]\n",
    "X = transpose(Matrix(X_df[!, 2:9]))\n",
    "X_mean = mean(X, dims=2);\n",
    "X_std = std(X, dims=2);\n",
    "X_scaled = (X .- X_mean) ./ X_std;\n",
    "X_train = X_scaled;\n",
    "n_parameters, n_samples = size(X);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd2995",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Log10-transform the training data and set -Inf to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a271ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = log10.(Data)\n",
    "F = replace!(F, -Inf=>0)\n",
    "dirichlet_dist = Dirichlet(n_samples, 1)\n",
    "\n",
    "area = ones(n_grid_points);\n",
    "area = area ./ sum(area);\n",
    "\n",
    "# Number of eigenglaciers\n",
    "q = 50;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c40cee",
   "metadata": {},
   "source": [
    "## Function to get Eigenglaciers using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe79ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_eigenglaciers(omegas, F, q)\n",
    "    \n",
    "    F_mean = sum(F .* omegas, dims=2);\n",
    "    F_bar = F .- F_mean;\n",
    "\n",
    "    Z = diagm(sqrt.(omegas[1, :] * n_grid_points))\n",
    "    U, S, V = tsvd(Z * transpose(F_bar), q);\n",
    "    lamda = S.^2 / n_grid_points\n",
    "    V_hat = V * diagm(sqrt.(lamda));\n",
    "    \n",
    "    return V_hat, F_bar, F_mean\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f35efd",
   "metadata": {},
   "source": [
    "## Set up the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9370444",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 128\n",
    "\n",
    "struct NNModel\n",
    "    chain::Chain\n",
    "end\n",
    "\n",
    "function (m::NNModel)(x, add_mean=false)\n",
    "    if add_mean\n",
    "        return V_hat * m.chain(x) .+ F_mean\n",
    "    else\n",
    "        return V_hat * m.chain(x)\n",
    "    end\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "# Call @functor to allow for training. Described below in more detail.\n",
    "Flux.@functor NNModel\n",
    "\n",
    "chain = Chain(\n",
    "    Dense(n_parameters => n_hidden),\n",
    "    LayerNorm(n_hidden),\n",
    "    Dropout(0.0),\n",
    "    Dense(n_hidden => n_hidden),\n",
    "    LayerNorm(n_hidden),\n",
    "    Dropout(0.5),\n",
    "    Dense(n_hidden => n_hidden),\n",
    "    LayerNorm(n_hidden),\n",
    "    Dropout(0.5),\n",
    "    Dense(n_hidden => n_hidden),\n",
    "    LayerNorm(n_hidden),\n",
    "    Dropout(0.3),\n",
    "    Dense(n_hidden => q, bias=false),\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c9a6550",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_models = 1\n",
    "n_epochs = 101\n",
    "opt = Adam(0.1, (0.9, 0.8));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd855ed",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6eefae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(y_pred, y, o) = sum(sum(abs.((y_pred - y)).^2 .* area, dims=1) .* o);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2af854a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model_index = 1\n",
    "    Random.seed!(model_index)\n",
    "    omegas = transpose(rand(dirichlet_dist, 1))\n",
    "    omegas_0 = omegas ./ size(omegas)[1];\n",
    "    V_hat, F_bar, F_mean = get_eigenglaciers(omegas, F, q);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975cf2ab",
   "metadata": {},
   "source": [
    "## We're ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5bbf4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training surrogate model 1\n",
      "  epoch, train_loss, test_loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   5%|██                                       |  ETA: 0:03:57\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5 0.06066475650939917 0.06066475650939917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  10%|████                                     |  ETA: 0:02:11\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10 0.06070377855428051 0.06070377855428051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  15%|██████▏                                  |  ETA: 0:01:34\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  15 0.05482887630593755 0.05482887630593755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  20%|████████▏                                |  ETA: 0:01:14\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  20 0.053407082659209064 0.053407082659209064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  25%|██████████▏                              |  ETA: 0:01:02\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  25 0.05866266457145048 0.05866266457145048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  30%|████████████▏                            |  ETA: 0:00:53\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  30 0.05100992290450186 0.05100992290450186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  35%|██████████████▎                          |  ETA: 0:00:46\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  35 0.05112867697287285 0.05112867697287285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  40%|████████████████▎                        |  ETA: 0:00:40\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  40 0.051033604727100355 0.051033604727100355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  45%|██████████████████▎                      |  ETA: 0:00:35\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  45 0.05256612450378154 0.05256612450378154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  50%|████████████████████▎                    |  ETA: 0:00:31\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  50 0.051055391231564114 0.051055391231564114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  54%|██████████████████████▍                  |  ETA: 0:00:27\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  55 0.050864238361456364 0.050864238361456364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  59%|████████████████████████▍                |  ETA: 0:00:23\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  60 0.051723588927197646 0.051723588927197646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  64%|██████████████████████████▍              |  ETA: 0:00:20\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  65 0.04912256217914614 0.04912256217914614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  69%|████████████████████████████▍            |  ETA: 0:00:17\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  70 0.04655362568251399 0.04655362568251399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  74%|██████████████████████████████▌          |  ETA: 0:00:14\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  75 0.04743961538485777 0.04743961538485777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  79%|████████████████████████████████▌        |  ETA: 0:00:11\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  80 0.0471768787939831 0.0471768787939831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  84%|██████████████████████████████████▌      |  ETA: 0:00:08\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  85 0.046946051594289086 0.046946051594289086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  89%|████████████████████████████████████▌    |  ETA: 0:00:06\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  90 0.04764170892220392 0.04764170892220392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  94%|██████████████████████████████████████▋  |  ETA: 0:00:03\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  95 0.04762742624497922 0.04762742624497922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  99%|████████████████████████████████████████▋|  ETA: 0:00:00\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 0.046280718306838345 0.046280718306838345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for model_index in 1:no_models\n",
    "    println(\"Training surrogate model \", model_index)\n",
    "    Random.seed!(model_index)\n",
    "    omegas = transpose(rand(dirichlet_dist, 1))\n",
    "    omegas_0 = omegas ./ size(omegas)[1];\n",
    "    \n",
    "    V_hat, F_bar, F_mean = get_eigenglaciers(omegas, F, q);\n",
    "    train_loader = Flux.DataLoader((X_train, F_bar, omegas), batchsize = 128, shuffle = true)\n",
    "    model = NNModel(chain);\n",
    "    ps = Flux.params(model);\n",
    "    opt_state = Flux.setup(opt, model);\n",
    "    \n",
    "    println(\"  epoch, train_loss, test_loss\")\n",
    "    @showprogress for epoch in 1:n_epochs\n",
    "        for (x, y, o) in train_loader\n",
    "\n",
    "          # Calculate the gradient of the objective\n",
    "          # with respect to the parameters within the model:\n",
    "          grads = Flux.gradient(model) do m\n",
    "              y_pred = m(x)\n",
    "              loss(y_pred, y, o)\n",
    "          end\n",
    "\n",
    "          # Update the parameters so as to reduce the objective,\n",
    "          # according the chosen optimisation rule:\n",
    "          Flux.update!(opt_state, model, grads[1])\n",
    "        end\n",
    "        F_pred = model(X_scaled)\n",
    "        train_loss = loss(F_pred, F_bar, omegas)\n",
    "        test_loss = loss(F_pred, F_bar, omegas_0)\n",
    "        if epoch % 5 == 0\n",
    "            println(\"  \", epoch, \" \", train_loss, \" \", test_loss)\n",
    "        end\n",
    "    end\n",
    "    push!(models, model)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7e4257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_glaciers = 10\n",
    "p = ones(n_samples)\n",
    "p = p / sum(p)\n",
    "# This does sampling with replacement, need to figure out how to do\n",
    "# sampling without replacement\n",
    "P = Categorical(p)\n",
    "glaciers = rand(P, n_glaciers);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d80de5",
   "metadata": {},
   "source": [
    "## Now calcuate some metrics to assess the surrogate committee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be5b12c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 32.25563707162096"
     ]
    }
   ],
   "source": [
    "F_train = F\n",
    "maes = []\n",
    "for m in glaciers\n",
    "    for (model_index, model) in enumerate(models)\n",
    "        X_val = X_train[:, m]\n",
    "        Y_val = F_train[:, m]\n",
    "        Y_pred = model(X_val, true)\n",
    "        mae = Flux.mae(10 .^ mean(Y_pred, dims=2), 10 .^ mean(Y_val, dims=2))\n",
    "        push!(maes, mae)\n",
    "    end\n",
    "end\n",
    "mae = mean(maes)\n",
    "print(\"MAE: \", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f2f73b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_b = 3;\n",
    "beta_b = 3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ce47f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_target = log10.(Obs);\n",
    "Y_target = replace!(Y_target, -Inf=>0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e25250d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_resolution = ones(n_grid_points) .* 9000\n",
    "sigma = 10\n",
    "rho = 1.0 / (1e4 .^ 2)\n",
    "point_area = (grid_resolution) .^ 2\n",
    "K = point_area .* rho\n",
    "sigma_hat = sqrt.(sigma .^ 2 ./ K .^ 2)\n",
    "\n",
    "X_min = minimum(X_scaled, dims=2);\n",
    "X_max = maximum(X_scaled, dims=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75e7c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "using TransformVariables, TransformedLogDensities, LogDensityProblems, LogDensityProblemsAD,\n",
    "    DynamicHMC, DynamicHMC.Diagnostics, Parameters, Statistics, Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84099085",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct SampleBayesProblem\n",
    "    nn\n",
    "    X_min\n",
    "    X_max\n",
    "    Y_target\n",
    "    sigma_hat\n",
    "    nu\n",
    "    alpha\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3474f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "function (problem::SampleBayesProblem)(θ)\n",
    "    @unpack α = θ               # extract the parameters\n",
    "    @unpack nn, X_min, X_max, Y_target, sigma_hat, nu, alpha = problem       # extract the data\n",
    "    \n",
    "    Y_pred = 10 .^ nn(α, true)\n",
    "    r = Y_pred .- Y_target\n",
    "    t = r ./ sigma_hat\n",
    "\n",
    "    # StudentT distribution\n",
    "    loglikelihood = sum(\n",
    "        loggamma((nu + 1) / 2)\n",
    "        - loggamma(nu / 2)\n",
    "        .- log.(sqrt.(pi * nu) .* sigma_hat)\n",
    "        .- (nu + 1) / 2.0 * log.(1 .+ 1.0 / nu .* t .^ 2)\n",
    "    )\n",
    "    # Beta prior\n",
    "    X_bar = (α .- X_min) ./ (X_max - X_min)\n",
    "    logprior = sum(\n",
    "        (alpha_b - 1) * log.(X_bar) + (beta_b - 1) * log.(1 .- X_bar)\n",
    "    )\n",
    "    (alpha * loglikelihood + logprior)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e71af45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1358.303183215249"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nu = 1\n",
    "alpha = 0.01\n",
    "logp = SampleBayesProblem(models[1], X_min, X_max, Y_target, sigma_hat, nu, alpha)\n",
    "logp((α = X_0,)) # make sure that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ab2952a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching as(::NamedTuple{(:α,), Tuple{DataType}})\n\u001b[0mClosest candidates are:\n\u001b[0m  as(\u001b[91m::Type{Real}\u001b[39m, \u001b[91m::Real\u001b[39m, \u001b[91m::TransformVariables.Infinity{true}\u001b[39m) at ~/.julia/packages/TransformVariables/fpJuU/src/scalar.jl:167\n\u001b[0m  as(\u001b[91m::Type{Real}\u001b[39m, \u001b[91m::TransformVariables.Infinity{false}\u001b[39m, \u001b[91m::Real\u001b[39m) at ~/.julia/packages/TransformVariables/fpJuU/src/scalar.jl:169\n\u001b[0m  as(\u001b[91m::Type{Real}\u001b[39m, \u001b[91m::Real\u001b[39m, \u001b[91m::Real\u001b[39m) at ~/.julia/packages/TransformVariables/fpJuU/src/scalar.jl:171\n\u001b[0m  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching as(::NamedTuple{(:α,), Tuple{DataType}})\n\u001b[0mClosest candidates are:\n\u001b[0m  as(\u001b[91m::Type{Real}\u001b[39m, \u001b[91m::Real\u001b[39m, \u001b[91m::TransformVariables.Infinity{true}\u001b[39m) at ~/.julia/packages/TransformVariables/fpJuU/src/scalar.jl:167\n\u001b[0m  as(\u001b[91m::Type{Real}\u001b[39m, \u001b[91m::TransformVariables.Infinity{false}\u001b[39m, \u001b[91m::Real\u001b[39m) at ~/.julia/packages/TransformVariables/fpJuU/src/scalar.jl:169\n\u001b[0m  as(\u001b[91m::Type{Real}\u001b[39m, \u001b[91m::Real\u001b[39m, \u001b[91m::Real\u001b[39m) at ~/.julia/packages/TransformVariables/fpJuU/src/scalar.jl:171\n\u001b[0m  ...",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[74]:2"
     ]
    }
   ],
   "source": [
    "trans = as((α = as𝕀,))\n",
    "trans = as((α = TransformVariables.UnitVector, ))\n",
    "P = TransformedLogDensity(trans, logp)\n",
    "∇P = ADgradient(:Zygote, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2099d664",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching (::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}})(::Float64)\n\u001b[0mClosest candidates are:\n\u001b[0m  (::Dense)(\u001b[91m::AbstractVecOrMat\u001b[39m) at ~/.julia/packages/Flux/v79Am/src/layers/basic.jl:170\n\u001b[0m  (::Dense)(\u001b[91m::AbstractArray\u001b[39m) at ~/.julia/packages/Flux/v79Am/src/layers/basic.jl:175",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching (::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}})(::Float64)\n\u001b[0mClosest candidates are:\n\u001b[0m  (::Dense)(\u001b[91m::AbstractVecOrMat\u001b[39m) at ~/.julia/packages/Flux/v79Am/src/layers/basic.jl:170\n\u001b[0m  (::Dense)(\u001b[91m::AbstractArray\u001b[39m) at ~/.julia/packages/Flux/v79Am/src/layers/basic.jl:175",
      "",
      "Stacktrace:",
      "  [1] macro expansion",
      "    @ ~/.julia/packages/Zygote/AS0Go/src/compiler/interface2.jl:0 [inlined]",
      "  [2] _pullback(ctx::Zygote.Context{false}, f::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, args::Float64)",
      "    @ Zygote ~/.julia/packages/Zygote/AS0Go/src/compiler/interface2.jl:9",
      "  [3] macro expansion",
      "    @ ~/.julia/packages/Flux/v79Am/src/layers/basic.jl:53 [inlined]",
      "  [4] _pullback",
      "    @ ~/.julia/packages/Flux/v79Am/src/layers/basic.jl:53 [inlined]",
      "  [5] _pullback(::Zygote.Context{false}, ::typeof(Flux._applychain), ::Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Bool}}, ::Float64)",
      "    @ Zygote ~/.julia/packages/Zygote/AS0Go/src/compiler/interface2.jl:0",
      "  [6] _pullback",
      "    @ ~/.julia/packages/Flux/v79Am/src/layers/basic.jl:51 [inlined]",
      "  [7] _pullback(ctx::Zygote.Context{false}, f::Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Bool}}}, args::Float64)",
      "    @ Zygote ~/.julia/packages/Zygote/AS0Go/src/compiler/interface2.jl:0",
      "  [8] _pullback",
      "    @ ./In[19]:0 [inlined]",
      "  [9] _pullback(::Zygote.Context{false}, ::NNModel, ::Float64, ::Bool)",
      "    @ Zygote ~/.julia/packages/Zygote/AS0Go/src/compiler/interface2.jl:0",
      " [10] _pullback",
      "    @ ./In[59]:4 [inlined]",
      " [11] _pullback(ctx::Zygote.Context{false}, f::SampleBayesProblem, args::NamedTuple{(:α,), Tuple{Float64}})",
      "    @ Zygote ~/.julia/packages/Zygote/AS0Go/src/compiler/interface2.jl:0",
      " [12] _pullback",
      "    @ ~/.julia/packages/TransformVariables/fpJuU/src/generic.jl:217 [inlined]",
      " [13] _pullback(::Zygote.Context{false}, ::typeof(transform_logdensity), ::TransformVariables.TransformTuple{NamedTuple{(:α,), Tuple{TransformVariables.ScaledShiftedLogistic{Int64}}}}, ::SampleBayesProblem, ::Vector{Float64})",
      "    @ Zygote ~/.julia/packages/Zygote/AS0Go/src/compiler/interface2.jl:0",
      " [14] _pullback",
      "    @ ~/.julia/packages/TransformedLogDensities/c6B0x/src/TransformedLogDensities.jl:56 [inlined]",
      " [15] _pullback(::Zygote.Context{false}, ::typeof(LogDensityProblems.logdensity), ::TransformedLogDensity{TransformVariables.TransformTuple{NamedTuple{(:α,), Tuple{TransformVariables.ScaledShiftedLogistic{Int64}}}}, SampleBayesProblem}, ::Vector{Float64})",
      "    @ Zygote ~/.julia/packages/Zygote/AS0Go/src/compiler/interface2.jl:0",
      " [16] _pullback",
      "    @ ~/.julia/packages/Zygote/AS0Go/src/lib/base.jl:225 [inlined]",
      " [17] _pullback(ctx::Zygote.Context{false}, f::Zygote.var\"#fallback_Fix1#338\"{TransformedLogDensity{TransformVariables.TransformTuple{NamedTuple{(:α,), Tuple{TransformVariables.ScaledShiftedLogistic{Int64}}}}, SampleBayesProblem}, typeof(LogDensityProblems.logdensity)}, args::Vector{Float64})",
      "    @ Zygote ~/.julia/packages/Zygote/AS0Go/src/compiler/interface2.jl:0",
      " [18] adjoint",
      "    @ ~/.julia/packages/Zygote/AS0Go/src/lib/base.jl:226 [inlined]",
      " [19] _pullback",
      "    @ ~/.julia/packages/ZygoteRules/AIbCs/src/adjoint.jl:65 [inlined]",
      " [20] pullback",
      "    @ ~/.julia/packages/Zygote/AS0Go/src/compiler/interface.jl:44 [inlined]",
      " [21] pullback",
      "    @ ~/.julia/packages/Zygote/AS0Go/src/compiler/interface.jl:42 [inlined]",
      " [22] logdensity_and_gradient(∇ℓ::LogDensityProblemsAD.ZygoteGradientLogDensity{TransformedLogDensity{TransformVariables.TransformTuple{NamedTuple{(:α,), Tuple{TransformVariables.ScaledShiftedLogistic{Int64}}}}, SampleBayesProblem}}, x::Vector{Float64})",
      "    @ LogDensityProblemsAD ~/.julia/packages/LogDensityProblemsAD/aJ61o/src/AD_Zygote.jl:19",
      " [23] evaluate_ℓ(ℓ::LogDensityProblemsAD.ZygoteGradientLogDensity{TransformedLogDensity{TransformVariables.TransformTuple{NamedTuple{(:α,), Tuple{TransformVariables.ScaledShiftedLogistic{Int64}}}}, SampleBayesProblem}}, q::Vector{Float64}; strict::Bool)",
      "    @ DynamicHMC ~/.julia/packages/DynamicHMC/Sg1nE/src/hamiltonian.jl:204",
      " [24] initialize_warmup_state(rng::TaskLocalRNG, ℓ::LogDensityProblemsAD.ZygoteGradientLogDensity{TransformedLogDensity{TransformVariables.TransformTuple{NamedTuple{(:α,), Tuple{TransformVariables.ScaledShiftedLogistic{Int64}}}}, SampleBayesProblem}}; q::Vector{Float64}, κ::GaussianKineticEnergy{Diagonal{Float64, FillArrays.Fill{Float64, 1, Tuple{Base.OneTo{Int64}}}}, Diagonal{Float64, Vector{Float64}}}, ϵ::Float64)",
      "    @ DynamicHMC ~/.julia/packages/DynamicHMC/Sg1nE/src/mcmc.jl:125",
      " [25] mcmc_keep_warmup(rng::TaskLocalRNG, ℓ::LogDensityProblemsAD.ZygoteGradientLogDensity{TransformedLogDensity{TransformVariables.TransformTuple{NamedTuple{(:α,), Tuple{TransformVariables.ScaledShiftedLogistic{Int64}}}}, SampleBayesProblem}}, N::Int64; initialization::NamedTuple{(:ϵ,), Tuple{Float64}}, warmup_stages::Tuple{InitialStepsizeSearch, TuningNUTS{Nothing, DualAveraging{Float64}}, TuningNUTS{Symmetric, DualAveraging{Float64}}, TuningNUTS{Symmetric, DualAveraging{Float64}}, TuningNUTS{Symmetric, DualAveraging{Float64}}, TuningNUTS{Symmetric, DualAveraging{Float64}}, TuningNUTS{Symmetric, DualAveraging{Float64}}, TuningNUTS{Nothing, DualAveraging{Float64}}}, algorithm::DynamicHMC.NUTS{Val{:generalized}}, reporter::LogProgressReport{Nothing})",
      "    @ DynamicHMC ~/.julia/packages/DynamicHMC/Sg1nE/src/mcmc.jl:496",
      " [26] macro expansion",
      "    @ ~/.julia/packages/UnPack/EkESO/src/UnPack.jl:100 [inlined]",
      " [27] mcmc_with_warmup(rng::TaskLocalRNG, ℓ::LogDensityProblemsAD.ZygoteGradientLogDensity{TransformedLogDensity{TransformVariables.TransformTuple{NamedTuple{(:α,), Tuple{TransformVariables.ScaledShiftedLogistic{Int64}}}}, SampleBayesProblem}}, N::Int64; initialization::NamedTuple{(:ϵ,), Tuple{Float64}}, warmup_stages::Tuple{InitialStepsizeSearch, TuningNUTS{Nothing, DualAveraging{Float64}}, TuningNUTS{Symmetric, DualAveraging{Float64}}, TuningNUTS{Symmetric, DualAveraging{Float64}}, TuningNUTS{Symmetric, DualAveraging{Float64}}, TuningNUTS{Symmetric, DualAveraging{Float64}}, TuningNUTS{Symmetric, DualAveraging{Float64}}, TuningNUTS{Nothing, DualAveraging{Float64}}}, algorithm::DynamicHMC.NUTS{Val{:generalized}}, reporter::LogProgressReport{Nothing})",
      "    @ DynamicHMC ~/.julia/packages/DynamicHMC/Sg1nE/src/mcmc.jl:547",
      " [28] top-level scope",
      "    @ In[63]:1"
     ]
    }
   ],
   "source": [
    "results = mcmc_with_warmup(Random.default_rng(), ∇P, 1000; \n",
    "    warmup_stages = default_warmup_stages(; M = Symmetric),\n",
    "    initialization = (ϵ = 0.1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b80318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_tree_statistics(results.tree_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f6690c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian logistic regression (LR)\n",
    "@model function bayes_nn(x, X_min, X_max, Y_target, sigma_hat, nu=1, alpha=0.01)\n",
    "\n",
    "    mu ~ Normal(0, 0.1)\n",
    "    x ~ MvNormal(mu, 0.5)\n",
    "    Y_pred = 10 .^ models[1](X, true)\n",
    "    r = Y_pred .- Y_target\n",
    "    t = r ./ sigma_hat\n",
    "    \n",
    "    log_likelihood = sum(\n",
    "        loggamma((nu + 1) / 2)\n",
    "        - loggamma(nu / 2)\n",
    "        .- log.(sqrt.(pi * nu) .* sigma_hat)\n",
    "        .- (nu + 1) / 2.0 * log.(1 .+ 1.0 / nu .* t .^ 2)\n",
    "    )\n",
    "\n",
    "    X_bar = (X .- X_min) ./ (X_max - X_min)\n",
    "    log_prior = sum(\n",
    "        (alpha_b - 1) * log.(X_bar) + (beta_b - 1) * log.(1 .- X_bar)\n",
    "    )\n",
    "\n",
    "    log_prob = alpha * log_likelihood + log_prior\n",
    "\n",
    "    \n",
    "    return x\n",
    "end;\n",
    "\n",
    "beta_dist = Beta(alpha_b, beta_b)\n",
    "X_prior = rand(beta_dist, n_parameters, 100000) .* (X_max - X_min) .+ X_min\n",
    "X_0 = mean(X_prior, dims=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0685010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = transform.(trans, eachcol(results.posterior_matrix))\n",
    "posterior_α = first.(posterior)\n",
    "mean(posterior_α)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a039744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function log_prob(X, X_min, X_max, Y_target, sigma_hat, nu=1, alpha=0.01)\n",
    "    \n",
    "    Y_pred = 10 .^ models[1](X, true)\n",
    "    r = Y_pred .- Y_target\n",
    "    t = r ./ sigma_hat\n",
    "    \n",
    "    log_likelihood = sum(\n",
    "        loggamma((nu + 1) / 2)\n",
    "        - loggamma(nu / 2)\n",
    "        .- log.(sqrt.(pi * nu) .* sigma_hat)\n",
    "        .- (nu + 1) / 2.0 * log.(1 .+ 1.0 / nu .* t .^ 2)\n",
    "    )\n",
    "\n",
    "    X_bar = (X .- X_min) ./ (X_max - X_min)\n",
    "    log_prior = sum(\n",
    "        (alpha_b - 1) * log.(X_bar) + (beta_b - 1) * log.(1 .- X_bar)\n",
    "    )\n",
    "\n",
    "    log_prob = alpha * log_likelihood + log_prior\n",
    "    \n",
    "    return -log_prob\n",
    "end;\n",
    "\n",
    "beta_dist = Beta(alpha_b, beta_b)\n",
    "X_prior = rand(beta_dist, n_parameters, 100000) .* (X_max - X_min) .+ X_min\n",
    "X_0 = mean(X_prior, dims=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8d5c3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1m_\u001b[22m\u001b[0m\u001b[1mw\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mh\u001b[22m\u001b[0m\u001b[1m_\u001b[22m\u001b[0m\u001b[1mw\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mp\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "mcmc_with_warmup(\n",
       "    rng,\n",
       "    ℓ,\n",
       "    N;\n",
       "    initialization,\n",
       "    warmup_stages,\n",
       "    algorithm,\n",
       "    reporter\n",
       ")\n",
       "\n",
       "\\end{verbatim}\n",
       "Perform MCMC with NUTS, including warmup which is not returned. Return a \\texttt{NamedTuple} of\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{posterior\\_matrix}, a matrix of position vectors, indexes by \\texttt{[parameter\\_index, draw\\_index]}\n",
       "\n",
       "\n",
       "\\item \\texttt{tree\\_statistics}, a vector of tree statistics for each sample\n",
       "\n",
       "\n",
       "\\item \\texttt{κ} and \\texttt{ϵ}, the adapted metric and stepsize.\n",
       "\n",
       "\\end{itemize}\n",
       "\\section{Arguments}\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{rng}: the random number generator, eg \\texttt{Random.GLOBAL\\_RNG}.\n",
       "\n",
       "\n",
       "\\item \\texttt{ℓ}: the log density, supporting the API of the \\texttt{LogDensityProblems} package\n",
       "\n",
       "\n",
       "\\item \\texttt{N}: the number of samples for inference, after the warmup.\n",
       "\n",
       "\\end{itemize}\n",
       "\\section{Keyword arguments}\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{initialization}: see below.\n",
       "\n",
       "\n",
       "\\item \\texttt{warmup\\_stages}: a sequence of warmup stages. See \\href{@ref}{\\texttt{default\\_warmup\\_stages}} and \\href{@ref}{\\texttt{fixed\\_stepsize\\_warmup\\_stages}}; the latter requires an \\texttt{ϵ} in initialization.\n",
       "\n",
       "\n",
       "\\item \\texttt{algorithm}: see \\href{@ref}{\\texttt{NUTS}}. It is very unlikely you need to modify this, except perhaps for the maximum depth.\n",
       "\n",
       "\n",
       "\\item \\texttt{reporter}: how progress is reported. By default, verbosely for interactive sessions using the log message mechanism (see \\href{@ref}{\\texttt{LogProgressReport}}, and no reporting for non-interactive sessions (see \\href{@ref}{\\texttt{NoProgressReport}}).\n",
       "\n",
       "\\end{itemize}\n",
       "\\section{Initialization}\n",
       "The \\texttt{initialization} keyword argument should be a \\texttt{NamedTuple} which can contain the following fields (all of them optional and provided with reasonable defaults):\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{q}: initial position. \\emph{Default}: random (uniform [-2,2] for each coordinate).\n",
       "\n",
       "\n",
       "\\item \\texttt{κ}: kinetic energy specification. \\emph{Default}: Gaussian with identity matrix.\n",
       "\n",
       "\n",
       "\\item \\texttt{ϵ}: a scalar for initial stepsize, or \\texttt{nothing} for heuristic finders.\n",
       "\n",
       "\\end{itemize}\n",
       "\\section{Usage examples}\n",
       "Using a fixed stepsize:\n",
       "\n",
       "\\begin{verbatim}\n",
       "mcmc_with_warmup(rng, ℓ, N;\n",
       "                 initialization = (ϵ = 0.1, ),\n",
       "                 warmup_stages = fixed_stepsize_warmup_stages())\n",
       "\\end{verbatim}\n",
       "Starting from a given position \\texttt{q₀} and kinetic energy scaled down (will still be adapted):\n",
       "\n",
       "\\begin{verbatim}\n",
       "mcmc_with_warmup(rng, ℓ, N;\n",
       "                 initialization = (q = q₀, κ = GaussianKineticEnergy(5, 0.1)))\n",
       "\\end{verbatim}\n",
       "Using a dense metric:\n",
       "\n",
       "\\begin{verbatim}\n",
       "mcmc_with_warmup(rng, ℓ, N;\n",
       "                 warmup_stages = default_warmup_stages(; M = Symmetric))\n",
       "\\end{verbatim}\n",
       "Disabling the initial stepsize search (provided explicitly, still adapted):\n",
       "\n",
       "\\begin{verbatim}\n",
       "mcmc_with_warmup(rng, ℓ, N;\n",
       "                 initialization = (ϵ = 1.0, ),\n",
       "                 warmup_stages = default_warmup_stages(; stepsize_search = nothing))\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```julia\n",
       "mcmc_with_warmup(\n",
       "    rng,\n",
       "    ℓ,\n",
       "    N;\n",
       "    initialization,\n",
       "    warmup_stages,\n",
       "    algorithm,\n",
       "    reporter\n",
       ")\n",
       "\n",
       "```\n",
       "\n",
       "Perform MCMC with NUTS, including warmup which is not returned. Return a `NamedTuple` of\n",
       "\n",
       "  * `posterior_matrix`, a matrix of position vectors, indexes by `[parameter_index, draw_index]`\n",
       "  * `tree_statistics`, a vector of tree statistics for each sample\n",
       "  * `κ` and `ϵ`, the adapted metric and stepsize.\n",
       "\n",
       "# Arguments\n",
       "\n",
       "  * `rng`: the random number generator, eg `Random.GLOBAL_RNG`.\n",
       "  * `ℓ`: the log density, supporting the API of the `LogDensityProblems` package\n",
       "  * `N`: the number of samples for inference, after the warmup.\n",
       "\n",
       "# Keyword arguments\n",
       "\n",
       "  * `initialization`: see below.\n",
       "  * `warmup_stages`: a sequence of warmup stages. See [`default_warmup_stages`](@ref) and [`fixed_stepsize_warmup_stages`](@ref); the latter requires an `ϵ` in initialization.\n",
       "  * `algorithm`: see [`NUTS`](@ref). It is very unlikely you need to modify this, except perhaps for the maximum depth.\n",
       "  * `reporter`: how progress is reported. By default, verbosely for interactive sessions using the log message mechanism (see [`LogProgressReport`](@ref), and no reporting for non-interactive sessions (see [`NoProgressReport`](@ref)).\n",
       "\n",
       "# Initialization\n",
       "\n",
       "The `initialization` keyword argument should be a `NamedTuple` which can contain the following fields (all of them optional and provided with reasonable defaults):\n",
       "\n",
       "  * `q`: initial position. *Default*: random (uniform [-2,2] for each coordinate).\n",
       "  * `κ`: kinetic energy specification. *Default*: Gaussian with identity matrix.\n",
       "  * `ϵ`: a scalar for initial stepsize, or `nothing` for heuristic finders.\n",
       "\n",
       "# Usage examples\n",
       "\n",
       "Using a fixed stepsize:\n",
       "\n",
       "```julia\n",
       "mcmc_with_warmup(rng, ℓ, N;\n",
       "                 initialization = (ϵ = 0.1, ),\n",
       "                 warmup_stages = fixed_stepsize_warmup_stages())\n",
       "```\n",
       "\n",
       "Starting from a given position `q₀` and kinetic energy scaled down (will still be adapted):\n",
       "\n",
       "```julia\n",
       "mcmc_with_warmup(rng, ℓ, N;\n",
       "                 initialization = (q = q₀, κ = GaussianKineticEnergy(5, 0.1)))\n",
       "```\n",
       "\n",
       "Using a dense metric:\n",
       "\n",
       "```julia\n",
       "mcmc_with_warmup(rng, ℓ, N;\n",
       "                 warmup_stages = default_warmup_stages(; M = Symmetric))\n",
       "```\n",
       "\n",
       "Disabling the initial stepsize search (provided explicitly, still adapted):\n",
       "\n",
       "```julia\n",
       "mcmc_with_warmup(rng, ℓ, N;\n",
       "                 initialization = (ϵ = 1.0, ),\n",
       "                 warmup_stages = default_warmup_stages(; stepsize_search = nothing))\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  mcmc_with_warmup(\u001b[39m\n",
       "\u001b[36m      rng,\u001b[39m\n",
       "\u001b[36m      ℓ,\u001b[39m\n",
       "\u001b[36m      N;\u001b[39m\n",
       "\u001b[36m      initialization,\u001b[39m\n",
       "\u001b[36m      warmup_stages,\u001b[39m\n",
       "\u001b[36m      algorithm,\u001b[39m\n",
       "\u001b[36m      reporter\u001b[39m\n",
       "\u001b[36m  )\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\n",
       "  Perform MCMC with NUTS, including warmup which is not returned. Return a\n",
       "  \u001b[36mNamedTuple\u001b[39m of\n",
       "\n",
       "    •  \u001b[36mposterior_matrix\u001b[39m, a matrix of position vectors, indexes by\n",
       "       \u001b[36m[parameter_index, draw_index]\u001b[39m\n",
       "\n",
       "    •  \u001b[36mtree_statistics\u001b[39m, a vector of tree statistics for each sample\n",
       "\n",
       "    •  \u001b[36mκ\u001b[39m and \u001b[36mϵ\u001b[39m, the adapted metric and stepsize.\n",
       "\n",
       "\u001b[1m  Arguments\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "    •  \u001b[36mrng\u001b[39m: the random number generator, eg \u001b[36mRandom.GLOBAL_RNG\u001b[39m.\n",
       "\n",
       "    •  \u001b[36mℓ\u001b[39m: the log density, supporting the API of the \u001b[36mLogDensityProblems\u001b[39m\n",
       "       package\n",
       "\n",
       "    •  \u001b[36mN\u001b[39m: the number of samples for inference, after the warmup.\n",
       "\n",
       "\u001b[1m  Keyword arguments\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "    •  \u001b[36minitialization\u001b[39m: see below.\n",
       "\n",
       "    •  \u001b[36mwarmup_stages\u001b[39m: a sequence of warmup stages. See\n",
       "       \u001b[36mdefault_warmup_stages\u001b[39m and \u001b[36mfixed_stepsize_warmup_stages\u001b[39m; the latter\n",
       "       requires an \u001b[36mϵ\u001b[39m in initialization.\n",
       "\n",
       "    •  \u001b[36malgorithm\u001b[39m: see \u001b[36mNUTS\u001b[39m. It is very unlikely you need to modify this,\n",
       "       except perhaps for the maximum depth.\n",
       "\n",
       "    •  \u001b[36mreporter\u001b[39m: how progress is reported. By default, verbosely for\n",
       "       interactive sessions using the log message mechanism (see\n",
       "       \u001b[36mLogProgressReport\u001b[39m, and no reporting for non-interactive sessions\n",
       "       (see \u001b[36mNoProgressReport\u001b[39m).\n",
       "\n",
       "\u001b[1m  Initialization\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "  The \u001b[36minitialization\u001b[39m keyword argument should be a \u001b[36mNamedTuple\u001b[39m which can contain\n",
       "  the following fields (all of them optional and provided with reasonable\n",
       "  defaults):\n",
       "\n",
       "    •  \u001b[36mq\u001b[39m: initial position. \u001b[4mDefault\u001b[24m: random (uniform [-2,2] for each\n",
       "       coordinate).\n",
       "\n",
       "    •  \u001b[36mκ\u001b[39m: kinetic energy specification. \u001b[4mDefault\u001b[24m: Gaussian with identity\n",
       "       matrix.\n",
       "\n",
       "    •  \u001b[36mϵ\u001b[39m: a scalar for initial stepsize, or \u001b[36mnothing\u001b[39m for heuristic\n",
       "       finders.\n",
       "\n",
       "\u001b[1m  Usage examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "  Using a fixed stepsize:\n",
       "\n",
       "\u001b[36m  mcmc_with_warmup(rng, ℓ, N;\u001b[39m\n",
       "\u001b[36m                   initialization = (ϵ = 0.1, ),\u001b[39m\n",
       "\u001b[36m                   warmup_stages = fixed_stepsize_warmup_stages())\u001b[39m\n",
       "\n",
       "  Starting from a given position \u001b[36mq₀\u001b[39m and kinetic energy scaled down (will still\n",
       "  be adapted):\n",
       "\n",
       "\u001b[36m  mcmc_with_warmup(rng, ℓ, N;\u001b[39m\n",
       "\u001b[36m                   initialization = (q = q₀, κ = GaussianKineticEnergy(5, 0.1)))\u001b[39m\n",
       "\n",
       "  Using a dense metric:\n",
       "\n",
       "\u001b[36m  mcmc_with_warmup(rng, ℓ, N;\u001b[39m\n",
       "\u001b[36m                   warmup_stages = default_warmup_stages(; M = Symmetric))\u001b[39m\n",
       "\n",
       "  Disabling the initial stepsize search (provided explicitly, still adapted):\n",
       "\n",
       "\u001b[36m  mcmc_with_warmup(rng, ℓ, N;\u001b[39m\n",
       "\u001b[36m                   initialization = (ϵ = 1.0, ),\u001b[39m\n",
       "\u001b[36m                   warmup_stages = default_warmup_stages(; stepsize_search = nothing))\u001b[39m"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?mcmc_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e51ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = mcmc_with_warmup(Random.default_rng(), ∇P, 1000; initialization = (ϵ = 0.1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4939f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logp_g(X) = logp_f(X, X_min, X_max, Y_target, sigma_hat)\n",
    "pathfinder(logp_g, X_0, 100; ndraws_elbo=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e1a2c2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "# 13 methods for generic function <b>as</b>:<ul><li> as(::<b>Type{Real}</b>, left::<b>Real</b>, ::<b>TransformVariables.Infinity{true}</b>) in TransformVariables at <a href=\"file:///Users/andy/.julia/packages/TransformVariables/fpJuU/src/scalar.jl\" target=\"_blank\">/Users/andy/.julia/packages/TransformVariables/fpJuU/src/scalar.jl:167</a></li> <li> as(::<b>Type{Real}</b>, ::<b>TransformVariables.Infinity{false}</b>, right::<b>Real</b>) in TransformVariables at <a href=\"file:///Users/andy/.julia/packages/TransformVariables/fpJuU/src/scalar.jl\" target=\"_blank\">/Users/andy/.julia/packages/TransformVariables/fpJuU/src/scalar.jl:169</a></li> <li> as(::<b>Type{Real}</b>, left::<b>Real</b>, right::<b>Real</b>) in TransformVariables at <a href=\"file:///Users/andy/.julia/packages/TransformVariables/fpJuU/src/scalar.jl\" target=\"_blank\">/Users/andy/.julia/packages/TransformVariables/fpJuU/src/scalar.jl:171</a></li> <li> as(::<b>Type{Array}</b>, transformation::<b>TransformVariables.AbstractTransform</b>, dims::<b>Tuple{Vararg{Int64}}</b>) in TransformVariables at <a href=\"file:///Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl\" target=\"_blank\">/Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl:35</a></li> <li> as(::<b>Type{Array}</b>, dims::<b>Tuple{Vararg{Int64}}</b>) in TransformVariables at <a href=\"file:///Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl\" target=\"_blank\">/Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl:38</a></li> <li> as(::<b>Type{Array}</b>, transformation::<b>TransformVariables.AbstractTransform</b>, dims::<b>Int64...</b>) in TransformVariables at <a href=\"file:///Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl\" target=\"_blank\">/Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl:40</a></li> <li> as(transformations::<b>Tuple{Vararg{TransformVariables.AbstractTransform, N}} where N</b>) in TransformVariables at <a href=\"file:///Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl\" target=\"_blank\">/Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl:152</a></li> <li> as(transformations::<b>NamedTuple{N, <:Tuple{Vararg{TransformVariables.AbstractTransform, N}} where N}</b>)<i> where N</i> in TransformVariables at <a href=\"file:///Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl\" target=\"_blank\">/Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl:223</a></li> <li> as(::<b>Type{Real}</b>, ::<b>TransformVariables.Infinity{false}</b>, ::<b>TransformVariables.Infinity{true}</b>) in TransformVariables at <a href=\"file:///Users/andy/.julia/packages/TransformVariables/fpJuU/src/scalar.jl\" target=\"_blank\">/Users/andy/.julia/packages/TransformVariables/fpJuU/src/scalar.jl:165</a></li> <li> as(::<b>Type{Real}</b>, left, right) in TransformVariables at <a href=\"file:///Users/andy/.julia/packages/TransformVariables/fpJuU/src/scalar.jl\" target=\"_blank\">/Users/andy/.julia/packages/TransformVariables/fpJuU/src/scalar.jl:162</a></li> <li> as(::<b>Type{Array}</b>, dims::<b>Int64...</b>) in TransformVariables at <a href=\"file:///Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl\" target=\"_blank\">/Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl:43</a></li> <li> as(::<b>Type{Vector}</b>, args...) in TransformVariables at <a href=\"file:///Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl\" target=\"_blank\">/Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl:45</a></li> <li> as(::<b>Type{Matrix}</b>, args...) in TransformVariables at <a href=\"file:///Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl\" target=\"_blank\">/Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl:51</a></li> </ul>"
      ],
      "text/plain": [
       "# 13 methods for generic function \"as\":\n",
       "[1] as(::Type{Real}, left::Real, ::TransformVariables.Infinity{true}) in TransformVariables at /Users/andy/.julia/packages/TransformVariables/fpJuU/src/scalar.jl:167\n",
       "[2] as(::Type{Real}, ::TransformVariables.Infinity{false}, right::Real) in TransformVariables at /Users/andy/.julia/packages/TransformVariables/fpJuU/src/scalar.jl:169\n",
       "[3] as(::Type{Real}, left::Real, right::Real) in TransformVariables at /Users/andy/.julia/packages/TransformVariables/fpJuU/src/scalar.jl:171\n",
       "[4] as(::Type{Array}, transformation::TransformVariables.AbstractTransform, dims::Tuple{Vararg{Int64}}) in TransformVariables at /Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl:35\n",
       "[5] as(::Type{Array}, dims::Tuple{Vararg{Int64}}) in TransformVariables at /Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl:38\n",
       "[6] as(::Type{Array}, transformation::TransformVariables.AbstractTransform, dims::Int64...) in TransformVariables at /Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl:40\n",
       "[7] as(transformations::Tuple{Vararg{TransformVariables.AbstractTransform, N}} where N) in TransformVariables at /Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl:152\n",
       "[8] as(transformations::NamedTuple{N, <:Tuple{Vararg{TransformVariables.AbstractTransform, N}} where N}) where N in TransformVariables at /Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl:223\n",
       "[9] as(::Type{Real}, ::TransformVariables.Infinity{false}, ::TransformVariables.Infinity{true}) in TransformVariables at /Users/andy/.julia/packages/TransformVariables/fpJuU/src/scalar.jl:165\n",
       "[10] as(::Type{Real}, left, right) in TransformVariables at /Users/andy/.julia/packages/TransformVariables/fpJuU/src/scalar.jl:162\n",
       "[11] as(::Type{Array}, dims::Int64...) in TransformVariables at /Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl:43\n",
       "[12] as(::Type{Vector}, args...) in TransformVariables at /Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl:45\n",
       "[13] as(::Type{Matrix}, args...) in TransformVariables at /Users/andy/.julia/packages/TransformVariables/fpJuU/src/aggregation.jl:51"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods(as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fd763b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnitVector"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TransformVariables.UnitVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "baa30844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "abstract type VectorTransform <: TransformVariables.AbstractTransform\n",
       "\\end{verbatim}\n",
       "Transformation that transforms \\texttt{<: AbstractVector}s to other values.\n",
       "\n",
       "\\section{Implementation}\n",
       "Implements \\href{@ref}{\\texttt{transform}} and \\href{@ref}{\\texttt{transform\\_and\\_logjac}} via \\href{@ref}{\\texttt{transform\\_with}}, and \\href{@ref}{\\texttt{inverse}} via \\href{@ref}{\\texttt{inverse!}}.\n",
       "\n"
      ],
      "text/markdown": [
       "```julia\n",
       "abstract type VectorTransform <: TransformVariables.AbstractTransform\n",
       "```\n",
       "\n",
       "Transformation that transforms `<: AbstractVector`s to other values.\n",
       "\n",
       "# Implementation\n",
       "\n",
       "Implements [`transform`](@ref) and [`transform_and_logjac`](@ref) via [`transform_with`](@ref), and [`inverse`](@ref) via [`inverse!`](@ref).\n"
      ],
      "text/plain": [
       "\u001b[36m  abstract type VectorTransform <: TransformVariables.AbstractTransform\u001b[39m\n",
       "\n",
       "  Transformation that transforms \u001b[36m<: AbstractVector\u001b[39ms to other values.\n",
       "\n",
       "\u001b[1m  Implementation\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "  Implements \u001b[36mtransform\u001b[39m and \u001b[36mtransform_and_logjac\u001b[39m via \u001b[36mtransform_with\u001b[39m, and\n",
       "  \u001b[36minverse\u001b[39m via \u001b[36minverse!\u001b[39m."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?TransformVariables.VectorTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec09b5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
