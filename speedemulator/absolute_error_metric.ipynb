{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f72b24",
   "metadata": {},
   "source": [
    "# Show metrics are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e38f8f3",
   "metadata": {},
   "source": [
    "Create some tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bbeb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0, 1, 2, 3], [1, 2, 3, 4]]).T\n",
    "y = torch.tensor([[0, 1, 2, 1], [2, 3, 4, 4]]).T\n",
    "o = torch.tensor([0.25, 0.25, 0.3, 0.2])\n",
    "a = torch.tensor([0.25, 0.25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f745f7e8",
   "metadata": {},
   "source": [
    "Absolute Error Metrics implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef847280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torchmetrics.utilities.checks import _check_same_shape\n",
    "from torchmetrics import Metric\n",
    "\n",
    "def _absolute_error_update(preds: Tensor, target: Tensor, area: Tensor) -> Tensor:\n",
    "    _check_same_shape(preds, target)\n",
    "    diff = torch.abs(preds - target)\n",
    "    sum_absolute_error = torch.sum(diff * diff * area, axis=1)\n",
    "    return sum_absolute_error\n",
    "\n",
    "\n",
    "def _absolute_error_compute(sum_absolute_error: Tensor, omegas: Tensor) -> Tensor:\n",
    "    return torch.sum(sum_absolute_error * omegas.squeeze())\n",
    "\n",
    "\n",
    "def absolute_error(\n",
    "    preds: Tensor, target: Tensor, omegas: Tensor, area: Tensor\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Computes squared absolute error\n",
    "    Args:\n",
    "        preds: estimated labels\n",
    "        target: ground truth labels\n",
    "        omegas\n",
    "    Return:\n",
    "        Tensor with ASE\n",
    "    Example:\n",
    "        >>> from torchmetrics.functional import mean_squared_error\n",
    "        >>> x = torch.tensor([0., 1, 2, 3])\n",
    "        >>> y = torch.tensor([0., 1, 2, 2])\n",
    "        >>> mean_squared_error(x, y)\n",
    "        tensor(0.2500)\n",
    "    \"\"\"\n",
    "    sum_abs_error = _absolute_error_update(preds, target, area)\n",
    "    return _absolute_error_compute(sum_abs_error, omegas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8633a8dd",
   "metadata": {},
   "source": [
    "Criteriona AE implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4933a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion_ae(F_pred, F_obs, omegas, area):\n",
    "    instance_misfit = torch.sum(torch.abs(F_pred - F_obs) ** 2 * area, axis=1)\n",
    "    return torch.sum(instance_misfit * omegas.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42609bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.testing import assert_almost_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa6d03a",
   "metadata": {},
   "source": [
    "This shows that both codes produce the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7cc87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(absolute_error(x, y, o, a))\n",
    "print(criterion_ae(x, y, o, a))\n",
    "assert_almost_equal(absolute_error(x, y, o, a), criterion_ae(x, y, o, a), decimal=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb85d7f",
   "metadata": {},
   "source": [
    "Now split into 2 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c089457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_ae_1 = _absolute_error_update(x[0:2], y[0:2], a)\n",
    "sum_ae_2 = _absolute_error_update(x[2:4], y[2:4], a)\n",
    "sum_ae = _absolute_error_compute(sum_ae_1, o[0:2]) + _absolute_error_compute(sum_ae_2, o[2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da36ae9",
   "metadata": {},
   "source": [
    "This shows that we can compute the absolute error per batch and then sum up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3e285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_almost_equal(absolute_error(x, y, o, a), sum_ae, decimal=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dc9866",
   "metadata": {},
   "source": [
    "However, we do have to refactor the code to properly implement it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a5262",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _absolute_error_update(\n",
    "    preds: Tensor, target: Tensor, omegas: Tensor, area: Tensor\n",
    ") -> Tensor:\n",
    "    _check_same_shape(preds, target)\n",
    "    diff = torch.abs(preds - target)\n",
    "    sum_abs_error = torch.sum(diff * diff * area, axis=1)\n",
    "    absolute_error = torch.sum(sum_abs_error * omegas.squeeze())\n",
    "    return absolute_error\n",
    "\n",
    "\n",
    "def _absolute_error_compute(absolute_error) -> Tensor:\n",
    "    return absolute_error\n",
    "\n",
    "\n",
    "def absolute_error(\n",
    "    preds: Tensor, target: Tensor, omegas: Tensor, area: Tensor\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Computes squared absolute error\n",
    "    Args:\n",
    "        preds: estimated labels\n",
    "        target: ground truth labels\n",
    "        omegas: weights\n",
    "        area: area of each cell\n",
    "    Return:\n",
    "        Tensor with absolute error\n",
    "    Example:\n",
    "        >>> x = torch.tensor([[0, 1, 2, 3], [1, 2, 3, 4]]).T\n",
    "        >>> y = torch.tensor([[0, 1, 2, 1], [2, 3, 4, 4]]).T\n",
    "        >>> o = torch.tensor([0.25, 0.25, 0.3, 0.2])\n",
    "        >>> a = torch.tensor([0.25, 0.25])\n",
    "        >>> absolute_error(x, y, o, a)\n",
    "        tensor(0.4000)\n",
    "    \"\"\"\n",
    "    sum_abs_error = _absolute_error_update(preds, target, omegas, area)\n",
    "    return _absolute_error_compute(sum_abs_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_error(x, y, o, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8432c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AbsoluteError(Metric):\n",
    "    def __init__(self, compute_on_step: bool = True, dist_sync_on_step=False):\n",
    "        # call `self.add_state`for every internal state that is needed for the metrics computations\n",
    "        # dist_reduce_fx indicates the function that should be used to reduce\n",
    "        # state from multiple processes\n",
    "        super().__init__(\n",
    "            compute_on_step=compute_on_step, dist_sync_on_step=dist_sync_on_step\n",
    "        )\n",
    "\n",
    "        self.add_state(\"sum_abs_error\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: Tensor, target: Tensor, omegas: Tensor, area: Tensor):\n",
    "        \"\"\"\n",
    "        Update state with predictions and targets, and area.\n",
    "        Args:\n",
    "            preds: Predictions from model\n",
    "            target: Ground truth values\n",
    "        \"\"\"\n",
    "        sum_abs_error = _absolute_error_update(preds, target, omegas, area)\n",
    "        self.sum_abs_error += sum_abs_error\n",
    "\n",
    "    def compute(self):\n",
    "        \"\"\"\n",
    "        Computes absolute error over state.\n",
    "        \"\"\"\n",
    "        return _absolute_error_compute(self.sum_abs_error)\n",
    "\n",
    "    @property\n",
    "    def is_differentiable(self):\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed767e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = AbsoluteError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be667c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae(x,y,o,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6bbc36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
