{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95516590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg\n",
    "Pkg.add(\"Turing\")\n",
    "Pkg.add(\"Flux\")\n",
    "Pkg.add(\"NCDatasets\")\n",
    "Pkg.add(\"TSVD\")\n",
    "Pkg.add(\"Statistics\")\n",
    "Pkg.add(\"Compat\")\n",
    "Pkg.add(\"LinearAlgebra\")\n",
    "Pkg.add(\"Glob\")\n",
    "Pkg.add(\"CSV\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"Distributions\")\n",
    "Pkg.add(\"ProgressMeter\")\n",
    "Pkg.add(\"PyPlot\")\n",
    "Pkg.add(\"Random\")\n",
    "Pkg.add(\"StatsPlots\")\n",
    "Pkg.add(\"SpecialFunctions\")\n",
    "Pkg.add(\"ReverseDiff\")\n",
    "Pkg.add(\"BSON\")\n",
    "Pkg.add(\"TransformVariables\")\n",
    "Pkg.add(\"TransformedLogDensities\")\n",
    "Pkg.add(\"LogDensityProblems\")\n",
    "Pkg.add(\"LogDensityProblemsAD\")\n",
    "Pkg.add(\"DynamicHMC\")\n",
    "Pkg.add(\"Parameters\")\n",
    "Pkg.add(\"TSVD\")\n",
    "Pkg.add(\"Glob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d319996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Statistics\n",
    "using LinearAlgebra\n",
    "using Compat\n",
    "using Glob\n",
    "using TSVD\n",
    "using NCDatasets\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Distributions: Categorical, Dirichlet, Gamma, Beta\n",
    "using ProgressMeter\n",
    "using PyPlot\n",
    "using Random\n",
    "using SpecialFunctions: loggamma\n",
    "using ReverseDiff\n",
    "using BSON: @load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dbeac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_file =\"../data/observed_speeds/greenland_vel_mosaic250_v1_g9000m.nc\"\n",
    "d_obs = NCDataset(obs_file)\n",
    "v_obs = d_obs[\"velsurf_mag\"][:]\n",
    "v_obs = nomissing(v_obs, 0.0);\n",
    "idx = findall(v_obs .> 0)\n",
    "Obs = v_obs[idx];\n",
    "\n",
    "n_grid_points = size(idx)[1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5373fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:02\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "training_files = sort(glob(\"../tests/training_data/*.nc\"))\n",
    "\n",
    "nf = length(training_files)\n",
    "d = NCDataset(training_files[1], \"r\")\n",
    "v = d[\"velsurf_mag\"]\n",
    "nx, ny, nt = size(v)\n",
    "\n",
    "Data = zeros(n_grid_points, nf * nt)\n",
    "ids = zeros(Int64, nf)\n",
    "@showprogress for (k, training_file) in enumerate(training_files)\n",
    "    m_id = match(r\"id_(.+?)_\", training_file)\n",
    "    ids[k] = parse(Int, m_id[1])\n",
    "    d = NCDataset(training_file, \"r\")\n",
    "    v = d[\"velsurf_mag\"][:]\n",
    "    v = nomissing(v, 0.0)\n",
    "    Data[:, k] = v[idx]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031e1c0a",
   "metadata": {},
   "source": [
    "## Read training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee568a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = DataFrame(CSV.File(\"../data/samples/velocity_calibration_samples_50.csv\"))\n",
    "X_df = X_df[ [x in ids for x in X_df[!, :id]] ,:]\n",
    "X = transpose(Matrix(X_df[!, 2:9]))\n",
    "X_mean = mean(X, dims=2);\n",
    "X_std = std(X, dims=2);\n",
    "X_scaled = (X .- X_mean) ./ X_std;\n",
    "X_train = X_scaled;\n",
    "n_parameters, n_samples = size(X);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd2995",
   "metadata": {},
   "source": [
    "## Load the model\n",
    "\n",
    "Should be a commmand line argument\n",
    "\n",
    "That we have to define the struct again is not ok. How can we avoid this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbbb0caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct NNModel\n",
    "    chain::Chain\n",
    "    V_hat::AbstractArray\n",
    "    F_mean::AbstractArray\n",
    "end\n",
    "\n",
    "function (m::NNModel)(x, add_mean=false)\n",
    "    if add_mean\n",
    "        return V_hat * m.chain(x) .+ F_mean\n",
    "    else\n",
    "        return V_hat * m.chain(x)\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1cdbeb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "@load \"emulator_1.bson\" model\n",
    "# model = Flux.loadmodel!(model, @load(\"mymodel.bson\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9e6da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_eigenglaciers(omegas, F, q)\n",
    "    \n",
    "    F_mean = sum(F .* omegas, dims=2);\n",
    "    F_bar = F .- F_mean;\n",
    "\n",
    "    Z = diagm(sqrt.(omegas[1, :] * n_grid_points))\n",
    "    U, S, V = tsvd(Z * transpose(F_bar), q);\n",
    "    lamda = S.^2 / n_grid_points\n",
    "    V_hat = V * diagm(sqrt.(lamda));\n",
    "    \n",
    "    return V_hat, F_bar, F_mean\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1faf9480",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 50\n",
    "F = log10.(Data)\n",
    "F = replace!(F, -Inf=>0)\n",
    "\n",
    "dirichlet_dist = Dirichlet(n_samples, 1)\n",
    "\n",
    "model_index = 1\n",
    "Random.seed!(model_index)\n",
    "omegas = transpose(rand(dirichlet_dist, 1))\n",
    "omegas_0 = omegas ./ size(omegas)[1];\n",
    "    \n",
    "V_hat, F_bar, F_mean = get_eigenglaciers(omegas, F, q);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f2f73b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_b = 3;\n",
    "beta_b = 3;\n",
    "beta_dist = Beta(alpha_b, beta_b);\n",
    "X_prior = rand(beta_dist, n_parameters, 100000);\n",
    "X_0 = mean(X_prior, dims=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ce47f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_target = log10.(Obs);\n",
    "Y_target = replace!(Y_target, -Inf=>0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e25250d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_resolution = ones(n_grid_points) .* 9000\n",
    "sigma = 10\n",
    "rho = 1.0 / (1e4 .^ 2)\n",
    "point_area = (grid_resolution) .^ 2\n",
    "K = point_area .* rho\n",
    "sigma_hat = sqrt.(sigma .^ 2 ./ K .^ 2)\n",
    "\n",
    "X_min = minimum(X_scaled, dims=2);\n",
    "X_max = maximum(X_scaled, dims=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75e7c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "using TransformVariables, TransformedLogDensities, LogDensityProblems, LogDensityProblemsAD,\n",
    "    DynamicHMC, DynamicHMC.Diagnostics, Parameters, Statistics, Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "84099085",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct SampleBayesProblem\n",
    "    nn\n",
    "    X_min::AbstractArray\n",
    "    X_max::AbstractArray\n",
    "    Y_target::AbstractArray\n",
    "    sigma_hat::AbstractArray\n",
    "    nu::Int\n",
    "    alpha::Float16\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3474f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "function (problem::SampleBayesProblem)(Œ∏)\n",
    "    @unpack Œ± = Œ∏               # extract the parameters\n",
    "    @unpack nn, X_min, X_max, Y_target, sigma_hat, nu, alpha = problem       # extract the data\n",
    "    \n",
    "    Y_pred = 10 .^ nn(Œ±, true)\n",
    "    r = Y_pred .- Y_target\n",
    "    t = r ./ sigma_hat\n",
    "\n",
    "    # StudentT distribution\n",
    "    loglikelihood = sum(\n",
    "        loggamma((nu + 1) / 2)\n",
    "        - loggamma(nu / 2)\n",
    "        .- log.(sqrt.(pi * nu) .* sigma_hat)\n",
    "        .- (nu + 1) / 2.0 * log.(1 .+ 1.0 / nu .* t .^ 2)\n",
    "    )\n",
    "    # Beta prior\n",
    "    X_bar = relu((Œ± .- X_min) ./ (X_max - X_min))\n",
    "    logprior = sum(\n",
    "        (alpha_b - 1) * log.(X_bar) + (beta_b - 1) * log.(1 .- X_bar) \n",
    "        .+ loggamma(alpha_b + beta_b) \n",
    "        .- loggamma(alpha_b)\n",
    "        .- loggamma(beta_b)\n",
    "    )\n",
    "    return (alpha * loglikelihood + logprior)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2e71af45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nu = 1\n",
    "alpha = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d18e4458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1452.0127961516039"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logp = SampleBayesProblem(model, X_min, X_max, Y_target, sigma_hat, nu, alpha)\n",
    "logp((Œ± = X_0,)) # make sure that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ab2952a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zygote AD wrapper for TransformedLogDensity of dimension 8"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = as((Œ± = as(Array, asùïÄ, n_parameters),))\n",
    "P = TransformedLogDensity(trans, logp)\n",
    "‚àáP = ADgradient(:Zygote, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2322c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LineSearches\n",
    "using Optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "76172a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "Iter     Function value   Gradient norm \n",
      "     0    -1.451702e+03     2.302032e+02\n",
      " * time: 1.9073486328125e-5\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "DomainError with -0.015968561594892794:\nlog will only return a complex result if called with a complex argument. Try log(Complex(x)).",
     "output_type": "error",
     "traceback": [
      "DomainError with -0.015968561594892794:\nlog will only return a complex result if called with a complex argument. Try log(Complex(x)).",
      "",
      "Stacktrace:",
      "  [1] throw_complex_domainerror(f::Symbol, x::Float64)",
      "    @ Base.Math ./math.jl:33",
      "  [2] _log(x::Float64, base::Val{:‚ÑØ}, func::Symbol)",
      "    @ Base.Math ./special/log.jl:301",
      "  [3] log",
      "    @ ./special/log.jl:267 [inlined]",
      "  [4] _broadcast_getindex_evalf",
      "    @ ./broadcast.jl:670 [inlined]",
      "  [5] _broadcast_getindex",
      "    @ ./broadcast.jl:643 [inlined]",
      "  [6] getindex",
      "    @ ./broadcast.jl:597 [inlined]",
      "  [7] macro expansion",
      "    @ ./broadcast.jl:961 [inlined]",
      "  [8] macro expansion",
      "    @ ./simdloop.jl:77 [inlined]",
      "  [9] copyto!",
      "    @ ./broadcast.jl:960 [inlined]",
      " [10] copyto!",
      "    @ ./broadcast.jl:913 [inlined]",
      " [11] copy",
      "    @ ./broadcast.jl:885 [inlined]",
      " [12] materialize",
      "    @ ./broadcast.jl:860 [inlined]",
      " [13] log_prior(X_bar::Matrix{Float64}, alpha_b::Int64, beta_b::Int64)",
      "    @ Main ./In[166]:2",
      " [14] logp_g(Œ±::Matrix{Float64}, nn::NNModel, X_min::Matrix{Float64}, X_max::Matrix{Float64}, Y_target::Vector{Float32}, sigma_hat::Vector{Float64}, nu::Int64, alpha::Float64)",
      "    @ Main ./In[166]:27",
      " [15] ll(X_0::Matrix{Float64})",
      "    @ Main ./In[166]:34",
      " [16] finite_difference_gradient!(df::Matrix{Float64}, f::typeof(ll), x::Matrix{Float64}, cache::FiniteDiff.GradientCache{Nothing, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}, Val{:central}(), Float64, Val{true}()}; relstep::Float64, absstep::Float64, dir::Bool)",
      "    @ FiniteDiff ~/.julia/packages/FiniteDiff/40JnL/src/gradients.jl:230",
      " [17] finite_difference_gradient!",
      "    @ ~/.julia/packages/FiniteDiff/40JnL/src/gradients.jl:172 [inlined]",
      " [18] (::NLSolversBase.var\"#g!#15\"{typeof(ll), FiniteDiff.GradientCache{Nothing, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}, Val{:central}(), Float64, Val{true}()}})(storage::Matrix{Float64}, x::Matrix{Float64})",
      "    @ NLSolversBase ~/.julia/packages/NLSolversBase/kavn7/src/objective_types/oncedifferentiable.jl:57",
      " [19] (::NLSolversBase.var\"#fg!#16\"{typeof(ll)})(storage::Matrix{Float64}, x::Matrix{Float64})",
      "    @ NLSolversBase ~/.julia/packages/NLSolversBase/kavn7/src/objective_types/oncedifferentiable.jl:61",
      " [20] value_gradient!!(obj::OnceDifferentiable{Float64, Matrix{Float64}, Matrix{Float64}}, x::Matrix{Float64})",
      "    @ NLSolversBase ~/.julia/packages/NLSolversBase/kavn7/src/interface.jl:82",
      " [21] value_gradient!(obj::OnceDifferentiable{Float64, Matrix{Float64}, Matrix{Float64}}, x::Matrix{Float64})",
      "    @ NLSolversBase ~/.julia/packages/NLSolversBase/kavn7/src/interface.jl:69",
      " [22] value_gradient!(obj::Optim.ManifoldObjective{OnceDifferentiable{Float64, Matrix{Float64}, Matrix{Float64}}}, x::Matrix{Float64})",
      "    @ Optim ~/.julia/packages/Optim/tP8PJ/src/Manifolds.jl:50",
      " [23] (::LineSearches.var\"#œïdœï#2\"{Optim.ManifoldObjective{OnceDifferentiable{Float64, Matrix{Float64}, Matrix{Float64}}}, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}})(Œ±::Float64)",
      "    @ LineSearches ~/.julia/packages/LineSearches/G1LRk/src/LineSearches.jl:35",
      " [24] (::MoreThuente{Float64})(œïdœï::LineSearches.var\"#œïdœï#2\"{Optim.ManifoldObjective{OnceDifferentiable{Float64, Matrix{Float64}, Matrix{Float64}}}, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}}, alpha::Float64, œï_0::Float64, dœï_0::Float64)",
      "    @ LineSearches ~/.julia/packages/LineSearches/G1LRk/src/morethuente.jl:233",
      " [25] MoreThuente",
      "    @ ~/.julia/packages/LineSearches/G1LRk/src/morethuente.jl:154 [inlined]",
      " [26] perform_linesearch!(state::Optim.LBFGSState{Matrix{Float64}, Vector{Matrix{Float64}}, Vector{Matrix{Float64}}, Float64, Matrix{Float64}}, method::LBFGS{Nothing, InitialStatic{Float64}, MoreThuente{Float64}, Optim.var\"#20#22\"}, d::Optim.ManifoldObjective{OnceDifferentiable{Float64, Matrix{Float64}, Matrix{Float64}}})",
      "    @ Optim ~/.julia/packages/Optim/tP8PJ/src/utilities/perform_linesearch.jl:59",
      " [27] update_state!(d::OnceDifferentiable{Float64, Matrix{Float64}, Matrix{Float64}}, state::Optim.LBFGSState{Matrix{Float64}, Vector{Matrix{Float64}}, Vector{Matrix{Float64}}, Float64, Matrix{Float64}}, method::LBFGS{Nothing, InitialStatic{Float64}, MoreThuente{Float64}, Optim.var\"#20#22\"})",
      "    @ Optim ~/.julia/packages/Optim/tP8PJ/src/multivariate/solvers/first_order/l_bfgs.jl:204",
      " [28] optimize(d::OnceDifferentiable{Float64, Matrix{Float64}, Matrix{Float64}}, initial_x::Matrix{Float64}, method::LBFGS{Nothing, InitialStatic{Float64}, MoreThuente{Float64}, Optim.var\"#20#22\"}, options::Optim.Options{Float64, Nothing}, state::Optim.LBFGSState{Matrix{Float64}, Vector{Matrix{Float64}}, Vector{Matrix{Float64}}, Float64, Matrix{Float64}})",
      "    @ Optim ~/.julia/packages/Optim/tP8PJ/src/multivariate/optimize/optimize.jl:54",
      " [29] optimize",
      "    @ ~/.julia/packages/Optim/tP8PJ/src/multivariate/optimize/optimize.jl:36 [inlined]",
      " [30] #optimize#89",
      "    @ ~/.julia/packages/Optim/tP8PJ/src/multivariate/optimize/interface.jl:142 [inlined]",
      " [31] optimize(f::Function, initial_x::Matrix{Float64}, method::LBFGS{Nothing, InitialStatic{Float64}, MoreThuente{Float64}, Optim.var\"#20#22\"}, options::Optim.Options{Float64, Nothing})",
      "    @ Optim ~/.julia/packages/Optim/tP8PJ/src/multivariate/optimize/interface.jl:138",
      " [32] top-level scope",
      "    @ In[166]:35"
     ]
    }
   ],
   "source": [
    "function log_prior(X_bar, alpha_b, beta_b)\n",
    "    sum(\n",
    "        (alpha_b - 1) * log.(X_bar) + (beta_b - 1) * log.(1 .- X_bar)\n",
    "        .+ loggamma(alpha_b + beta_b) \n",
    "        .- loggamma(alpha_b)\n",
    "        .- loggamma(beta_b)\n",
    "    )\n",
    "end\n",
    "\n",
    "function logp_g(Œ±, nn, X_min, X_max, Y_target, sigma_hat, nu, alpha)\n",
    "    \n",
    "    Y_pred = 10 .^ nn(Œ±, true)\n",
    "    r = Y_pred .- Y_target\n",
    "    t = r ./ sigma_hat\n",
    "\n",
    "    # StudentT distribution\n",
    "    loglikelihood = sum(\n",
    "        loggamma((nu + 1) / 2)\n",
    "        - loggamma(nu / 2)\n",
    "        .- log.(sqrt.(pi * nu) .* sigma_hat)\n",
    "        .- (nu + 1) / 2.0 * log.(1 .+ 1.0 / nu .* t .^ 2)\n",
    "    )\n",
    "    # Beta prior\n",
    "    X_bar = (Œ± .- X_min) ./ (X_max - X_min)\n",
    "    insupport(X) = sum(X_bar .< 0) == 0\n",
    "    println(insupport(X))\n",
    "    logprior = insupport(X) ?  log_prior(X_bar, alpha_b, beta_b) : -Inf\n",
    "    \n",
    "    (alpha * loglikelihood + logprior)\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "ll(X_0) = logp_g(X_0, model, X_min, X_max, Y_target, sigma_hat, nu, alpha)\n",
    "res = optimize(ll, X_0, LBFGS(linesearch = LineSearches.MoreThuente(), ), Optim.Options(show_trace=true, iterations = 51))\n",
    "X_map = Optim.minimizer(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f93c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_map .* X_std .+ X_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2099d664",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = mcmc_with_warmup(Random.default_rng(), ‚àáP, 2; \n",
    "    initialization = (q = vec(X_map), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b80318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_tree_statistics(results.tree_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0685010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = transform.(trans, eachcol(results.posterior_matrix))\n",
    "posterior_Œ± = first.(posterior)\n",
    "mean(posterior_Œ±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6d6fdd14",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: pathfinder not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: pathfinder not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[97]:3"
     ]
    }
   ],
   "source": [
    "logp_p(x) = LogDensityProblems.logdensity(P, x)\n",
    "‚àálogp_p(x) = LogDensityProblems.logdensity_and_gradient(‚àáP, x)[2]\n",
    "result_pf = pathfinder(logp_p, ‚àálogp_p; dim=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a269cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = result_pf.draws[:, 1]\n",
    "result_dhmc1 = mcmc_with_warmup(\n",
    "    Random.GLOBAL_RNG,\n",
    "    ‚àáP,\n",
    "    1;\n",
    "    initialization=(; q=init_params),\n",
    "    reporter=NoProgressReport(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c8cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add(\"Optim\")\n",
    "using Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372b96a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add(\"StatsBase\")\n",
    "using StatsBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93930176",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add(\"Pathfinder\")\n",
    "using Pathfinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb081029",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add(\"AdvancedMH\")\n",
    "Pkg.add(\"MCMCChains\")\n",
    "using AdvancedMH\n",
    "using MCMCChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29182947",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add(\"StructArrays\")\n",
    "using LogDensityProblemsAD\n",
    "using LogDensityProblems\n",
    "using AdvancedMH\n",
    "using Distributions\n",
    "using MCMCChains\n",
    "using ForwardDiff\n",
    "using StructArrays\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6005f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample(‚àáP, logp, 100000; init_params=ones(2), chain_type=StructArray, param_names=[\"Œº\", \"œÉ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f44b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a =log(Complex(-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6d6b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "?real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d2cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using Distributions\n",
    "Pkg.add(\"Arpack\")\n",
    "using Arpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4ad123",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "function mala(logdensity,gradient,h,M,niter,Œ∏init)       \n",
    "        function gradientStep(Œ∏,t)                                                                                                                                                                                 \n",
    "                Œ∏-t*M*gradient(Œ∏)                                                                                                                                                                                  \n",
    "        end        \n",
    "        print(Œ∏init)\n",
    "        Œ∏trace = zeros(length(Œ∏init),niter)\n",
    "        #Œ∏trace=Array{Float64}(length(Œ∏init),niter)    \n",
    "        Œ∏=Œ∏init\n",
    "        Œ∏trace[:,1]=Œ∏init                                                                                                                                                                                          \n",
    "        for i=2:niter                                                                                                                                                                                              \n",
    "                Œ∏old=Œ∏                                                                                                                                                                                             \n",
    "                Œ∏=rand(MvNormal(gradientStep(Œ∏,0.5*h),h*M))                                                                                                                                                        \n",
    "                d=logdensity(Œ∏) - logdensity(Œ∏old) + logpdf(MvNormal(gradientStep(Œ∏,0.5*h),h*M),Œ∏old) - logpdf(MvNormal(gradientStep(Œ∏old,0.5*h),h*M),Œ∏)                                                           \n",
    "                if(!(log(rand(Uniform(0,1)))<d))                                                                                                                                                                   \n",
    "                        Œ∏=Œ∏old                                                                                                                                                                                     \n",
    "                end                                                                                                                                                                                                \n",
    "                Œ∏trace[:,i]=Œ∏                                                                                                                                                                                      \n",
    "        end                                                                                                                                                                                                        \n",
    "        Œ∏trace                                                                                                                                                                                                     \n",
    "end  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "884c3f30",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "error in method definition: function Zygote.gradient must be explicitly imported to be extended",
     "output_type": "error",
     "traceback": [
      "error in method definition: function Zygote.gradient must be explicitly imported to be extended",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ none:0",
      " [2] top-level scope",
      "   @ In[60]:8"
     ]
    }
   ],
   "source": [
    "œÅ¬≤=0.8                                                                                                                                                                                                             \n",
    "Œ£=[1 œÅ¬≤;œÅ¬≤ 1]                                                                                                                                                                                                      \n",
    "                                                                                                                                                                                                                   \n",
    "function logdensity(Œ∏)                                                                                                                                                                                             \n",
    "        logpdf(MvNormal(Œ£),Œ∏)                                                                                                                                                                                      \n",
    "end                                                                                                                                                                                                                \n",
    "                                                                                                                                                                                                                   \n",
    "function gradient(Œ∏)                                                                                                                                                                                               \n",
    "        Œ£\\Œ∏                                                                                                                                                                                                        \n",
    "end  \n",
    " \n",
    "\n",
    "function Hinv\n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "gradient((Œ±= X_0),)\n",
    "niter=1000                                                                                                                                                                                                         \n",
    "h=1/eigs(inv(Œ£),nev=1)[1][1]                                                                                                                                                                                       \n",
    "#draws=mala(logp,gradient,h,I,niter,[5,50]);   #No preconditioning                                                                                                                                                                                                                                                                                                    \n",
    "pdraws=mala(logp,gradient,h,Œ£,niter, X_0);       #With Preconditioning                                                                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c81c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(pdraws, dims=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413d4da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logp_gg(X_0) = logp_g(X_0, model, X_min, X_max, Y_target, sigma_hat, nu, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f865a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zygote.gradient(logp_gg, X_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5710594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Flux.gradient(logp_gg, X_0)\n",
    "g[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b886cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "?gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e59577",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add(\"Zygote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be1d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Zygote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ff018f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logpi (generic function with 2 methods)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function logpi(Œ±, nn, X_min, X_max, Y_target, sigma_hat, nu, alpha)\n",
    "    \n",
    "    Y_pred = 10 .^ nn(Œ±, true)\n",
    "    r = Y_pred .- Y_target\n",
    "    t = r ./ sigma_hat\n",
    "\n",
    "    # StudentT distribution\n",
    "    loglikelihood = sum(\n",
    "        loggamma((nu + 1) / 2)\n",
    "        - loggamma(nu / 2)\n",
    "        .- log.(sqrt.(pi * nu) .* sigma_hat)\n",
    "        .- (nu + 1) / 2.0 * log.(1 .+ 1.0 / nu .* t .^ 2)\n",
    "    )\n",
    "    # Beta prior\n",
    "    X_bar = (Œ± .- X_min) ./ (X_max - X_min)\n",
    "    logprior = sum(\n",
    "        (alpha_b - 1) * log.(X_bar) + (beta_b - 1) * log.(1 .- X_bar)\n",
    "        .+ loggamma(alpha_b + beta_b) \n",
    "        .- loggamma(alpha_b)\n",
    "        .- loggamma(beta_b)\n",
    "    )\n",
    "\n",
    "    insupport(X) = sum(X_bar .< 0) == 0\n",
    "    insupport(X) ?  (alpha * loglikelihood + logprior) : -Inf\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b57c2a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llogpi (generic function with 1 method)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llogpi(X_0) = logpi(X_0, model, X_min, X_max, Y_target, sigma_hat, nu, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "022e5d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_log_like_gradient_and_hessian (generic function with 1 method)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_log_like_gradient_and_hessian(X;  eps=1e-2, compute_hessian=false)\n",
    "   log_pi =  llogpi(X)\n",
    "    if compute_hessian\n",
    "        g = Zygote.gradient(llogpi, X)\n",
    "        H = Zygote.hessian(llogpi, X)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "965c64f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: Zygote not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: Zygote not defined",
      "",
      "Stacktrace:",
      " [1] get_log_like_gradient_and_hessian(X::Matrix{Float64}; eps::Float64, compute_hessian::Bool)",
      "   @ Main ./In[65]:4",
      " [2] top-level scope",
      "   @ In[66]:1"
     ]
    }
   ],
   "source": [
    "get_log_like_gradient_and_hessian(X_0, compute_hessian=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "33b84acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nu = 1\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7844470e",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: Sampler for this object is not defined",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Sampler for this object is not defined",
      "",
      "Stacktrace:",
      "  [1] Random.Sampler(#unused#::Type{TaskLocalRNG}, sp::Random.SamplerType{ForwardDiff.Dual{Nothing, Float64, 8}}, #unused#::Val{1})",
      "    @ Random /opt/local/share/julia/stdlib/v1.8/Random/src/Random.jl:146",
      "  [2] Random.Sampler(rng::TaskLocalRNG, x::Random.SamplerType{ForwardDiff.Dual{Nothing, Float64, 8}}, r::Val{1})",
      "    @ Random /opt/local/share/julia/stdlib/v1.8/Random/src/Random.jl:140",
      "  [3] rand(rng::TaskLocalRNG, X::Random.SamplerType{ForwardDiff.Dual{Nothing, Float64, 8}})",
      "    @ Random /opt/local/share/julia/stdlib/v1.8/Random/src/Random.jl:254",
      "  [4] rand!",
      "    @ /opt/local/share/julia/stdlib/v1.8/Random/src/Random.jl:272 [inlined]",
      "  [5] rand! (repeats 2 times)",
      "    @ /opt/local/share/julia/stdlib/v1.8/Random/src/Random.jl:268 [inlined]",
      "  [6] _dropout_mask(rng::TaskLocalRNG, x::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}}, p::Float64; dims::Function)",
      "    @ Flux ~/.julia/packages/Flux/v79Am/src/layers/normalise.jl:45",
      "  [7] #dropout_mask#304",
      "    @ ~/.julia/packages/Flux/v79Am/src/layers/normalise.jl:42 [inlined]",
      "  [8] chain_rrule_kw",
      "    @ ~/.julia/packages/Zygote/g2w9o/src/compiler/chainrules.jl:235 [inlined]",
      "  [9] macro expansion",
      "    @ ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:0 [inlined]",
      " [10] _pullback",
      "    @ ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:9 [inlined]",
      " [11] _pullback",
      "    @ ~/.julia/packages/Flux/v79Am/src/layers/normalise.jl:34 [inlined]",
      " [12] _pullback(::Zygote.Context{false}, ::Flux.var\"##dropout#300\", ::Colon, ::Bool, ::typeof(dropout), ::TaskLocalRNG, ::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}}, ::Float64)",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:0",
      " [13] _pullback",
      "    @ ~/.julia/packages/Flux/v79Am/src/layers/normalise.jl:32 [inlined]",
      " [14] _pullback(::Zygote.Context{false}, ::Flux.var\"#dropout##kw\", ::NamedTuple{(:dims, :active), Tuple{Colon, Bool}}, ::typeof(dropout), ::TaskLocalRNG, ::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}}, ::Float64)",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:0",
      " [15] _pullback",
      "    @ ~/.julia/packages/Flux/v79Am/src/layers/normalise.jl:111 [inlined]",
      " [16] _pullback(ctx::Zygote.Context{false}, f::Dropout{Float64, Colon, TaskLocalRNG}, args::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}})",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:0",
      " [17] macro expansion",
      "    @ ~/.julia/packages/Flux/v79Am/src/layers/basic.jl:53 [inlined]",
      " [18] _pullback",
      "    @ ~/.julia/packages/Flux/v79Am/src/layers/basic.jl:53 [inlined]",
      " [19] _pullback(::Zygote.Context{false}, ::typeof(Flux._applychain), ::Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Bool}}, ::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}})",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:0",
      " [20] _pullback",
      "    @ ~/.julia/packages/Flux/v79Am/src/layers/basic.jl:51 [inlined]",
      " [21] _pullback(ctx::Zygote.Context{false}, f::Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Bool}}}, args::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}})",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:0",
      " [22] _pullback",
      "    @ ./In[5]:0 [inlined]",
      " [23] _pullback(::Zygote.Context{false}, ::NNModel, ::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}}, ::Bool)",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:0",
      " [24] _pullback",
      "    @ ./In[63]:3 [inlined]",
      " [25] _pullback(::Zygote.Context{false}, ::typeof(logpi), ::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}}, ::NNModel, ::Matrix{Float64}, ::Matrix{Float64}, ::Vector{Float32}, ::Vector{Float64}, ::Int64, ::Float64)",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:0",
      " [26] _pullback",
      "    @ ./In[64]:1 [inlined]",
      " [27] _pullback(ctx::Zygote.Context{false}, f::typeof(llogpi), args::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}})",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:0",
      " [28] pullback(f::Function, cx::Zygote.Context{false}, args::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}})",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface.jl:44",
      " [29] pullback",
      "    @ ~/.julia/packages/Zygote/g2w9o/src/compiler/interface.jl:42 [inlined]",
      " [30] gradient(f::Function, args::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}})",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface.jl:96",
      " [31] (::Zygote.var\"#102#103\"{typeof(llogpi)})(x::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}})",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/lib/grad.jl:64",
      " [32] forward_jacobian(f::Zygote.var\"#102#103\"{typeof(llogpi)}, x::Matrix{Float64}, #unused#::Val{8})",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/lib/forward.jl:29",
      " [33] forward_jacobian(f::Function, x::Matrix{Float64}; chunk_threshold::Int64)",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/lib/forward.jl:44",
      " [34] forward_jacobian",
      "    @ ~/.julia/packages/Zygote/g2w9o/src/lib/forward.jl:42 [inlined]",
      " [35] hessian_dual",
      "    @ ~/.julia/packages/Zygote/g2w9o/src/lib/grad.jl:64 [inlined]",
      " [36] hessian(f::Function, x::Matrix{Float64})",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/lib/grad.jl:62",
      " [37] top-level scope",
      "    @ In[68]:1"
     ]
    }
   ],
   "source": [
    "Flux.hessian(llogpi, X_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "75b636ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching llogpi()\n\u001b[0mClosest candidates are:\n\u001b[0m  llogpi(\u001b[91m::Any\u001b[39m) at In[64]:1",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching llogpi()\n\u001b[0mClosest candidates are:\n\u001b[0m  llogpi(\u001b[91m::Any\u001b[39m) at In[64]:1",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[69]:1"
     ]
    }
   ],
   "source": [
    "Flux.gradient(llogpi(), X_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9618772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "?Zygote.hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e900a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "f(x, y) = sum((x .- y) .^ 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7fe08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.gradient(f, [2, 1], [2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "g(x, y, a, b) = sum((a .* x .- b .* y) .^ 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8740d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.gradient(g, [2, 1], [2, 0], 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e737cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zygote.hessian(logpi, X_0, model, X_min, X_max, Y_target, sigma_hat, nu, alpha)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3f4aca84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_pred: 58.99657521835326\n",
      "Log_prob: -1451.7018975352285\n",
      "Y_pred: 99.79009360000074\n",
      "Y_pred: 61.590387812293535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1444.0742151359996"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function logpi(Œ±, nn, X_min, X_max, Y_target, sigma_hat, nu, alpha)\n",
    "    Y_pred = 10 .^ nn(Œ±, true);\n",
    "    r = Y_pred .- Y_target\n",
    "    t = r ./ sigma_hat\n",
    "\n",
    "    # StudentT distribution\n",
    "    loglikelihood = sum(\n",
    "        loggamma((nu + 1) / 2)\n",
    "        - loggamma(nu / 2)\n",
    "        .- log.(sqrt.(pi * nu) .* sigma_hat)\n",
    "        .- (nu + 1) / 2.0 * log.(1 .+ 1.0 / nu .* t .^ 2)\n",
    "    )\n",
    "    \n",
    "    println(\"Y_pred: \", mean(Y_pred))\n",
    "    \n",
    "    # Beta prior\n",
    "    X_bar = (Œ± .- X_min) ./ (X_max - X_min)\n",
    "    logprior = sum(\n",
    "        (alpha_b - 1) * log.(X_bar) + (beta_b - 1) * log.(1 .- X_bar)\n",
    "        .+ loggamma(alpha_b + beta_b) \n",
    "        .- loggamma(alpha_b)\n",
    "        .- loggamma(beta_b)\n",
    "    )\n",
    "\n",
    "    insupport(X) = sum(X_bar .< 0) == 0\n",
    "    insupport(X) ?  (alpha * loglikelihood + logprior) : -Inf\n",
    "\n",
    "end\n",
    "\n",
    "lp = logpi(X_0, model, X_min, X_max, Y_target, sigma_hat, nu, alpha)\n",
    "println(\"Log_prob: \", lp)\n",
    "Flux.gradient(logpi, X_0, model, X_min, X_max, Y_target, sigma_hat, nu, alpha)[1]\n",
    "Flux.withgradient(logpi, X_0, model, X_min, X_max, Y_target, sigma_hat, nu, alpha)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dee4aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6942285259538075"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    Y_pred = 10 .^ model(X_0, true)\n",
    "    r = Y_pred .- Y_target\n",
    "    t = r ./ sigma_hat\n",
    "    mean(t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679bf1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "function logpii(Œ±, nn)\n",
    "    Y_pred = 10 .^ nn(Œ±, true)\n",
    "    println(mean(Y_pred))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b47b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logpii(X_0, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00833f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5e574af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "gradient(f, args...)\n",
       "\\end{verbatim}\n",
       "Returns a tuple containing \\texttt{‚àÇf/‚àÇx} for each argument \\texttt{x}, the derivative (for scalar \\texttt{x}) or the gradient.\n",
       "\n",
       "\\texttt{f(args...)} must be a real number, see \\href{@ref}{\\texttt{jacobian}} for array output.\n",
       "\n",
       "See also \\href{@ref}{\\texttt{withgradient}} to keep the value \\texttt{f(args...)}, and \\href{@ref}{\\texttt{pullback}} for value and back-propagator.\n",
       "\n",
       "\\begin{verbatim}\n",
       "julia> gradient(*, 2.0, 3.0, 5.0)\n",
       "(15.0, 10.0, 6.0)\n",
       "\n",
       "julia> gradient(x -> sum(abs2,x), [7.0, 11.0, 13.0])\n",
       "([14.0, 22.0, 26.0],)\n",
       "\n",
       "julia> gradient([7, 11], 0, 1) do x, y, d\n",
       "         p = size(x, d)\n",
       "         sum(x.^p .+ y)\n",
       "       end\n",
       "([14.0, 22.0], 2.0, nothing)\n",
       "\\end{verbatim}\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "gradient(() -> loss(), ps::Params) -> Grads\n",
       "\\end{verbatim}\n",
       "Gradient with implicit parameters. Takes a zero-argument function, and returns a dictionary-like container, whose keys are arrays \\texttt{x in ps}.\n",
       "\n",
       "See also \\href{@ref}{\\texttt{withgradient}} to keep the value \\texttt{loss()}.\n",
       "\n",
       "\\begin{verbatim}\n",
       "julia> x = [1 2 3; 4 5 6]; y = [7, 8]; z = [1, 10, 100];\n",
       "\n",
       "julia> g = gradient(Params([x, y])) do\n",
       "         sum(x .* y .* z')\n",
       "       end\n",
       "Grads(...)\n",
       "\n",
       "julia> g[x]\n",
       "2√ó3 Matrix{Float64}:\n",
       " 7.0  70.0  700.0\n",
       " 8.0  80.0  800.0\n",
       "\n",
       "julia> haskey(g, z)  # only x and y are parameters\n",
       "false\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "gradient(f, args...)\n",
       "```\n",
       "\n",
       "Returns a tuple containing `‚àÇf/‚àÇx` for each argument `x`, the derivative (for scalar `x`) or the gradient.\n",
       "\n",
       "`f(args...)` must be a real number, see [`jacobian`](@ref) for array output.\n",
       "\n",
       "See also [`withgradient`](@ref) to keep the value `f(args...)`, and [`pullback`](@ref) for value and back-propagator.\n",
       "\n",
       "```jldoctest; setup=:(using Zygote)\n",
       "julia> gradient(*, 2.0, 3.0, 5.0)\n",
       "(15.0, 10.0, 6.0)\n",
       "\n",
       "julia> gradient(x -> sum(abs2,x), [7.0, 11.0, 13.0])\n",
       "([14.0, 22.0, 26.0],)\n",
       "\n",
       "julia> gradient([7, 11], 0, 1) do x, y, d\n",
       "         p = size(x, d)\n",
       "         sum(x.^p .+ y)\n",
       "       end\n",
       "([14.0, 22.0], 2.0, nothing)\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "gradient(() -> loss(), ps::Params) -> Grads\n",
       "```\n",
       "\n",
       "Gradient with implicit parameters. Takes a zero-argument function, and returns a dictionary-like container, whose keys are arrays `x in ps`.\n",
       "\n",
       "See also [`withgradient`](@ref) to keep the value `loss()`.\n",
       "\n",
       "```jldoctest; setup=:(using Zygote)\n",
       "julia> x = [1 2 3; 4 5 6]; y = [7, 8]; z = [1, 10, 100];\n",
       "\n",
       "julia> g = gradient(Params([x, y])) do\n",
       "         sum(x .* y .* z')\n",
       "       end\n",
       "Grads(...)\n",
       "\n",
       "julia> g[x]\n",
       "2√ó3 Matrix{Float64}:\n",
       " 7.0  70.0  700.0\n",
       " 8.0  80.0  800.0\n",
       "\n",
       "julia> haskey(g, z)  # only x and y are parameters\n",
       "false\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  gradient(f, args...)\u001b[39m\n",
       "\n",
       "  Returns a tuple containing \u001b[36m‚àÇf/‚àÇx\u001b[39m for each argument \u001b[36mx\u001b[39m, the derivative (for\n",
       "  scalar \u001b[36mx\u001b[39m) or the gradient.\n",
       "\n",
       "  \u001b[36mf(args...)\u001b[39m must be a real number, see \u001b[36mjacobian\u001b[39m for array output.\n",
       "\n",
       "  See also \u001b[36mwithgradient\u001b[39m to keep the value \u001b[36mf(args...)\u001b[39m, and \u001b[36mpullback\u001b[39m for value\n",
       "  and back-propagator.\n",
       "\n",
       "\u001b[36m  julia> gradient(*, 2.0, 3.0, 5.0)\u001b[39m\n",
       "\u001b[36m  (15.0, 10.0, 6.0)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> gradient(x -> sum(abs2,x), [7.0, 11.0, 13.0])\u001b[39m\n",
       "\u001b[36m  ([14.0, 22.0, 26.0],)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> gradient([7, 11], 0, 1) do x, y, d\u001b[39m\n",
       "\u001b[36m           p = size(x, d)\u001b[39m\n",
       "\u001b[36m           sum(x.^p .+ y)\u001b[39m\n",
       "\u001b[36m         end\u001b[39m\n",
       "\u001b[36m  ([14.0, 22.0], 2.0, nothing)\u001b[39m\n",
       "\n",
       "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
       "\n",
       "\u001b[36m  gradient(() -> loss(), ps::Params) -> Grads\u001b[39m\n",
       "\n",
       "  Gradient with implicit parameters. Takes a zero-argument function, and\n",
       "  returns a dictionary-like container, whose keys are arrays \u001b[36mx in ps\u001b[39m.\n",
       "\n",
       "  See also \u001b[36mwithgradient\u001b[39m to keep the value \u001b[36mloss()\u001b[39m.\n",
       "\n",
       "\u001b[36m  julia> x = [1 2 3; 4 5 6]; y = [7, 8]; z = [1, 10, 100];\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> g = gradient(Params([x, y])) do\u001b[39m\n",
       "\u001b[36m           sum(x .* y .* z')\u001b[39m\n",
       "\u001b[36m         end\u001b[39m\n",
       "\u001b[36m  Grads(...)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> g[x]\u001b[39m\n",
       "\u001b[36m  2√ó3 Matrix{Float64}:\u001b[39m\n",
       "\u001b[36m   7.0  70.0  700.0\u001b[39m\n",
       "\u001b[36m   8.0  80.0  800.0\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> haskey(g, z)  # only x and y are parameters\u001b[39m\n",
       "\u001b[36m  false\u001b[39m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?Flux.gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c7de2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real(log(Complex(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "735a1e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mSampling: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100000-element StructArray(::Vector{Float64}, ::Vector{Float64}, ::Vector{Float64}) with eltype NamedTuple{(:Œº, :œÉ, :lp), Tuple{Float64, Float64, Float64}}:\n",
       " (Œº = 1.0, œÉ = 1.0, lp = -455.3876282711064)\n",
       " (Œº = 1.4279958663926915, œÉ = 1.2326476257668044, lp = -432.6222032600074)\n",
       " (Œº = 1.6140884866437557, œÉ = 0.9854582772505509, lp = -412.70040952940894)\n",
       " (Œº = 1.8752723351125504, œÉ = 0.9301501467333264, lp = -402.32850249450405)\n",
       " (Œº = 1.8597574663454057, œÉ = 0.7416082786230347, lp = -390.3932035619456)\n",
       " (Œº = 1.8597574663454057, œÉ = 0.7416082786230347, lp = -390.3932035619456)\n",
       " (Œº = 2.031570902119432, œÉ = 0.5696234020560965, lp = -381.7442692222307)\n",
       " (Œº = 2.031570902119432, œÉ = 0.5696234020560965, lp = -381.7442692222307)\n",
       " (Œº = 2.031570902119432, œÉ = 0.5696234020560965, lp = -381.7442692222307)\n",
       " (Œº = 2.031570902119432, œÉ = 0.5696234020560965, lp = -381.7442692222307)\n",
       " (Œº = 2.031570902119432, œÉ = 0.5696234020560965, lp = -381.7442692222307)\n",
       " (Œº = 2.031570902119432, œÉ = 0.5696234020560965, lp = -381.7442692222307)\n",
       " (Œº = 2.031570902119432, œÉ = 0.5696234020560965, lp = -381.7442692222307)\n",
       " ‚ãÆ\n",
       " (Œº = 1.977570184176096, œÉ = 0.5263644604545878, lp = -381.5091650957073)\n",
       " (Œº = 1.977570184176096, œÉ = 0.5263644604545878, lp = -381.5091650957073)\n",
       " (Œº = 1.977570184176096, œÉ = 0.5263644604545878, lp = -381.5091650957073)\n",
       " (Œº = 1.977570184176096, œÉ = 0.5263644604545878, lp = -381.5091650957073)\n",
       " (Œº = 1.977570184176096, œÉ = 0.5263644604545878, lp = -381.5091650957073)\n",
       " (Œº = 1.977570184176096, œÉ = 0.5263644604545878, lp = -381.5091650957073)\n",
       " (Œº = 1.977570184176096, œÉ = 0.5263644604545878, lp = -381.5091650957073)\n",
       " (Œº = 1.977570184176096, œÉ = 0.5263644604545878, lp = -381.5091650957073)\n",
       " (Œº = 1.977570184176096, œÉ = 0.5263644604545878, lp = -381.5091650957073)\n",
       " (Œº = 1.977570184176096, œÉ = 0.5263644604545878, lp = -381.5091650957073)\n",
       " (Œº = 1.977570184176096, œÉ = 0.5263644604545878, lp = -381.5091650957073)\n",
       " (Œº = 1.977570184176096, œÉ = 0.5263644604545878, lp = -381.5091650957073)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the package.\n",
    "using AdvancedMH\n",
    "using Distributions\n",
    "using MCMCChains\n",
    "using ForwardDiff\n",
    "using StructArrays\n",
    "\n",
    "using LinearAlgebra\n",
    "\n",
    "Œº_true = 2\n",
    "œÉ_true = 0.5\n",
    "# Generate a set of data from the posterior we want to estimate.\n",
    "data = rand(Normal(Œº_true, œÉ_true), 100)\n",
    "\n",
    "# Define the components of a basic model.\n",
    "insupport(Œ∏) = Œ∏[2] >= 0\n",
    "likelihood(Œ∏) = Normal(Œ∏[1], Œ∏[2])\n",
    "prior(Œ∏) = Uniform(-10, 10)\n",
    "density(Œ∏) = insupport(Œ∏) ? sum(logpdf.(likelihood(Œ∏), data)) + sum(logpdf.(prior(Œ∏), data)) : -Inf\n",
    "\n",
    "# Construct a DensityModel.\n",
    "dmodel = DensityModel(density)\n",
    "\n",
    "# Set up the sampler with a multivariate Gaussian proposal.\n",
    "œÉ¬≤ = 0.01\n",
    "spl = MALA(x -> MvNormal((œÉ¬≤ / 2) .* x, œÉ¬≤ * I))\n",
    "\n",
    "# Sample from the posterior.\n",
    "chain = sample(dmodel, spl, 100000; init_params=ones(2), chain_type=StructArray, param_names=[\"Œº\", \"œÉ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b8e92728",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: the log density function does not support the LogDensityProblems.jl interface. Please implement the interface or provide a model of type `AbstractMCMC.AbstractModel`",
     "output_type": "error",
     "traceback": [
      "ArgumentError: the log density function does not support the LogDensityProblems.jl interface. Please implement the interface or provide a model of type `AbstractMCMC.AbstractModel`",
      "",
      "Stacktrace:",
      " [1] _model(logdensity::SampleBayesProblem)",
      "   @ AbstractMCMC ~/.julia/packages/AbstractMCMC/F9Hbk/src/logdensityproblems.jl:112",
      " [2] sample(rng::TaskLocalRNG, logdensity::SampleBayesProblem, sampler::MALA{RandomWalkProposal{false, var\"#6#7\"}}, N_or_isdone::Int64; kwargs::Base.Pairs{Symbol, Any, Tuple{Symbol, Symbol}, NamedTuple{(:init_params, :chain_type), Tuple{Matrix{Float64}, UnionAll}}})",
      "   @ AbstractMCMC ~/.julia/packages/AbstractMCMC/F9Hbk/src/logdensityproblems.jl:46",
      " [3] sample(model_or_logdensity::SampleBayesProblem, sampler::MALA{RandomWalkProposal{false, var\"#6#7\"}}, N_or_isdone::Int64; kwargs::Base.Pairs{Symbol, Any, Tuple{Symbol, Symbol}, NamedTuple{(:init_params, :chain_type), Tuple{Matrix{Float64}, UnionAll}}})",
      "   @ AbstractMCMC ~/.julia/packages/AbstractMCMC/F9Hbk/src/sample.jl:18",
      " [4] top-level scope",
      "   @ In[118]:3"
     ]
    }
   ],
   "source": [
    "using LogDensityProblemsAD\n",
    "#model_with_ad = LogDensityProblemsAD.ADgradient(Val(:ForwardDiff), ‚àáP)\n",
    "sample(logp, spl, 100000; init_params=X_0, chain_type=StructArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "32cb47a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zygote AD wrapper for TransformedLogDensity of dimension 8"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = as((Œ± = as(Array, asùïÄ, n_parameters),))\n",
    "P = TransformedLogDensity(trans, logp)\n",
    "‚àáP = ADgradient(:Zygote, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "139dc8ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: extra token \"logpdf\" after end of expression",
     "output_type": "error",
     "traceback": [
      "syntax: extra token \"logpdf\" after end of expression",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[5]:1"
     ]
    }
   ],
   "source": [
    "help logpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "33f2924b",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: psample not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: psample not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[93]:1"
     ]
    }
   ],
   "source": [
    "chain = psample(model, RWMH(init_params), 100000, 4; param_names=[\"Œº\",\"œÉ\"], chain_type=Chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73ec263e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1mf\u001b[22m \u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1mf\u001b[22m! grad\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1mf\u001b[22m componentwise_\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1mf\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "logpdf(d::Distribution{ArrayLikeVariate{N}}, x::AbstractArray{<:Real,N}) where {N}\n",
       "\\end{verbatim}\n",
       "Evaluate the probability density function of \\texttt{d} at \\texttt{x}.\n",
       "\n",
       "This function checks if the size of \\texttt{x} is compatible with distribution \\texttt{d}. This check can be disabled by using \\texttt{@inbounds}.\n",
       "\n",
       "\\section{Implementation}\n",
       "Instead of \\texttt{logpdf} one should implement \\texttt{\\_logpdf(d, x)} which does not have to check the size of \\texttt{x}.\n",
       "\n",
       "See also: \\href{@ref}{\\texttt{pdf}}.\n",
       "\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "logpdf(d::Distribution{ArrayLikeVariate{N}}, x) where {N}\n",
       "\\end{verbatim}\n",
       "Evaluate the logarithm of the probability density function of \\texttt{d} at every element in a collection \\texttt{x}.\n",
       "\n",
       "This function checks for every element of \\texttt{x} if its size is compatible with distribution \\texttt{d}. This check can be disabled by using \\texttt{@inbounds}.\n",
       "\n",
       "Here, \\texttt{x} can be\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item an array of dimension \\texttt{> N} with \\texttt{size(x)[1:N] == size(d)}, or\n",
       "\n",
       "\n",
       "\\item an array of arrays \\texttt{xi} of dimension \\texttt{N} with \\texttt{size(xi) == size(d)}.\n",
       "\n",
       "\\end{itemize}\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "logpdf(d::UnivariateDistribution, x::Real)\n",
       "\\end{verbatim}\n",
       "Evaluate the logarithm of probability density (mass) at \\texttt{x}.\n",
       "\n",
       "See also: \\href{@ref}{\\texttt{pdf}}.\n",
       "\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "logpdf(d::Union{UnivariateMixture, MultivariateMixture}, x)\n",
       "\\end{verbatim}\n",
       "Evaluate the logarithm of the (mixed) probability density function over \\texttt{x}. Here, \\texttt{x} can be a single sample or an array of multiple samples.\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "logpdf(d::Distribution{ArrayLikeVariate{N}}, x::AbstractArray{<:Real,N}) where {N}\n",
       "```\n",
       "\n",
       "Evaluate the probability density function of `d` at `x`.\n",
       "\n",
       "This function checks if the size of `x` is compatible with distribution `d`. This check can be disabled by using `@inbounds`.\n",
       "\n",
       "# Implementation\n",
       "\n",
       "Instead of `logpdf` one should implement `_logpdf(d, x)` which does not have to check the size of `x`.\n",
       "\n",
       "See also: [`pdf`](@ref).\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "logpdf(d::Distribution{ArrayLikeVariate{N}}, x) where {N}\n",
       "```\n",
       "\n",
       "Evaluate the logarithm of the probability density function of `d` at every element in a collection `x`.\n",
       "\n",
       "This function checks for every element of `x` if its size is compatible with distribution `d`. This check can be disabled by using `@inbounds`.\n",
       "\n",
       "Here, `x` can be\n",
       "\n",
       "  * an array of dimension `> N` with `size(x)[1:N] == size(d)`, or\n",
       "  * an array of arrays `xi` of dimension `N` with `size(xi) == size(d)`.\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "logpdf(d::UnivariateDistribution, x::Real)\n",
       "```\n",
       "\n",
       "Evaluate the logarithm of probability density (mass) at `x`.\n",
       "\n",
       "See also: [`pdf`](@ref).\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "logpdf(d::Union{UnivariateMixture, MultivariateMixture}, x)\n",
       "```\n",
       "\n",
       "Evaluate the logarithm of the (mixed) probability density function over `x`. Here, `x` can be a single sample or an array of multiple samples.\n"
      ],
      "text/plain": [
       "\u001b[36m  logpdf(d::Distribution{ArrayLikeVariate{N}}, x::AbstractArray{<:Real,N}) where {N}\u001b[39m\n",
       "\n",
       "  Evaluate the probability density function of \u001b[36md\u001b[39m at \u001b[36mx\u001b[39m.\n",
       "\n",
       "  This function checks if the size of \u001b[36mx\u001b[39m is compatible with distribution \u001b[36md\u001b[39m.\n",
       "  This check can be disabled by using \u001b[36m@inbounds\u001b[39m.\n",
       "\n",
       "\u001b[1m  Implementation\u001b[22m\n",
       "\u001b[1m  ‚â°‚â°‚â°‚â°‚â°‚â°‚â°‚â°‚â°‚â°‚â°‚â°‚â°‚â°‚â°‚â°\u001b[22m\n",
       "\n",
       "  Instead of \u001b[36mlogpdf\u001b[39m one should implement \u001b[36m_logpdf(d, x)\u001b[39m which does not have to\n",
       "  check the size of \u001b[36mx\u001b[39m.\n",
       "\n",
       "  See also: \u001b[36mpdf\u001b[39m.\n",
       "\n",
       "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
       "\n",
       "\u001b[36m  logpdf(d::Distribution{ArrayLikeVariate{N}}, x) where {N}\u001b[39m\n",
       "\n",
       "  Evaluate the logarithm of the probability density function of \u001b[36md\u001b[39m at every\n",
       "  element in a collection \u001b[36mx\u001b[39m.\n",
       "\n",
       "  This function checks for every element of \u001b[36mx\u001b[39m if its size is compatible with\n",
       "  distribution \u001b[36md\u001b[39m. This check can be disabled by using \u001b[36m@inbounds\u001b[39m.\n",
       "\n",
       "  Here, \u001b[36mx\u001b[39m can be\n",
       "\n",
       "    ‚Ä¢  an array of dimension \u001b[36m> N\u001b[39m with \u001b[36msize(x)[1:N] == size(d)\u001b[39m, or\n",
       "\n",
       "    ‚Ä¢  an array of arrays \u001b[36mxi\u001b[39m of dimension \u001b[36mN\u001b[39m with \u001b[36msize(xi) == size(d)\u001b[39m.\n",
       "\n",
       "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
       "\n",
       "\u001b[36m  logpdf(d::UnivariateDistribution, x::Real)\u001b[39m\n",
       "\n",
       "  Evaluate the logarithm of probability density (mass) at \u001b[36mx\u001b[39m.\n",
       "\n",
       "  See also: \u001b[36mpdf\u001b[39m.\n",
       "\n",
       "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
       "\n",
       "\u001b[36m  logpdf(d::Union{UnivariateMixture, MultivariateMixture}, x)\u001b[39m\n",
       "\n",
       "  Evaluate the logarithm of the (mixed) probability density function over \u001b[36mx\u001b[39m.\n",
       "  Here, \u001b[36mx\u001b[39m can be a single sample or an array of multiple samples."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?logpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75392b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m‚îå \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mcould not download https://pkg.julialang.org/registries\n",
      "\u001b[33m\u001b[1m‚îÇ \u001b[22m\u001b[39m  exception = Could not resolve host: pkg.julialang.org while requesting https://pkg.julialang.org/registries\n",
      "\u001b[33m\u001b[1m‚îî \u001b[22m\u001b[39m\u001b[90m@ Pkg.Registry /opt/local/var/macports/build/_opt_bblocal_var_buildworker_ports_build_ports_lang_julia/julia/work/julia-1.8.4/usr/share/julia/stdlib/v1.8/Pkg/src/Registry/Registry.jl:68\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"AbstractMCMC\")\n",
    "using AbstractMCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fe7f36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search:\n",
      "\n",
      "Couldn't find \u001b[36mLogDensityProblemsAD\u001b[39m\n",
      "Perhaps you meant DensityModel\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "No documentation found.\n",
       "\n",
       "Binding \\texttt{LogDensityProblemsAD} does not exist.\n",
       "\n"
      ],
      "text/markdown": [
       "No documentation found.\n",
       "\n",
       "Binding `LogDensityProblemsAD` does not exist.\n"
      ],
      "text/plain": [
       "  No documentation found.\n",
       "\n",
       "  Binding \u001b[36mLogDensityProblemsAD\u001b[39m does not exist."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?LogDensityProblemsAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3086c155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search:\n",
      "\n",
      "Couldn't find \u001b[36mLogDensityProblems\u001b[39m\n",
      "Perhaps you meant DensityModel\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "No documentation found.\n",
       "\n",
       "Binding \\texttt{LogDensityProblems} does not exist.\n",
       "\n"
      ],
      "text/markdown": [
       "No documentation found.\n",
       "\n",
       "Binding `LogDensityProblems` does not exist.\n"
      ],
      "text/plain": [
       "  No documentation found.\n",
       "\n",
       "  Binding \u001b[36mLogDensityProblems\u001b[39m does not exist."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?LogDensityProblems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "61f173f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8√ó1 Matrix{Float64}:\n",
       " 0.6483565433127019\n",
       " 0.647910676617902\n",
       " 0.6273077544435656\n",
       " 0.6478926462889346\n",
       " 0.6505437104220909\n",
       " 0.6353471420662554\n",
       " 0.6483217215407353\n",
       " 0.63814507171178"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b032f497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       "  2.5\n",
       "  3.0\n",
       " -1.0\n",
       "  3.0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [2.5, 3, -1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "935097d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logpi (generic function with 2 methods)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function logpi(Œ±, nn, X_min, X_max, Y_target, sigma_hat; nu=1, alpha=0.01, alpha_b=3, beta_b=3)\n",
    "    \n",
    "    Y_pred = 10 .^ nn(Œ±, true)\n",
    "    r = Y_pred .- Y_target\n",
    "    t = r ./ sigma_hat\n",
    "\n",
    "    # StudentT distribution\n",
    "    loglikelihood = sum(\n",
    "        loggamma((nu + 1) / 2)\n",
    "        - loggamma(nu / 2)\n",
    "        .- log.(sqrt.(pi * nu) .* sigma_hat)\n",
    "        .- (nu + 1) / 2.0 * log.(1 .+ 1.0 / nu .* t .^ 2)\n",
    "    )\n",
    "    # Beta prior\n",
    "    X_bar = (Œ± .- X_min) ./ (X_max - X_min)\n",
    "    logprior = sum(\n",
    "        (alpha_b - 1) * log.(X_bar) + (beta_b - 1) * log.(1 .- X_bar)\n",
    "        .+ loggamma(alpha_b + beta_b) \n",
    "        .- loggamma(alpha_b)\n",
    "        .- loggamma(beta_b)\n",
    "    )\n",
    "\n",
    "    insupport(X) = sum(X_bar .< 0) == 0\n",
    "    insupport(X) ?  (alpha * loglikelihood + logprior) : -Inf\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "40636f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "density (generic function with 1 method)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function bar(X, X_min, X_max)\n",
    "    (X .- X_min) ./ (X_max .- X_min)\n",
    "end\n",
    "\n",
    "insupport(X) = sum(bar(X, X_min, X_max) .< 0) == 0\n",
    "density(X) = insupport(X) ? logpi(X, model, X_min, X_max, Y_target, sigma_hat) : -Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "30b54025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1451.7018975352285"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logpi(X_0, model, X_min, X_max, Y_target, sigma_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2cc1f3f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching hessian(::typeof(logpi))\n\u001b[0mClosest candidates are:\n\u001b[0m  hessian(::Any, \u001b[91m::Any\u001b[39m) at ~/.julia/packages/Zygote/g2w9o/src/lib/grad.jl:62",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching hessian(::typeof(logpi))\n\u001b[0mClosest candidates are:\n\u001b[0m  hessian(::Any, \u001b[91m::Any\u001b[39m) at ~/.julia/packages/Zygote/g2w9o/src/lib/grad.jl:62",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[153]:5"
     ]
    }
   ],
   "source": [
    "# Construct a DensityModel.\n",
    "dmodel = DensityModel(density)\n",
    "\n",
    "# Set up the sampler with a multivariate Gaussian proposal.\n",
    "H = Flux.hessian(logpi)\n",
    "œÉ¬≤ = 1 / H\n",
    "spl = MALA(x -> MvNormal((œÉ¬≤ / 2) .* x, œÉ¬≤ * I))\n",
    "\n",
    "# Sample from the posterior.\n",
    "chain = sample(dmodel, spl, 100000; init_params=X_0, chain_type=StructArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e0d15477",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "45644beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "hessian(f, x)\n",
       "\\end{verbatim}\n",
       "Construct the Hessian \\texttt{‚àÇ¬≤f/‚àÇx¬≤}, where \\texttt{x} is a real number or an array, and \\texttt{f(x)} is a real number. When \\texttt{x} is an array, the result is a matrix \\texttt{H[i,j] = ‚àÇ¬≤f/‚àÇx[i]‚àÇx[j]}, using linear indexing \\texttt{x[i]} even if the argument is higher-dimensional.\n",
       "\n",
       "This uses forward over reverse, ForwardDiff over Zygote, calling \\texttt{hessian\\_dual(f, x)}. See \\href{@ref}{\\texttt{hessian\\_reverse}} for an all-Zygote alternative.\n",
       "\n",
       "See also \\href{@ref}{\\texttt{diaghessian}} to compute only the diagonal part.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> hessian(x -> x[1]*x[2], randn(2))\n",
       "2√ó2 Matrix{Float64}:\n",
       " 0.0  1.0\n",
       " 1.0  0.0\n",
       "\n",
       "julia> hessian(x -> sum(x.^3), [1 2; 3 4])  # uses linear indexing of x\n",
       "4√ó4 Matrix{Int64}:\n",
       " 6   0   0   0\n",
       " 0  18   0   0\n",
       " 0   0  12   0\n",
       " 0   0   0  24\n",
       "\n",
       "julia> hessian(sin, pi/2)\n",
       "-1.0\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "hessian(f, x)\n",
       "```\n",
       "\n",
       "Construct the Hessian `‚àÇ¬≤f/‚àÇx¬≤`, where `x` is a real number or an array, and `f(x)` is a real number. When `x` is an array, the result is a matrix `H[i,j] = ‚àÇ¬≤f/‚àÇx[i]‚àÇx[j]`, using linear indexing `x[i]` even if the argument is higher-dimensional.\n",
       "\n",
       "This uses forward over reverse, ForwardDiff over Zygote, calling `hessian_dual(f, x)`. See [`hessian_reverse`](@ref) for an all-Zygote alternative.\n",
       "\n",
       "See also [`diaghessian`](@ref) to compute only the diagonal part.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest; setup=:(using Zygote)\n",
       "julia> hessian(x -> x[1]*x[2], randn(2))\n",
       "2√ó2 Matrix{Float64}:\n",
       " 0.0  1.0\n",
       " 1.0  0.0\n",
       "\n",
       "julia> hessian(x -> sum(x.^3), [1 2; 3 4])  # uses linear indexing of x\n",
       "4√ó4 Matrix{Int64}:\n",
       " 6   0   0   0\n",
       " 0  18   0   0\n",
       " 0   0  12   0\n",
       " 0   0   0  24\n",
       "\n",
       "julia> hessian(sin, pi/2)\n",
       "-1.0\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  hessian(f, x)\u001b[39m\n",
       "\n",
       "  Construct the Hessian \u001b[36m‚àÇ¬≤f/‚àÇx¬≤\u001b[39m, where \u001b[36mx\u001b[39m is a real number or an array, and\n",
       "  \u001b[36mf(x)\u001b[39m is a real number. When \u001b[36mx\u001b[39m is an array, the result is a matrix \u001b[36mH[i,j] =\n",
       "  ‚àÇ¬≤f/‚àÇx[i]‚àÇx[j]\u001b[39m, using linear indexing \u001b[36mx[i]\u001b[39m even if the argument is\n",
       "  higher-dimensional.\n",
       "\n",
       "  This uses forward over reverse, ForwardDiff over Zygote, calling\n",
       "  \u001b[36mhessian_dual(f, x)\u001b[39m. See \u001b[36mhessian_reverse\u001b[39m for an all-Zygote alternative.\n",
       "\n",
       "  See also \u001b[36mdiaghessian\u001b[39m to compute only the diagonal part.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ‚â°‚â°‚â°‚â°‚â°‚â°‚â°‚â°‚â°‚â°\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> hessian(x -> x[1]*x[2], randn(2))\u001b[39m\n",
       "\u001b[36m  2√ó2 Matrix{Float64}:\u001b[39m\n",
       "\u001b[36m   0.0  1.0\u001b[39m\n",
       "\u001b[36m   1.0  0.0\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> hessian(x -> sum(x.^3), [1 2; 3 4])  # uses linear indexing of x\u001b[39m\n",
       "\u001b[36m  4√ó4 Matrix{Int64}:\u001b[39m\n",
       "\u001b[36m   6   0   0   0\u001b[39m\n",
       "\u001b[36m   0  18   0   0\u001b[39m\n",
       "\u001b[36m   0   0  12   0\u001b[39m\n",
       "\u001b[36m   0   0   0  24\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> hessian(sin, pi/2)\u001b[39m\n",
       "\u001b[36m  -1.0\u001b[39m"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?Flux.hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e47bfef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m BitTwiddlingConvenienceFunctions ‚îÄ v0.1.5\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m GPUArraysCore ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v0.1.4\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ArrayInterfaceStaticArrays ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v0.1.5\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MCMCDiagnostics ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v0.3.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Adapt ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v3.5.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m SIMDTypes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v0.1.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m TransformVariables ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v0.3.12\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Rmath ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v0.7.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CpuId ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v0.3.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StatsFuns ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v0.9.18\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LayoutPointers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v0.1.13\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m OffsetArrays ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v1.12.9\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m VectorizationBase ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v0.21.58\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DynamicHMC ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ v3.3.0\n",
      "\u001b[32m\u001b[1m     Cloning\u001b[22m\u001b[39m [6e4b80f9-dd63-53aa-95a3-0cdb28fa8baf] BenchmarkTools from https://github.com/JuliaCI/BenchmarkTools.jl.git\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "failed to clone from https://github.com/JuliaCI/BenchmarkTools.jl.git, error: GitError(Code:ERROR, Class:Net, failed to resolve address for github.com: nodename nor servname provided, or not known)",
     "output_type": "error",
     "traceback": [
      "failed to clone from https://github.com/JuliaCI/BenchmarkTools.jl.git, error: GitError(Code:ERROR, Class:Net, failed to resolve address for github.com: nodename nor servname provided, or not known)",
      "",
      "Stacktrace:",
      "  [1] pkgerror(msg::String)",
      "    @ Pkg.Types /opt/local/share/julia/stdlib/v1.8/Pkg/src/Types.jl:67",
      "  [2] clone(io::IJulia.IJuliaStdio{Base.PipeEndpoint}, url::String, source_path::String; header::String, credentials::Nothing, kwargs::Base.Pairs{Symbol, Bool, Tuple{Symbol}, NamedTuple{(:isbare,), Tuple{Bool}}})",
      "    @ Pkg.GitTools /opt/local/share/julia/stdlib/v1.8/Pkg/src/GitTools.jl:126",
      "  [3] #ensure_clone#2",
      "    @ /opt/local/share/julia/stdlib/v1.8/Pkg/src/GitTools.jl:74 [inlined]",
      "  [4] install_git(io::IJulia.IJuliaStdio{Base.PipeEndpoint}, uuid::Base.UUID, name::String, hash::Base.SHA1, urls::Set{String}, version_path::String)",
      "    @ Pkg.Operations /opt/local/share/julia/stdlib/v1.8/Pkg/src/Operations.jl:587",
      "  [5] download_source(ctx::Pkg.Types.Context; readonly::Bool)",
      "    @ Pkg.Operations /opt/local/share/julia/stdlib/v1.8/Pkg/src/Operations.jl:814",
      "  [6] download_source",
      "    @ /opt/local/share/julia/stdlib/v1.8/Pkg/src/Operations.jl:700 [inlined]",
      "  [7] add(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec}, new_git::Set{Base.UUID}; preserve::Pkg.Types.PreserveLevel, platform::Base.BinaryPlatforms.Platform)",
      "    @ Pkg.Operations /opt/local/share/julia/stdlib/v1.8/Pkg/src/Operations.jl:1278",
      "  [8] add(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec}; preserve::Pkg.Types.PreserveLevel, platform::Base.BinaryPlatforms.Platform, kwargs::Base.Pairs{Symbol, IJulia.IJuliaStdio{Base.PipeEndpoint}, Tuple{Symbol}, NamedTuple{(:io,), Tuple{IJulia.IJuliaStdio{Base.PipeEndpoint}}}})",
      "    @ Pkg.API /opt/local/share/julia/stdlib/v1.8/Pkg/src/API.jl:275",
      "  [9] add(pkgs::Vector{Pkg.Types.PackageSpec}; io::IJulia.IJuliaStdio{Base.PipeEndpoint}, kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ Pkg.API /opt/local/share/julia/stdlib/v1.8/Pkg/src/API.jl:156",
      " [10] add(pkgs::Vector{Pkg.Types.PackageSpec})",
      "    @ Pkg.API /opt/local/share/julia/stdlib/v1.8/Pkg/src/API.jl:145",
      " [11] #add#27",
      "    @ /opt/local/share/julia/stdlib/v1.8/Pkg/src/API.jl:144 [inlined]",
      " [12] add",
      "    @ /opt/local/share/julia/stdlib/v1.8/Pkg/src/API.jl:144 [inlined]",
      " [13] #add#26",
      "    @ /opt/local/share/julia/stdlib/v1.8/Pkg/src/API.jl:143 [inlined]",
      " [14] add(pkg::String)",
      "    @ Pkg.API /opt/local/share/julia/stdlib/v1.8/Pkg/src/API.jl:143",
      " [15] top-level scope",
      "    @ In[16]:4"
     ]
    }
   ],
   "source": [
    "### A Pluto.jl notebook ###\n",
    "# v0.19.24\n",
    "\n",
    "import Pkg; \n",
    "Pkg.add(\"DynamicHMCModels\")\n",
    "using Markdown\n",
    "using InteractiveUtils\n",
    "\n",
    "# ‚ïî‚ïê‚ï° c0452572-c9ba-4833-b22a-49c0889b16b2\n",
    "using Pkg\n",
    "\n",
    "# ‚ïî‚ïê‚ï° a8c916a9-d464-4fe2-9b6b-ab61308bffed\n",
    "Pkg.activate(expanduser(\"~/.julia/dev/DynamicHMCModels\"))\n",
    "\n",
    "# ‚ïî‚ïê‚ï° e5a5c94e-402c-48a8-b573-5b5c877dba69\n",
    "begin\n",
    "\tusing DynamicHMCModels\n",
    "\tusing BenchmarkTools\n",
    "\tusing RegressionAndOtherStories\n",
    "end\n",
    "\n",
    "# ‚ïî‚ïê‚ï° c565bfd9-b5d2-4e50-9527-c8df52579858\n",
    "md\" ## Linear regression example\"\n",
    "\n",
    "# ‚ïî‚ïê‚ï° 2cf37bf9-9412-42cf-a524-0041581b48f9\n",
    "html\"\"\"\n",
    "<style>\n",
    "\tmain {\n",
    "\t\tmargin: 0 auto;\n",
    "\t\tmax-width: 3500px;\n",
    "    \tpadding-left: max(10px, 5%);\n",
    "    \tpadding-right: max(10px, 5%);\n",
    "\t}\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "# ‚ïî‚ïê‚ï° c897fe4c-4d26-40d0-9338-48022c7044bd\n",
    "md\" ### Estimate simple linear regression model with a half-T prior.\"\n",
    "\n",
    "# ‚ïî‚ïê‚ï° b9e2f55a-f809-4467-b617-b292e12b55c3\n",
    "begin\n",
    "\t# A structure to hold the data: observables, covariates, and the degrees of freedom for the prior.\n",
    "\n",
    "\t\"\"\"\n",
    "\tLinear regression model ``y ‚àº XŒ≤ + œµ``, where ``œµ ‚àº N(0, œÉ¬≤)`` IID.\n",
    "\tWeakly informative prior for `Œ≤`, half-T for `œÉ`.\n",
    "\t\"\"\"\n",
    "\tstruct LinearRegressionProblem{TY <: AbstractVector, TX <: AbstractMatrix, TŒΩ <: Real}\n",
    "\t    \"Observations.\"\n",
    "\t    y::TY\n",
    "\t    \"Covariates\"\n",
    "\t    X::TX\n",
    "\t    \"Degrees of freedom for prior.\"\n",
    "\t    ŒΩ::TŒΩ\n",
    "\tend\n",
    "\t\n",
    "\t# Make the type callable with the parameters *as a single argument*.\n",
    "\n",
    "\tfunction (problem::LinearRegressionProblem)(Œ∏)\n",
    "\t    @unpack y, X, ŒΩ = problem                    # extract the data\n",
    "\t    @unpack Œ≤, œÉ = Œ∏                             # works on the named tuple too\n",
    "\t    œµ_distribution = Normal(0, œÉ)                # the error term\n",
    "\t\t                                             # likelihood for error\n",
    "\t    ‚Ñì_error = mapreduce((y, x) -> logpdf(œµ_distribution, y - dot(x, Œ≤)), +, y, eachrow(X)) \n",
    "\t    ‚Ñì_œÉ = logpdf(TDist(ŒΩ), œÉ)                    # prior for œÉ\n",
    "\t    ‚Ñì_Œ≤ = loglikelihood(Normal(0, 10), Œ≤)        # prior for Œ≤\n",
    "\t    ‚Ñì_error + ‚Ñì_œÉ + ‚Ñì_Œ≤\n",
    "\tend\n",
    "end\n",
    "\n",
    "# ‚ïî‚ïê‚ï° 52bcf291-bae0-484d-83ac-2b72487584c9\n",
    "# Make up random data and test the function runs.\n",
    "\n",
    "begin\n",
    "\tN = 100\n",
    "\tX = hcat(ones(N), randn(N, 2));\n",
    "\tŒ≤ = [1.0, 2.0, -1.0]\n",
    "\tœÉ = 0.5\n",
    "\ty = X*Œ≤ .+ randn(N) .* œÉ;\n",
    "\tp = LinearRegressionProblem(y, X, 1.0);\n",
    "\tp((Œ≤ = Œ≤, œÉ = œÉ))\n",
    "end\n",
    "\n",
    "# ‚ïî‚ïê‚ï° 404098e3-543c-492e-8bff-0ac0c770dd3e\n",
    "md\" ##### It is usually a good idea to benchmark and optimize your log posterior code at this stage. Above, we have carefully optimized allocations away using `mapreduce`.\"\n",
    "\n",
    "# ‚ïî‚ïê‚ï° c3294c81-72a3-4435-8019-b0285ad33f6d\n",
    "@btime p((Œ≤ = $Œ≤, œÉ = $œÉ))\n",
    "\n",
    "# ‚ïî‚ïê‚ï° 21f09380-9554-47b3-b8b8-d04b6fc7260e\n",
    "md\" ##### For this problem, we write a function to return the transformation (as it varies with the number of covariates).\"\n",
    "\n",
    "# ‚ïî‚ïê‚ï° 14d716cb-6c14-45c0-8ef3-0065b2076b57\n",
    "function problem_transformation(p::LinearRegressionProblem)\n",
    "    as((Œ≤ = as(Array, size(p.X, 2)), œÉ = as‚Ñù‚Çä))\n",
    "end\n",
    "\n",
    "# ‚ïî‚ïê‚ï° f825e1bb-13d1-42f5-9808-de29b85604a2\n",
    "md\" ##### Wrap the problem with a transformation, then use ForwardDiff for the gradient.\"\n",
    "\n",
    "# ‚ïî‚ïê‚ï° 8519b5bd-797a-4513-82b3-1cfc072db755\n",
    "t = problem_transformation(p)\n",
    "\n",
    "# ‚ïî‚ïê‚ï° 70418813-3ea7-4143-9804-3a98f3f682dc\n",
    "P = TransformedLogDensity(t, p)\n",
    "\n",
    "# ‚ïî‚ïê‚ï° 275a0030-11ef-4533-b412-4ac82a8c795f\n",
    "‚àáP = ADgradient(:ForwardDiff, P);\n",
    "\n",
    "# ‚ïî‚ïê‚ï° ce7f9c63-6f71-480b-ad5b-95dae7f08dac\n",
    "md\" ##### Sample from the posterior. `results` holds the chain, positions, diagnostic information, and the tuned sampler (which would allow continuation of sampling).\"\n",
    "\n",
    "# ‚ïî‚ïê‚ï° 3b727805-8d0a-4d72-8b8c-7135095e1ff5\n",
    "results = map(_ -> mcmc_with_warmup(Random.default_rng(), ‚àáP, 1000), 1:5)\n",
    "\n",
    "# ‚ïî‚ïê‚ï° 83bef086-3538-4ae8-ac10-778fb1d0ce30\n",
    "md\" ##### We use the transformation to obtain the posterior from the chain.\"\n",
    "\n",
    "# ‚ïî‚ïê‚ï° 0d3a5d33-e49f-4a41-b190-a44ca915a1a4\n",
    "posterior = TransformVariables.transform.(t, eachcol(pool_posterior_matrices(results)))\n",
    "\n",
    "# ‚ïî‚ïê‚ï° 7a8ec9c6-2f00-450c-8d5a-2754f8e443d9\n",
    "md\" ##### Extract the parameter posterior means: `Œ≤`.\"\n",
    "\n",
    "# ‚ïî‚ïê‚ï° 11d815b2-8375-4229-970e-f66187b4d014\n",
    "posterior_Œ≤ = mean(first, posterior)\n",
    "\n",
    "# ‚ïî‚ïê‚ï° 4c790100-a9c9-452b-9e6a-6d9147a8d807\n",
    "md\" ##### then `œÉ`:\"\n",
    "\n",
    "# ‚ïî‚ïê‚ï° bfd42f7a-6d73-45cc-8112-c44749c2c1e7\n",
    "posterior_œÉ = mean(last, posterior)\n",
    "\n",
    "# ‚ïî‚ïê‚ï° fee2b723-23b7-45d3-add4-6657396a389b\n",
    "md\" ##### Effective sample sizes (of untransformed draws)\"\n",
    "\n",
    "# ‚ïî‚ïê‚ï° 2eeecb48-f659-4a26-89b1-0b16d64450ec\n",
    "ess, RÃÇ = ess_rhat(stack_posterior_matrices(results))\n",
    "\n",
    "# ‚ïî‚ïê‚ï° e3c07642-86f0-4d5c-b9e3-dc4f59731604\n",
    "md\" ##### Summarize NUTS-specific statistics of all chains\"\n",
    "\n",
    "# ‚ïî‚ïê‚ï° 2580659d-1186-481b-a1e7-d0f21cf08d94\n",
    "summarize_tree_statistics(mapreduce(x -> x.tree_statistics, vcat, results))\n",
    "\n",
    "# ‚ïî‚ïê‚ï° Cell order:\n",
    "# ‚ïü‚îÄc565bfd9-b5d2-4e50-9527-c8df52579858\n",
    "# ‚ï†‚ïê2cf37bf9-9412-42cf-a524-0041581b48f9\n",
    "# ‚ï†‚ïêc0452572-c9ba-4833-b22a-49c0889b16b2\n",
    "# ‚ï†‚ïêa8c916a9-d464-4fe2-9b6b-ab61308bffed\n",
    "# ‚ïü‚îÄc897fe4c-4d26-40d0-9338-48022c7044bd\n",
    "# ‚ï†‚ïêe5a5c94e-402c-48a8-b573-5b5c877dba69\n",
    "# ‚ï†‚ïêb9e2f55a-f809-4467-b617-b292e12b55c3\n",
    "# ‚ï†‚ïê52bcf291-bae0-484d-83ac-2b72487584c9\n",
    "# ‚ïü‚îÄ404098e3-543c-492e-8bff-0ac0c770dd3e\n",
    "# ‚ï†‚ïêc3294c81-72a3-4435-8019-b0285ad33f6d\n",
    "# ‚ïü‚îÄ21f09380-9554-47b3-b8b8-d04b6fc7260e\n",
    "# ‚ï†‚ïê14d716cb-6c14-45c0-8ef3-0065b2076b57\n",
    "# ‚ïü‚îÄf825e1bb-13d1-42f5-9808-de29b85604a2\n",
    "# ‚ï†‚ïê8519b5bd-797a-4513-82b3-1cfc072db755\n",
    "# ‚ï†‚ïê70418813-3ea7-4143-9804-3a98f3f682dc\n",
    "# ‚ï†‚ïê275a0030-11ef-4533-b412-4ac82a8c795f\n",
    "# ‚ïü‚îÄce7f9c63-6f71-480b-ad5b-95dae7f08dac\n",
    "# ‚ï†‚ïê3b727805-8d0a-4d72-8b8c-7135095e1ff5\n",
    "# ‚ïü‚îÄ83bef086-3538-4ae8-ac10-778fb1d0ce30\n",
    "# ‚ï†‚ïê0d3a5d33-e49f-4a41-b190-a44ca915a1a4\n",
    "# ‚ïü‚îÄ7a8ec9c6-2f00-450c-8d5a-2754f8e443d9\n",
    "# ‚ï†‚ïê11d815b2-8375-4229-970e-f66187b4d014\n",
    "# ‚ïü‚îÄ4c790100-a9c9-452b-9e6a-6d9147a8d807\n",
    "# ‚ï†‚ïêbfd42f7a-6d73-45cc-8112-c44749c2c1e7\n",
    "# ‚ïü‚îÄfee2b723-23b7-45d3-add4-6657396a389b\n",
    "# ‚ï†‚ïê2eeecb48-f659-4a26-89b1-0b16d64450ec\n",
    "# ‚ïü‚îÄe3c07642-86f0-4d5c-b9e3-dc4f59731604\n",
    "# ‚ï†‚ïê2580659d-1186-481b-a1e7-d0f21cf08d94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d36bf0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
