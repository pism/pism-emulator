{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95516590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg\n",
    "Pkg.add(\"Turing\")\n",
    "Pkg.add(\"Flux\")\n",
    "Pkg.add(\"NCDatasets\")\n",
    "Pkg.add(\"TSVD\")\n",
    "Pkg.add(\"Statistics\")\n",
    "Pkg.add(\"Compat\")\n",
    "Pkg.add(\"LinearAlgebra\")\n",
    "Pkg.add(\"Glob\")\n",
    "Pkg.add(\"CSV\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"Distributions\")\n",
    "Pkg.add(\"ProgressMeter\")\n",
    "Pkg.add(\"PyPlot\")\n",
    "Pkg.add(\"Random\")\n",
    "Pkg.add(\"StatsPlots\")\n",
    "Pkg.add(\"SpecialFunctions\")\n",
    "Pkg.add(\"ReverseDiff\")\n",
    "Pkg.add(\"BSON\")\n",
    "Pkg.add(\"TransformVariables\")\n",
    "Pkg.add(\"TransformedLogDensities\")\n",
    "Pkg.add(\"LogDensityProblems\")\n",
    "Pkg.add(\"LogDensityProblemsAD\")\n",
    "Pkg.add(\"DynamicHMC\")\n",
    "Pkg.add(\"Parameters\")\n",
    "Pkg.add(\"TSVD\")\n",
    "Pkg.add(\"Glob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d319996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Statistics\n",
    "using LinearAlgebra\n",
    "using Compat\n",
    "using Glob\n",
    "using TSVD\n",
    "using NCDatasets\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Distributions: Categorical, Dirichlet, Gamma, Beta\n",
    "using ProgressMeter\n",
    "using PyPlot\n",
    "using Random\n",
    "using SpecialFunctions: loggamma\n",
    "using ReverseDiff\n",
    "using BSON: @load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dbeac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_file =\"../data/observed_speeds/greenland_vel_mosaic250_v1_g9000m.nc\"\n",
    "d_obs = NCDataset(obs_file)\n",
    "v_obs = d_obs[\"velsurf_mag\"][:]\n",
    "v_obs = nomissing(v_obs, 0.0);\n",
    "idx = findall(v_obs .> 0)\n",
    "Obs = v_obs[idx];\n",
    "\n",
    "n_grid_points = size(idx)[1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5373fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:02\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "training_files = sort(glob(\"../tests/training_data/*.nc\"))\n",
    "\n",
    "nf = length(training_files)\n",
    "d = NCDataset(training_files[1], \"r\")\n",
    "v = d[\"velsurf_mag\"]\n",
    "nx, ny, nt = size(v)\n",
    "\n",
    "Data = zeros(n_grid_points, nf * nt)\n",
    "ids = zeros(Int64, nf)\n",
    "@showprogress for (k, training_file) in enumerate(training_files)\n",
    "    m_id = match(r\"id_(.+?)_\", training_file)\n",
    "    ids[k] = parse(Int, m_id[1])\n",
    "    d = NCDataset(training_file, \"r\")\n",
    "    v = d[\"velsurf_mag\"][:]\n",
    "    v = nomissing(v, 0.0)\n",
    "    Data[:, k] = v[idx]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031e1c0a",
   "metadata": {},
   "source": [
    "## Read training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee568a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = DataFrame(CSV.File(\"../data/samples/velocity_calibration_samples_50.csv\"))\n",
    "X_df = X_df[ [x in ids for x in X_df[!, :id]] ,:]\n",
    "X = transpose(Matrix(X_df[!, 2:9]))\n",
    "X_mean = mean(X, dims=2);\n",
    "X_std = std(X, dims=2);\n",
    "X_scaled = (X .- X_mean) ./ X_std;\n",
    "X_train = X_scaled;\n",
    "n_parameters, n_samples = size(X);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd2995",
   "metadata": {},
   "source": [
    "## Load the model\n",
    "\n",
    "Should be a commmand line argument\n",
    "\n",
    "That we have to define the struct again is not ok. How can we avoid this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbbb0caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct NNModel\n",
    "    chain::Chain\n",
    "    V_hat::AbstractArray\n",
    "    F_mean::AbstractArray\n",
    "end\n",
    "\n",
    "function (m::NNModel)(x, add_mean=false)\n",
    "    if add_mean\n",
    "        return V_hat * m.chain(x) .+ F_mean\n",
    "    else\n",
    "        return V_hat * m.chain(x)\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1cdbeb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "@load \"emulator_1.bson\" model\n",
    "# model = Flux.loadmodel!(model, @load(\"mymodel.bson\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9e6da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_eigenglaciers(omegas, F, q)\n",
    "    \n",
    "    F_mean = sum(F .* omegas, dims=2);\n",
    "    F_bar = F .- F_mean;\n",
    "\n",
    "    Z = diagm(sqrt.(omegas[1, :] * n_grid_points))\n",
    "    U, S, V = tsvd(Z * transpose(F_bar), q);\n",
    "    lamda = S.^2 / n_grid_points\n",
    "    V_hat = V * diagm(sqrt.(lamda));\n",
    "    \n",
    "    return V_hat, F_bar, F_mean\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1faf9480",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 50\n",
    "F = log10.(Data)\n",
    "F = replace!(F, -Inf=>0)\n",
    "\n",
    "dirichlet_dist = Dirichlet(n_samples, 1)\n",
    "\n",
    "model_index = 1\n",
    "Random.seed!(model_index)\n",
    "omegas = transpose(rand(dirichlet_dist, 1))\n",
    "omegas_0 = omegas ./ size(omegas)[1];\n",
    "    \n",
    "V_hat, F_bar, F_mean = get_eigenglaciers(omegas, F, q);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f2f73b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_b = 3;\n",
    "beta_b = 3;\n",
    "beta_dist = Beta(alpha_b, beta_b);\n",
    "X_prior = rand(beta_dist, n_parameters, 100000);\n",
    "X_0 = mean(X_prior, dims=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ce47f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_target = log10.(Obs);\n",
    "Y_target = replace!(Y_target, -Inf=>0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e25250d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_resolution = ones(n_grid_points) .* 9000\n",
    "sigma = 10\n",
    "rho = 1.0 / (1e4 .^ 2)\n",
    "point_area = (grid_resolution) .^ 2\n",
    "K = point_area .* rho\n",
    "sigma_hat = sqrt.(sigma .^ 2 ./ K .^ 2)\n",
    "\n",
    "X_min = minimum(X_scaled, dims=2);\n",
    "X_max = maximum(X_scaled, dims=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75e7c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "using TransformVariables, TransformedLogDensities, LogDensityProblems, LogDensityProblemsAD,\n",
    "    DynamicHMC, DynamicHMC.Diagnostics, Parameters, Statistics, Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "84099085",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct SampleBayesProblem\n",
    "    nn\n",
    "    X_min::AbstractArray\n",
    "    X_max::AbstractArray\n",
    "    Y_target::AbstractArray\n",
    "    sigma_hat::AbstractArray\n",
    "    nu::Int\n",
    "    alpha::Float16\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3474f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "function (problem::SampleBayesProblem)(Œ∏)\n",
    "    @unpack Œ± = Œ∏               # extract the parameters\n",
    "    @unpack nn, X_min, X_max, Y_target, sigma_hat, nu, alpha = problem       # extract the data\n",
    "    \n",
    "    Y_pred = 10 .^ nn(Œ±, true)\n",
    "    r = Y_pred .- Y_target\n",
    "    t = r ./ sigma_hat\n",
    "\n",
    "    # StudentT distribution\n",
    "    loglikelihood = sum(\n",
    "        loggamma((nu + 1) / 2)\n",
    "        - loggamma(nu / 2)\n",
    "        .- log.(sqrt.(pi * nu) .* sigma_hat)\n",
    "        .- (nu + 1) / 2.0 * log.(1 .+ 1.0 / nu .* t .^ 2)\n",
    "    )\n",
    "    # Beta prior\n",
    "    X_bar = relu((Œ± .- X_min) ./ (X_max - X_min))\n",
    "    logprior = sum(\n",
    "        (alpha_b - 1) * log.(X_bar) + (beta_b - 1) * log.(1 .- X_bar) \n",
    "        .+ loggamma(alpha_b + beta_b) \n",
    "        .- loggamma(alpha_b)\n",
    "        .- loggamma(beta_b)\n",
    "    )\n",
    "    return (alpha * loglikelihood + logprior)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2e71af45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nu = 1\n",
    "alpha = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d18e4458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1452.0127961516039"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logp = SampleBayesProblem(model, X_min, X_max, Y_target, sigma_hat, nu, alpha)\n",
    "logp((Œ± = X_0,)) # make sure that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ab2952a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zygote AD wrapper for TransformedLogDensity of dimension 8"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = as((Œ± = as(Array, asùïÄ, n_parameters),))\n",
    "P = TransformedLogDensity(trans, logp)\n",
    "‚àáP = ADgradient(:Zygote, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2322c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LineSearches\n",
    "using Optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "76172a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "Iter     Function value   Gradient norm \n",
      "     0    -1.451702e+03     2.302032e+02\n",
      " * time: 1.9073486328125e-5\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "DomainError with -0.015968561594892794:\nlog will only return a complex result if called with a complex argument. Try log(Complex(x)).",
     "output_type": "error",
     "traceback": [
      "DomainError with -0.015968561594892794:\nlog will only return a complex result if called with a complex argument. Try log(Complex(x)).",
      "",
      "Stacktrace:",
      "  [1] throw_complex_domainerror(f::Symbol, x::Float64)",
      "    @ Base.Math ./math.jl:33",
      "  [2] _log(x::Float64, base::Val{:‚ÑØ}, func::Symbol)",
      "    @ Base.Math ./special/log.jl:301",
      "  [3] log",
      "    @ ./special/log.jl:267 [inlined]",
      "  [4] _broadcast_getindex_evalf",
      "    @ ./broadcast.jl:670 [inlined]",
      "  [5] _broadcast_getindex",
      "    @ ./broadcast.jl:643 [inlined]",
      "  [6] getindex",
      "    @ ./broadcast.jl:597 [inlined]",
      "  [7] macro expansion",
      "    @ ./broadcast.jl:961 [inlined]",
      "  [8] macro expansion",
      "    @ ./simdloop.jl:77 [inlined]",
      "  [9] copyto!",
      "    @ ./broadcast.jl:960 [inlined]",
      " [10] copyto!",
      "    @ ./broadcast.jl:913 [inlined]",
      " [11] copy",
      "    @ ./broadcast.jl:885 [inlined]",
      " [12] materialize",
      "    @ ./broadcast.jl:860 [inlined]",
      " [13] log_prior(X_bar::Matrix{Float64}, alpha_b::Int64, beta_b::Int64)",
      "    @ Main ./In[166]:2",
      " [14] logp_g(Œ±::Matrix{Float64}, nn::NNModel, X_min::Matrix{Float64}, X_max::Matrix{Float64}, Y_target::Vector{Float32}, sigma_hat::Vector{Float64}, nu::Int64, alpha::Float64)",
      "    @ Main ./In[166]:27",
      " [15] ll(X_0::Matrix{Float64})",
      "    @ Main ./In[166]:34",
      " [16] finite_difference_gradient!(df::Matrix{Float64}, f::typeof(ll), x::Matrix{Float64}, cache::FiniteDiff.GradientCache{Nothing, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}, Val{:central}(), Float64, Val{true}()}; relstep::Float64, absstep::Float64, dir::Bool)",
      "    @ FiniteDiff ~/.julia/packages/FiniteDiff/40JnL/src/gradients.jl:230",
      " [17] finite_difference_gradient!",
      "    @ ~/.julia/packages/FiniteDiff/40JnL/src/gradients.jl:172 [inlined]",
      " [18] (::NLSolversBase.var\"#g!#15\"{typeof(ll), FiniteDiff.GradientCache{Nothing, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}, Val{:central}(), Float64, Val{true}()}})(storage::Matrix{Float64}, x::Matrix{Float64})",
      "    @ NLSolversBase ~/.julia/packages/NLSolversBase/kavn7/src/objective_types/oncedifferentiable.jl:57",
      " [19] (::NLSolversBase.var\"#fg!#16\"{typeof(ll)})(storage::Matrix{Float64}, x::Matrix{Float64})",
      "    @ NLSolversBase ~/.julia/packages/NLSolversBase/kavn7/src/objective_types/oncedifferentiable.jl:61",
      " [20] value_gradient!!(obj::OnceDifferentiable{Float64, Matrix{Float64}, Matrix{Float64}}, x::Matrix{Float64})",
      "    @ NLSolversBase ~/.julia/packages/NLSolversBase/kavn7/src/interface.jl:82",
      " [21] value_gradient!(obj::OnceDifferentiable{Float64, Matrix{Float64}, Matrix{Float64}}, x::Matrix{Float64})",
      "    @ NLSolversBase ~/.julia/packages/NLSolversBase/kavn7/src/interface.jl:69",
      " [22] value_gradient!(obj::Optim.ManifoldObjective{OnceDifferentiable{Float64, Matrix{Float64}, Matrix{Float64}}}, x::Matrix{Float64})",
      "    @ Optim ~/.julia/packages/Optim/tP8PJ/src/Manifolds.jl:50",
      " [23] (::LineSearches.var\"#œïdœï#2\"{Optim.ManifoldObjective{OnceDifferentiable{Float64, Matrix{Float64}, Matrix{Float64}}}, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}})(Œ±::Float64)",
      "    @ LineSearches ~/.julia/packages/LineSearches/G1LRk/src/LineSearches.jl:35",
      " [24] (::MoreThuente{Float64})(œïdœï::LineSearches.var\"#œïdœï#2\"{Optim.ManifoldObjective{OnceDifferentiable{Float64, Matrix{Float64}, Matrix{Float64}}}, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}}, alpha::Float64, œï_0::Float64, dœï_0::Float64)",
      "    @ LineSearches ~/.julia/packages/LineSearches/G1LRk/src/morethuente.jl:233",
      " [25] MoreThuente",
      "    @ ~/.julia/packages/LineSearches/G1LRk/src/morethuente.jl:154 [inlined]",
      " [26] perform_linesearch!(state::Optim.LBFGSState{Matrix{Float64}, Vector{Matrix{Float64}}, Vector{Matrix{Float64}}, Float64, Matrix{Float64}}, method::LBFGS{Nothing, InitialStatic{Float64}, MoreThuente{Float64}, Optim.var\"#20#22\"}, d::Optim.ManifoldObjective{OnceDifferentiable{Float64, Matrix{Float64}, Matrix{Float64}}})",
      "    @ Optim ~/.julia/packages/Optim/tP8PJ/src/utilities/perform_linesearch.jl:59",
      " [27] update_state!(d::OnceDifferentiable{Float64, Matrix{Float64}, Matrix{Float64}}, state::Optim.LBFGSState{Matrix{Float64}, Vector{Matrix{Float64}}, Vector{Matrix{Float64}}, Float64, Matrix{Float64}}, method::LBFGS{Nothing, InitialStatic{Float64}, MoreThuente{Float64}, Optim.var\"#20#22\"})",
      "    @ Optim ~/.julia/packages/Optim/tP8PJ/src/multivariate/solvers/first_order/l_bfgs.jl:204",
      " [28] optimize(d::OnceDifferentiable{Float64, Matrix{Float64}, Matrix{Float64}}, initial_x::Matrix{Float64}, method::LBFGS{Nothing, InitialStatic{Float64}, MoreThuente{Float64}, Optim.var\"#20#22\"}, options::Optim.Options{Float64, Nothing}, state::Optim.LBFGSState{Matrix{Float64}, Vector{Matrix{Float64}}, Vector{Matrix{Float64}}, Float64, Matrix{Float64}})",
      "    @ Optim ~/.julia/packages/Optim/tP8PJ/src/multivariate/optimize/optimize.jl:54",
      " [29] optimize",
      "    @ ~/.julia/packages/Optim/tP8PJ/src/multivariate/optimize/optimize.jl:36 [inlined]",
      " [30] #optimize#89",
      "    @ ~/.julia/packages/Optim/tP8PJ/src/multivariate/optimize/interface.jl:142 [inlined]",
      " [31] optimize(f::Function, initial_x::Matrix{Float64}, method::LBFGS{Nothing, InitialStatic{Float64}, MoreThuente{Float64}, Optim.var\"#20#22\"}, options::Optim.Options{Float64, Nothing})",
      "    @ Optim ~/.julia/packages/Optim/tP8PJ/src/multivariate/optimize/interface.jl:138",
      " [32] top-level scope",
      "    @ In[166]:35"
     ]
    }
   ],
   "source": [
    "function log_prior(X_bar, alpha_b, beta_b)\n",
    "    sum(\n",
    "        (alpha_b - 1) * log.(X_bar) + (beta_b - 1) * log.(1 .- X_bar)\n",
    "        .+ loggamma(alpha_b + beta_b) \n",
    "        .- loggamma(alpha_b)\n",
    "        .- loggamma(beta_b)\n",
    "    )\n",
    "end\n",
    "\n",
    "function logp_g(Œ±, nn, X_min, X_max, Y_target, sigma_hat, nu, alpha)\n",
    "    \n",
    "    Y_pred = 10 .^ nn(Œ±, true)\n",
    "    r = Y_pred .- Y_target\n",
    "    t = r ./ sigma_hat\n",
    "\n",
    "    # StudentT distribution\n",
    "    loglikelihood = sum(\n",
    "        loggamma((nu + 1) / 2)\n",
    "        - loggamma(nu / 2)\n",
    "        .- log.(sqrt.(pi * nu) .* sigma_hat)\n",
    "        .- (nu + 1) / 2.0 * log.(1 .+ 1.0 / nu .* t .^ 2)\n",
    "    )\n",
    "    # Beta prior\n",
    "    X_bar = (Œ± .- X_min) ./ (X_max - X_min)\n",
    "    insupport(X) = sum(X_bar .< 0) == 0\n",
    "    println(insupport(X))\n",
    "    logprior = insupport(X) ?  log_prior(X_bar, alpha_b, beta_b) : -Inf\n",
    "    \n",
    "    (alpha * loglikelihood + logprior)\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "ll(X_0) = logp_g(X_0, model, X_min, X_max, Y_target, sigma_hat, nu, alpha)\n",
    "res = optimize(ll, X_0, LBFGS(linesearch = LineSearches.MoreThuente(), ), Optim.Options(show_trace=true, iterations = 51))\n",
    "X_map = Optim.minimizer(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f93c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_map .* X_std .+ X_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2099d664",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = mcmc_with_warmup(Random.default_rng(), ‚àáP, 2; \n",
    "    initialization = (q = vec(X_map), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b80318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_tree_statistics(results.tree_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0685010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = transform.(trans, eachcol(results.posterior_matrix))\n",
    "posterior_Œ± = first.(posterior)\n",
    "mean(posterior_Œ±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6d6fdd14",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: pathfinder not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: pathfinder not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[97]:3"
     ]
    }
   ],
   "source": [
    "logp_p(x) = LogDensityProblems.logdensity(P, x)\n",
    "‚àálogp_p(x) = LogDensityProblems.logdensity_and_gradient(‚àáP, x)[2]\n",
    "result_pf = pathfinder(logp_p, ‚àálogp_p; dim=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a269cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = result_pf.draws[:, 1]\n",
    "result_dhmc1 = mcmc_with_warmup(\n",
    "    Random.GLOBAL_RNG,\n",
    "    ‚àáP,\n",
    "    1;\n",
    "    initialization=(; q=init_params),\n",
    "    reporter=NoProgressReport(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c8cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add(\"Optim\")\n",
    "using Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372b96a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add(\"StatsBase\")\n",
    "using StatsBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93930176",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add(\"Pathfinder\")\n",
    "using Pathfinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb081029",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add(\"AdvancedMH\")\n",
    "Pkg.add(\"MCMCChains\")\n",
    "using AdvancedMH\n",
    "using MCMCChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29182947",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add(\"StructArrays\")\n",
    "using LogDensityProblemsAD\n",
    "using LogDensityProblems\n",
    "using AdvancedMH\n",
    "using Distributions\n",
    "using MCMCChains\n",
    "using ForwardDiff\n",
    "using StructArrays\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6005f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample(‚àáP, logp, 100000; init_params=ones(2), chain_type=StructArray, param_names=[\"Œº\", \"œÉ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f44b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a =log(Complex(-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6d6b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "?real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d2cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using Distributions\n",
    "Pkg.add(\"Arpack\")\n",
    "using Arpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4ad123",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "function mala(logdensity,gradient,h,M,niter,Œ∏init)       \n",
    "        function gradientStep(Œ∏,t)                                                                                                                                                                                 \n",
    "                Œ∏-t*M*gradient(Œ∏)                                                                                                                                                                                  \n",
    "        end        \n",
    "        print(Œ∏init)\n",
    "        Œ∏trace = zeros(length(Œ∏init),niter)\n",
    "        #Œ∏trace=Array{Float64}(length(Œ∏init),niter)    \n",
    "        Œ∏=Œ∏init\n",
    "        Œ∏trace[:,1]=Œ∏init                                                                                                                                                                                          \n",
    "        for i=2:niter                                                                                                                                                                                              \n",
    "                Œ∏old=Œ∏                                                                                                                                                                                             \n",
    "                Œ∏=rand(MvNormal(gradientStep(Œ∏,0.5*h),h*M))                                                                                                                                                        \n",
    "                d=logdensity(Œ∏) - logdensity(Œ∏old) + logpdf(MvNormal(gradientStep(Œ∏,0.5*h),h*M),Œ∏old) - logpdf(MvNormal(gradientStep(Œ∏old,0.5*h),h*M),Œ∏)                                                           \n",
    "                if(!(log(rand(Uniform(0,1)))<d))                                                                                                                                                                   \n",
    "                        Œ∏=Œ∏old                                                                                                                                                                                     \n",
    "                end                                                                                                                                                                                                \n",
    "                Œ∏trace[:,i]=Œ∏                                                                                                                                                                                      \n",
    "        end                                                                                                                                                                                                        \n",
    "        Œ∏trace                                                                                                                                                                                                     \n",
    "end  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "884c3f30",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "error in method definition: function Zygote.gradient must be explicitly imported to be extended",
     "output_type": "error",
     "traceback": [
      "error in method definition: function Zygote.gradient must be explicitly imported to be extended",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ none:0",
      " [2] top-level scope",
      "   @ In[60]:8"
     ]
    }
   ],
   "source": [
    "œÅ¬≤=0.8                                                                                                                                                                                                             \n",
    "Œ£=[1 œÅ¬≤;œÅ¬≤ 1]                                                                                                                                                                                                      \n",
    "                                                                                                                                                                                                                   \n",
    "function logdensity(Œ∏)                                                                                                                                                                                             \n",
    "        logpdf(MvNormal(Œ£),Œ∏)                                                                                                                                                                                      \n",
    "end                                                                                                                                                                                                                \n",
    "                                                                                                                                                                                                                   \n",
    "function gradient(Œ∏)                                                                                                                                                                                               \n",
    "        Œ£\\Œ∏                                                                                                                                                                                                        \n",
    "end  \n",
    " \n",
    "\n",
    "function Hinv\n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "gradient((Œ±= X_0),)\n",
    "niter=1000                                                                                                                                                                                                         \n",
    "h=1/eigs(inv(Œ£),nev=1)[1][1]                                                                                                                                                                                       \n",
    "#draws=mala(logp,gradient,h,I,niter,[5,50]);   #No preconditioning                                                                                                                                                                                                                                                                                                    \n",
    "pdraws=mala(logp,gradient,h,Œ£,niter, X_0);       #With Preconditioning                                                                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c81c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(pdraws, dims=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413d4da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logp_gg(X_0) = logp_g(X_0, model, X_min, X_max, Y_target, sigma_hat, nu, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f865a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zygote.gradient(logp_gg, X_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5710594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Flux.gradient(logp_gg, X_0)\n",
    "g[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b886cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "?gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e59577",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add(\"Zygote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be1d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Zygote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ff018f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logpi (generic function with 2 methods)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function logpi(Œ±, nn, X_min, X_max, Y_target, sigma_hat, nu, alpha)\n",
    "    \n",
    "    Y_pred = 10 .^ nn(Œ±, true)\n",
    "    r = Y_pred .- Y_target\n",
    "    t = r ./ sigma_hat\n",
    "\n",
    "    # StudentT distribution\n",
    "    loglikelihood = sum(\n",
    "        loggamma((nu + 1) / 2)\n",
    "        - loggamma(nu / 2)\n",
    "        .- log.(sqrt.(pi * nu) .* sigma_hat)\n",
    "        .- (nu + 1) / 2.0 * log.(1 .+ 1.0 / nu .* t .^ 2)\n",
    "    )\n",
    "    # Beta prior\n",
    "    X_bar = (Œ± .- X_min) ./ (X_max - X_min)\n",
    "    logprior = sum(\n",
    "        (alpha_b - 1) * log.(X_bar) + (beta_b - 1) * log.(1 .- X_bar)\n",
    "        .+ loggamma(alpha_b + beta_b) \n",
    "        .- loggamma(alpha_b)\n",
    "        .- loggamma(beta_b)\n",
    "    )\n",
    "\n",
    "    insupport(X) = sum(X_bar .< 0) == 0\n",
    "    insupport(X) ?  (alpha * loglikelihood + logprior) : -Inf\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b57c2a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llogpi (generic function with 1 method)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llogpi(X_0) = logpi(X_0, model, X_min, X_max, Y_target, sigma_hat, nu, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "022e5d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_log_like_gradient_and_hessian (generic function with 1 method)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_log_like_gradient_and_hessian(X;  eps=1e-2, compute_hessian=false)\n",
    "   log_pi =  llogpi(X)\n",
    "    if compute_hessian\n",
    "        g = Zygote.gradient(llogpi, X)\n",
    "        H = Zygote.hessian(llogpi, X)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "965c64f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: Zygote not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: Zygote not defined",
      "",
      "Stacktrace:",
      " [1] get_log_like_gradient_and_hessian(X::Matrix{Float64}; eps::Float64, compute_hessian::Bool)",
      "   @ Main ./In[65]:4",
      " [2] top-level scope",
      "   @ In[66]:1"
     ]
    }
   ],
   "source": [
    "get_log_like_gradient_and_hessian(X_0, compute_hessian=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "33b84acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nu = 1\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7844470e",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: Sampler for this object is not defined",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Sampler for this object is not defined",
      "",
      "Stacktrace:",
      "  [1] Random.Sampler(#unused#::Type{TaskLocalRNG}, sp::Random.SamplerType{ForwardDiff.Dual{Nothing, Float64, 8}}, #unused#::Val{1})",
      "    @ Random /opt/local/share/julia/stdlib/v1.8/Random/src/Random.jl:146",
      "  [2] Random.Sampler(rng::TaskLocalRNG, x::Random.SamplerType{ForwardDiff.Dual{Nothing, Float64, 8}}, r::Val{1})",
      "    @ Random /opt/local/share/julia/stdlib/v1.8/Random/src/Random.jl:140",
      "  [3] rand(rng::TaskLocalRNG, X::Random.SamplerType{ForwardDiff.Dual{Nothing, Float64, 8}})",
      "    @ Random /opt/local/share/julia/stdlib/v1.8/Random/src/Random.jl:254",
      "  [4] rand!",
      "    @ /opt/local/share/julia/stdlib/v1.8/Random/src/Random.jl:272 [inlined]",
      "  [5] rand! (repeats 2 times)",
      "    @ /opt/local/share/julia/stdlib/v1.8/Random/src/Random.jl:268 [inlined]",
      "  [6] _dropout_mask(rng::TaskLocalRNG, x::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}}, p::Float64; dims::Function)",
      "    @ Flux ~/.julia/packages/Flux/v79Am/src/layers/normalise.jl:45",
      "  [7] #dropout_mask#304",
      "    @ ~/.julia/packages/Flux/v79Am/src/layers/normalise.jl:42 [inlined]",
      "  [8] chain_rrule_kw",
      "    @ ~/.julia/packages/Zygote/g2w9o/src/compiler/chainrules.jl:235 [inlined]",
      "  [9] macro expansion",
      "    @ ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:0 [inlined]",
      " [10] _pullback",
      "    @ ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:9 [inlined]",
      " [11] _pullback",
      "    @ ~/.julia/packages/Flux/v79Am/src/layers/normalise.jl:34 [inlined]",
      " [12] _pullback(::Zygote.Context{false}, ::Flux.var\"##dropout#300\", ::Colon, ::Bool, ::typeof(dropout), ::TaskLocalRNG, ::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}}, ::Float64)",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:0",
      " [13] _pullback",
      "    @ ~/.julia/packages/Flux/v79Am/src/layers/normalise.jl:32 [inlined]",
      " [14] _pullback(::Zygote.Context{false}, ::Flux.var\"#dropout##kw\", ::NamedTuple{(:dims, :active), Tuple{Colon, Bool}}, ::typeof(dropout), ::TaskLocalRNG, ::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}}, ::Float64)",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:0",
      " [15] _pullback",
      "    @ ~/.julia/packages/Flux/v79Am/src/layers/normalise.jl:111 [inlined]",
      " [16] _pullback(ctx::Zygote.Context{false}, f::Dropout{Float64, Colon, TaskLocalRNG}, args::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}})",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:0",
      " [17] macro expansion",
      "    @ ~/.julia/packages/Flux/v79Am/src/layers/basic.jl:53 [inlined]",
      " [18] _pullback",
      "    @ ~/.julia/packages/Flux/v79Am/src/layers/basic.jl:53 [inlined]",
      " [19] _pullback(::Zygote.Context{false}, ::typeof(Flux._applychain), ::Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Bool}}, ::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}})",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:0",
      " [20] _pullback",
      "    @ ~/.julia/packages/Flux/v79Am/src/layers/basic.jl:51 [inlined]",
      " [21] _pullback(ctx::Zygote.Context{false}, f::Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dropout{Float64, Colon, TaskLocalRNG}, Dense{typeof(identity), Matrix{Float32}, Bool}}}, args::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}})",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:0",
      " [22] _pullback",
      "    @ ./In[5]:0 [inlined]",
      " [23] _pullback(::Zygote.Context{false}, ::NNModel, ::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}}, ::Bool)",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:0",
      " [24] _pullback",
      "    @ ./In[63]:3 [inlined]",
      " [25] _pullback(::Zygote.Context{false}, ::typeof(logpi), ::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}}, ::NNModel, ::Matrix{Float64}, ::Matrix{Float64}, ::Vector{Float32}, ::Vector{Float64}, ::Int64, ::Float64)",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:0",
      " [26] _pullback",
      "    @ ./In[64]:1 [inlined]",
      " [27] _pullback(ctx::Zygote.Context{false}, f::typeof(llogpi), args::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}})",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface2.jl:0",
      " [28] pullback(f::Function, cx::Zygote.Context{false}, args::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}})",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface.jl:44",
      " [29] pullback",
      "    @ ~/.julia/packages/Zygote/g2w9o/src/compiler/interface.jl:42 [inlined]",
      " [30] gradient(f::Function, args::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}})",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/compiler/interface.jl:96",
      " [31] (::Zygote.var\"#102#103\"{typeof(llogpi)})(x::Matrix{ForwardDiff.Dual{Nothing, Float64, 8}})",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/lib/grad.jl:64",
      " [32] forward_jacobian(f::Zygote.var\"#102#103\"{typeof(llogpi)}, x::Matrix{Float64}, #unused#::Val{8})",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/lib/forward.jl:29",
      " [33] forward_jacobian(f::Function, x::Matrix{Float64}; chunk_threshold::Int64)",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/lib/forward.jl:44",
      " [34] forward_jacobian",
      "    @ ~/.julia/packages/Zygote/g2w9o/src/lib/forward.jl:42 [inlined]",
      " [35] hessian_dual",
      "    @ ~/.julia/packages/Zygote/g2w9o/src/lib/grad.jl:64 [inlined]",
      " [36] hessian(f::Function, x::Matrix{Float64})",
      "    @ Zygote ~/.julia/packages/Zygote/g2w9o/src/lib/grad.jl:62",
      " [37] top-level scope",
      "    @ In[68]:1"
     ]
    }
   ],
   "source": [
    "Flux.hessian(llogpi, X_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "75b636ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching llogpi()\n\u001b[0mClosest candidates are:\n\u001b[0m  llogpi(\u001b[91m::Any\u001b[39m) at In[64]:1",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching llogpi()\n\u001b[0mClosest candidates are:\n\u001b[0m  llogpi(\u001b[91m::Any\u001b[39m) at In[64]:1",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[69]:1"
     ]
    }
   ],
   "source": [
    "Flux.gradient(llogpi(), X_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9618772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "?Zygote.hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e900a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "f(x, y) = sum((x .- y) .^ 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7fe08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.gradient(f, [2, 1], [2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "g(x, y, a, b) = sum((a .* x .- b .* y) .^ 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8740d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.gradient(g, [2, 1], [2, 0], 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e737cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zygote.hessian(logpi, X_0, model, X_min, X_max, Y_target, sigma_hat, nu, alpha)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3f4aca84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_pred: 58.99657521835326\n",
      "Log_prob: -1451.7018975352285\n",
      "Y_pred: 99.79009360000074\n",
      "Y_pred: 61.590387812293535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1444.0742151359996"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function logpi(Œ±, nn, X_min, X_max, Y_target, sigma_hat, nu, alpha)\n",
    "    Y_pred = 10 .^ nn(Œ±, true);\n",
    "    r = Y_pred .- Y_target\n",
    "    t = r ./ sigma_hat\n",
    "\n",
    "    # StudentT distribution\n",
    "    loglikelihood = sum(\n",
    "        loggamma((nu + 1) / 2)\n",
    "        - loggamma(nu / 2)\n",
    "        .- log.(sqrt.(pi * nu) .* sigma_hat)\n",
    "        .- (nu + 1) / 2.0 * log.(1 .+ 1.0 / nu .* t .^ 2)\n",
    "    )\n",
    "    \n",
    "    println(\"Y_pred: \", mean(Y_pred))\n",
    "    \n",
    "    # Beta prior\n",
    "    X_bar = (Œ± .- X_min) ./ (X_max - X_min)\n",
    "    logprior = sum(\n",
    "        (alpha_b - 1) * log.(X_bar) + (beta_b - 1) * log.(1 .- X_bar)\n",
    "        .+ loggamma(alpha_b + beta_b) \n",
    "        .- loggamma(alpha_b)\n",
    "        .- loggamma(beta_b)\n",
    "    )\n",
    "\n",
    "    insupport(X) = sum(X_bar .< 0) == 0\n",
    "    insupport(X) ?  (alpha * loglikelihood + logprior) : -Inf\n",
    "\n",
    "end\n",
    "\n",
    "lp = logpi(X_0, model, X_min, X_max, Y_target, sigma_hat, nu, alpha)\n",
    "println(\"Log_prob: \", lp)\n",
    "Flux.gradient(logpi, X_0, model, X_min, X_max, Y_target, sigma_hat, nu, alpha)[1]\n",
    "Flux.withgradient(logpi, X_0, model, X_min, X_max, Y_target, sigma_hat, nu, alpha)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dee4aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6942285259538075"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    Y_pred = 10 .^ model(X_0, true)\n",
    "    r = Y_pred .- Y_target\n",
    "    t = r ./ sigma_hat\n",
    "    mean(t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679bf1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "function logpii(Œ±, nn)\n",
    "    Y_pred = 10 .^ nn(Œ±, true)\n",
    "    println(mean(Y_pred))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b47b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logpii(X_0, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00833f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5e574af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "gradient(f, args...)\n",
       "\\end{verbatim}\n",
       "Returns a tuple containing \\texttt{‚àÇf/‚àÇx} for each argument \\texttt{x}, the derivative (for scalar \\texttt{x}) or the gradient.\n",
       "\n",
       "\\texttt{f(args...)} must be a real number, see \\href{@ref}{\\texttt{jacobian}} for array output.\n",
       "\n",
       "See also \\href{@ref}{\\texttt{withgradient}} to keep the value \\texttt{f(args...)}, and \\href{@ref}{\\texttt{pullback}} for value and back-propagator.\n",
       "\n",
       "\\begin{verbatim}\n",
       "julia> gradient(*, 2.0, 3.0, 5.0)\n",
       "(15.0, 10.0, 6.0)\n",
       "\n",
       "julia> gradient(x -> sum(abs2,x), [7.0, 11.0, 13.0])\n",
       "([14.0, 22.0, 26.0],)\n",
       "\n",
       "julia> gradient([7, 11], 0, 1) do x, y, d\n",
       "         p = size(x, d)\n",
       "         sum(x.^p .+ y)\n",
       "       end\n",
       "([14.0, 22.0], 2.0, nothing)\n",
       "\\end{verbatim}\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "gradient(() -> loss(), ps::Params) -> Grads\n",
       "\\end{verbatim}\n",
       "Gradient with implicit parameters. Takes a zero-argument function, and returns a dictionary-like container, whose keys are arrays \\texttt{x in ps}.\n",
       "\n",
       "See also \\href{@ref}{\\texttt{withgradient}} to keep the value \\texttt{loss()}.\n",
       "\n",
       "\\begin{verbatim}\n",
       "julia> x = [1 2 3; 4 5 6]; y = [7, 8]; z = [1, 10, 100];\n",
       "\n",
       "julia> g = gradient(Params([x, y])) do\n",
       "         sum(x .* y .* z')\n",
       "       end\n",
       "Grads(...)\n",
       "\n",
       "julia> g[x]\n",
       "2√ó3 Matrix{Float64}:\n",
       " 7.0  70.0  700.0\n",
       " 8.0  80.0  800.0\n",
       "\n",
       "julia> haskey(g, z)  # only x and y are parameters\n",
       "false\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "gradient(f, args...)\n",
       "```\n",
       "\n",
       "Returns a tuple containing `‚àÇf/‚àÇx` for each argument `x`, the derivative (for scalar `x`) or the gradient.\n",
       "\n",
       "`f(args...)` must be a real number, see [`jacobian`](@ref) for array output.\n",
       "\n",
       "See also [`withgradient`](@ref) to keep the value `f(args...)`, and [`pullback`](@ref) for value and back-propagator.\n",
       "\n",
       "```jldoctest; setup=:(using Zygote)\n",
       "julia> gradient(*, 2.0, 3.0, 5.0)\n",
       "(15.0, 10.0, 6.0)\n",
       "\n",
       "julia> gradient(x -> sum(abs2,x), [7.0, 11.0, 13.0])\n",
       "([14.0, 22.0, 26.0],)\n",
       "\n",
       "julia> gradient([7, 11], 0, 1) do x, y, d\n",
       "         p = size(x, d)\n",
       "         sum(x.^p .+ y)\n",
       "       end\n",
       "([14.0, 22.0], 2.0, nothing)\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "gradient(() -> loss(), ps::Params) -> Grads\n",
       "```\n",
       "\n",
       "Gradient with implicit parameters. Takes a zero-argument function, and returns a dictionary-like container, whose keys are arrays `x in ps`.\n",
       "\n",
       "See also [`withgradient`](@ref) to keep the value `loss()`.\n",
       "\n",
       "```jldoctest; setup=:(using Zygote)\n",
       "julia> x = [1 2 3; 4 5 6]; y = [7, 8]; z = [1, 10, 100];\n",
       "\n",
       "julia> g = gradient(Params([x, y])) do\n",
       "         sum(x .* y .* z')\n",
       "       end\n",
       "Grads(...)\n",
       "\n",
       "julia> g[x]\n",
       "2√ó3 Matrix{Float64}:\n",
       " 7.0  70.0  700.0\n",
       " 8.0  80.0  800.0\n",
       "\n",
       "julia> haskey(g, z)  # only x and y are parameters\n",
       "false\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  gradient(f, args...)\u001b[39m\n",
       "\n",
       "  Returns a tuple containing \u001b[36m‚àÇf/‚àÇx\u001b[39m for each argument \u001b[36mx\u001b[39m, the derivative (for\n",
       "  scalar \u001b[36mx\u001b[39m) or the gradient.\n",
       "\n",
       "  \u001b[36mf(args...)\u001b[39m must be a real number, see \u001b[36mjacobian\u001b[39m for array output.\n",
       "\n",
       "  See also \u001b[36mwithgradient\u001b[39m to keep the value \u001b[36mf(args...)\u001b[39m, and \u001b[36mpullback\u001b[39m for value\n",
       "  and back-propagator.\n",
       "\n",
       "\u001b[36m  julia> gradient(*, 2.0, 3.0, 5.0)\u001b[39m\n",
       "\u001b[36m  (15.0, 10.0, 6.0)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> gradient(x -> sum(abs2,x), [7.0, 11.0, 13.0])\u001b[39m\n",
       "\u001b[36m  ([14.0, 22.0, 26.0],)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> gradient([7, 11], 0, 1) do x, y, d\u001b[39m\n",
       "\u001b[36m           p = size(x, d)\u001b[39m\n",
       "\u001b[36m           sum(x.^p .+ y)\u001b[39m\n",
       "\u001b[36m         end\u001b[39m\n",
       "\u001b[36m  ([14.0, 22.0], 2.0, nothing)\u001b[39m\n",
       "\n",
       "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
       "\n",
       "\u001b[36m  gradient(() -> loss(), ps::Params) -> Grads\u001b[39m\n",
       "\n",
       "  Gradient with implicit parameters. Takes a zero-argument function, and\n",
       "  returns a dictionary-like container, whose keys are arrays \u001b[36mx in ps\u001b[39m.\n",
       "\n",
       "  See also \u001b[36mwithgradient\u001b[39m to keep the value \u001b[36mloss()\u001b[39m.\n",
       "\n",
       "\u001b[36m  julia> x = [1 2 3; 4 5 6]; y = [7, 8]; z = [1, 10, 100];\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> g = gradient(Params([x, y])) do\u001b[39m\n",
       "\u001b[36m           sum(x .* y .* z')\u001b[39m\n",
       "\u001b[36m         end\u001b[39m\n",
       "\u001b[36m  Grads(...)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> g[x]\u001b[39m\n",
       "\u001b[36m  2√ó3 Matrix{Float64}:\u001b[39m\n",
       "\u001b[36m   7.0  70.0  700.0\u001b[39m\n",
       "\u001b[36m   8.0  80.0  800.0\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> haskey(g, z)  # only x and y are parameters\u001b[39m\n",
       "\u001b[36m  false\u001b[39m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?Flux.gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c7de2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real(log(Complex(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "735a1e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mSampling: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100000-element StructArray(::Vector{Float64}, ::Vector{Float64}, ::Vector{Float64}) with eltype NamedTuple{(:Œº, :œÉ, :lp), Tuple{Float64, Float64, Float64}}:\n",
       " (Œº = 1.0, œÉ = 1.0, lp = -189.11523941639828)\n",
       " (Œº = 0.273728438246548, œÉ = 1.4132555425870523, lp = -153.54113798572345)\n",
       " (Œº = 0.1919442936011536, œÉ = 1.102784385401957, lp = -144.8341700440923)\n",
       " (Œº = 0.12489662055020483, œÉ = 1.0770692867552696, lp = -143.88909519634018)\n",
       " (Œº = 0.044343474516469736, œÉ = 1.0199874919854182, lp = -143.24457304491935)\n",
       " (Œº = 0.044343474516469736, œÉ = 1.0199874919854182, lp = -143.24457304491935)\n",
       " (Œº = 0.044343474516469736, œÉ = 1.0199874919854182, lp = -143.24457304491935)\n",
       " (Œº = 0.044343474516469736, œÉ = 1.0199874919854182, lp = -143.24457304491935)\n",
       " (Œº = 0.044343474516469736, œÉ = 1.0199874919854182, lp = -143.24457304491935)\n",
       " (Œº = 0.044343474516469736, œÉ = 1.0199874919854182, lp = -143.24457304491935)\n",
       " (Œº = 0.024122981905275776, œÉ = 0.9813923232044656, lp = -143.3638728955839)\n",
       " (Œº = 0.024122981905275776, œÉ = 0.9813923232044656, lp = -143.3638728955839)\n",
       " (Œº = 0.024122981905275776, œÉ = 0.9813923232044656, lp = -143.3638728955839)\n",
       " ‚ãÆ\n",
       " (Œº = -0.03117554081029945, œÉ = 1.0776899544970555, lp = -143.83450419915442)\n",
       " (Œº = 0.05625448722453537, œÉ = 1.1156982241615025, lp = -144.11378786384608)\n",
       " (Œº = 0.14448534160758292, œÉ = 1.0425866707649794, lp = -143.79868583521161)\n",
       " (Œº = 0.05895729761938376, œÉ = 1.0552620427782846, lp = -143.41112315685683)\n",
       " (Œº = 0.08502144405863804, œÉ = 1.0945636709742814, lp = -143.8784931060907)\n",
       " (Œº = 0.12862073926079887, œÉ = 0.9709254899797963, lp = -143.82538216355442)\n",
       " (Œº = 0.11090725701665662, œÉ = 1.0114187028531725, lp = -143.47070065723756)\n",
       " (Œº = 0.11090725701665662, œÉ = 1.0114187028531725, lp = -143.47070065723756)\n",
       " (Œº = 0.05835695129013542, œÉ = 0.9558878258808913, lp = -143.61141639489736)\n",
       " (Œº = 0.05835695129013542, œÉ = 0.9558878258808913, lp = -143.61141639489736)\n",
       " (Œº = 0.05835695129013542, œÉ = 0.9558878258808913, lp = -143.61141639489736)\n",
       " (Œº = 0.05835695129013542, œÉ = 0.9558878258808913, lp = -143.61141639489736)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the package.\n",
    "using AdvancedMH\n",
    "using Distributions\n",
    "using MCMCChains\n",
    "using ForwardDiff\n",
    "using StructArrays\n",
    "\n",
    "using LinearAlgebra\n",
    "\n",
    "# Generate a set of data from the posterior we want to estimate.\n",
    "data = rand(Normal(0, 1), 100)\n",
    "\n",
    "# Define the components of a basic model.\n",
    "insupport(Œ∏) = Œ∏[2] >= 0\n",
    "dist(Œ∏) = Normal(Œ∏[1], Œ∏[2])\n",
    "density(Œ∏) = insupport(Œ∏) ? sum(logpdf.(dist(Œ∏), data)) : -Inf\n",
    "\n",
    "# Construct a DensityModel.\n",
    "dmodel = DensityModel(density)\n",
    "\n",
    "# Set up the sampler with a multivariate Gaussian proposal.\n",
    "œÉ¬≤ = 0.01\n",
    "spl = MALA(x -> MvNormal((œÉ¬≤ / 2) .* x, œÉ¬≤ * I))\n",
    "\n",
    "# Sample from the posterior.\n",
    "chain = sample(dmodel, spl, 100000; init_params=ones(2), chain_type=StructArray, param_names=[\"Œº\", \"œÉ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b8e92728",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: the log density function does not support the LogDensityProblems.jl interface. Please implement the interface or provide a model of type `AbstractMCMC.AbstractModel`",
     "output_type": "error",
     "traceback": [
      "ArgumentError: the log density function does not support the LogDensityProblems.jl interface. Please implement the interface or provide a model of type `AbstractMCMC.AbstractModel`",
      "",
      "Stacktrace:",
      " [1] _model(logdensity::SampleBayesProblem)",
      "   @ AbstractMCMC ~/.julia/packages/AbstractMCMC/F9Hbk/src/logdensityproblems.jl:112",
      " [2] sample(rng::TaskLocalRNG, logdensity::SampleBayesProblem, sampler::MALA{RandomWalkProposal{false, var\"#6#7\"}}, N_or_isdone::Int64; kwargs::Base.Pairs{Symbol, Any, Tuple{Symbol, Symbol}, NamedTuple{(:init_params, :chain_type), Tuple{Matrix{Float64}, UnionAll}}})",
      "   @ AbstractMCMC ~/.julia/packages/AbstractMCMC/F9Hbk/src/logdensityproblems.jl:46",
      " [3] sample(model_or_logdensity::SampleBayesProblem, sampler::MALA{RandomWalkProposal{false, var\"#6#7\"}}, N_or_isdone::Int64; kwargs::Base.Pairs{Symbol, Any, Tuple{Symbol, Symbol}, NamedTuple{(:init_params, :chain_type), Tuple{Matrix{Float64}, UnionAll}}})",
      "   @ AbstractMCMC ~/.julia/packages/AbstractMCMC/F9Hbk/src/sample.jl:18",
      " [4] top-level scope",
      "   @ In[118]:3"
     ]
    }
   ],
   "source": [
    "using LogDensityProblemsAD\n",
    "#model_with_ad = LogDensityProblemsAD.ADgradient(Val(:ForwardDiff), ‚àáP)\n",
    "sample(logp, spl, 100000; init_params=X_0, chain_type=StructArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "32cb47a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zygote AD wrapper for TransformedLogDensity of dimension 8"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = as((Œ± = as(Array, asùïÄ, n_parameters),))\n",
    "P = TransformedLogDensity(trans, logp)\n",
    "‚àáP = ADgradient(:Zygote, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "139dc8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([1.0, 0.0, 4.0, 15.0, 20.0, 20.0, 17.0, 14.0, 8.0, 1.0], [-2.8570588615376273, -2.3144068535370845, -1.7717548455365422, -1.2291028375359996, -0.686450829535457, -0.1437988215349142, 0.3988531864656282, 0.9415051944661705, 1.4841572024667133, 2.026809210467256, 2.569461218467798], (PyObject <matplotlib.patches.Rectangle object at 0x28279fe50>, PyObject <matplotlib.patches.Rectangle object at 0x28279fca0>, PyObject <matplotlib.patches.Rectangle object at 0x2827c82b0>, PyObject <matplotlib.patches.Rectangle object at 0x2827c84f0>, PyObject <matplotlib.patches.Rectangle object at 0x2827c86d0>, PyObject <matplotlib.patches.Rectangle object at 0x2827c88b0>, PyObject <matplotlib.patches.Rectangle object at 0x2827c8a90>, PyObject <matplotlib.patches.Rectangle object at 0x2827c8c70>, PyObject <matplotlib.patches.Rectangle object at 0x2827c8e50>, PyObject <matplotlib.patches.Rectangle object at 0x2827c9030>))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "33f2924b",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: psample not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: psample not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[93]:1"
     ]
    }
   ],
   "source": [
    "chain = psample(model, RWMH(init_params), 100000, 4; param_names=[\"Œº\",\"œÉ\"], chain_type=Chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "73ec263e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 1.0\n",
       " 1.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_params=ones(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "75392b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.8/Project.toml`\n",
      " \u001b[90m [80f14c24] \u001b[39m\u001b[92m+ AbstractMCMC v4.4.0\u001b[39m\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"AbstractMCMC\")\n",
    "using AbstractMCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9fe7f36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mL\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1my\u001b[22m\u001b[0m\u001b[1mP\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mb\u001b[22m\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mA\u001b[22m\u001b[0m\u001b[1mD\u001b[22m \u001b[0m\u001b[1mL\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1my\u001b[22m\u001b[0m\u001b[1mP\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mb\u001b[22m\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "Automatic differentiation backends for LogDensityProblems.\n",
       "\n"
      ],
      "text/markdown": [
       "Automatic differentiation backends for LogDensityProblems.\n"
      ],
      "text/plain": [
       "  Automatic differentiation backends for LogDensityProblems."
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?LogDensityProblemsAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3086c155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mL\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1my\u001b[22m\u001b[0m\u001b[1mP\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mb\u001b[22m\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1ms\u001b[22m \u001b[0m\u001b[1mL\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1my\u001b[22m\u001b[0m\u001b[1mP\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mb\u001b[22m\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1ms\u001b[22mAD\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "A unified interface for log density problems, for\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item[1. ] defining mappings to a log density (eg Bayesian for inference),\n",
       "\n",
       "\n",
       "\\item[2. ] optionally obtaining a gradient using automatic differentiation,\n",
       "\n",
       "\n",
       "\\item[3. ] defining a common interface for working with such log densities and gradients (eg MCMC).\n",
       "\n",
       "\\end{itemize}\n",
       "These use cases utilize different parts of this package, make sure you read the documentation.\n",
       "\n"
      ],
      "text/markdown": [
       "A unified interface for log density problems, for\n",
       "\n",
       "1. defining mappings to a log density (eg Bayesian for inference),\n",
       "2. optionally obtaining a gradient using automatic differentiation,\n",
       "3. defining a common interface for working with such log densities and gradients (eg MCMC).\n",
       "\n",
       "These use cases utilize different parts of this package, make sure you read the documentation.\n"
      ],
      "text/plain": [
       "  A unified interface for log density problems, for\n",
       "\n",
       "    1. defining mappings to a log density (eg Bayesian for inference),\n",
       "\n",
       "    2. optionally obtaining a gradient using automatic differentiation,\n",
       "\n",
       "    3. defining a common interface for working with such log densities\n",
       "       and gradients (eg MCMC).\n",
       "\n",
       "  These use cases utilize different parts of this package, make sure you read\n",
       "  the documentation."
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?LogDensityProblems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "61f173f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8√ó1 Matrix{Float64}:\n",
       " 0.6483565433127019\n",
       " 0.647910676617902\n",
       " 0.6273077544435656\n",
       " 0.6478926462889346\n",
       " 0.6505437104220909\n",
       " 0.6353471420662554\n",
       " 0.6483217215407353\n",
       " 0.63814507171178"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b032f497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       "  2.5\n",
       "  3.0\n",
       " -1.0\n",
       "  3.0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [2.5, 3, -1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "935097d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logpi (generic function with 2 methods)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function logpi(Œ±, nn, X_min, X_max, Y_target, sigma_hat; nu=1, alpha=0.01, alpha_b=3, beta_b=3)\n",
    "    \n",
    "    Y_pred = 10 .^ nn(Œ±, true)\n",
    "    r = Y_pred .- Y_target\n",
    "    t = r ./ sigma_hat\n",
    "\n",
    "    # StudentT distribution\n",
    "    loglikelihood = sum(\n",
    "        loggamma((nu + 1) / 2)\n",
    "        - loggamma(nu / 2)\n",
    "        .- log.(sqrt.(pi * nu) .* sigma_hat)\n",
    "        .- (nu + 1) / 2.0 * log.(1 .+ 1.0 / nu .* t .^ 2)\n",
    "    )\n",
    "    # Beta prior\n",
    "    X_bar = (Œ± .- X_min) ./ (X_max - X_min)\n",
    "    logprior = sum(\n",
    "        (alpha_b - 1) * log.(X_bar) + (beta_b - 1) * log.(1 .- X_bar)\n",
    "        .+ loggamma(alpha_b + beta_b) \n",
    "        .- loggamma(alpha_b)\n",
    "        .- loggamma(beta_b)\n",
    "    )\n",
    "\n",
    "    insupport(X) = sum(X_bar .< 0) == 0\n",
    "    insupport(X) ?  (alpha * loglikelihood + logprior) : -Inf\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "40636f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "density (generic function with 1 method)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function bar(X, X_min, X_max)\n",
    "    (X .- X_min) ./ (X_max .- X_min)\n",
    "end\n",
    "\n",
    "insupport(X) = sum(bar(X, X_min, X_max) .< 0) == 0\n",
    "density(X) = insupport(X) ? logpi(X, model, X_min, X_max, Y_target, sigma_hat) : -Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "30b54025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1451.7018975352285"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logpi(X_0, model, X_min, X_max, Y_target, sigma_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2cc1f3f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching hessian(::typeof(logpi))\n\u001b[0mClosest candidates are:\n\u001b[0m  hessian(::Any, \u001b[91m::Any\u001b[39m) at ~/.julia/packages/Zygote/g2w9o/src/lib/grad.jl:62",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching hessian(::typeof(logpi))\n\u001b[0mClosest candidates are:\n\u001b[0m  hessian(::Any, \u001b[91m::Any\u001b[39m) at ~/.julia/packages/Zygote/g2w9o/src/lib/grad.jl:62",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[153]:5"
     ]
    }
   ],
   "source": [
    "# Construct a DensityModel.\n",
    "dmodel = DensityModel(density)\n",
    "\n",
    "# Set up the sampler with a multivariate Gaussian proposal.\n",
    "H = Flux.hessian(logpi)\n",
    "œÉ¬≤ = 1 / H\n",
    "spl = MALA(x -> MvNormal((œÉ¬≤ / 2) .* x, œÉ¬≤ * I))\n",
    "\n",
    "# Sample from the posterior.\n",
    "chain = sample(dmodel, spl, 100000; init_params=X_0, chain_type=StructArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e0d15477",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "45644beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "hessian(f, x)\n",
       "\\end{verbatim}\n",
       "Construct the Hessian \\texttt{‚àÇ¬≤f/‚àÇx¬≤}, where \\texttt{x} is a real number or an array, and \\texttt{f(x)} is a real number. When \\texttt{x} is an array, the result is a matrix \\texttt{H[i,j] = ‚àÇ¬≤f/‚àÇx[i]‚àÇx[j]}, using linear indexing \\texttt{x[i]} even if the argument is higher-dimensional.\n",
       "\n",
       "This uses forward over reverse, ForwardDiff over Zygote, calling \\texttt{hessian\\_dual(f, x)}. See \\href{@ref}{\\texttt{hessian\\_reverse}} for an all-Zygote alternative.\n",
       "\n",
       "See also \\href{@ref}{\\texttt{diaghessian}} to compute only the diagonal part.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> hessian(x -> x[1]*x[2], randn(2))\n",
       "2√ó2 Matrix{Float64}:\n",
       " 0.0  1.0\n",
       " 1.0  0.0\n",
       "\n",
       "julia> hessian(x -> sum(x.^3), [1 2; 3 4])  # uses linear indexing of x\n",
       "4√ó4 Matrix{Int64}:\n",
       " 6   0   0   0\n",
       " 0  18   0   0\n",
       " 0   0  12   0\n",
       " 0   0   0  24\n",
       "\n",
       "julia> hessian(sin, pi/2)\n",
       "-1.0\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "hessian(f, x)\n",
       "```\n",
       "\n",
       "Construct the Hessian `‚àÇ¬≤f/‚àÇx¬≤`, where `x` is a real number or an array, and `f(x)` is a real number. When `x` is an array, the result is a matrix `H[i,j] = ‚àÇ¬≤f/‚àÇx[i]‚àÇx[j]`, using linear indexing `x[i]` even if the argument is higher-dimensional.\n",
       "\n",
       "This uses forward over reverse, ForwardDiff over Zygote, calling `hessian_dual(f, x)`. See [`hessian_reverse`](@ref) for an all-Zygote alternative.\n",
       "\n",
       "See also [`diaghessian`](@ref) to compute only the diagonal part.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest; setup=:(using Zygote)\n",
       "julia> hessian(x -> x[1]*x[2], randn(2))\n",
       "2√ó2 Matrix{Float64}:\n",
       " 0.0  1.0\n",
       " 1.0  0.0\n",
       "\n",
       "julia> hessian(x -> sum(x.^3), [1 2; 3 4])  # uses linear indexing of x\n",
       "4√ó4 Matrix{Int64}:\n",
       " 6   0   0   0\n",
       " 0  18   0   0\n",
       " 0   0  12   0\n",
       " 0   0   0  24\n",
       "\n",
       "julia> hessian(sin, pi/2)\n",
       "-1.0\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  hessian(f, x)\u001b[39m\n",
       "\n",
       "  Construct the Hessian \u001b[36m‚àÇ¬≤f/‚àÇx¬≤\u001b[39m, where \u001b[36mx\u001b[39m is a real number or an array, and\n",
       "  \u001b[36mf(x)\u001b[39m is a real number. When \u001b[36mx\u001b[39m is an array, the result is a matrix \u001b[36mH[i,j] =\n",
       "  ‚àÇ¬≤f/‚àÇx[i]‚àÇx[j]\u001b[39m, using linear indexing \u001b[36mx[i]\u001b[39m even if the argument is\n",
       "  higher-dimensional.\n",
       "\n",
       "  This uses forward over reverse, ForwardDiff over Zygote, calling\n",
       "  \u001b[36mhessian_dual(f, x)\u001b[39m. See \u001b[36mhessian_reverse\u001b[39m for an all-Zygote alternative.\n",
       "\n",
       "  See also \u001b[36mdiaghessian\u001b[39m to compute only the diagonal part.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ‚â°‚â°‚â°‚â°‚â°‚â°‚â°‚â°‚â°‚â°\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> hessian(x -> x[1]*x[2], randn(2))\u001b[39m\n",
       "\u001b[36m  2√ó2 Matrix{Float64}:\u001b[39m\n",
       "\u001b[36m   0.0  1.0\u001b[39m\n",
       "\u001b[36m   1.0  0.0\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> hessian(x -> sum(x.^3), [1 2; 3 4])  # uses linear indexing of x\u001b[39m\n",
       "\u001b[36m  4√ó4 Matrix{Int64}:\u001b[39m\n",
       "\u001b[36m   6   0   0   0\u001b[39m\n",
       "\u001b[36m   0  18   0   0\u001b[39m\n",
       "\u001b[36m   0   0  12   0\u001b[39m\n",
       "\u001b[36m   0   0   0  24\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> hessian(sin, pi/2)\u001b[39m\n",
       "\u001b[36m  -1.0\u001b[39m"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?Flux.hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47bfef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
