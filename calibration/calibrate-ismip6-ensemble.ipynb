{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f14f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "from urllib.request import HTTPError\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from scipy.interpolate import interp1d\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from functools import reduce\n",
    "from matplotlib import colors\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "from pismemulator.utils import load_imbie, load_imbie_csv\n",
    "\n",
    "secpera = 3.15569259747e7\n",
    "hist_start = 2008\n",
    "hist_end = 2014\n",
    "proj_start = 2015\n",
    "proj_end = 2100\n",
    "proj_time = np.arange(proj_start, proj_end + 1)\n",
    "\n",
    "rcps = [26, 45, 85]\n",
    "rcpss = [26, 45, 85, \"Union\"]\n",
    "rcp_col_dict = {26: \"#003466\", 45: \"#5492CD\", 85: \"#990002\"}\n",
    "rcp_shade_col_dict = {26: \"#4393C3\", 45: \"#92C5DE\", 85: \"#F4A582\"}\n",
    "rcp_dict = {26: \"RCP 2.6\", 45: \"RCP 4.5\", 85: \"RCP 8.5\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8926c78c",
   "metadata": {},
   "source": [
    "# Load ISMIP6 -- Normalization to year 2008 (hack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c0b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ismip6_gis(remove_ctrl=True):\n",
    "    outpath = \".\"\n",
    "    v_dir = \"v7_CMIP5_pub\"\n",
    "    url = f\"https://zenodo.org/record/3939037/files/{v_dir}.zip\"\n",
    "\n",
    "    if remove_ctrl:\n",
    "        ismip6_filename = \"ismip6_gis_ctrl_removed.csv.gz\"\n",
    "    else:\n",
    "        ismip6_filename = \"ismip6_gis_ctrl.csv.gz\"\n",
    "\n",
    "    if os.path.isfile(ismip6_filename):\n",
    "        df = pd.read_csv(ismip6_filename)\n",
    "    else:\n",
    "        print(f\"{ismip6_filename} not found locally. Downloading the ISMIP6 archive.\")\n",
    "        if not os.path.isfile(f\"{v_dir}.zip\"):\n",
    "            with urlopen(url) as zipresp:\n",
    "                with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "                    zfile.extractall(outpath)\n",
    "        print(\"   ...and converting to CSV\")\n",
    "        ismip6_gis_to_csv(v_dir, ismip6_filename, remove_ctrl)\n",
    "        df = pd.read_csv(ismip6_filename)\n",
    "    return df\n",
    "\n",
    "\n",
    "def ismip6_gis_to_csv(basedir, ismip6_filename, remove_ctrl):\n",
    "    # Now read model output from each of the ISMIP6 files. The information we\n",
    "    # need is in the file names, not the metadate so this is no fun.\n",
    "    # Approach is to read each dataset into a dataframe, then concatenate all\n",
    "    #   dataframes into one Arch dataframe that contains all model runs.\n",
    "    # Resulting dataframe consists of both historical and projected changes\n",
    "\n",
    "    ctrl_files = []\n",
    "    for path in Path(basedir).rglob(\"*_mm_*_ctrl_proj.nc\"):\n",
    "        ctrl_files.append(path)\n",
    "\n",
    "    hist_files = []\n",
    "    for path in Path(basedir).rglob(\"*_mm_*_historical.nc\"):\n",
    "        hist_files.append(path)\n",
    "\n",
    "    dfs = []\n",
    "    for path in Path(basedir).rglob(\"*_mm_cr_*.nc\"):\n",
    "        # Experiment\n",
    "        nc = NC(path)\n",
    "        exp_sle = nc.variables[\"sle\"][:]\n",
    "        # For comparison with GRACE, we use grounded ice mass, converted to Gt\n",
    "        exp_mass = nc.variables[\"limgr\"][:] / 1e12\n",
    "        exp_smb = nc.variables[\"smb\"][:] / 1e12 * secpera\n",
    "\n",
    "        f = path.name.split(f\"scalars_mm_cr_GIS_\")[-1].split(\".nc\")[0].split(\"_\")\n",
    "        # This is ugly, because of \"ITLS_PIK\"\n",
    "        if len(f) == 3:\n",
    "            group, model, exp = f\n",
    "        else:\n",
    "            g1, g2, model, exp = f\n",
    "            group = f\"{g1}_{g2}\"\n",
    "\n",
    "        if exp in [\"exp07\"]:\n",
    "            rcp = 26\n",
    "        else:\n",
    "            rcp = 85\n",
    "        # Find the coressponding CTRL Historical simulations\n",
    "        ctrl_file = [m for m in ctrl_files if (f\"_{group}_{model}_\" in m.name)][0]\n",
    "        hist_file = [m for m in hist_files if (f\"_{group}_{model}_\" in m.name)][0]\n",
    "\n",
    "        # The last entry of the historical and the first entry of the projection are the same\n",
    "\n",
    "        # Projection\n",
    "        nc_ctrl = NC(ctrl_file)\n",
    "        ctrl_sle = nc_ctrl.variables[\"sle\"][:] - nc_ctrl.variables[\"sle\"][0]\n",
    "        ctrl_mass = (nc_ctrl.variables[\"limgr\"][:] - nc_ctrl.variables[\"limgr\"][0]) / 1e12\n",
    "        ctrl_smb = nc_ctrl.variables[\"smb\"][:] / 1e12 * secpera\n",
    "\n",
    "        # Per email with Heiko on Nov. 13, 2020, stick with just the exp projections alone, without adding back the ctrl projections\n",
    "        \"\"\"\n",
    "        from Heiko:\n",
    "        \"The solution that we chose for ISMIP6 is therefore to remove the ctrl_proj from the projections\n",
    "        and communicate the numbers as such, i.e. SL contribution for additional forcing after 2014. \n",
    "        In our (strong) opinion, the results should never be communicated uncorrected.\"\n",
    "        \n",
    "        Also, point of reference from Goelzer et al., 2020, the ctrl simulations represent mass change\n",
    "        with the SMB fixed to 1960-1989 levels (no anomaly in SMB) and no change in ice sheet mask.\n",
    "        So ctrl after the historical spinup represents an abrupt return to an earlier SMB forcing in 2015.\n",
    "        \"\"\"\n",
    "\n",
    "        # Historical\n",
    "        nc_hist = NC(hist_file)\n",
    "        hist_sle = nc_hist.variables[\"sle\"][:-1] - nc_hist.variables[\"sle\"][-1]\n",
    "        hist_mass = (nc_hist.variables[\"limgr\"][:-1] - nc_hist.variables[\"limgr\"][-1]) / 1e12\n",
    "        hist_smb = nc_hist.variables[\"smb\"][:-1] / 1e12 * secpera\n",
    "        if remove_ctrl:\n",
    "            proj_sle = exp_sle\n",
    "            proj_mass = exp_mass\n",
    "            proj_smb = exp_smb\n",
    "        else:\n",
    "            proj_sle = exp_sle + ctrl_sle\n",
    "            proj_mass = exp_mass + ctrl_mass\n",
    "            proj_smb = exp_smb + ctrl_smb\n",
    "\n",
    "        # Historical simulations start at different years since initialization was left\n",
    "        # up to the modelers\n",
    "        hist_time = -np.arange(len(hist_sle))[::-1] + hist_end\n",
    "\n",
    "        # Let's add the data to the main DataFrame\n",
    "        m_time = np.hstack((hist_time, proj_time))\n",
    "        m_sle = -np.hstack((hist_sle, proj_sle)) * 100\n",
    "        m_sle -= np.interp(2008, m_time, m_sle)\n",
    "        m_mass = np.hstack((hist_mass, proj_mass))\n",
    "        m_smb = np.cumsum(np.hstack((hist_smb, proj_smb)))\n",
    "        m_smb -= np.interp(2088, m_time, m_smb)\n",
    "        m_d = m_mass - m_smb\n",
    "        m_mass_rate = np.gradient(np.hstack((hist_mass, proj_mass)))\n",
    "        m_smb_rate = np.hstack((hist_smb, proj_smb))\n",
    "        m_d_rate = m_mass_rate - m_smb_rate\n",
    "        m_mass -= np.interp(2008, m_time, m_mass)\n",
    "\n",
    "        n = len(m_time)\n",
    "        dfs.append(\n",
    "            pd.DataFrame(\n",
    "                data=np.hstack(\n",
    "                    [\n",
    "                        m_time.reshape(-1, 1),\n",
    "                        m_sle.reshape(-1, 1),\n",
    "                        m_mass.reshape(-1, 1),\n",
    "                        m_smb.reshape(-1, 1),\n",
    "                        m_d.reshape(-1, 1),\n",
    "                        m_mass_rate.reshape(-1, 1),\n",
    "                        m_smb_rate.reshape(-1, 1),\n",
    "                        m_d_rate.reshape(-1, 1),\n",
    "                        np.repeat(group, n).reshape(-1, 1),\n",
    "                        np.repeat(model, n).reshape(-1, 1),\n",
    "                        np.repeat(exp, n).reshape(-1, 1),\n",
    "                        np.repeat(rcp, n).reshape(-1, 1),\n",
    "                    ]\n",
    "                ),\n",
    "                columns=[\n",
    "                    \"Year\",\n",
    "                    \"SLE (cm)\",\n",
    "                    \"Cumulative ice sheet mass change (Gt)\",\n",
    "                    \"Cumulative surface mass balance anomaly (Gt)\",\n",
    "                    \"Cumulative ice dynamics anomaly (Gt)\",\n",
    "                    \"Rate of ice sheet mass change (Gt/yr)\",\n",
    "                    \"Rate of surface mass balance anomaly (Gt/yr)\",\n",
    "                    \"Rate of ice dynamics anomaly (Gt/yr)\",\n",
    "                    \"Group\",\n",
    "                    \"Model\",\n",
    "                    \"Exp\",\n",
    "                    \"RCP\",\n",
    "                ],\n",
    "            )\n",
    "        )\n",
    "        # End of working with each model run individually (the path for-loop)\n",
    "\n",
    "    # Concatenate all DataFrames and convert object types\n",
    "    df = pd.concat(dfs)\n",
    "    df = df.astype(\n",
    "        {\n",
    "            \"Year\": float,\n",
    "            \"SLE (cm)\": float,\n",
    "            \"Cumulative ice sheet mass change (Gt)\": float,\n",
    "            \"Cumulative surface mass balance anomaly (Gt)\": float,\n",
    "            \"Cumulative ice dynamics anomaly (Gt)\": float,\n",
    "            \"Rate of ice sheet mass change (Gt/yr)\": float,\n",
    "            \"Rate of surface mass balance anomaly (Gt/yr)\": float,\n",
    "            \"Rate of ice dynamics anomaly (Gt/yr)\": float,\n",
    "            \"Model\": str,\n",
    "            \"Exp\": str,\n",
    "            \"RCP\": str,\n",
    "        }\n",
    "    )\n",
    "    df.to_csv(ismip6_filename, compression=\"gzip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a44dc5",
   "metadata": {},
   "source": [
    "# Plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a20082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_posterior_sle_pdfs(\n",
    "    out_filename,\n",
    "    df,\n",
    "    observed=None,\n",
    "    rcps=[26, 45, 85],\n",
    "    ensembles=[\"AS19\", \"Flow Calib.\", \"Flow+Mass Calib.\"],\n",
    "    years=[2020, 2100],\n",
    "    ylim=None,\n",
    "):\n",
    "\n",
    "    n_rcps = len(rcps)\n",
    "    legend_rcp = 85\n",
    "    alphas = [0.4, 0.7, 1.0]\n",
    "    m_alphas = alphas[: len(ensembles)]\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        n_rcps * 2,\n",
    "        2,\n",
    "        sharex=\"col\",\n",
    "        figsize=[5.8, 4.2],\n",
    "        gridspec_kw=dict(height_ratios=[0.30 * len(ensembles), 4] * n_rcps),\n",
    "    )\n",
    "    fig.subplots_adjust(hspace=0.0, wspace=0)\n",
    "    for k, rcp in enumerate(rcps):\n",
    "        for y, year in enumerate(years):\n",
    "            y_df = df[df[\"Year\"] == year]\n",
    "            q_df = make_quantile_df(y_df, quantiles=[0.05, 0.16, 0.5, 0.84, 0.95])\n",
    "\n",
    "            m_df = y_df[y_df[\"RCP\"] == rcp]\n",
    "            p_df = q_df[q_df[\"RCP\"] == rcp]\n",
    "\n",
    "            sns.kdeplot(\n",
    "                data=m_df,\n",
    "                x=\"SLE (cm)\",\n",
    "                hue=\"Ensemble\",\n",
    "                hue_order=ensembles,\n",
    "                common_norm=False,\n",
    "                common_grid=True,\n",
    "                multiple=\"layer\",\n",
    "                fill=True,\n",
    "                lw=0,\n",
    "                palette=[color_tint(rcp_col_dict[rcp], alpha) for alpha in m_alphas],\n",
    "                ax=axs[k * 2 + 1, y],\n",
    "            )\n",
    "\n",
    "            sns.kdeplot(\n",
    "                data=m_df,\n",
    "                x=\"SLE (cm)\",\n",
    "                hue=\"Ensemble\",\n",
    "                hue_order=ensembles,\n",
    "                common_norm=False,\n",
    "                common_grid=True,\n",
    "                multiple=\"layer\",\n",
    "                fill=False,\n",
    "                lw=0.8,\n",
    "                palette=[color_tint(rcp_col_dict[rcp], alpha) for alpha in m_alphas],\n",
    "                ax=axs[k * 2 + 1, y],\n",
    "            )\n",
    "\n",
    "            for e, ens in enumerate(ensembles):\n",
    "                s_df = p_df[p_df[\"Ensemble\"] == ens]\n",
    "                mk_df = y_df[y_df[\"Ensemble\"] == ens]\n",
    "\n",
    "                alpha = alphas[e]\n",
    "                m_color = color_tint(rcp_col_dict[rcp], alpha)\n",
    "                lw = 0.25\n",
    "\n",
    "                axs[(k * 2), y].vlines(\n",
    "                    s_df[[0.5]].values[0][0], e, e + 1, colors=\"k\", lw=1\n",
    "                )\n",
    "\n",
    "                rect1 = plt.Rectangle(\n",
    "                    (s_df[[0.05]].values[0][0], e + 0.4),\n",
    "                    s_df[[0.95]].values[0][0] - s_df[[0.05]].values[0][0],\n",
    "                    0.2,\n",
    "                    color=m_color,\n",
    "                    alpha=1,\n",
    "                    lw=0,\n",
    "                )\n",
    "                rect2 = plt.Rectangle(\n",
    "                    (s_df[[0.16]].values[0][0], e + 0.2),\n",
    "                    s_df[[0.84]].values[0][0] - s_df[[0.16]].values[0][0],\n",
    "                    0.6,\n",
    "                    color=m_color,\n",
    "                    alpha=1,\n",
    "                    lw=0,\n",
    "                )\n",
    "                rect3 = plt.Rectangle(\n",
    "                    (s_df[[0.05]].values[0][0], e + 0.4),\n",
    "                    s_df[[0.95]].values[0][0] - s_df[[0.05]].values[0][0],\n",
    "                    0.2,\n",
    "                    color=\"k\",\n",
    "                    alpha=1,\n",
    "                    fill=False,\n",
    "                    lw=lw,\n",
    "                )\n",
    "                rect4 = plt.Rectangle(\n",
    "                    (s_df[[0.16]].values[0][0], e + 0.2),\n",
    "                    s_df[[0.84]].values[0][0] - s_df[[0.16]].values[0][0],\n",
    "                    0.6,\n",
    "                    color=\"k\",\n",
    "                    alpha=1,\n",
    "                    fill=False,\n",
    "                    lw=lw,\n",
    "                )\n",
    "\n",
    "                axs[(k * 2), y].add_patch(rect1)\n",
    "                axs[(k * 2), y].add_patch(rect3)\n",
    "                axs[(k * 2), y].add_patch(rect2)\n",
    "                axs[(k * 2), y].add_patch(rect4)\n",
    "\n",
    "                axs[(k * 2), y].set_ylabel(None)\n",
    "                axs[(k * 2), y].axes.xaxis.set_visible(False)\n",
    "                axs[(k * 2), y].axes.yaxis.set_visible(False)\n",
    "                sns.despine(ax=axs[(k * 2), y], left=True, bottom=True)\n",
    "                sns.despine(ax=axs[(k * 2) + 1, y], top=True)\n",
    "\n",
    "                axs[(k * 2), y].set_ylim(0, len(ensembles))\n",
    "\n",
    "                if y > 0:\n",
    "                    axs[k * 2 + 1, y].set_ylabel(None)\n",
    "\n",
    "                axs[k, y].legend().remove()\n",
    "                axs[k * 2 + 1, y].legend().remove()\n",
    "\n",
    "                axs[0, y].set_title(f\"Year {year}\")\n",
    "                if ylim is not None:\n",
    "                    axs[(k * 2) + 1, y].set_ylim(ylim)\n",
    "\n",
    "                if (k == 0) and (e == 0) and (y == 0):\n",
    "                    for pctl in [0.05, 0.16, 0.5, 0.84, 0.95]:\n",
    "                        axs[0, 0].text(\n",
    "                            s_df[[pctl]].values[0][0],\n",
    "                            -1.5,\n",
    "                            int(pctl * 100),\n",
    "                            ha=\"center\",\n",
    "                            fontsize=5,\n",
    "                        )\n",
    "\n",
    "        if observed is not None:\n",
    "            obs = observed[\n",
    "                (observed[\"Year\"] >= years[0]) & (observed[\"Year\"] < years[0] + 1)\n",
    "            ]\n",
    "            obs_mean = obs[\"SLE (cm)\"].mean()\n",
    "            obs_std = obs[\"SLE uncertainty (cm)\"].mean()\n",
    "            axs[(k * 2) + 1, 0].axvline(obs_mean, c=\"k\", lw=0.5)\n",
    "            axs[(k * 2) + 1, 0].axvline(\n",
    "                obs_mean - 2 * obs_std, c=\"k\", lw=0.5, ls=\"dotted\"\n",
    "            )\n",
    "            axs[(k * 2) + 1, 0].axvline(\n",
    "                obs_mean + 2 * obs_std, c=\"k\", lw=0.5, ls=\"dotted\"\n",
    "            )\n",
    "\n",
    "    for k, rcp in enumerate(rcps):\n",
    "        axs[k * 2, 0].text(\n",
    "            -0.125,\n",
    "            0.2,\n",
    "            rcp_dict[rcp],\n",
    "            transform=axs[k * 2, 0].transAxes,\n",
    "            fontsize=7,\n",
    "            fontweight=\"bold\",\n",
    "            horizontalalignment=\"left\",\n",
    "        )\n",
    "\n",
    "    l_as19 = Patch(\n",
    "        facecolor=color_tint(rcp_col_dict[legend_rcp], alphas[0]),\n",
    "        edgecolor=\"0.0\",\n",
    "        linewidth=0.25,\n",
    "        label=\"Prior (AS19)\",\n",
    "    )\n",
    "    l_ismip6 = Patch(\n",
    "        facecolor=color_tint(rcp_col_dict[legend_rcp], alphas[0]),\n",
    "        edgecolor=\"0.0\",\n",
    "        linewidth=0.25,\n",
    "        label=\"Prior (ISMIP6)\",\n",
    "    )\n",
    "    l_flow = Patch(\n",
    "        facecolor=color_tint(rcp_col_dict[legend_rcp], alphas[1]),\n",
    "        edgecolor=\"0.0\",\n",
    "        linewidth=0.25,\n",
    "        label=\"Posterior (Flow Calib.)\",\n",
    "    )\n",
    "    l_mass = Patch(\n",
    "        facecolor=color_tint(rcp_col_dict[legend_rcp], alphas[1]),\n",
    "        edgecolor=\"0.0\",\n",
    "        linewidth=0.25,\n",
    "        label=\"Posterior (Mass Calib.)\",\n",
    "    )\n",
    "    l_calib = Patch(\n",
    "        facecolor=color_tint(rcp_col_dict[legend_rcp], alphas[2]),\n",
    "        edgecolor=\"0.0\",\n",
    "        linewidth=0.25,\n",
    "        label=\"Posterior (Flow+Mass Calib.)\",\n",
    "    )\n",
    "    l_ismip6_calib = Patch(\n",
    "        facecolor=color_tint(rcp_col_dict[legend_rcp], alphas[2]),\n",
    "        edgecolor=\"0.0\",\n",
    "        linewidth=0.25,\n",
    "        label=\"Posterior (ISMIP6 Calib.)\",\n",
    "    )\n",
    "\n",
    "    ens_label_dict = {\n",
    "        \"AS19\": l_as19,\n",
    "        \"Flow Calib.\": l_flow,\n",
    "        \"Mass Calib.\": l_mass,\n",
    "        \"Flow+Mass Calib.\": l_calib,\n",
    "        \"ISMIP6\": l_ismip6,\n",
    "        \"ISMIP6 Calib.\": l_ismip6_calib,\n",
    "    }\n",
    "\n",
    "    legend_1 = axs[-1, 0].legend(\n",
    "        handles=[ens_label_dict[e] for e in ensembles],\n",
    "        loc=\"lower left\",\n",
    "        bbox_to_anchor=(0.4, 0.45, 0, 0),\n",
    "    )\n",
    "    legend_1.get_frame().set_linewidth(0.0)\n",
    "    legend_1.get_frame().set_alpha(0.0)\n",
    "    axs[-1, 0].add_artist(legend_1)\n",
    "\n",
    "    if observed is not None:\n",
    "        l_obs_mean = Line2D(\n",
    "            [], [], c=\"k\", lw=0.5, ls=\"solid\", label=\"Observed (IMBIE) mean\"\n",
    "        )\n",
    "        l_obs_std = Line2D(\n",
    "            [], [], c=\"k\", lw=0.5, ls=\"dotted\", label=\"Observed (IMBIE) $\\pm2-\\sigma$\"\n",
    "        )\n",
    "        legend_2 = axs[-3, 0].legend(\n",
    "            handles=[l_obs_mean, l_obs_std],\n",
    "            loc=\"lower left\",\n",
    "            bbox_to_anchor=(0.4, 0.45, 0, 0),\n",
    "        )\n",
    "        legend_2.get_frame().set_linewidth(0.0)\n",
    "        legend_2.get_frame().set_alpha(0.0)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_filename)\n",
    "    plt.close(fig)\n",
    "\n",
    "def color_tint(m_color, alpha):\n",
    "    m_color = list(colors.to_rgba(m_color))\n",
    "    m_color[-1] = alpha\n",
    "    m_color = np.array(m_color) * 255\n",
    "    return rgba2rgb(m_color) / 255\n",
    "\n",
    "\n",
    "def rgba2rgb(rgba, background=(255, 255, 255)):\n",
    "\n",
    "    rgb = np.zeros((3), dtype=\"float32\")\n",
    "    r, g, b, a = rgba[0], rgba[1], rgba[2], rgba[3]\n",
    "\n",
    "    a = np.asarray(a, dtype=\"float32\") / 255.0\n",
    "\n",
    "    R, G, B = background\n",
    "\n",
    "    rgb[0] = r * a + (1.0 - a) * R\n",
    "    rgb[1] = g * a + (1.0 - a) * G\n",
    "    rgb[2] = b * a + (1.0 - a) * B\n",
    "\n",
    "    return np.asarray(rgb, dtype=\"uint8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb8018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_ensemble_by_data(\n",
    "    observed,\n",
    "    simulated,\n",
    "    rcps=[26, 45, 85],\n",
    "    calibration_start=2010,\n",
    "    calibration_end=2020,\n",
    "    fudge_factor=3,\n",
    "    n_samples=500,\n",
    "    verbose=False,\n",
    "    m_var=\"Mass (Gt)\",\n",
    "    m_var_std=\"Mass uncertainty (Gt)\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Resampling algorithm by Douglas C. Brinkerhoff\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    observed : pandas.DataFrame\n",
    "        A dataframe with observations\n",
    "    simulated : pandas.DataFrame\n",
    "        A dataframe with simulations\n",
    "    calibration_start : float\n",
    "        Start year for calibration\n",
    "    calibration_end : float\n",
    "        End year for calibration\n",
    "    fudge_factor : float\n",
    "        Tolerance for simulations. Calculated as fudge_factor * standard deviation of observed\n",
    "    n_samples : int\n",
    "        Number of samples to draw.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    observed_calib_time = (observed[\"Year\"] >= calibration_start) & (\n",
    "        observed[\"Year\"] <= calibration_end\n",
    "    )\n",
    "    observed_calib_period = observed[observed_calib_time]\n",
    "    # print(observed_calib_period)\n",
    "    # Should we interpolate the simulations at observed time?\n",
    "    observed_interp_mean = interp1d(\n",
    "        observed_calib_period[\"Year\"], observed_calib_period[m_var]\n",
    "    )\n",
    "    observed_interp_std = interp1d(\n",
    "        observed_calib_period[\"Year\"], observed_calib_period[m_var_std]\n",
    "    )\n",
    "\n",
    "    simulated_calib_time = (simulated[\"Year\"] >= calibration_start) & (\n",
    "        simulated[\"Year\"] <= calibration_end\n",
    "    )\n",
    "    simulated_calib_period = simulated[simulated_calib_time]\n",
    "\n",
    "    resampled_list = []\n",
    "    for rcp in rcps:\n",
    "        log_likes = []\n",
    "        experiments = np.unique(simulated_calib_period[\"Experiment\"])\n",
    "        evals = []\n",
    "        for i in experiments:\n",
    "            exp_ = simulated_calib_period[\n",
    "                (simulated_calib_period[\"Experiment\"] == i)\n",
    "                & (simulated_calib_period[\"RCP\"] == rcp)\n",
    "            ]\n",
    "            log_like = 0.0\n",
    "            for year, exp_mass in zip(exp_[\"Year\"], exp_[m_var]):\n",
    "                try:\n",
    "                    observed_mass = observed_interp_mean(year)\n",
    "                    observed_std = observed_interp_std(year) * fudge_factor\n",
    "                    log_like -= 0.5 * (\n",
    "                        (exp_mass - observed_mass) / observed_std\n",
    "                    ) ** 2 + 0.5 * np.log(2 * np.pi * observed_std**2)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            if log_like != 0:\n",
    "                evals.append(i)\n",
    "                log_likes.append(log_like)\n",
    "                if verbose:\n",
    "                    print(f\"{rcp_dict[rcp]}, Experiment {i:.0f}: {log_like:.2f}\")\n",
    "        experiments = np.array(evals)\n",
    "        w = np.array(log_likes)\n",
    "        w -= w.mean()\n",
    "        weights = np.exp(w)\n",
    "        weights /= weights.sum()\n",
    "        resampled_experiments = np.random.choice(experiments, n_samples, p=weights)\n",
    "        new_frame = []\n",
    "        for i in resampled_experiments:\n",
    "            new_frame.append(\n",
    "                simulated[(simulated[\"Experiment\"] == i) & (simulated[\"RCP\"] == rcp)]\n",
    "            )\n",
    "        simulated_resampled = pd.concat(new_frame)\n",
    "        resampled_list.append(simulated_resampled)\n",
    "\n",
    "    simulated_resampled = pd.concat(resampled_list)\n",
    "\n",
    "    return simulated_resampled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5bbf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_quantile_df(df, quantiles):\n",
    "    q_dfs = [\n",
    "        df.groupby(by=[\"RCP\", \"Ensemble\"])[\"SLE (cm)\"]\n",
    "        .quantile(q)\n",
    "        .reset_index()\n",
    "        .rename(columns={\"SLE (cm)\": q})\n",
    "        for q in quantiles\n",
    "    ]\n",
    "    q_df = reduce(lambda df1, df2: pd.merge(df1, df2, on=[\"RCP\", \"Ensemble\"]), q_dfs)\n",
    "    a_dfs = [\n",
    "        df.groupby(by=[\"Ensemble\"])[\"SLE (cm)\"]\n",
    "        .quantile(q)\n",
    "        .reset_index()\n",
    "        .rename(columns={\"SLE (cm)\": q})\n",
    "        for q in quantiles\n",
    "    ]\n",
    "    a_df = reduce(lambda df1, df2: pd.merge(df1, df2, on=[\"Ensemble\"]), a_dfs)\n",
    "    a_df[\"RCP\"] = \"Union\"\n",
    "    return pd.concat([q_df, a_df]).round(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33af7ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = load_imbie_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee87ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_ismip6_gis(remove_ctrl=False)\n",
    "ismip6 = pd.read_csv(\"ismip6_gis_ctrl.csv.gz\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ismip6[\"Experiment\"] = ismip6[\"Group\"] + ismip6[\"Model\"] + ismip6[\"Exp\"]\n",
    "ismip6[\"Mass (Gt)\"] = ismip6[\"Cumulative ice sheet mass change (Gt)\"]\n",
    "ismip6[\"Ensemble\"] = \"ISMIP6\"\n",
    "ismip6_calib = resample_ensemble_by_data(observed, ismip6, rcps=[26, 85], calibration_end=2015, fudge_factor=3)\n",
    "ismip6_calib[\"Ensemble\"] = \"ISMIP6 Calib.\"\n",
    "ismip6_df = pd.concat([ismip6, ismip6_calib])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d9ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_posterior_sle_pdfs(\"ismip6_calibrated.pdf\", ismip6_df.reset_index(), observed, rcps=[26, 85], years=[2015, 2100], ensembles=[\"ISMIP6\", \"ISMIP6 Calib.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43fd9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_median_palette_dict = {\n",
    "    \"AS19\": \"0.6\",\n",
    "    \"Flow Calib.\": \"0.3\",\n",
    "    \"Mass Calib.\": \"#e6550d\",\n",
    "    \"Flow+Mass Calib.\": \"0.0\",\n",
    "    \"ISMIP6\": \"0.6\",\n",
    "    \"ISMIP6 Calib.\": \"0.0\",\n",
    "}\n",
    "palette_dict = {\n",
    "    \"AS19\": \"#c51b8a\",\n",
    "    \"Flow Calib.\": \"#31a354\",\n",
    "    \"Mass Calib.\": \"#2c7fb8\",\n",
    "    \"Flow+Mass Calib.\": \"0.0\",\n",
    "    \"ISMIP6\": \"#c51b8a\",\n",
    "    \"ISMIP6 Calib.\": \"0.0\",\n",
    "}\n",
    "ts_fill_palette_dict = {\n",
    "    \"AS19\": \"0.80\",\n",
    "    \"Flow Calib.\": \"0.70\",\n",
    "    \"Mass Calib.\": \"#fee6ce\",\n",
    "    \"Flow+Mass Calib.\": \"0.60\",\n",
    "    \"ISMIP6\": \"0.80\",\n",
    "    \"ISMIP6 Calib.\": \"0.60\",\n",
    "}\n",
    "\n",
    "def plot_historical(\n",
    "    out_filename,\n",
    "    simulated=None,\n",
    "    observed=None,\n",
    "    ensembles=[\"AS19\", \"Flow+Mass Calib.\"],\n",
    "    quantiles=[0.05, 0.95],\n",
    "    sigma=2,\n",
    "    simulated_ctrl=None,\n",
    "    xlims=[2008, 2021],\n",
    "    ylims=[-10000, 500],\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot historical simulations and observations\n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure(num=\"historical\", clear=True, figsize=[4.6, 1.6])\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    if simulated is not None:\n",
    "        for r, ens in enumerate(ensembles):\n",
    "            legend_handles = []\n",
    "            sim = simulated[simulated[\"Ensemble\"] == ens]\n",
    "            g = sim.groupby(by=\"Year\")[\"Mass (Gt)\"]\n",
    "            sim_median = g.quantile(0.50)\n",
    "            sim_low = g.quantile(quantiles[0])\n",
    "            sim_high = g.quantile(quantiles[-1])\n",
    "\n",
    "            l_es_median = ax.plot(\n",
    "                sim_median.index,\n",
    "                sim_median,\n",
    "                color=ts_median_palette_dict[ens],\n",
    "                linewidth=signal_lw,\n",
    "                label=\"Median\",\n",
    "            )\n",
    "            legend_handles.append(l_es_median[0])\n",
    "            ci = ax.fill_between(\n",
    "                sim_median.index,\n",
    "                sim_low,\n",
    "                sim_high,\n",
    "                color=ts_fill_palette_dict[ens],\n",
    "                alpha=0.75,\n",
    "                linewidth=0.0,\n",
    "                zorder=-11,\n",
    "                label=f\"{quantiles[0]*100:.0f}-{quantiles[-1]*100:.0f}%\",\n",
    "            )\n",
    "            legend_handles.append(ci)\n",
    "\n",
    "            legend = ax.legend(\n",
    "                handles=legend_handles,\n",
    "                loc=\"lower left\",\n",
    "                ncol=1,\n",
    "                title=ens,\n",
    "                bbox_to_anchor=(r * 0.2, 0.01),\n",
    "            )\n",
    "            legend.get_frame().set_linewidth(0.0)\n",
    "            legend.get_frame().set_alpha(0.0)\n",
    "            ax.add_artist(legend)\n",
    "\n",
    "    if observed is not None:\n",
    "        legend_handles = []\n",
    "        obs_line = ax.plot(\n",
    "            observed[\"Year\"],\n",
    "            observed[\"Mass (Gt)\"],\n",
    "            \"-\",\n",
    "            color=obs_signal_color,\n",
    "            linewidth=signal_lw,\n",
    "            label=\"Mean\",\n",
    "            zorder=20,\n",
    "        )\n",
    "        legend_handles.append(obs_line[0])\n",
    "        obs_ci = ax.fill_between(\n",
    "            observed[\"Year\"],\n",
    "            observed[\"Mass (Gt)\"] - sigma * observed[\"Mass uncertainty (Gt)\"],\n",
    "            observed[\"Mass (Gt)\"] + sigma * observed[\"Mass uncertainty (Gt)\"],\n",
    "            color=obs_sigma_color,\n",
    "            alpha=0.75,\n",
    "            linewidth=0,\n",
    "            zorder=5,\n",
    "            label=f\"{sigma}-$\\sigma$\",\n",
    "        )\n",
    "        legend_handles.append(obs_ci)\n",
    "\n",
    "        if simulated is None:\n",
    "            r = 0\n",
    "        legend = ax.legend(\n",
    "            handles=legend_handles,\n",
    "            loc=\"lower left\",\n",
    "            ncol=1,\n",
    "            title=\"Observed (IMBIE)\",\n",
    "            bbox_to_anchor=((r + 1.0) * 0.2, 0.01),\n",
    "        )\n",
    "        legend.get_frame().set_linewidth(0.0)\n",
    "        legend.get_frame().set_alpha(0.0)\n",
    "        ax.add_artist(legend)\n",
    "\n",
    "    ax.axhline(0, color=\"k\", linestyle=\"dotted\", linewidth=0.6)\n",
    "\n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_ylabel(f\"Cumulative mass change\\nsince {proj_start} (Gt)\")\n",
    "\n",
    "    ax.set_xlim(xlims)\n",
    "    ax.set_ylim(ylims)\n",
    "    ax_sle = ax.twinx()\n",
    "    ax_sle.set_ylabel(f\"Contribution to sea-level \\nsince {proj_start} (cm SLE)\")\n",
    "    ax_sle.set_ylim(-np.array(ylims) * gt2cmSLE)\n",
    "\n",
    "    fig.savefig(out_filename, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49107f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_lw = 1.0\n",
    "obs_signal_color = \"#6a51a3\"\n",
    "obs_sigma_color = \"#cbc9e2\"\n",
    "gt2cmSLE = 1.0 / 362.5 / 10.0\n",
    "\n",
    "plot_historical(\"historical-ismip6.pdf\", simulated=ismip6_df, observed=observed, ensembles=[\"ISMIP6\", \"ISMIP6 Calib.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e74541",
   "metadata": {},
   "outputs": [],
   "source": [
    "!open *ismip*pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30162699",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
